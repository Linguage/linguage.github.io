<!doctype html><html lang=zh-CN class=skin-gold><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>「Scripts」Module 3: Tool Use • Linguista</title><script>(function(){try{var s="theme",e=window.localStorage?localStorage.getItem(s):null,n=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,t=e==="dark"||e==="light"?e:n?"dark":null;t?document.documentElement.dataset.theme=t:delete document.documentElement.dataset.theme}catch{}})()</script><link rel=preconnect href=https://fonts.loli.net><link rel=preconnect href=https://gstatic.loli.net crossorigin><link href="https://fonts.loli.net/css2?family=Inter:wght@400;500;600&family=Lora:wght@500;600&family=Josefin+Sans:wght@400;600;700&display=swap" rel=stylesheet><link rel=stylesheet href="/css/amp.css?v=20260121-05"><link rel=stylesheet href="/css/mobile-toc-fix.css?v=20260121-05"><style>:root{--bg:#ffffff;--surface:#ffffff;--text:#2b2b2b;--muted:#6c757d;--border:#e9ecef;--brand-text:var(--text, #2b2b2b);--brand-muted:var(--muted, #6c757d);--brand-surface:var(--surface, #ffffff);--brand-border:var(--border, #e9ecef);--brand-accent:var(--accent, #2E7D6B);--brand-accent-soft:rgba(46, 125, 107, 0.12);--brand-accent-soft-strong:rgba(46, 125, 107, 0.18);--gold:#e6db74;--gold-soft:rgba(230, 219, 116, 0.12);--gold-soft-strong:rgba(230, 219, 116, 0.2);--hero-pattern-color:#000000;--hero-pattern-opacity:0.2}html[data-theme=dark]{--bg:#000000;--surface:#111111;--text:#ffffff;--muted:#a1a1aa;--border:#333333;--hero-pattern-color:#ffffff;--hero-pattern-opacity:0.3}.container h1:first-of-type{color:var(--brand-accent)}.hero .hero-title{color:inherit!important}.hero .hero-title .hero-greeting{color:var(--brand-text,#111)!important}.hero .hero-title .hero-brand{color:var(--brand-accent,#0e6a85)!important}html[data-theme=dark] .hero .hero-title .hero-greeting{color:#f8f8f2}html[data-theme=dark] .hero .hero-title .hero-brand{color:var(--gold)}html[data-theme=dark] .container h1{color:#f8f8f2}html[data-theme=dark] .container,html[data-theme=dark] .hero{--brand-accent:var(--gold)}:is(.container,.prose) h2{position:relative;display:flex;flex-direction:column;align-items:center;justify-content:center;width:100%;margin:2.6rem auto 2.4rem;padding:0 0 .9rem;font-weight:600;text-align:center;color:var(--heading-h2-color,#14532d)}:is(.container,.prose) h2 .anchor-link{position:absolute;top:50%;right:clamp(16px,3vw,48px);transform:translateY(-50%);font-size:1.3rem;color:color-mix(in srgb,var(--heading-h2-color,#14532d) 70%,transparent 30%);text-decoration:none;opacity:0;transition:opacity .2s ease,color .2s ease}:is(.container,.prose) h2:hover .anchor-link,:is(.container,.prose) h2 .anchor-link:focus{opacity:1;color:var(--heading-h2-color,#14532d)}:is(.container,.prose) h2::after{content:"";position:absolute;left:50%;bottom:0;width:clamp(220px,38vw,520px);height:3px;transform:translateX(-50%);background:linear-gradient(90deg,color-mix(in srgb,var(--heading-h2-color,#14532d) 0%,transparent 100%) 0%,color-mix(in srgb,var(--heading-h2-color,#14532d) 22%,transparent 78%) 20%,color-mix(in srgb,var(--heading-h2-color,#14532d) 75%,transparent 25%) 50%,color-mix(in srgb,var(--heading-h2-color,#14532d) 22%,transparent 78%) 80%,color-mix(in srgb,var(--heading-h2-color,#14532d) 0%,transparent 100%) 100%);border-radius:999px}:is(.container,.prose) h2::before{content:"";position:absolute;left:50%;bottom:-8px;width:clamp(120px,28vw,360px);height:1px;transform:translateX(-50%);background:linear-gradient(90deg,color-mix(in srgb,var(--heading-h2-color,#14532d) 0%,transparent 100%) 0%,color-mix(in srgb,var(--heading-h2-color,#14532d) 35%,transparent 65%) 45%,color-mix(in srgb,var(--heading-h2-color,#14532d) 70%,transparent 30%) 50%,color-mix(in srgb,var(--heading-h2-color,#14532d) 35%,transparent 65%) 55%,color-mix(in srgb,var(--heading-h2-color,#14532d) 0%,transparent 100%) 100%);opacity:.85}:is(.container,.prose) h2 a{color:var(--brand-accent,#0e6a85)}:is(.container,.prose) h2 a:visited{color:var(--brand-accent-visited,#094c60)}html[data-theme=dark] :is(.container,.prose) h2{--heading-h2-color:rgba(230,219,116,1);color:var(--heading-h2-color)}html[data-theme=dark] .prose h2,html[data-theme=dark] .container h2{color:#e6db74}html[data-theme=dark] :is(.container,.prose) h2 a{color:var(--gold)}html[data-theme=dark] :is(.container,.prose) h2 a:visited{color:rgba(230,219,116,.85)}.container h3{border-left:4px solid var(--brand-accent);border-bottom:1px solid rgba(46,125,107,.25);padding-left:14px;padding-bottom:6px;margin-top:1.5rem;margin-bottom:.75rem;color:var(--brand-text)}.container h4{border-left:3px solid var(--brand-accent);border-bottom:1px solid rgba(46,125,107,.2);padding-left:12px;padding-bottom:4px;margin-top:1.25rem;margin-bottom:.5rem;color:var(--brand-text);font-weight:500}.container h5{border-left:2px solid var(--brand-accent);border-bottom:1px solid rgba(46,125,107,.15);padding-left:10px;padding-bottom:3px;margin-top:1rem;margin-bottom:.4rem;color:var(--brand-text);font-weight:500}.container h6{border-left:1px solid var(--brand-accent);border-bottom:1px solid rgba(46,125,107,.1);padding-left:8px;padding-bottom:2px;margin-top:.75rem;margin-bottom:.3rem;color:var(--brand-text);font-weight:500}.container blockquote{margin:30px 0;padding:20px 25px;border-left:4px solid var(--brand-muted);background-color:#f8f9fa;font-style:italic;border-radius:0 8px 8px 0}.container blockquote footer{margin-top:10px;font-size:.9em;color:var(--brand-muted)}.container .figure-caption,.container .caption,.container figure figcaption,.container .table-caption,.container table caption,.container .quarto-float-caption-top,.container .quarto-float-caption{text-align:left!important;caption-side:top!important;font-weight:500!important;margin-bottom:.75rem!important;margin-top:1rem!important;color:var(--brand-muted)!important;font-size:.9rem!important;line-height:1.4!important}.container table{border-collapse:collapse;width:100%;margin:1.2rem 0;font-size:.95rem}.container table th{background-color:#f8f9fa;font-weight:600;text-align:left;padding:12px 16px;border-bottom:2px solid var(--brand-border)}.container table td{text-align:left;padding:10px 16px;border-bottom:1px solid var(--brand-border);vertical-align:top}.container table tbody tr:nth-child(even){background-color:#f8f9fa}.container table tbody tr:hover{background-color:#f1f3f5}html[data-theme=dark] .container h2{border-color:rgba(230,219,116,.22);color:#f8f8f2}.container h2 a{color:var(--brand-accent,#0e6a85)}.container h2 a:visited{color:var(--brand-accent-visited,#094c60)}html[data-theme=dark] .container blockquote{background-color:rgba(230,219,116,8%);border-left-color:rgba(230,219,116,.6)}html[data-theme=dark] .docs-content .prose blockquote,html[data-theme=dark] .prose blockquote{background-color:rgba(230,219,116,8%);border-left-color:rgba(230,219,116,.6)}html[data-theme=dark] .container .figure-caption,html[data-theme=dark] .container .caption,html[data-theme=dark] .container figure figcaption,html[data-theme=dark] .container .table-caption,html[data-theme=dark] .container table caption,html[data-theme=dark] .container .quarto-float-caption-top,html[data-theme=dark] .container .quarto-float-caption{color:#c9ced6!important}html[data-theme=dark] .container table th{background-color:rgba(255,255,255,6%);border-bottom-color:rgba(230,219,116,.22)}html[data-theme=dark] .docs-content .prose table thead th,html[data-theme=dark] .prose table thead th{background-color:rgba(255,255,255,6%);border-bottom-color:rgba(230,219,116,.22)}html[data-theme=dark] .container table thead,html[data-theme=dark] .docs-content .prose table thead{background-color:rgba(255,255,255,4%)}html[data-theme=dark] .container table td{border-bottom-color:rgba(255,255,255,.12)}html[data-theme=dark] .container table tbody tr:nth-child(even){background-color:rgba(255,255,255,4%)}html[data-theme=dark] .docs-content .prose table tbody tr:nth-child(even),html[data-theme=dark] .prose table tbody tr:nth-child(even){background-color:rgba(255,255,255,4%)}html[data-theme=dark] .container table tbody tr:hover{background-color:rgba(255,255,255,8%)}html[data-theme=dark] .docs-content .prose table tbody tr:hover,html[data-theme=dark] .prose table tbody tr:hover{background-color:rgba(255,255,255,8%)}html[data-theme=dark] .container h1:first-of-type{color:var(--brand-color,var(--link-color,var(--gold)))}html[data-theme=dark] .container h3{border-left-color:var(--gold);border-bottom-color:rgba(230,219,116,.22);color:#f8f8f2}html[data-theme=dark] .container h4{border-left-color:var(--gold);border-bottom-color:rgba(230,219,116,.18);color:#f8f8f2}html[data-theme=dark] .container h5{border-left-color:var(--gold);border-bottom-color:rgba(230,219,116,.14);color:#f8f8f2}html[data-theme=dark] .container h6{border-left-color:var(--gold);border-bottom-color:rgba(230,219,116,.1);color:#f8f8f2}.prose a{color:var(--link-color,var(--brand-accent,#0e6a85))}.prose a:visited{color:var(--visited-color,var(--brand-accent-visited,#094c60))}html[data-theme=dark] .prose a{color:var(--gold)}html[data-theme=dark] .prose a:visited{color:rgba(230,219,116,.85)}html[data-theme=dark] .callout{background:rgba(255,255,255,6%);border-color:rgba(255,255,255,.18)}html[data-theme=dark] .callout.tip{background:rgba(230,219,116,8%);border-color:rgba(230,219,116,.22)}html[data-theme=dark] .callout.warn{background:rgba(253,151,31,.1);border-color:rgba(253,151,31,.28)}.search-hit-flash{animation:searchHitFlash 1.2s ease-out 1;outline:2px solid var(--accent-2,#0F6DDC);outline-offset:2px;scroll-margin-top:calc(var(--theme-header-height,64px) + 8px)}@keyframes searchHitFlash{0%{background-color:rgba(15,109,220,.18)}60%{background-color:rgba(15,109,220,8%)}100%{background-color:initial}}</style><style>:root{--theme-breadcrumbs-height:0px}</style><script>window.tailwind=window.tailwind||{},tailwind.config={darkMode:["class",'[data-theme="dark"]'],theme:{extend:{colors:{bg:"var(--bg)",surface:"var(--surface)",border:"var(--border)",text:"var(--text)",muted:"var(--muted)",accent:"var(--accent)","accent-2":"var(--accent-2)"},fontFamily:{sans:["Inter","system-ui","-apple-system","Segoe UI","Roboto","sans-serif"],serif:["Lora","Georgia","Times New Roman","serif"],josefin:['"Josefin Sans"',"sans-serif"]},maxWidth:{container:"var(--container)"},spacing:{header:"var(--theme-header-height)",footer:"var(--theme-footer-height)"}}},corePlugins:{preflight:!1},safelist:["group/link-card","sm:flex-row","sm:items-center","h-[84px]","w-[84px]","sm:h-[84px]","sm:w-[84px]","line-clamp-2"]}</script><script src="https://cdn.tailwindcss.com?plugins=aspect-ratio"></script><style>html.skin-gold{--gold:#e6db74;--deep-green:#0e6a85;--deep-green-visited:#094c60}html.skin-gold[data-theme=light],html.skin-gold:not([data-theme]){--bg:#ffffff;--surface:#ffffff;--text:#2b2b2b;--muted:#6c757d;--border:#e9ecef;--accent:var(--deep-green);--accent-2:var(--deep-green);--link-color:var(--deep-green);--visited-color:var(--deep-green-visited)}@media(prefers-color-scheme:light){html.skin-gold:not([data-theme]){--bg:#ffffff;--surface:#ffffff;--text:#2b2b2b;--muted:#6c757d;--border:#e9ecef;--accent:var(--deep-green);--accent-2:var(--deep-green);--link-color:var(--deep-green);--visited-color:var(--deep-green-visited)}}html.skin-gold[data-theme=dark]{--bg:#000000;--surface:#111111;--text:#ffffff;--muted:#a1a1aa;--border:#333333;--accent:var(--gold);--accent-2:var(--gold);--link-color:var(--gold);--visited-color:rgba(230,219,116,0.85);--tw-prose-body:#ffffff;--tw-prose-headings:var(--gold);--tw-prose-lead:#ffffff;--tw-prose-links:var(--gold);--tw-prose-bold:var(--gold);--tw-prose-counters:var(--gold);--tw-prose-bullets:var(--gold);--tw-prose-hr:var(--border);--tw-prose-quotes:#ffffff;--tw-prose-quote-borders:var(--gold);--tw-prose-captions:var(--muted);--tw-prose-code:var(--gold);--tw-prose-pre-code:#e5e7eb;--tw-prose-pre-bg:#111111;--tw-prose-th-borders:var(--border);--tw-prose-td-borders:var(--border)}@media(prefers-color-scheme:dark){html.skin-gold:not([data-theme]){--bg:#000000;--surface:#111111;--text:#ffffff;--muted:#a1a1aa;--border:#333333;--accent:var(--gold);--accent-2:var(--gold);--link-color:var(--gold);--visited-color:rgba(230,219,116,0.85);--tw-prose-body:#ffffff;--tw-prose-headings:var(--gold);--tw-prose-lead:#ffffff;--tw-prose-links:var(--gold);--tw-prose-bold:var(--gold);--tw-prose-counters:var(--gold);--tw-prose-bullets:var(--gold);--tw-prose-hr:var(--border);--tw-prose-quotes:#ffffff;--tw-prose-quote-borders:var(--gold);--tw-prose-captions:var(--muted);--tw-prose-code:var(--gold);--tw-prose-pre-code:#e5e7eb;--tw-prose-pre-bg:#111111;--tw-prose-th-borders:var(--border);--tw-prose-td-borders:var(--border)}}html.skin-gold .hero-title .hero-greeting{color:var(--text,#111)}html.skin-gold .hero-title .hero-brand{color:var(--link-color)}html.skin-gold[data-theme=dark] .hero-title .hero-greeting{color:var(--text)}html.skin-gold .prose a{color:var(--link-color)}html.skin-gold .prose a:visited{color:var(--visited-color)}html.skin-gold[data-theme=dark] .container blockquote{background-color:rgba(230,219,116,.1);border-left-color:var(--gold)}html.skin-gold[data-theme=dark] .container table th{border-bottom-color:rgba(230,219,116,.3)}</style><style>:root{}.footer-hidden{transform:translateY(100%);opacity:.85}.docs-nav a.is-active,.toc a.is-active,.nav-drawer a.is-active{background-color:var(--surface)!important;color:var(--text)!important;font-weight:500!important;box-shadow:0 1px 2px rgba(0,0,0,5%);border-color:var(--border)!important}</style><link rel=icon href=/favicon_io/favicon.ico sizes=any><link rel=icon type=image/png sizes=32x32 href=/favicon_io/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon_io/favicon-16x16.png><link rel=apple-touch-icon href=/favicon_io/apple-touch-icon.png><link rel=manifest href=/favicon_io/site.webmanifest><meta property="og:site_name" content="Linguista"><meta property="og:type" content="article"><meta property="og:title" content="「Scripts」Module 3: Tool Use"><meta property="og:description" content="```"><meta property="og:url" content="https://linguista.cn/courses/andrew-ng-agentic-ai/lecture/lec-03/"><meta property="og:image" content="https://linguista.cn/img/Linguista_imresizer.png"><meta property="og:image:width" content="400"><meta property="og:image:height" content="400"><meta name=twitter:card content="summary"><meta name=twitter:site content="@linguista2025"><meta name=twitter:creator content="@linguista2025"><meta name=twitter:title content="「Scripts」Module 3: Tool Use"><meta name=twitter:description content="```"><meta name=twitter:image content="https://linguista.cn/img/Linguista_imresizer.png"><link rel=canonical href=https://linguista.cn/courses/andrew-ng-agentic-ai/lecture/lec-03/><script>window.MathJax={loader:{load:["[tex]/ams"]},tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,packages:{"[+]":["ams"]},macros:{unicodeInt:[`\\mathop{\\vcenter{\\mathchoice{\\huge\\unicode{#1}}{\\unicode{#1}}{\\unicode{#1}}{\\unicode{#1}}}}\\nolimits`,1],oiint:"\\unicodeInt{x222F}",oiiint:"\\unicodeInt{x2230}"}},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"]}}</script><script defer src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-99PGBGJH4S"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-99PGBGJH4S")</script></head><body class="bg-bg text-text font-sans antialiased pt-header min-h-screen flex flex-col" style=background-color:var(--bg);color:var(--text)><header class="site-header sticky top-0 z-50 bg-bg/80 backdrop-blur-md border-b border-border transition-colors duration-300"><div class="header-container container mx-auto px-4 flex items-center gap-6 h-16"><div class=header-before></div><div class="header-brand flex items-center gap-3 shrink-0"><button id=navToggleBtn class="nav-toggle-btn inline-flex items-center justify-center w-10 h-10 rounded-full hover:bg-black/5 dark:hover:bg-white/10 text-text transition-colors focus-visible:outline focus-visible:outline-2 focus-visible:outline-accent" aria-controls=navDrawer aria-expanded=false aria-label="Toggle menu">
<svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"><line x1="4" y1="12" x2="20" y2="12"/><line x1="4" y1="6" x2="20" y2="6"/><line x1="4" y1="18" x2="20" y2="18"/></svg>
</button>
<a href=/ id=brand-logo class="flex items-center gap-2 font-josefin font-bold text-2xl tracking-tight text-accent hover:opacity-80 transition-opacity no-underline" style="font-family:josefin sans,sans-serif!important;color:var(--accent)!important"><span class=md:hidden>Ling</span>
<span class="hidden md:inline">Linguista</span>
<span id=comm-dot class="inline-block w-2 h-2 rounded-full bg-accent ml-1 animate-pulse" style=background-color:var(--accent);vertical-align:middle title="Browser Communication: Active"></span>
</a><script>console.log("%c Cascade Agent Connected ","background: #2E7D6B; color: #fff; border-radius: 3px; padding: 2px 5px;"),console.log("Visual Communication: The pulsing dot next to the logo indicates CSS variables are active.");const logo=document.getElementById("brand-logo");if(logo){const e=getComputedStyle(logo).color;console.log("Diagnostics - Logo Color:",e),console.log("Diagnostics - Theme Mode:",document.documentElement.dataset.theme||"auto/light"),console.log("Diagnostics - Font Family:",getComputedStyle(logo).fontFamily)}</script></div><div class="header-search flex-1 flex justify-center px-4"><div id=siteSearchContainer class="site-search relative flex items-center w-full max-w-md transition-all duration-300" role=search><button id=searchBackBtn class="mobile-search-back hidden mr-2 text-muted hover:text-text" aria-label=Cancel type=button>
<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 18l-6-6 6-6"/></svg>
</button>
<span class="site-search-icon absolute left-3 text-muted pointer-events-none transition-opacity" aria-hidden=true><svg width="16" height="16" viewBox="0 0 24 24" fill="none"><circle cx="11" cy="11" r="7" stroke="currentColor" stroke-width="2"/><line x1="16.65" y1="16.65" x2="21" y2="21" stroke="currentColor" stroke-width="2" stroke-linecap="round"/></svg>
</span><input id=globalSearchInput class="site-search-input w-full bg-black/5 dark:bg-white/5 border border-border rounded-full py-2 pl-10 pr-4 text-sm text-text placeholder-muted focus:bg-surface focus:border-accent focus:outline-none transition-all focus:shadow-md" type=search placeholder=全站搜索… aria-label=站内搜索 autocomplete=off spellcheck=false><div id=globalSearchPopover class="site-search-popover glass-popover absolute top-full left-0 right-0 mt-2 max-h-[80vh] overflow-y-auto border border-border rounded-xl shadow-2xl z-[100] text-text" style=display:none aria-live=polite></div></div></div><div class="header-actions flex items-center gap-2.5 shrink-0"><button id=themeToggle class="inline-flex items-center justify-center min-w-[44px] px-3 py-1.5 text-base rounded-full cursor-pointer border border-border bg-transparent text-text hover:bg-surface transition-colors" aria-label=切换主题 title=切换主题></button></div></div><style>#themeToggle::after{content:'◐'}html[data-theme=dark] #themeToggle::after{content:'◑'}.glass-popover{background-color:rgba(255,255,255,.9);backdrop-filter:blur(20px);-webkit-backdrop-filter:blur(20px)}html[data-theme=dark] .glass-popover{background-color:rgba(0,0,0,.9)}.site-search-popover mark{background-color:#facc15;color:#000!important;border-radius:2px;padding:0 2px;font-weight:600;box-shadow:0 0 0 1px rgba(234,179,8,.5)}html[data-theme=dark] .site-search-popover mark{background-color:#facc15;color:#000!important;box-shadow:0 0 0 1px rgba(234,179,8,.8)}@media(max-width:900px){body.mobile-searching .header-before,body.mobile-searching .header-brand,body.mobile-searching .header-actions{display:none!important}body.mobile-searching .header-container{padding-left:.5rem;padding-right:.5rem;gap:0}body.mobile-searching .header-search{padding-left:0;padding-right:0;flex:1 1 100%}body.mobile-searching #siteSearchContainer{max-width:100%;width:100%}body.mobile-searching #searchBackBtn{display:flex!important;align-items:center;justify-content:center}body.mobile-searching .site-search-icon{display:none}body.mobile-searching #globalSearchInput{padding-left:1rem;width:auto;flex:1}}html:not([data-theme=dark]) #navDrawer{background-color:rgba(255,255,255,.94)!important}html:not([data-theme=dark]) #navDrawer .nav-drawer-header,html:not([data-theme=dark]) #navDrawer .nav-drawer-footer{background-color:rgba(255,255,255,.78)!important}html[data-theme=dark] #navDrawer{background-color:#000!important}html[data-theme=dark] #navDrawer .nav-drawer-header,html[data-theme=dark] #navDrawer .nav-drawer-footer{background-color:#000!important;border-color:rgba(255,255,255,.1)!important}.site-search-popover::-webkit-scrollbar{width:6px}.site-search-popover::-webkit-scrollbar-track{background:0 0}.site-search-popover::-webkit-scrollbar-thumb{background-color:rgba(156,163,175,.5);border-radius:3px}html[data-theme=dark] #mobileTocPanel,html[data-theme=dark] #mobileTocPanel>div:first-child,html[data-theme=dark] #mobileTocToggleBtn{background-color:rgba(0,0,0,.9)!important;border-color:rgba(255,255,255,.15)!important;color:#f4f4f5!important}html[data-theme=dark] #mobileTocPanel h4,html[data-theme=dark] #mobileTocToggleBtn span,html[data-theme=dark] #mobileTocToggleBtn svg{color:#f4f4f5!important}html[data-theme=dark] #mobileTocToggleBtn>div:first-child>div{background-color:rgba(255,255,255,.1)!important}</style></header><div id=navOverlay class="fixed inset-0 z-[90] bg-black/40 backdrop-blur-sm opacity-0 pointer-events-none transition-opacity duration-300" aria-hidden=true></div><aside id=navDrawer class="fixed inset-y-0 left-0 z-[100] w-72 bg-white/92 dark:bg-black/85 backdrop-blur-md border-r border-border transform -translate-x-full transition-transform duration-300 flex flex-col shadow-2xl" aria-hidden=true><div class="nav-drawer-header flex items-center justify-between p-4 border-b border-border bg-white/75 dark:bg-black/60 backdrop-blur-sm"><a href=/ class="font-josefin font-bold text-xl tracking-tight text-accent hover:opacity-80 transition-opacity no-underline">Linguista</a>
<button id=navCloseBtn class="p-2 rounded-lg hover:bg-black/5 dark:hover:bg-white/5 text-muted transition-colors" aria-label="Close menu">
<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 6 6 18"/><path d="m6 6 12 12"/></svg></button></div><div class="flex-1 overflow-y-auto p-4 custom-scrollbar"><nav class="flex flex-col gap-1 mb-6" aria-label=Primary><div class="text-xs font-semibold text-muted uppercase tracking-wider mb-2 px-2">Menu</div><a class="flex items-center gap-2 px-3 py-2 rounded-lg text-sm font-medium text-text hover:bg-black/5 dark:hover:bg-white/5 transition-colors" href=/labs/>工坊
</a><a class="flex items-center gap-2 px-3 py-2 rounded-lg text-sm font-medium text-text hover:bg-black/5 dark:hover:bg-white/5 transition-colors" href=/essays/>经典
</a><a class="flex items-center gap-2 px-3 py-2 rounded-lg text-sm font-medium text-text hover:bg-black/5 dark:hover:bg-white/5 transition-colors" href=/courses/>课程资料
</a><a class="flex items-center gap-2 px-3 py-2 rounded-lg text-sm font-medium text-text hover:bg-black/5 dark:hover:bg-white/5 transition-colors" href=/bookmarks/>书签
</a><a class="flex items-center gap-2 px-3 py-2 rounded-lg text-sm font-medium text-text hover:bg-black/5 dark:hover:bg-white/5 transition-colors" href=/about/>关于我</a></nav><div class=nav-drawer-folder><div class="text-xs font-semibold text-muted uppercase tracking-wider mb-2 px-2">Directory</div><nav class="flex flex-col gap-1" aria-label="Current Section"><a class="block px-2.5 py-1.5 rounded-lg text-sm transition-colors border border-transparent text-muted hover:text-text hover:bg-black/5 dark:hover:bg-white/5" href=/courses/andrew-ng-agentic-ai/lecture/lec-01/>「Scripts」Module 1: Introduction to Agentic Workflows</a>
<a class="block px-2.5 py-1.5 rounded-lg text-sm transition-colors border border-transparent text-muted hover:text-text hover:bg-black/5 dark:hover:bg-white/5" href=/courses/andrew-ng-agentic-ai/lecture/lec-02/>「Scripts」Module 2: Reflection Design Pattern</a>
<a class="block px-2.5 py-1.5 rounded-lg text-sm transition-colors border border-transparent bg-surface text-text font-medium shadow-sm border-border" href=/courses/andrew-ng-agentic-ai/lecture/lec-03/>「Scripts」Module 3: Tool Use</a>
<a class="block px-2.5 py-1.5 rounded-lg text-sm transition-colors border border-transparent text-muted hover:text-text hover:bg-black/5 dark:hover:bg-white/5" href=/courses/andrew-ng-agentic-ai/lecture/lec-04/>「Scripts」Module 4: Practical Tips for Building Agentic AI</a>
<a class="block px-2.5 py-1.5 rounded-lg text-sm transition-colors border border-transparent text-muted hover:text-text hover:bg-black/5 dark:hover:bg-white/5" href=/courses/andrew-ng-agentic-ai/lecture/lec-05/>「Scripts」Module 5: Patterns for Highly Autonomous Agents</a></nav></div></div><div class="nav-drawer-footer p-4 border-t border-border bg-white/75 dark:bg-black/60 backdrop-blur-sm"><div class="flex flex-col gap-4"><nav class="flex items-center gap-2 flex-wrap" aria-label="Social links"><a class="inline-flex w-8 h-8 rounded-full items-center justify-center text-muted/80 bg-black/5 no-underline transition-all duration-250 hover:bg-accent hover:text-white hover:-translate-y-0.5 dark:bg-white/10 dark:text-gray-300 dark:hover:bg-gray-200 dark:hover:text-black" href=https://x.com/AztecaAlpaca target=_blank rel=noopener aria-label="X / Twitter"><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/X_logo.jpg/500px-X_logo.jpg alt="X logo" class="w-4.5 h-4.5 object-contain rounded" loading=lazy decoding=async>
</a><a class="inline-flex w-8 h-8 rounded-full items-center justify-center text-muted/80 bg-black/5 no-underline transition-all duration-250 hover:bg-accent hover:text-white hover:-translate-y-0.5 dark:bg-white/10 dark:text-gray-300 dark:hover:bg-gray-200 dark:hover:text-black" href=https://github.com/Linguage target=_blank rel=noopener aria-label=GitHub><svg viewBox="0 0 24 24" aria-hidden="true" class="w-4.5 h-4.5 block"><path fill="currentColor" fill-rule="evenodd" d="M12 2C6.48 2 2 6.58 2 12.26c0 4.52 2.87 8.35 6.84 9.71.5.1.68-.22.68-.49.0-.24-.01-.87-.01-1.71-2.78.62-3.37-1.37-3.37-1.37-.45-1.18-1.11-1.5-1.11-1.5-.91-.64.07-.63.07-.63 1 .07 1.53 1.05 1.53 1.05.89 1.56 2.34 1.11 2.91.85.09-.66.35-1.11.63-1.37-2.22-.26-4.56-1.14-4.56-5.07.0-1.12.39-2.03 1.03-2.74-.1-.26-.45-1.3.1-2.71.0.0.84-.27 2.75 1.05A9.28 9.28.0 0112 6.84c.85.01 1.71.12 2.51.35 1.9-1.32 2.74-1.05 2.74-1.05.55 1.41.2 2.45.1 2.71.64.71 1.03 1.62 1.03 2.74.0 3.94-2.34 4.8-4.57 5.05.36.32.68.95.68 1.92.0 1.38-.01 2.49-.01 2.83.0.27.18.6.69.49A10.03 10.03.0 0022 12.26C22 6.58 17.52 2 12 2z" clip-rule="evenodd"/></svg>
</a><a class="inline-flex w-8 h-8 rounded-full items-center justify-center text-muted/80 bg-black/5 no-underline transition-all duration-250 hover:bg-accent hover:text-white hover:-translate-y-0.5 dark:bg-white/10 dark:text-gray-300 dark:hover:bg-gray-200 dark:hover:text-black" href=https://linguista.notion.site/linguista-hub target=_blank rel=noopener aria-label=Notion><img src=https://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Notion-logo.svg/200px-Notion-logo.svg.png?20220918151013 alt="Notion logo" class="w-4.5 h-4.5 object-contain rounded" loading=lazy decoding=async>
</a><a class="inline-flex w-auto min-w-[32px] px-3.5 h-8 rounded-full items-center justify-center text-sm font-semibold tracking-wide leading-none text-muted/80 bg-black/5 no-underline transition-all duration-250 hover:bg-accent hover:text-white hover:-translate-y-0.5 dark:bg-white/10 dark:text-gray-300 dark:hover:bg-gray-200 dark:hover:text-black" href=https://linguista.bearblog.dev/ target=_blank rel=noopener aria-label="Bear Blog ʕ•ᴥ•ʔ">ʕ•ᴥ•ʔ</a></nav><div class="text-xs text-muted">© 2026 Linguista</div></div></div></aside><main class="mx-auto max-w-container w-full px-4 flex-grow"><div class="grid grid-cols-1 lg:grid-cols-[200px_minmax(0,1fr)_220px] gap-8 py-8 pb-20 items-start max-w-7xl mx-auto"><div class="hidden lg:block" aria-hidden=true></div><article class="docs-content min-w-0"><div class=md-theme-amp-outer><div class=md-theme-amp><div class="text-muted text-sm mb-6"><span class=font-medium>Andrew Ng</span>
·
<span>2025-10-17</span></div><div class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md" data-url=https://learn.deeplearning.ai/courses/agentic-ai/><a class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline" href=https://learn.deeplearning.ai/courses/agentic-ai/ target=_blank rel=noopener>https://learn.deeplearning.ai/courses/agentic-ai/</a></div><h1 id=module-3-tool-use>Module 3: Tool Use</h1><h2 id=31-what-are-tools>3.1 What are tools?</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>In this module, you learn about <span style=color:#66d9ef>tool</span> use by LLMs, <span style=color:#f92672>and</span> that means letting your LLM decide when it might want to request to have a function called to take some action, <span style=color:#f92672>or</span> gather some information, <span style=color:#f92672>or</span> <span style=color:#66d9ef>do</span> something <span style=color:#66d9ef>else</span><span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>Just as we as humans can <span style=color:#66d9ef>do</span> a lot more with tools than we can with just our bare hands, LLMs too can also <span style=color:#66d9ef>do</span> a lot more with access to tools<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>But rather than using hammers <span style=color:#f92672>and</span> spanners <span style=color:#f92672>and</span> pliers, when we give tools, that is, functions, <span style=color:#66d9ef>for</span> an LLM to request a call, that<span style=color:#e6db74>&#39;s what lets it do a lot more.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>33</span>
</span></span><span style=display:flex><span>Let<span style=color:#e6db74>&#39;s take a look.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>34</span>
</span></span><span style=display:flex><span>If you were to ask an LLM that<span style=color:#e6db74>&#39;s been trained maybe many months ago, what time is it right now?</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>40</span>
</span></span><span style=display:flex><span>Well, that trained model does <span style=color:#f92672>not</span> know exactly what time it is, <span style=color:#f92672>and</span> so hopefully it responds, sorry, I <span style=color:#66d9ef>do</span> <span style=color:#f92672>not</span> have access to the current time<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>48</span>
</span></span><span style=display:flex><span>But <span style=color:#66d9ef>if</span> you were to write a function <span style=color:#f92672>and</span> give the LLM access to this function, then that lets it respond with a more useful answer<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>56</span>
</span></span><span style=display:flex><span>When we let LLMs call functions, <span style=color:#f92672>or</span> more precisely, let an LLM request to call functions, that<span style=color:#e6db74>&#39;s what we mean by tool use, and the tools are just functions that we provide to the LLM that it can request to call.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>08</span>
</span></span><span style=display:flex><span>In detail, this is how <span style=color:#66d9ef>tool</span> use works<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>11</span>
</span></span><span style=display:flex><span>In this example, I<span style=color:#e6db74>&#39;m going to give the getCurrentTime function that I showed on the previous slide to the LLM.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>18</span>
</span></span><span style=display:flex><span>When you then prompt it, what time is it, the LLM can decide to call the getCurrentTime function<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>That will <span style=color:#66d9ef>return</span> the current time, which is then fed back to the LLM <span style=color:#f92672>in</span> the conversational history, <span style=color:#f92672>and</span> finally the LLM can output is, say, <span style=color:#ae81ff>3.20</span>pm<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>33</span>
</span></span><span style=display:flex><span>So the sequence of steps is, there<span style=color:#e6db74>&#39;s the input prompt.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>36</span>
</span></span><span style=display:flex><span>The LLM, <span style=color:#f92672>in</span> this <span style=color:#66d9ef>case</span>, looks at the set of tools, which is just one <span style=color:#66d9ef>tool</span> <span style=color:#f92672>in</span> this example, but looks at the set of tools available, <span style=color:#f92672>and</span> it will decide <span style=color:#f92672>in</span> this example to call the <span style=color:#66d9ef>tool</span><span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>47</span>
</span></span><span style=display:flex><span>The <span style=color:#66d9ef>tool</span> is a function that then returns a value, that value is fed back to the LLM, <span style=color:#f92672>and</span> then finally the LLM generates its output<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>54</span>
</span></span><span style=display:flex><span>Now, one important aspect of <span style=color:#66d9ef>tool</span> use is, we can leave it up to the LLM to decide whether <span style=color:#f92672>or</span> <span style=color:#f92672>not</span> to use any of the tools<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>03</span>
</span></span><span style=display:flex><span>So <span style=color:#66d9ef>for</span> the same setup, <span style=color:#66d9ef>if</span> I was asking it, how much caffeine is <span style=color:#f92672>in</span> green tea, the LLM doesn<span style=color:#e6db74>&#39;t need to know the current time to answer this, and so it can generate an answer directly,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>green tea typically has this much caffeine, <span style=color:#f92672>and</span> it does so without invoking the getCurrentTime function<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>18</span>
</span></span><span style=display:flex><span>In my slides, I<span style=color:#e6db74>&#39;m going to use this notation with this dashed box on top of the LLM to indicate that we&#39;</span>re providing a set of tools to the LLM <span style=color:#66d9ef>for</span> the LLM to choose to use when it deems appropriate<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>This is as opposed to some examples you saw <span style=color:#f92672>in</span> earlier videos, where I, as a developer, had hard<span style=color:#f92672>-</span>coded <span style=color:#f92672>in</span>, <span style=color:#66d9ef>for</span> example, that I will always <span style=color:#66d9ef>do</span> a web search at this point <span style=color:#f92672>in</span> the research agent<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span>In contrast, the getCurrentTime function call is <span style=color:#f92672>not</span> hard<span style=color:#f92672>-</span>coded <span style=color:#f92672>in</span>, it<span style=color:#e6db74>&#39;s up to the LLM to decide whether or not it wants to request a call to the getCurrentTime function.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>51</span>
</span></span><span style=display:flex><span>And again, we<span style=color:#e6db74>&#39;re going to use this dashed box notation to indicate when we&#39;</span>re giving one <span style=color:#f92672>or</span> more tools to the LLM <span style=color:#66d9ef>for</span> the LLM to decide what tools, <span style=color:#66d9ef>if</span> any, it wants to call<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>02</span>
</span></span><span style=display:flex><span>Here are some more examples of when <span style=color:#66d9ef>tool</span> use may help an LLM<span style=color:#f92672>-</span>based app generate better answers<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>08</span>
</span></span><span style=display:flex><span>If you were to ask it, can you find some Italian restaurants near Mountain View, California<span style=color:#960050;background-color:#1e0010>?</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>If it has a web search <span style=color:#66d9ef>tool</span>, then an LLM might elect to call a web search engine <span style=color:#66d9ef>for</span> a query, restaurants near Mountain View, California, <span style=color:#f92672>and</span> use the results that fetches to generate the output<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>Or <span style=color:#66d9ef>if</span> you are running a retail store <span style=color:#f92672>and</span> you want to be able to answer questions like, show me customers who bought white sunglasses, <span style=color:#66d9ef>if</span> your LLM is given access to a query database <span style=color:#66d9ef>tool</span>, then it might look up the table of sales <span style=color:#66d9ef>for</span> what entries had a pair of white sunglasses sold <span style=color:#f92672>and</span> then use that to then generate the output<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>44</span>
</span></span><span style=display:flex><span>Finally, <span style=color:#66d9ef>if</span> you wanted to <span style=color:#66d9ef>do</span> an interest rate calculation, <span style=color:#66d9ef>if</span> I were to deposit <span style=color:#f92672>$</span><span style=color:#ae81ff>500</span> <span style=color:#f92672>and</span> after <span style=color:#ae81ff>10</span> years, an interest rate of <span style=color:#ae81ff>5</span><span style=color:#f92672>%</span>, what would I have<span style=color:#960050;background-color:#1e0010>?</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>53</span>
</span></span><span style=display:flex><span>If you happen to have an interest calculation <span style=color:#66d9ef>tool</span>, then it could invoke the interest calculation function to calculate that<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>01</span>
</span></span><span style=display:flex><span>Or it turns out, one thing you see later is letting an LLM write code, like just write a mathematical expression like this, <span style=color:#f92672>and</span> then to evaluate it, that would be another way to let an LLM calculate the right answer<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>16</span>
</span></span><span style=display:flex><span>So as a developer, it<span style=color:#e6db74>&#39;ll be up to you to think through what are the sorts of things you want an application to really do, and then to create the functions or the tools that are needed to make them available to the LLM to let it use the appropriate tools to complete the sorts of tasks that maybe a restaurant recommender or a retail question answer or a finance assistant may want to do.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>39</span>
</span></span><span style=display:flex><span>So depending on your application, you may have to implement <span style=color:#f92672>and</span> make different tools available to your LLM<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>46</span>
</span></span><span style=display:flex><span>So far, most of the examples we<span style=color:#e6db74>&#39;ve gone through made only one tool or one function available to the LLM.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>52</span>
</span></span><span style=display:flex><span>But there are many use cases where you want to make multiple tools <span style=color:#f92672>or</span> multiple functions available <span style=color:#66d9ef>for</span> the LLM <span style=color:#66d9ef>for</span> it to choose which of any to call<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>59</span>
</span></span><span style=display:flex><span>For example, <span style=color:#66d9ef>if</span> you<span style=color:#e6db74>&#39;re building a calendar assistant agent, you might then want it to be able to fulfill requests like, please find a free slot on Thursday in my calendar and make an appointment with Alice.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>11</span>
</span></span><span style=display:flex><span>So <span style=color:#f92672>in</span> this example, we might make available to the LLM a <span style=color:#66d9ef>tool</span> <span style=color:#f92672>or</span> a function to make an appointment, that is, to send a calendar invite, to check the calendar to see when I might be free, as well as to delete the appointment <span style=color:#66d9ef>if</span> it ever wants to cancel an existing calendar entry<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>26</span>
</span></span><span style=display:flex><span>And so given the set of instructions, the LLM would first decide that of the different tools available, probably the first one it should use is check calendar<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>35</span>
</span></span><span style=display:flex><span>So call a check calendar function that will <span style=color:#66d9ef>return</span> when I am free on Thursday<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>40</span>
</span></span><span style=display:flex><span>Based on that information, which is fed back to the LLM, it can then decide that the next step is to pick a slot, let<span style=color:#e6db74>&#39;s say 3 p.m., and then to call the make appointment function to send a calendar invite to Alice, as well as to add it to my calendar.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>56</span>
</span></span><span style=display:flex><span>The output of that, which hopefully is a confirmation that the calendar entry was sent out successfully, is fed back to the LLM, <span style=color:#f92672>and</span> then lastly, the LLM might tell me your appointment is set up with Alice at <span style=color:#ae81ff>3</span> p<span style=color:#f92672>.</span>m<span style=color:#f92672>.</span> Thursday<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>6</span>:<span style=color:#ae81ff>08</span>
</span></span><span style=display:flex><span>Being able to give your LLM access to tools is a pretty big deal<span style=color:#f92672>.</span> It will make your applications much more powerful<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>6</span>:<span style=color:#ae81ff>15</span>
</span></span><span style=display:flex><span>In the next video, we<span style=color:#e6db74>&#39;ll take a look at how to write functions, how to create tools to then make them available to your LLM. Let&#39;</span>s go on to the next video<span style=color:#f92672>.</span>
</span></span></code></pre></div><h2 id=32-creating-a-tool>3.2 Creating a tool</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>01</span>
</span></span><span style=display:flex><span>The process of how an LLM decides to call a function maybe seems a little bit mysterious
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>05</span>
</span></span><span style=display:flex><span>initially because an LLM is just trained to generate output text <span style=color:#f92672>or</span> output text tokens<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>11</span>
</span></span><span style=display:flex><span>So how does that work<span style=color:#960050;background-color:#1e0010>?</span> In this video, I<span style=color:#e6db74>&#39;d like to walk through with you step-by-step</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>15</span>
</span></span><span style=display:flex><span>what the process of getting an LLM to be able to get a function called really looks like<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>21</span>
</span></span><span style=display:flex><span>Let<span style=color:#e6db74>&#39;s take a look.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>22</span>
</span></span><span style=display:flex><span>So tools are just codes <span style=color:#f92672>or</span> functions that an LLM can request to be executed,
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>27</span>
</span></span><span style=display:flex><span>like this getCurrentTime function that we saw from the previous video<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span>Now, today<span style=color:#e6db74>&#39;s leading LLMs are all trained directly to use tools,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>36</span>
</span></span><span style=display:flex><span>but I want to walk through with you what it would look like <span style=color:#66d9ef>if</span> you had to write prompts yourself
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span>to tell it when to use tools, <span style=color:#f92672>and</span> this is what we had to <span style=color:#66d9ef>do</span> <span style=color:#f92672>in</span> an earlier era
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>46</span>
</span></span><span style=display:flex><span>before LLMs were trained directly to use tools<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>49</span>
</span></span><span style=display:flex><span>And even though we don<span style=color:#e6db74>&#39;t do it exactly this way anymore,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>51</span>
</span></span><span style=display:flex><span>this will hopefully give you a better understanding of the process,
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>54</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> we<span style=color:#e6db74>&#39;ll walk through the more modern syntax in the next video.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>57</span>
</span></span><span style=display:flex><span>If you<span style=color:#e6db74>&#39;ve implemented this function to getCurrentTime,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>then <span style=color:#f92672>in</span> order to give this <span style=color:#66d9ef>tool</span> to the LLM, you might write a prompt like this<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>05</span>
</span></span><span style=display:flex><span>You may tell it, LLM, you have access to a <span style=color:#66d9ef>tool</span> called getCurrentTime<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>09</span>
</span></span><span style=display:flex><span>To use it, I want you to print out the following text<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>Print out all caps function <span style=color:#f92672>and</span> then print out getCurrentTime<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>15</span>
</span></span><span style=display:flex><span>And <span style=color:#66d9ef>if</span> I ever see this text, all caps function <span style=color:#f92672>and</span> then getCurrentTime,
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>19</span>
</span></span><span style=display:flex><span>that<span style=color:#e6db74>&#39;s when I know you want me to call the getCurrentTime function for you.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>When a user asks, what time is it<span style=color:#960050;background-color:#1e0010>?</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>25</span>
</span></span><span style=display:flex><span>The LLM will then realize it needs to call <span style=color:#f92672>or</span> request to get called the getCurrentTime function<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>29</span>
</span></span><span style=display:flex><span>And so the LLM will then output what it was told<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>32</span>
</span></span><span style=display:flex><span>It<span style=color:#e6db74>&#39;ll output all caps function: getCurrentTime.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>35</span>
</span></span><span style=display:flex><span>Now, I then have to have written code to look at the output of the LLM
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>40</span>
</span></span><span style=display:flex><span>to see <span style=color:#66d9ef>if</span> there is this all caps function<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>42</span>
</span></span><span style=display:flex><span>And <span style=color:#66d9ef>if</span> so, then I need to pull out the argument of this getCurrentTime
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>47</span>
</span></span><span style=display:flex><span>to figure out what function the LLM wants to call<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>49</span>
</span></span><span style=display:flex><span>And then I need to write code to actually call the getCurrentTime function
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>53</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> then pull out the output, which is, let<span style=color:#e6db74>&#39;s say, 8 a.m.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>57</span>
</span></span><span style=display:flex><span>And then it is the developer written code, my code,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>that has to take <span style=color:#ae81ff>8</span> a<span style=color:#f92672>.</span>m<span style=color:#f92672>.</span> <span style=color:#f92672>and</span> feed that time, <span style=color:#ae81ff>8</span> a<span style=color:#f92672>.</span>m<span style=color:#f92672>.</span>,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>back into the LLM as part of this conversational history<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>07</span>
</span></span><span style=display:flex><span>And the conversational history, of course, includes the initial user prompt,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>the fact that the request is a function call, <span style=color:#f92672>and</span> so on<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>13</span>
</span></span><span style=display:flex><span>And lastly, the LLM, knowing what had happened earlier,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>17</span>
</span></span><span style=display:flex><span>that the user asks a question, requests a function call,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>19</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> then also that I call the function <span style=color:#f92672>and</span> <span style=color:#66d9ef>return</span> <span style=color:#ae81ff>8</span> a<span style=color:#f92672>.</span>m<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>Finally, the LLM can look at all this <span style=color:#f92672>and</span> generate the final response,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>26</span>
</span></span><span style=display:flex><span>which is, it is <span style=color:#ae81ff>8</span> a<span style=color:#f92672>.</span>m<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>28</span>
</span></span><span style=display:flex><span>So to be clear, <span style=color:#f92672>in</span> order to call a function,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span>the LLM doesn<span style=color:#e6db74>&#39;t call the function directly.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>34</span>
</span></span><span style=display:flex><span>It instead outputs something <span style=color:#f92672>in</span> a specific format like this
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>38</span>
</span></span><span style=display:flex><span>that tells me that I need to call the function <span style=color:#66d9ef>for</span> the LLM
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> then tell the LLM what was the output of the function I requested<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>45</span>
</span></span><span style=display:flex><span>In this example, we had given the LLM only a single function,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>49</span>
</span></span><span style=display:flex><span>but you can imagine <span style=color:#66d9ef>if</span> we gave it three <span style=color:#f92672>or</span> four functions,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>52</span>
</span></span><span style=display:flex><span>we could tell it to output functions <span style=color:#f92672>in</span> all caps,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>55</span>
</span></span><span style=display:flex><span>then the name of the function it wants called,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>57</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> maybe even some arguments of these functions<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>In fact, now let<span style=color:#e6db74>&#39;s take a look at a slightly more complex example</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>03</span>
</span></span><span style=display:flex><span>where the getCurrentTime function accepts an argument <span style=color:#66d9ef>for</span> the time zone
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>08</span>
</span></span><span style=display:flex><span>at which you want the current time<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>For this second example, I<span style=color:#e6db74>&#39;ve written a function</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>14</span>
</span></span><span style=display:flex><span>that gets the current time <span style=color:#f92672>in</span> a specified time zone,
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>16</span>
</span></span><span style=display:flex><span>where here the time zone is the input argument
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>19</span>
</span></span><span style=display:flex><span>to the getCurrentTime function<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>22</span>
</span></span><span style=display:flex><span>So to let the LLM use this <span style=color:#66d9ef>tool</span> to answer questions
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>25</span>
</span></span><span style=display:flex><span>like maybe, what time is it <span style=color:#f92672>in</span> New Zealand<span style=color:#960050;background-color:#1e0010>?</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>27</span>
</span></span><span style=display:flex><span>Because my answer is there, so before I call her up,
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>29</span>
</span></span><span style=display:flex><span>I <span style=color:#66d9ef>do</span> look up what time it is <span style=color:#f92672>in</span> New Zealand<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span>To let the LLM use this <span style=color:#66d9ef>tool</span>, you might modify the system prompt
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>35</span>
</span></span><span style=display:flex><span>to say you can use the getCurrentTime <span style=color:#66d9ef>tool</span> <span style=color:#66d9ef>for</span> a specific time zone<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>39</span>
</span></span><span style=display:flex><span>To use it, I<span style=color:#e6db74>&#39;ll put the following, getCurrentTime,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> then, you know, include the time zone<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>43</span>
</span></span><span style=display:flex><span>And this is an abbreviated prompt<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>45</span>
</span></span><span style=display:flex><span>In practice, you might put more details than this into the prompt
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>48</span>
</span></span><span style=display:flex><span>to tell it what is the function, how to use it, <span style=color:#f92672>and</span> so on<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>In this example, the LLM will then realize
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>53</span>
</span></span><span style=display:flex><span>it needs to fetch the time <span style=color:#f92672>in</span> New Zealand,
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>56</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> so it will generate output like this,
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>58</span>
</span></span><span style=display:flex><span>function: getCurrentTime Pacific<span style=color:#f92672>/</span>Auckland<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>02</span>
</span></span><span style=display:flex><span>This is the New Zealand time zone
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>because Auckland is a major city <span style=color:#f92672>in</span> New Zealand<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>06</span>
</span></span><span style=display:flex><span>Then I have to write code to search <span style=color:#66d9ef>for</span> whether <span style=color:#f92672>or</span> <span style=color:#f92672>not</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>this function all caps appeared <span style=color:#f92672>in</span> the LLM output,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>13</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> <span style=color:#66d9ef>if</span> so, then I need to pull out the function to call<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>17</span>
</span></span><span style=display:flex><span>Lastly, I will then call getCurrentTime
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>19</span>
</span></span><span style=display:flex><span>with the specified arguments, which is generated by the LLM,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>22</span>
</span></span><span style=display:flex><span>which is Pacific<span style=color:#f92672>/</span>Auckland, <span style=color:#f92672>and</span> maybe returns is <span style=color:#ae81ff>4</span> a<span style=color:#f92672>.</span>m<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>25</span>
</span></span><span style=display:flex><span>Then as usual, I feed this to the LLM <span style=color:#f92672>and</span> the LLM outputs<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>28</span>
</span></span><span style=display:flex><span>It is <span style=color:#ae81ff>4</span> a<span style=color:#f92672>.</span>m<span style=color:#f92672>.</span> <span style=color:#f92672>in</span> New Zealand<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>To summarize, here<span style=color:#e6db74>&#39;s the process for getting LLM to use tools.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>34</span>
</span></span><span style=display:flex><span>First, you have to provide the <span style=color:#66d9ef>tool</span> to the LLM,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>37</span>
</span></span><span style=display:flex><span>implement the function, <span style=color:#f92672>and</span> then tell the LLM that it is available<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>40</span>
</span></span><span style=display:flex><span>When the LLM decides to call a <span style=color:#66d9ef>tool</span>,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>42</span>
</span></span><span style=display:flex><span>it then generates a specific output that lets you know
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>45</span>
</span></span><span style=display:flex><span>that you need to call the function <span style=color:#66d9ef>for</span> the LLM<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>48</span>
</span></span><span style=display:flex><span>Then you call the function, get its output,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>51</span>
</span></span><span style=display:flex><span>take the output of the function you just called,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>53</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> give that output back to the LLM,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>55</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> the LLM then uses that to go on to whatever it decides to <span style=color:#66d9ef>do</span> next,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>59</span>
</span></span><span style=display:flex><span>which <span style=color:#f92672>in</span> our examples <span style=color:#f92672>in</span> this video was to just generate the final output,
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>03</span>
</span></span><span style=display:flex><span>but sometimes it may even decide that the next step
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>05</span>
</span></span><span style=display:flex><span>is to go call yet another <span style=color:#66d9ef>tool</span>, <span style=color:#f92672>and</span> the process continues<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>09</span>
</span></span><span style=display:flex><span>Now, it turns out that this all<span style=color:#f92672>-</span>caps function syntax is a little bit clunky<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>13</span>
</span></span><span style=display:flex><span>This is what we used to <span style=color:#66d9ef>do</span> before LLMs were trained natively
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>17</span>
</span></span><span style=display:flex><span><span style=color:#f92672>or</span> to know by themselves how to request that tools be called<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>21</span>
</span></span><span style=display:flex><span>With modern LLMs, you don<span style=color:#e6db74>&#39;t need to tell it to output all-caps function,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>25</span>
</span></span><span style=display:flex><span>then search <span style=color:#66d9ef>for</span> all<span style=color:#f92672>-</span>caps function, <span style=color:#f92672>and</span> so on<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>27</span>
</span></span><span style=display:flex><span>Instead, LLMs are trained to use a specific syntax
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span>to request very clearly when it wants a <span style=color:#66d9ef>tool</span> called<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>34</span>
</span></span><span style=display:flex><span>In the next video, I want to share with you
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>36</span>
</span></span><span style=display:flex><span>what the modern syntax actually looks like
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>38</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> letting LLMs request to have tools be called<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>42</span>
</span></span><span style=display:flex><span>Let<span style=color:#e6db74>&#39;s go on to the next video.</span>
</span></span></code></pre></div><h2 id=33-tool-syntax>3.3 Tool syntax</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>01</span>
</span></span><span style=display:flex><span>Let<span style=color:#e6db74>&#39;s take a look at how to write code to have your LLM get tools called.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>Here<span style=color:#e6db74>&#39;s our old getCurrentTime function without the time zone argument.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>09</span>
</span></span><span style=display:flex><span>Let me show you how to use the AI Suite open source library <span style=color:#f92672>in</span> order to have your LLM call
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>14</span>
</span></span><span style=display:flex><span>tools<span style=color:#f92672>.</span> By the way, technically, as you saw from the last video, the LLM doesn<span style=color:#e6db74>&#39;t call the tool.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>20</span>
</span></span><span style=display:flex><span>The LLM just requests that you call the <span style=color:#66d9ef>tool</span><span style=color:#f92672>.</span> But among developers building agentic workflows,
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>25</span>
</span></span><span style=display:flex><span>many of us will occasionally just say the LLM calls the <span style=color:#66d9ef>tool</span>, even though it<span style=color:#e6db74>&#39;s not technically</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>what happens, but because it<span style=color:#e6db74>&#39;s just a shorter way to say it.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>34</span>
</span></span><span style=display:flex><span>This syntax here is very similar to the OpenAI syntax <span style=color:#66d9ef>for</span> calling these LLMs, except that here,
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span>I<span style=color:#e6db74>&#39;m using the AI Suite library, which is an open source package that some friends and I had worked</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>46</span>
</span></span><span style=display:flex><span>on that makes it easy to call multiple LLM providers<span style=color:#f92672>.</span> So the code syntax, <span style=color:#f92672>and</span> <span style=color:#66d9ef>if</span> this
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>53</span>
</span></span><span style=display:flex><span>looks like a lot to you, don<span style=color:#e6db74>&#39;t worry about it. You&#39;</span>ll see more of this <span style=color:#f92672>in</span> the code labs<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>57</span>
</span></span><span style=display:flex><span>But very briefly, this is very similar to the OpenAI syntax, where you say response equals
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>02</span>
</span></span><span style=display:flex><span>client check, completions create, then select the model, which <span style=color:#f92672>in</span> this <span style=color:#66d9ef>case</span>, we<span style=color:#e6db74>&#39;ll use the</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>07</span>
</span></span><span style=display:flex><span>OpenAI model GPT<span style=color:#f92672>-</span><span style=color:#ae81ff>4</span>o, messages equals messages, assuming you<span style=color:#e6db74>&#39;ve put into an array here the</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>13</span>
</span></span><span style=display:flex><span>messages you want to <span style=color:#66d9ef>pass</span> the LLM, <span style=color:#f92672>and</span> it will say tools equals, then a list of the tools you want
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>19</span>
</span></span><span style=display:flex><span>the LLM to have access to<span style=color:#f92672>.</span> And <span style=color:#f92672>in</span> this <span style=color:#66d9ef>case</span>, there<span style=color:#e6db74>&#39;s just one tool, which is get current time,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> then don<span style=color:#e6db74>&#39;t worry too much about the max turns parameter. This is included because</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>28</span>
</span></span><span style=display:flex><span>after a <span style=color:#66d9ef>tool</span> call returns, the LLM might decide to call another <span style=color:#66d9ef>tool</span>, <span style=color:#f92672>and</span> after that <span style=color:#66d9ef>tool</span> call
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>33</span>
</span></span><span style=display:flex><span>returns, the LLM might decide to call yet another <span style=color:#66d9ef>tool</span><span style=color:#f92672>.</span> So max turns is just a ceiling on how many
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>38</span>
</span></span><span style=display:flex><span>times you want the LLM to request one <span style=color:#66d9ef>tool</span> after another before you stop to just <span style=color:#66d9ef>break</span> out of a
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>44</span>
</span></span><span style=display:flex><span>possible infinite loop<span style=color:#f92672>.</span> In practice, you almost never hit this limit unless your code is doing
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>49</span>
</span></span><span style=display:flex><span>something unusually ambitious<span style=color:#f92672>.</span> So I wouldn<span style=color:#e6db74>&#39;t worry about the max turns parameter. I usually just set it to</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>54</span>
</span></span><span style=display:flex><span>five, but <span style=color:#f92672>in</span> practice, it doesn<span style=color:#e6db74>&#39;t matter that much. And it turns out that with AISuite, the function</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>get current time is automatically described to the LLM <span style=color:#f92672>in</span> an appropriate way to enable the LLM to
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>06</span>
</span></span><span style=display:flex><span>know when to call it<span style=color:#f92672>.</span> So rather than you needing to manually write a long prompt to tell the LLM,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>once get current time, this syntax <span style=color:#f92672>in</span> AISuite does that automatically<span style=color:#f92672>.</span> And to make it seem <span style=color:#f92672>not</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>18</span>
</span></span><span style=display:flex><span>too mysterious, the way it does that, it actually looks at the dot string associated with get current
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>time with this comments <span style=color:#f92672>in</span> get current time <span style=color:#f92672>in</span> order to figure out how to describe this function
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>to the LLM<span style=color:#f92672>.</span> So to illustrate how this works, here<span style=color:#e6db74>&#39;s the function again, and here&#39;</span>s the
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>36</span>
</span></span><span style=display:flex><span>snippet of code using AISuite to call the LLM<span style=color:#f92672>.</span> Behind the scenes, what this will <span style=color:#66d9ef>do</span> is create a
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>43</span>
</span></span><span style=display:flex><span>JSON schema that describes the function <span style=color:#f92672>in</span> detail<span style=color:#f92672>.</span> And this over here on the right is what is actually
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>passed to the LLM<span style=color:#f92672>.</span> And specifically, it will pull the name of the function, which is get current time,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>55</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> then also a description of the function, which is pulled out from the doc string to tell the LLM
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>01</span>
</span></span><span style=display:flex><span>what this function does, which lets it decide when to call it<span style=color:#f92672>.</span> There<span style=color:#e6db74>&#39;s some APIs which require that</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>06</span>
</span></span><span style=display:flex><span>you manually construct this JSON schema <span style=color:#f92672>and</span> then <span style=color:#66d9ef>pass</span> this JSON schema to the LLM, but the AISuite
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>13</span>
</span></span><span style=display:flex><span>package does this automatically <span style=color:#66d9ef>for</span> you<span style=color:#f92672>.</span> To go through a slightly more complex example, <span style=color:#66d9ef>if</span> you
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>18</span>
</span></span><span style=display:flex><span>have this more complex get current time <span style=color:#66d9ef>tool</span> that also has an input time zone parameter, then AISuite
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>25</span>
</span></span><span style=display:flex><span>will create this more complex JSON schema where, as before, it pulls out the name of the function,
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>which is get current time, pulls out the description from the doc string, <span style=color:#f92672>and</span> then also identifies
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>35</span>
</span></span><span style=display:flex><span>what are the parameters <span style=color:#f92672>and</span> describes them to the LLM based on the documentation here shown on the
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span>left, so that when it<span style=color:#e6db74>&#39;s generating the function arguments to call the tool, it knows that it</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>47</span>
</span></span><span style=display:flex><span>should be something like America<span style=color:#f92672>/</span>New York <span style=color:#f92672>or</span> Pacific<span style=color:#f92672>/</span>Auckland <span style=color:#f92672>or</span> some other time zone<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>53</span>
</span></span><span style=display:flex><span>And so <span style=color:#66d9ef>if</span> you execute this code snippet here on the lower left, it will use the OpenAI
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>59</span>
</span></span><span style=display:flex><span>GPT<span style=color:#f92672>-</span><span style=color:#ae81ff>4</span>o model, see <span style=color:#66d9ef>if</span> the LLM wants the function called, <span style=color:#f92672>and</span> <span style=color:#66d9ef>if</span> so, it<span style=color:#e6db74>&#39;ll call the function,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>get the output from the function, feed that back to the LLM, <span style=color:#f92672>and</span> <span style=color:#66d9ef>do</span> that up to a maximum of five
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>turns <span style=color:#f92672>and</span> then <span style=color:#66d9ef>return</span> the response<span style=color:#f92672>.</span> Note that <span style=color:#66d9ef>if</span> the LLM requests to call the get current time
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>17</span>
</span></span><span style=display:flex><span>function, AISuite <span style=color:#f92672>or</span> this client, it will call the get current time <span style=color:#66d9ef>for</span> you, so you don<span style=color:#e6db74>&#39;t need</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>to explicitly <span style=color:#66d9ef>do</span> it yourself<span style=color:#f92672>.</span> All that is done <span style=color:#f92672>in</span> this single function call that you have to write<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>29</span>
</span></span><span style=display:flex><span>Just note that there are some other implementations of LLM interfaces where you have to <span style=color:#66d9ef>do</span> that step
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>36</span>
</span></span><span style=display:flex><span>manually, but with this particular package, this is all wrapped into this client chat completions
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span>create function call<span style=color:#f92672>.</span> So you now know how to get an LLM to call functions, <span style=color:#f92672>and</span> I hope that you enjoy
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>49</span>
</span></span><span style=display:flex><span>playing with this <span style=color:#f92672>in</span> the labs, <span style=color:#f92672>and</span> it<span style=color:#e6db74>&#39;s actually really amazing when you provide a few functions</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>54</span>
</span></span><span style=display:flex><span>to LLM <span style=color:#f92672>and</span> LLM decides to go <span style=color:#f92672>and</span> take action <span style=color:#f92672>in</span> the world, go <span style=color:#f92672>and</span> get more information
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>59</span>
</span></span><span style=display:flex><span>to fulfill your requests<span style=color:#f92672>.</span> If you haven<span style=color:#e6db74>&#39;t played with this before, I think you&#39;</span>ll find this to be
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>really cool<span style=color:#f92672>.</span> It turns out that of all the tools you can give an LLM, there<span style=color:#e6db74>&#39;s one that&#39;</span>s a bit special,
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>which is a code execution <span style=color:#66d9ef>tool</span><span style=color:#f92672>.</span> It turns out to be really powerful<span style=color:#f92672>.</span> If you can tell an LLM,
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>16</span>
</span></span><span style=display:flex><span>you can write code, <span style=color:#f92672>and</span> I will have a <span style=color:#66d9ef>tool</span> to execute that code <span style=color:#66d9ef>for</span> you, because code can <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>21</span>
</span></span><span style=display:flex><span>a lot of things, <span style=color:#f92672>and</span> we give an LLM the flexibility to write code <span style=color:#f92672>and</span> have code executed<span style=color:#f92672>.</span> That turns
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>28</span>
</span></span><span style=display:flex><span>out to be an incredibly powerful <span style=color:#66d9ef>tool</span> to give to LLMs<span style=color:#f92672>.</span> So code execution is special<span style=color:#f92672>.</span> Let<span style=color:#e6db74>&#39;s go</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>35</span>
</span></span><span style=display:flex><span>on to the next video to talk about the code execution <span style=color:#66d9ef>tool</span> <span style=color:#66d9ef>for</span> LLMs<span style=color:#f92672>.</span>
</span></span></code></pre></div><h2 id=34-code-execution>3.4 Code execution</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>05</span>
</span></span><span style=display:flex><span>In a few agentic applications I<span style=color:#e6db74>&#39;ve worked on, I gave the LLM the option to write code to then</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>06</span>
</span></span><span style=display:flex><span>carry out the task I wanted it to<span style=color:#f92672>.</span> And I<span style=color:#e6db74>&#39;ve been a few times now, I&#39;</span>ve been really surprised <span style=color:#f92672>and</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>delighted by the cleverness of the code solutions it generated <span style=color:#f92672>in</span> order to solve various tasks <span style=color:#66d9ef>for</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>17</span>
</span></span><span style=display:flex><span>me<span style=color:#f92672>.</span> So <span style=color:#66d9ef>if</span> you haven<span style=color:#e6db74>&#39;t used code execution much, I think you might be surprised and delighted at</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>what this will let your LLM applications <span style=color:#66d9ef>do</span><span style=color:#f92672>.</span> Let<span style=color:#e6db74>&#39;s take a look. Let&#39;</span>s take an example of
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>29</span>
</span></span><span style=display:flex><span>building an application that can input math word problems <span style=color:#f92672>and</span> solve them <span style=color:#66d9ef>for</span> you<span style=color:#f92672>.</span> So you might
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>36</span>
</span></span><span style=display:flex><span>create tools that add numbers, subtract numbers, multiply numbers, <span style=color:#f92672>and</span> divide numbers<span style=color:#f92672>.</span> And <span style=color:#66d9ef>if</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>40</span>
</span></span><span style=display:flex><span>someone says, please add <span style=color:#ae81ff>13.2</span> plus <span style=color:#ae81ff>18.9</span>, then it triggers the add <span style=color:#66d9ef>tool</span> <span style=color:#f92672>and</span> then it gets you the
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>46</span>
</span></span><span style=display:flex><span>right answer<span style=color:#f92672>.</span> But what <span style=color:#66d9ef>if</span> someone now types <span style=color:#f92672>in</span>, what is the square root of two<span style=color:#960050;background-color:#1e0010>?</span> Well, one thing
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>you could <span style=color:#66d9ef>do</span> is write a new <span style=color:#66d9ef>tool</span> <span style=color:#66d9ef>for</span> a square root, but then maybe some new thing is needed to
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>56</span>
</span></span><span style=display:flex><span>carry out exponentiation<span style=color:#f92672>.</span> And <span style=color:#f92672>in</span> fact, <span style=color:#66d9ef>if</span> you look at the number of buttons on your modern
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>02</span>
</span></span><span style=display:flex><span>scientific calculator, are you going to create a separate <span style=color:#66d9ef>tool</span> <span style=color:#66d9ef>for</span> every one of these buttons <span style=color:#f92672>and</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>06</span>
</span></span><span style=display:flex><span>the many more things that we would want to <span style=color:#66d9ef>do</span> <span style=color:#f92672>in</span> math calculation<span style=color:#960050;background-color:#1e0010>?</span> So instead of trying to implement
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>one <span style=color:#66d9ef>tool</span> after another, a different approach is to let it write <span style=color:#f92672>and</span> execute code<span style=color:#f92672>.</span> To tell the LLM
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>19</span>
</span></span><span style=display:flex><span>to write code, you might write a prompt like this<span style=color:#f92672>.</span> Write code to solve the user<span style=color:#e6db74>&#39;s query. Return your</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>24</span>
</span></span><span style=display:flex><span>answer as Python code delimited with execute Python <span style=color:#f92672>and</span> closing execute Python tags<span style=color:#f92672>.</span> So given a query
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span>like what is the square root of two, the LLM might generate outputs like this<span style=color:#f92672>.</span> You can then use
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>37</span>
</span></span><span style=display:flex><span>pattern matching, <span style=color:#66d9ef>for</span> example, a regular expression to look <span style=color:#66d9ef>for</span> the start <span style=color:#f92672>and</span> end execute Python tags
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>44</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> extract the code <span style=color:#f92672>in</span> between<span style=color:#f92672>.</span> So here you get these two lines of code shown <span style=color:#f92672>in</span> the green box,
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> you can then execute this code <span style=color:#66d9ef>for</span> the LLM <span style=color:#f92672>and</span> get the output, <span style=color:#f92672>in</span> this <span style=color:#66d9ef>case</span>, <span style=color:#ae81ff>1.4142</span> <span style=color:#f92672>and</span> so on<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>57</span>
</span></span><span style=display:flex><span>Lastly, this numerical answer is then passed back to the LLM <span style=color:#f92672>and</span> it can write a nicely formatted
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>answer to the original question<span style=color:#f92672>.</span> There are a few different ways you can carry out the code
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>08</span>
</span></span><span style=display:flex><span>execution step <span style=color:#66d9ef>for</span> the LLM<span style=color:#f92672>.</span> One is to use Python<span style=color:#e6db74>&#39;s exec function. This is a built-in Python function</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>15</span>
</span></span><span style=display:flex><span>which will execute whatever code you <span style=color:#66d9ef>pass</span> <span style=color:#f92672>in</span><span style=color:#f92672>.</span> And this is very powerful <span style=color:#66d9ef>for</span> your LLM to really
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>21</span>
</span></span><span style=display:flex><span>write code <span style=color:#f92672>and</span> get you to execute that code, although there are some security implications
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>26</span>
</span></span><span style=display:flex><span>which we<span style=color:#e6db74>&#39;ll see later in this video. And then there are also some tools that will let you run the code</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span><span style=color:#f92672>in</span> a safer sandbox environment<span style=color:#f92672>.</span> And of course, square root of two is a relatively simple example<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>38</span>
</span></span><span style=display:flex><span>An LLM can also accurately write code to, <span style=color:#66d9ef>for</span> example, <span style=color:#66d9ef>do</span> interest calculations <span style=color:#f92672>and</span> solve much harder
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>45</span>
</span></span><span style=display:flex><span>math calculations than this<span style=color:#f92672>.</span> One refinement to this idea, which you sort of saw <span style=color:#f92672>in</span> our section
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>52</span>
</span></span><span style=display:flex><span>on reflection, is that <span style=color:#66d9ef>if</span> code execution fails, so <span style=color:#66d9ef>if</span> <span style=color:#66d9ef>for</span> some reason the LLM had generated code
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>58</span>
</span></span><span style=display:flex><span>that wasn<span style=color:#e6db74>&#39;t quite correct, then passing that error message back to the LLM to let it reflect and</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>maybe revise this code <span style=color:#f92672>and</span> try another one <span style=color:#f92672>or</span> two times<span style=color:#f92672>.</span> That can sometimes also allow it to get a
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>more accurate answer<span style=color:#f92672>.</span> Now, running arbitrary code that an LLM generates does have a small chance of
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>17</span>
</span></span><span style=display:flex><span>causing something bad to happen<span style=color:#f92672>.</span> Recently, one of my team members was using a highly agentic coder
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>24</span>
</span></span><span style=display:flex><span><span style=color:#f92672>and</span> it actually chose to remove star<span style=color:#f92672>.</span>py within a project directory<span style=color:#f92672>.</span> So this is actually a real
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>30</span>
</span></span><span style=display:flex><span>example<span style=color:#f92672>.</span> And eventually that agentic coder did apologize<span style=color:#f92672>.</span> It said, yes, that<span style=color:#e6db74>&#39;s actually right,</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>35</span>
</span></span><span style=display:flex><span>that was an incredibly stupid mistake<span style=color:#f92672>.</span> I guess I was glad that this agentic coder was really sorry,
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>40</span>
</span></span><span style=display:flex><span>but I already deleted a bunch of Python files<span style=color:#f92672>.</span> Unfortunately, the team member had it backed
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>44</span>
</span></span><span style=display:flex><span>up on GitHub repo, so there was no real harm done, but it would have been <span style=color:#f92672>not</span> great <span style=color:#66d9ef>if</span> this
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>arbitrary code, which made the mistake of deleting a bunch of files, had been executed
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>55</span>
</span></span><span style=display:flex><span>without the backup<span style=color:#f92672>.</span> So the best practice <span style=color:#66d9ef>for</span> code execution is to run it inside a sandbox
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>environment<span style=color:#f92672>.</span> In practice, the risk <span style=color:#66d9ef>for</span> any single line of code is <span style=color:#f92672>not</span> that high<span style=color:#f92672>.</span> So <span style=color:#66d9ef>if</span> I<span style=color:#e6db74>&#39;m being</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>07</span>
</span></span><span style=display:flex><span>candid, many developers will execute code from the LLM without too much checking<span style=color:#f92672>.</span> But <span style=color:#66d9ef>if</span> you want to
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>12</span>
</span></span><span style=display:flex><span>be a bit safer, then the best practice is to create a sandbox so that <span style=color:#66d9ef>if</span> an LLM generates bad
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>19</span>
</span></span><span style=display:flex><span>code, there<span style=color:#e6db74>&#39;s a lower risk of data loss or leakage of sensitive data and so on. So sandbox</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>26</span>
</span></span><span style=display:flex><span>environments like Docker <span style=color:#f92672>or</span> E2B as a lightweight sandbox environment can reduce the risk of
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>33</span>
</span></span><span style=display:flex><span>arbitrary codes being executed <span style=color:#f92672>in</span> a way that damages your system <span style=color:#f92672>or</span> your environment<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>39</span>
</span></span><span style=display:flex><span>It turns out that code execution is so important that a lot of trainers of LLMs actually <span style=color:#66d9ef>do</span> special
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>46</span>
</span></span><span style=display:flex><span>work to make sure that code execution works well on their applications<span style=color:#f92672>.</span> But I hope that as you add
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>52</span>
</span></span><span style=display:flex><span>this as one more <span style=color:#66d9ef>tool</span> <span style=color:#66d9ef>for</span> you to potentially offer to LLMs <span style=color:#f92672>or</span> let you make your applications
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>58</span>
</span></span><span style=display:flex><span>much more powerful<span style=color:#f92672>.</span> So far <span style=color:#f92672>and</span> what we<span style=color:#e6db74>&#39;ve discussed, you have to create tools and make them</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>05</span>
</span></span><span style=display:flex><span>available one at a time to your LLM<span style=color:#f92672>.</span> It turns out that many different teams are building similar
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>11</span>
</span></span><span style=display:flex><span>tools <span style=color:#f92672>and</span> having to <span style=color:#66d9ef>do</span> all this work of building functions <span style=color:#f92672>and</span> making them available to the OMs<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>18</span>
</span></span><span style=display:flex><span>But there is recently a new standard called MCP, Model Context Protocol, that<span style=color:#e6db74>&#39;s making it much</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>24</span>
</span></span><span style=display:flex><span>easier <span style=color:#66d9ef>for</span> developers to get access to a huge set of tools <span style=color:#66d9ef>for</span> LLMs to use<span style=color:#f92672>.</span> This is an important
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span>protocol that more <span style=color:#f92672>and</span> more teams are using to develop LLM based applications<span style=color:#f92672>.</span> Let<span style=color:#e6db74>&#39;s go learn</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>37</span>
</span></span><span style=display:flex><span>about MCP <span style=color:#f92672>in</span> the next video<span style=color:#f92672>.</span>
</span></span></code></pre></div><h2 id=35-mcp>3.5 MCP</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-gdscript3 data-lang=gdscript3><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>MCP, the Model Context Protocol, was a standard proposed by Anthropic but now adopted by many
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>07</span>
</span></span><span style=display:flex><span>other companies <span style=color:#f92672>and</span> by many developers as a way to give an LLM access to more context <span style=color:#f92672>and</span> to
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>13</span>
</span></span><span style=display:flex><span>more tools<span style=color:#f92672>.</span> There are a lot of developers developing around the MCP ecosystem <span style=color:#f92672>and</span> so
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>18</span>
</span></span><span style=display:flex><span>learning about this will give you a lot more access to resources <span style=color:#66d9ef>for</span> your applications<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>24</span>
</span></span><span style=display:flex><span>Let<span style=color:#e6db74>&#39;s take a look. This is the pain points that MCP attempts to solve. If one developer is writing</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>31</span>
</span></span><span style=display:flex><span>an application that wants to integrate with data from Slack <span style=color:#f92672>and</span> Google Drive <span style=color:#f92672>and</span> GitHub <span style=color:#f92672>or</span> access
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>37</span>
</span></span><span style=display:flex><span>data from a Postgres database, then they might have to write code to wrap around Slack APIs
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>42</span>
</span></span><span style=display:flex><span>to have functions to provide to the application, write code to wrap around Google Drive APIs to
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>47</span>
</span></span><span style=display:flex><span>parse the application, <span style=color:#f92672>and</span> similarly <span style=color:#66d9ef>for</span> these other tools <span style=color:#f92672>or</span> data sources<span style=color:#f92672>.</span> Then what has been
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>54</span>
</span></span><span style=display:flex><span>happening <span style=color:#f92672>in</span> the developer community is <span style=color:#66d9ef>if</span> a different team is building a different application,
</span></span><span style=display:flex><span><span style=color:#ae81ff>0</span>:<span style=color:#ae81ff>59</span>
</span></span><span style=display:flex><span>then they too will integrate by themselves with Slack <span style=color:#f92672>and</span> Google Drive <span style=color:#f92672>and</span> GitHub <span style=color:#f92672>and</span> so on<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>So many developers were all building custom wrappers around these types of data sources<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>10</span>
</span></span><span style=display:flex><span>And so <span style=color:#66d9ef>if</span> there are M applications being developed <span style=color:#f92672>and</span> there are N tools out there,
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>16</span>
</span></span><span style=display:flex><span>the total amount of work done by the community was M times N<span style=color:#f92672>.</span> What MCP did was propose a standard
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>24</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> applications to get access to tools <span style=color:#f92672>and</span> data sources so that the total work that needs to be
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>29</span>
</span></span><span style=display:flex><span>done by the community is now M plus N rather than M times N<span style=color:#f92672>.</span> The initial design of MCP focused a lot
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>38</span>
</span></span><span style=display:flex><span>on how to give more context to an LLM <span style=color:#f92672>or</span> how to fetch data<span style=color:#f92672>.</span> So a lot of the initial tools were
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>44</span>
</span></span><span style=display:flex><span>ones that would just fetch data<span style=color:#f92672>.</span> And <span style=color:#66d9ef>if</span> you read the MCP documentation, that refers to these as
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>51</span>
</span></span><span style=display:flex><span>resources<span style=color:#f92672>.</span> But MCP gives access to both data as well as the more general functions that an
</span></span><span style=display:flex><span><span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>57</span>
</span></span><span style=display:flex><span>application may want to call<span style=color:#f92672>.</span> And it turns out that there are many MCP clients<span style=color:#f92672>.</span> These are the
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>04</span>
</span></span><span style=display:flex><span>applications that want access to tools <span style=color:#f92672>or</span> to data as well as service, which are often the software
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>11</span>
</span></span><span style=display:flex><span>wrappers that then give access to data <span style=color:#f92672>in</span> Slack <span style=color:#f92672>or</span> GitHub <span style=color:#f92672>or</span> Google Drive <span style=color:#f92672>or</span> allows you to take
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>16</span>
</span></span><span style=display:flex><span>actions at these different types of resources<span style=color:#f92672>.</span> So today there<span style=color:#e6db74>&#39;s a rapidly growing list of MCP</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>23</span>
</span></span><span style=display:flex><span>clients that consume the tools <span style=color:#f92672>or</span> the resources as well as MCP service that provide the tools <span style=color:#f92672>and</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>28</span>
</span></span><span style=display:flex><span>the resources<span style=color:#f92672>.</span> And I hope that you find it useful to build your own MCP client<span style=color:#f92672>.</span> Your application
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>35</span>
</span></span><span style=display:flex><span>maybe one day will be an MCP client<span style=color:#f92672>.</span> And <span style=color:#66d9ef>if</span> you want to provide resources to other developers,
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>40</span>
</span></span><span style=display:flex><span>maybe you can build your own MCP server someday<span style=color:#f92672>.</span> Let me show you a quick example of using an MCP
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>46</span>
</span></span><span style=display:flex><span>client<span style=color:#f92672>.</span> This is a cloud desktop app <span style=color:#f92672>and</span> it has been connected to a GitHub MCP server<span style=color:#f92672>.</span> So when
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span>:<span style=color:#ae81ff>54</span>
</span></span><span style=display:flex><span>I enter this query, summarize the readme<span style=color:#f92672>.</span>md from the GitHub repo at this URL, this is actually
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>an AI suite repo<span style=color:#f92672>.</span> Then this application, which is an MCP client, uses the GitHub MCP server with
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>07</span>
</span></span><span style=display:flex><span>the request, please get the file readme<span style=color:#f92672>.</span>md from the repo AI suite from this repo<span style=color:#f92672>.</span> And then it
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>14</span>
</span></span><span style=display:flex><span>gets this response, which is pretty long<span style=color:#f92672>.</span> All this is then fed back to the LLMs context <span style=color:#f92672>and</span> the LLM
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>21</span>
</span></span><span style=display:flex><span>then generates the summary of the markdown file<span style=color:#f92672>.</span> Now let me enter another request, which is let me
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>27</span>
</span></span><span style=display:flex><span>enter what are the latest pull requests<span style=color:#f92672>.</span> This <span style=color:#f92672>in</span> turn causes the LLMs to use the MCP server to make
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>36</span>
</span></span><span style=display:flex><span>a different request, to list the pull request<span style=color:#f92672>.</span> This is another <span style=color:#66d9ef>tool</span> provided by GitHub<span style=color:#e6db74>&#39;s MCP</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>42</span>
</span></span><span style=display:flex><span>server<span style=color:#f92672>.</span> And so it makes this request with repo AI suite, sort, going to update it, list <span style=color:#ae81ff>20</span>, <span style=color:#f92672>and</span> so on<span style=color:#f92672>.</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>50</span>
</span></span><span style=display:flex><span>And then it gives this response, which is fed back to the LLM <span style=color:#f92672>and</span> the LLM then writes this nice
</span></span><span style=display:flex><span><span style=color:#ae81ff>3</span>:<span style=color:#ae81ff>55</span>
</span></span><span style=display:flex><span>text summary of the latest pull request <span style=color:#66d9ef>for</span> this repo<span style=color:#f92672>.</span> MCP is an important standard<span style=color:#f92672>.</span> If you want to
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>01</span>
</span></span><span style=display:flex><span>learn more about it, DeepLearning<span style=color:#f92672>.</span>ai also has a short course that goes much deeper into just the MCP
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>08</span>
</span></span><span style=display:flex><span>protocol that you can check out after finishing the course, <span style=color:#66d9ef>if</span> you<span style=color:#e6db74>&#39;re interested. I hope this</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>13</span>
</span></span><span style=display:flex><span>video gives you a brief overview of why it<span style=color:#e6db74>&#39;s useful and also why many developers are now building to</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>20</span>
</span></span><span style=display:flex><span>this standard<span style=color:#f92672>.</span> This brings us to the last video on <span style=color:#66d9ef>tool</span> use<span style=color:#f92672>.</span> And I hope that by giving your own access
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>27</span>
</span></span><span style=display:flex><span>to tools, you build <span style=color:#f92672>and</span> build agentic applications that are much more powerful<span style=color:#f92672>.</span> In the next module,
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>34</span>
</span></span><span style=display:flex><span>we<span style=color:#e6db74>&#39;ll talk about evaluations and error analysis. It turns out that one of the things I&#39;</span>ve seen
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>41</span>
</span></span><span style=display:flex><span>that distinguishes people that can execute agentic workflows really well versus teams that are <span style=color:#f92672>not</span>
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>47</span>
</span></span><span style=display:flex><span>as efficient at it is your ability to drive a disciplined evaluation process<span style=color:#f92672>.</span> In the next
</span></span><span style=display:flex><span><span style=color:#ae81ff>4</span>:<span style=color:#ae81ff>55</span>
</span></span><span style=display:flex><span>set of videos, which I think is maybe the most important module of this entire course,
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>00</span>
</span></span><span style=display:flex><span>I hope to share with you some of the best practices of how to use evals to drive
</span></span><span style=display:flex><span><span style=color:#ae81ff>5</span>:<span style=color:#ae81ff>05</span>
</span></span><span style=display:flex><span>development of agentic workflows<span style=color:#f92672>.</span> Look forward to seeing you <span style=color:#f92672>in</span> the next module<span style=color:#f92672>.</span>
</span></span></code></pre></div></div></div><div class="grid grid-cols-1 sm:grid-cols-2 gap-4 mt-10 border-t border-border pt-8"><a class="flex items-stretch gap-3 p-4 rounded-xl border border-border bg-surface transition-all duration-200 hover:shadow-md hover:border-accent/40 group no-underline text-inherit" href=/courses/andrew-ng-agentic-ai/lecture/lec-04/ aria-label="上一篇：「Scripts」Module 4: Practical Tips for Building Agentic AI"><div class="flex items-center text-2xl text-muted font-light group-hover:text-accent transition-colors">‹</div><div class="flex-1 min-w-0 flex flex-col justify-center"><div class="font-semibold text-base text-text line-clamp-2 group-hover:text-accent transition-colors">「Scripts」Module 4: Practical Tips for Building Agentic AI</div><div class="text-xs text-muted mt-1"><span>Han ZL</span>
·
<span>2025-10-17</span></div></div></a><a class="flex items-stretch gap-3 p-4 rounded-xl border border-border bg-surface transition-all duration-200 hover:shadow-md hover:border-accent/40 group no-underline text-inherit text-right" href=/courses/andrew-ng-agentic-ai/lecture/lec-02/ aria-label="下一篇：「Scripts」Module 2: Reflection Design Pattern"><div class="flex-1 min-w-0 flex flex-col justify-center items-end"><div class="font-semibold text-base text-text line-clamp-2 group-hover:text-accent transition-colors">「Scripts」Module 2: Reflection Design Pattern</div><div class="text-xs text-muted mt-1"><span>Andrew Ng</span>
·
<span>2025-10-17</span></div></div><div class="flex items-center text-2xl text-muted font-light group-hover:text-accent transition-colors">›</div></a></div><section class="comments mt-12 pt-8 border-t border-border" aria-label=Comments><div id=giscus_thread class=giscus data-repo=Linguage/Giscus data-repo-id=R_kgDOLxA-eA data-category=Announcements data-category-id=DIC_kwDOLxA-eM4Ce06R data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme-light=light data-theme-dark=dark data-lang=zh-CN></div><script>(function(){try{const e=document.getElementById("giscus_thread");if(!e)return;let n=null;try{const e=localStorage.getItem("theme");(e==="light"||e==="dark")&&(n=e)}catch{n=null}const o=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,i=n?n:o?"dark":"light",s=i==="dark"?e.dataset.themeDark||"dark":e.dataset.themeLight||"light";e.setAttribute("data-theme",s);const t=document.createElement("script");t.src="https://giscus.app/client.js",t.setAttribute("data-repo",e.dataset.repo||""),t.setAttribute("data-repo-id",e.dataset.repoId||""),t.setAttribute("data-category",e.dataset.category||"General"),t.setAttribute("data-category-id",e.dataset.categoryId||""),t.setAttribute("data-mapping",e.dataset.mapping||"pathname"),t.setAttribute("data-strict",String(e.dataset.strict||"0")),t.setAttribute("data-reactions-enabled",String(e.dataset.reactionsEnabled||"1")),t.setAttribute("data-emit-metadata",String(e.dataset.emitMetadata||"0")),t.setAttribute("data-input-position",e.dataset.inputPosition||"bottom"),t.setAttribute("data-theme",s),t.setAttribute("data-lang",e.dataset.lang||"zh-CN"),t.setAttribute("crossorigin","anonymous"),t.async=!0,e.parentNode.insertBefore(t,e.nextSibling)}catch{}})()</script></section></article><aside class="docs-toc sticky top-[84px] max-h-[calc(100vh-100px)] overflow-y-auto hidden xl:block md-theme-amp-toc" aria-label="On this page"><div class="toc-title uppercase mb-4">On this page</div><nav class="toc flex flex-col gap-1"><nav id=TableOfContents><ul><li><a href=#31-what-are-tools>3.1 What are tools?</a></li><li><a href=#32-creating-a-tool>3.2 Creating a tool</a></li><li><a href=#33-tool-syntax>3.3 Tool syntax</a></li><li><a href=#34-code-execution>3.4 Code execution</a></li><li><a href=#35-mcp>3.5 MCP</a></li></ul></nav></nav></aside></div><button class="fixed right-6 bottom-20 z-50 p-2 rounded-full bg-surface border border-border shadow-lg cursor-pointer opacity-0 transition-opacity duration-300 hover:bg-bg" id=backToTop aria-label="Back to top">↑</button><div id=mobileTocContainer class="xl:hidden fixed bottom-6 left-4 right-4 z-[80] flex flex-col items-center"><div id=mobileTocPanel class="w-full max-w-md bg-white/95 dark:bg-black/95 backdrop-blur-xl border border-slate-200 dark:border-white/10 rounded-xl shadow-2xl mb-3 max-h-[60vh] overflow-y-auto p-4 hidden transition-all duration-200 origin-bottom scale-95 opacity-0"><div class="flex justify-between items-center mb-4 sticky top-0 bg-white/95 dark:bg-black/95 backdrop-blur-xl pb-2 border-b border-slate-200 dark:border-white/10 -mx-4 px-4 pt-1 z-10"><h4 class="text-sm font-bold text-slate-900 dark:text-slate-100 flex items-center gap-2"><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-accent-2"><line x1="21" y1="10" x2="3" y2="10"/><line x1="21" y1="6" x2="3" y2="6"/><line x1="21" y1="14" x2="3" y2="14"/><line x1="21" y1="18" x2="3" y2="18"/></svg>
目录</h4><button id=mobileTocCloseBtn class="p-1 text-slate-500 hover:text-slate-900 dark:hover:text-slate-100 transition-colors">
<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="18" y1="6" x2="6" y2="18"/><line x1="6" y1="6" x2="18" y2="18"/></svg></button></div><nav class="toc text-sm leading-relaxed [&_a]:block [&_a]:py-1.5 [&_li]:my-1"><nav id=TableOfContents><ul><li><a href=#31-what-are-tools>3.1 What are tools?</a></li><li><a href=#32-creating-a-tool>3.2 Creating a tool</a></li><li><a href=#33-tool-syntax>3.3 Tool syntax</a></li><li><a href=#34-code-execution>3.4 Code execution</a></li><li><a href=#35-mcp>3.5 MCP</a></li></ul></nav></nav></div><button id=mobileTocToggleBtn class="w-full max-w-md bg-white/90 dark:bg-black/90 backdrop-blur-md border border-slate-200 dark:border-white/10 shadow-lg rounded-full px-5 py-3 flex items-center justify-between text-sm font-medium hover:bg-slate-50 dark:hover:bg-white/5 transition-all active:scale-[0.98]" aria-controls=mobileTocPanel aria-expanded=false aria-label="Toggle Table of Contents"><div class="flex items-center overflow-hidden mr-4"><div class="bg-slate-100 dark:bg-white/10 p-1.5 rounded-full mr-3 shrink-0"><svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-slate-900 dark:text-slate-100"><line x1="8" y1="6" x2="21" y2="6"/><line x1="8" y1="12" x2="21" y2="12"/><line x1="8" y1="18" x2="21" y2="18"/><line x1="3" y1="6" x2="3.01" y2="6"/><line x1="3" y1="12" x2="3.01" y2="12"/><line x1="3" y1="18" x2="3.01" y2="18"/></svg></div><span id=mobileTocCurrentHeading class="truncate text-slate-900/90 dark:text-slate-100/90 font-medium text-left">目录</span></div><div id=mobileTocChevron class="text-slate-500 shrink-0 transition-transform duration-200"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 18l6-6-6-6"/></svg></div></button></div></main><script src="/script.js?v=20260121-05" defer></script><script defer src="/js/search-core.js?v=20260121-05"></script><script>window.SEARCH_INDEX_URL_LITE="/index-lite.json?v=20260121-05",window.SEARCH_INDEX_URL="/index.json?v=20260121-05"</script><script src="/js/search-advanced.js?v=20260121-05" defer></script><script defer src="/js/table-7char.js?v=20260121-05"></script><script defer src="/js/linkcard.js?v=20260121-05"></script><script defer src="/js/table-tooltips.js?v=20260121-05"></script><script defer src="/js/social-popup.js?v=20260121-05"></script><div id=social-popup-overlay aria-hidden=true class="fixed inset-0 z-[200] bg-black/60 backdrop-blur-sm flex items-center justify-center opacity-0 pointer-events-none transition-opacity duration-300"><div class="social-popup-card bg-surface p-6 rounded-2xl shadow-2xl max-w-sm w-[90%] relative transform scale-95 transition-transform duration-300" role=dialog aria-modal=true aria-labelledby=social-popup-title aria-describedby=social-popup-desc><button class="social-popup-close absolute top-3 right-3 p-2 rounded-full bg-muted/10 hover:bg-muted/20 text-muted transition-colors" type=button aria-label=关闭>×</button>
<img class="social-popup-image w-full h-auto rounded-lg mb-4" src alt><div class="social-popup-title text-xl font-semibold text-text mb-2" id=social-popup-title></div><div class="social-popup-desc text-sm text-muted" id=social-popup-desc></div></div></div></body></html>