<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>深度学习 on Linguista</title>
    <link>https://linguage.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 深度学习 on Linguista</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Thu, 01 Jan 1970 08:33:39 +0800</lastBuildDate>
    <atom:link href="https://linguage.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>苦涩的教训</title>
      <link>https://linguage.github.io/essays/bitter-lesson/</link>
      <pubDate>Thu, 01 Jan 1970 08:33:39 +0800</pubDate>
      <guid>https://linguage.github.io/essays/bitter-lesson/</guid>
      <description>&lt;p&gt;本文是里奇·萨顿（Richard Sutton）2019年著名文章《The Bitter Lesson（苦涩的教训）》。&lt;/p&gt;&#xA;&lt;!---more---&gt;&#xA;&lt;h2 id=&#34;中文版&#34;&gt;中文版&lt;/h2&gt;&#xA;&lt;p&gt;从70年的人工智能研究中能够读出的最大教训是，利用计算力的通用方法最终是最有效的，而且优势巨大。&lt;/p&gt;&#xA;&lt;p&gt;其根本原因是摩尔定律，或者更准确地说，是计算单位成本持续呈指数级下降这一普遍规律。&lt;/p&gt;&#xA;&lt;p&gt;大多数人工智能研究都是在假设智能体可用的计算力是恒定的前提下进行的（在这种情况下，利用人类知识是提升性能的唯一途径之一）。但是，在比典型研究项目稍长的时间内，必然会有大量更多的计算力变得可用。&lt;/p&gt;&#xA;&lt;p&gt;为寻求在短期内产生差异的改进，研究人员试图利用他们对领域的人类知识，但从长远来看，唯一重要的是对计算力的利用。这两者并不一定彼此矛盾，但在实践中经常如此。花在一方面的时间就是没有花在另一方面的时间，对某种方法的投入还会带来心理上的承诺。而且基于人类知识的方法往往会使方法变得复杂，使其不太适合利用计算力的通用方法。&lt;/p&gt;&#xA;&lt;p&gt;有许多人工智能研究人员迟来地学到这个苦涩教训的例子，回顾其中一些最突出的例子是很有启发性的。&lt;/p&gt;&#xA;&lt;p&gt;在计算机国际象棋中，1997年击败世界冠军卡斯帕罗夫的方法是基于大规模的深度搜索。当时，大多数计算机国际象棋研究人员对此感到沮丧，他们一直在追求利用人类对国际象棋特殊结构理解的方法。当一个更简单的、基于搜索的方法配合专门的硬件和软件被证明更加有效时，这些基于人类知识的国际象棋研究人员并不是优雅的失败者。他们说“暴力”搜索这次可能赢了，但这不是一个通用策略，而且也不是人类下棋的方式。这些研究人员希望基于人类输入的方法能够获胜，当它们没有获胜时，他们感到失望。&lt;/p&gt;&#xA;&lt;p&gt;在计算机围棋中也出现了类似的研究进展模式，只是延迟了20年。最初的巨大努力都投入到通过利用人类知识或游戏的特殊特征来避免搜索。但一旦搜索在规模上得到有效应用，所有这些努力都被证明是无关紧要的，甚至更糟。同样重要的是使用自我对弈学习来学习价值函数（在许多其他游戏甚至国际象棋中也是如此，尽管学习在1997年首次击败世界冠军的程序中并没有发挥重要作用）。自我对弈学习，以及一般的学习，就像搜索一样，它使得大规模计算力得以发挥作用。搜索和学习是人工智能研究中利用大量计算力的两类最重要的技术。在计算机围棋中，就像在计算机国际象棋中一样，研究人员最初的努力是利用人类的理解（这样就需要更少的搜索），只有在很久以后，通过拥抱搜索和学习才取得了更大的成功。&lt;/p&gt;&#xA;&lt;p&gt;在语音识别中，20世纪70年代有一场由DARPA赞助的早期竞赛。参赛者包括许多利用人类知识的特殊方法——关于单词、音素、人类声道等的知识。另一方面是更具统计性质的新方法，它们基于隐马尔可夫模型（HMMs）进行更多的计算。再一次，统计方法战胜了基于人类知识的方法。这导致了整个自然语言处理领域的重大变化，在几十年的时间里逐渐地，统计和计算开始主导这个领域。深度学习在语音识别中的最近兴起是这个一致方向上的最新一步。深度学习方法更少依赖人类知识，使用更多的计算，结合在庞大训练集上的学习，产生了显著更好的语音识别系统。&lt;/p&gt;&#xA;&lt;p&gt;就像在游戏中一样，研究人员总是试图制造按照他们认为自己思维方式工作的系统——他们试图将那些知识放入他们的系统中——但这最终被证明是适得其反的。当通过摩尔定律，大规模计算变得可用并找到了充分利用它的方法时，这是研究人员时间的巨大浪费。&lt;/p&gt;&#xA;&lt;p&gt;在计算机视觉中，也有类似的模式。早期方法将视觉理解为搜索边缘、广义圆柱体，或者用SIFT特征来理解。但今天所有这些都被抛弃了。现代深度学习神经网络只使用卷积和某些不变性的概念，表现要好得多。&lt;/p&gt;&#xA;&lt;p&gt;这是一个重要的教训。作为一个领域，我们仍然没有彻底学会它，因为我们还在继续犯同样的错误。要看到这一点，并有效地抵制它，我们必须理解这些错误的吸引力。我们必须学会这个苦涩的教训：将我们认为自己如何思考的方式内置进去，从长远来看是行不通的。&lt;/p&gt;&#xA;&lt;p&gt;苦涩的教训基于历史观察：&lt;/p&gt;&#xA;&lt;p&gt;1）人工智能研究人员经常试图将知识构建到他们的智能体中。&#xA;2）这在短期内总是有帮助的，并且对研究人员个人来说是令人满意的。&#xA;3）从长远来看，它会达到瓶颈，甚至阻碍进一步的进展，&#xA;4）突破性进展最终通过基于搜索和学习扩展计算的相反方法到来。&lt;/p&gt;&#xA;&lt;p&gt;最终的成功带有苦涩，而且往往没有完全消化，因为这是对受青睐的、以人为中心的方法的胜利。&lt;/p&gt;&#xA;&lt;p&gt;从苦涩的教训中应该学到的一件事是通用方法的巨大力量，这些方法即使在可用计算变得非常庞大时，仍能随着计算的增加而继续扩展。似乎能以这种方式任意扩展的两种方法是搜索和学习。&lt;/p&gt;&#xA;&lt;p&gt;从苦涩的教训中要学到的第二个要点是，思维的实际内容是极其、无可救药地复杂的；我们应该停止试图找到思考思维内容的简单方法，比如思考空间、对象、多个智能体或对称性的简单方法。所有这些都是任意的、内在复杂的外部世界的一部分。它们不应该被内置，因为它们的复杂性是无穷无尽的；相反，我们应该只内置能够发现和捕获这种任意复杂性的元方法。这些方法的关键是它们能够找到好的近似，但对它们的搜索应该由我们的方法来完成，而不是由我们来完成。我们想要的是能够像我们一样发现的人工智能智能体，而不是包含我们已经发现的东西的智能体。内置我们的发现只会让我们更难看清发现过程是如何完成的。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;english-version&#34;&gt;English Version&lt;/h2&gt;&#xA;&lt;p&gt;The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin.&lt;/p&gt;&#xA;&lt;p&gt;The ultimate reason for this is Moore&amp;rsquo;s law, or rather its generalization of continued exponentially falling cost per unit of computation.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
