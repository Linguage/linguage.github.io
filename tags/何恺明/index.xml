<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>何恺明 on Linguista</title><link>https://linguista.cn/tags/%E4%BD%95%E6%81%BA%E6%98%8E/</link><description>Recent content in 何恺明 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 04 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E4%BD%95%E6%81%BA%E6%98%8E/index.xml" rel="self" type="application/rss+xml"/><item><title>从机器学习模型的视角看机器学习研究</title><link>https://linguista.cn/curated/henrinotes-2025/kaiming-he-ml-research-from-model-perspective/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025/kaiming-he-ml-research-from-model-perspective/</guid><description>&lt;h1 id="从机器学习模型的视角看机器学习研究"&gt;从机器学习模型的视角看机器学习研究&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;何恺明教授在 NeurIPS 2024 NewInML Workshop 上发表演讲，从机器学习模型自身的视角出发，通过四个生动类比来阐释机器学习研究的本质与方向。这四个类比分别是：研究如同随机梯度下降、研究的目标是寻找&amp;quot;惊喜&amp;quot;、未来是真正的测试集、以及研究需要具备可扩展性。演讲深刻揭示了研究过程中的不确定性、探索性与长远价值。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;何恺明教授的这次演讲以一种独特的视角切入——用机器学习自身的概念和框架来审视机器学习研究本身。这种&amp;quot;元认知&amp;quot;式的思考方式，不仅展现了深刻的学术洞察力，也为研究者提供了一套理解和反思自身工作的思维工具。&lt;/p&gt;
&lt;p&gt;演讲的核心结构围绕四个类比展开。第一个类比将研究过程比作在非凸损失函数上执行随机梯度下降（SGD），强调研究中充满噪声和不确定性，大学习率代表快速探索新领域，小学习率则代表在已知方向上深入挖掘。第二个类比指出，机器学习模型追求的是期望收益的最大化，而研究的真正价值在于发现那些挑战现有认知的&amp;quot;惊喜&amp;quot;。&lt;/p&gt;
&lt;p&gt;第三个类比提出&amp;quot;未来是真正的测试集&amp;quot;这一深刻观点，提醒研究者警惕对当前基准和评估体系的&amp;quot;过拟合&amp;quot;，真正有价值的研究应当经得起未来的检验。第四个类比则聚焦于可扩展性，随着计算能力的持续提升，研究工作是否具备良好的扩展规律，将决定其长期影响力。&lt;/p&gt;
&lt;p&gt;整体而言，演讲通过这些精妙的类比，鼓励研究者在探索中保持开放心态，关注研究的长远价值与实际应用，而非仅仅追求短期的指标提升。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;研究即随机梯度下降&lt;/strong&gt;：何恺明将研究过程比作 SGD 在非凸损失函数中的优化过程。研究充满不确定性和噪声，每一次实验就像一步梯度更新。大学习率意味着敢于跳出舒适区探索全新方向，小学习率则意味着在有前景的方向上精细打磨。这个类比提醒研究者，既要有勇气进行大胆探索，也要有耐心做深入研究，二者的平衡至关重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;寻找&amp;quot;惊喜&amp;quot;而非期望&lt;/strong&gt;：机器学习模型以最大化期望收益为目标，但研究的突破往往来自于那些违反直觉、挑战常识的意外发现。这些&amp;quot;惊喜&amp;quot;可能最初只是偶然观察到的异常现象，但经过严谨验证后，可能颠覆现有理论，成为未来新范式的基石。这一类比鼓励研究者重视实验中的异常结果，而非简单忽略或丢弃。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;未来作为测试集&lt;/strong&gt;：在机器学习中，模型的真正能力体现在从未见过的测试数据上的表现。类似地，研究成果的真正价值取决于其对未来的影响力，而非仅仅在当前基准上的分数。研究者需要警惕对现有评估体系的&amp;quot;过拟合&amp;quot;——即过度针对特定数据集或指标进行优化，而忽视了方法的普适性和鲁棒性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;研究的可扩展性&lt;/strong&gt;：随着算力和数据规模的持续增长，研究方法是否具备良好的扩展规律（Scaling Law）变得愈发重要。一个在小规模上表现优异但无法扩展的方法，其长期价值可能有限。理解并利用扩展规律，有助于研究者将工作聚焦于那些能够随技术发展而持续受益的方向，从而在快速演进的领域中保持竞争力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;探索与利用的平衡&lt;/strong&gt;：贯穿整个演讲的一个隐含主题是研究中&amp;quot;探索&amp;quot;与&amp;quot;利用&amp;quot;的平衡问题。这与强化学习中的经典难题一脉相承——何时应该探索全新的未知方向，何时应该深入利用已知的有效路径。何恺明的四个类比从不同角度回应了这一根本问题，为研究者提供了多维度的思考框架。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/QtfAJ-I5KZfWSBmCwEam3A"&gt;何恺明 NeurIPS 2024 Talk 分享&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;何恺明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年12月27日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;会议&lt;/td&gt;
 &lt;td&gt;NeurIPS 2024 NewInML Workshop&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;论文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://people.csail.mit.edu/kaiming/neurips2024workshop/neurips2024_newinml_kaiming.pdf"&gt;PDF链接&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>