<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AGI on Linguista</title><link>https://linguista.cn/tags/agi/</link><description>Recent content in AGI on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 23 Jan 2026 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/agi/index.xml" rel="self" type="application/rss+xml"/><item><title>AGI NEXT：范式裂变与中国机遇</title><link>https://linguista.cn/static/china-agi-next-chat-20260111-thu/</link><pubDate>Fri, 23 Jan 2026 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/china-agi-next-chat-20260111-thu/</guid><description>2026年初闭门圆桌讨论AGI的范式裂变与中国机遇。核心议题包括：硅谷与中国AI生态分化、ToB与ToC价值分野、从Scaling Law到自主进化、智能效率突围、长时程Agent、产学边界消融，以及中国在20%概率下的超越可能。</description></item><item><title>Most Books Should Be Skimmed, A Few Should Be Devoured</title><link>https://linguista.cn/naval/orig/most-books-should-be-skimmed-a-few-should-be-devoured/</link><pubDate>Fri, 26 Sep 2025 22:05:38 +0000</pubDate><guid>https://linguista.cn/naval/orig/most-books-should-be-skimmed-a-few-should-be-devoured/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/zh/most-books-should-be-skimmed-a-few-should-be-devoured.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/get"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/get"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/get
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="most-books-should-be-skimmed-a-few-should-be-devoured"&gt;Most Books Should Be Skimmed, A Few Should Be Devoured&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Sep 26 2025&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Nivi:&lt;/strong&gt; For the state of the art on the philosophy of knowledge, which people call &lt;strong&gt;epistemology&lt;/strong&gt;, you can basically skip everything and jump straight to &lt;strong&gt;David Deutsch&lt;/strong&gt;.&lt;/p&gt;</description></item><item><title>OpenAI联合创始人Ilya Sutskever深度解读AI现状与未来</title><link>https://linguista.cn/curated/henrinotes-2025_p2/ilya-sutskever-ai-future-superalignment/</link><pubDate>Sat, 27 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/ilya-sutskever-ai-future-superalignment/</guid><description>&lt;h1 id="openai联合创始人ilya-sutskever深度解读ai现状与未来"&gt;OpenAI联合创始人Ilya Sutskever深度解读AI现状与未来&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本期No Priors节目邀请OpenAI联合创始人兼首席科学家Ilya Sutskever，与主持人Sarah Guo和Elad Gil共同探讨人工智能的演进脉络与未来图景。对话从深度学习的早期困境切入，系统梳理了OpenAI的创立初心与有限利润模式的设计逻辑，深入剖析GPT模型从1到3的规模跃迁与涌现行为，并围绕模型可靠性、小模型局限、开源边界等实践问题展开讨论。Sutskever进一步类比生物智能与数字生命，强调超级对齐在AGI时代的必要性，并分享了规模驱动的AI研发框架与心智模型。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;访谈始于AI研究的早期困境。Sutskever回忆了前AlexNet时代神经网络被边缘化的灰暗阶段，指出真正的突破源于GPU算力、大规模网络直觉与算法优化的三者结合。团队通过将大规模卷积神经网络应用于视觉识别，完成了从学术质疑到工程实证的转折，而初期目标不过是把模型做大、看能成就什么。&lt;/p&gt;
&lt;p&gt;OpenAI的创立始终围绕让AGI造福全人类的使命。Sutskever解释了从非营利组织转向有限利润模式的战略考量：AGI一旦出现可能重塑社会根基，若由单一公司无限获利将带来伦理风险。限定投资回报倍数意在削弱纯粹利益诱惑，强化技术使命感，同时也解决了非营利路径在算力和资金上的瓶颈。&lt;/p&gt;
&lt;p&gt;在模型演进上，OpenAI从Dota 2的端到端学习转向大规模Transformer的文本预测路线。GPT-2到GPT-3的规模跃迁带来了链式推理等涌现能力，Sutskever称之为整体效果的出现与被理解的感觉。他强调，模型规模变大的最大收益在于可靠性——从稳定回答到极低失误率，这正是自动驾驶等高风险场景的关键要求。小模型虽推理成本低，但难以保证长期可靠，未来将形成多层模型生态，小模型做领域应用，大模型承担高门槛任务。&lt;/p&gt;
&lt;p&gt;关于开源角色，Sutskever持审慎态度：短期看开源推动创新与应用多样化，长期则需警惕能力边界开放后的不可预期后果。他类比生物大脑的可塑性，认为统一架构在AI世界同样可行，真正的数字生命关键在于高度自治，而当前AI尚未达到此标准。&lt;/p&gt;
&lt;p&gt;超级对齐是应对未来超级智能的核心命题。Sutskever指出，超级智能可能在数据中心中孕育，带来极端不确定性，因此必须提前投入研究，让AI保持以人为本的价值印记。这不是梦幻主义，而是需要科学界、工程界和社会共同认清现实进程、主动推动价值观嵌入的责任。AI的加速取决于算力、数据、工程、资金等多因素平衡，减速则源于数据瓶颈与系统复杂性，未来进步将在拉锯中前行。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;有限利润模式（Capped Profit）&lt;/strong&gt;：OpenAI为平衡AGI使命与资金需求而设计的制度创新。通过限定投资回报倍数，削弱纯利润驱动，强化技术普惠与伦理约束。这一模式承认AGI可能对社会根基产生深远影响，避免单一公司因无限获利而偏离人类整体利益，同时为大规模算力需求提供资金保障。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;涌现行为（Emergence）&lt;/strong&gt;：模型在规模跃迁时呈现的预期之外能力，如GPT-2到GPT-3出现的链式推理。Sutskever称之为整体效果的出现，反映了神经网络在大规模数据与参数下从量变到质变的临界现象。涌现能力的不可预测性既是惊喜也是风险，要求在扩大规模时持续观察与评估。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;超级对齐（Superalignment）&lt;/strong&gt;：面向超级智能时代的价值对齐方案，目标是让比人类更聪明的AI系统保持以人为本的价值印记。Sutskever强调这不会自动出现，而是需要科学家、工程师和社会角色共同参与，在未来5到10年的能力演进中主动推动价值观注入与演化。这是AI安全在超级智能阶段的终极挑战，也是不可回避的责任。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规模驱动的AI研发框架&lt;/strong&gt;：现代AI进步的核心范式，以统一神经网络架构、大规模数据集和强大算力为三大支柱。流程上放弃过度依赖理论证明，敢于用工程手段验证规律；寻找可扩展架构并持续加大规模；以实验和迭代为中心，先训练看结果再逆向理解机理。该框架要求研究者具备大胆假设、小心求证、不断迭代的心智模型，同时对可控性与可靠性保持警觉。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性（Reliability）&lt;/strong&gt;：模型规模变大的最大收益点，定义为在连续多次交互中保持准确回答、避免巨大失误的能力。Sutskever以自动驾驶为例，说明高风险场景要求极低失误率，而小模型因推理成本限制难以保证长期可靠。未来生态将是小模型处理领域任务、大模型承担高门槛风险的分层格局，应用场景越复杂，对模型规模要求越高。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Ft0gTO2K85A"&gt;No Priors Ep. 39 | With OpenAI Co-Founder &amp;amp; Chief Scientist Ilya Sutskever&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;No Priors Podcast&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-27&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>山姆·奥特曼与Vinod Khosla深谈AI前沿与AGI未来</title><link>https://linguista.cn/curated/henrinotes-2025-p1/sam-altman-khosla-ai-future-agi-society/</link><pubDate>Sat, 13 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/sam-altman-khosla-ai-future-agi-society/</guid><description>&lt;h1 id="山姆奥特曼与vinod-khosla深谈ai前沿与agi未来"&gt;山姆·奥特曼与Vinod Khosla深谈AI前沿与AGI未来&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文整理自OpenAI CEO山姆·奥特曼与知名投资人Vinod Khosla于2025年9月的深度对谈。两人围绕AI从聊天机器人迈向通用人工智能（AGI）的技术跃迁展开讨论，涵盖未来企业形态演变、职业替代与新生、创业投资范式转移、社会公平与财富分配、政府角色与全球协作等核心议题。核心结论是AI变革速度将超乎想象，社会需在价值观、制度和个人能力层面持续适应与创新。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次对谈以&amp;quot;AI将把我们带向何方&amp;quot;为主线，从技术演进、商业重构、社会治理三个维度展开。奥特曼认为ChatGPT的发布是AI&amp;quot;从零到一&amp;quot;的震撼时刻，而后续向AGI的跃迁虽然技术跨度更大，但社会已逐渐适应这种预期。未来AI系统将具备持续学习和自我进化能力，推动科研与产业创新进入指数级加速通道。&lt;/p&gt;
&lt;p&gt;在企业与商业层面，两人描绘了一个&amp;quot;10人团队创造十亿美元收入&amp;quot;的新型企业图景。AI将率先变革软件行业，&amp;ldquo;任何你想要的软件都能即时生成&amp;rdquo;，SaaS模式面临根本性颠覆。奥特曼分享了OpenAI自身从研究实验室到产品公司的转型历程，强调产品哪怕初期仅有极低留存率，也可能成为未来变革的种子。&lt;/p&gt;
&lt;p&gt;在社会影响层面，对谈深入讨论了AI对高智力职业的替代可能性，同时指出人类在情感交流和关怀方面的独特价值难以被AI取代。在资源分配问题上，奥特曼认为&amp;quot;让算力极大丰富&amp;quot;是唯一持久的解决方案，政府需承担基础设施建设和规则制定的责任，推动AI红利向全社会普及。&lt;/p&gt;
&lt;p&gt;两人还就创业者如何应对极端不确定性给出了务实建议：默认AI模型每年进步10倍，不要试图预测哪一点会停滞，而应将精力集中于新机会窗口。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI非线性跃迁与指数型进化&lt;/strong&gt;：奥特曼提出理解AI发展的根本范式是&amp;quot;指数型进化&amp;quot;，建议在个人和组织决策中默认AI能力以年均10倍速度自我加强，放弃线性预测思维。从ChatGPT到AGI的过程并非匀速推进，而是由更好的算法、更大的算力和更多优质数据三股力量共同驱动的加速过程，最终实现AI自主提出假设、验证并自我提升的闭环。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人机共同加速模型（Joint Acceleration）&lt;/strong&gt;：这一路径描述了AI与人类协作的演化方向——初期AI辅助科学家和工程师，逐渐过渡到AI独立提出并验证假设。衡量标准不是人与AI的工作占比，而是科研创新速率的整体提升。这意味着企业和研究机构应建立弹性架构，能够快速集成AI新工具并适配未知的加速节奏。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI后的新价值空间&lt;/strong&gt;：奥特曼明确告诫资本和创业者&amp;quot;不要追逐上一个AI赢家&amp;quot;，而应专注于&amp;quot;AI普及后诞生的全新价值空间&amp;quot;。核心思路不是成为&amp;quot;下一个OpenAI&amp;quot;，而是发现因为AGI存在才被激发出来的全新业态。这一观点重新定义了AI时代的创业逻辑——真正的机会在于AGI所开启的可能性边界之外。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算力作为新时代公平的关键基础设施&lt;/strong&gt;：在AI红利分配问题上，奥特曼将&amp;quot;算力&amp;quot;定位为新的稀缺资源，认为唯一持久的解决方案是让算力极大丰富。如果算力资源集中在少数国家或企业手中，全球社会将面临严重的分配失衡。因此政府应承担平台与规则塑造责任，在电力、数据中心等基础设施领域加大投入。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人类不可替代的情感与创造价值&lt;/strong&gt;：尽管AI在智力任务上的能力日益强大，奥特曼强调人类对他人关照和情感交流的本能需求很难被完全替代。一位真人教师对学生的激励效果远超算法教师。个人职业发展应聚焦于人类独特的情感、创造与共情能力，同时主动学习AI工具来优化生产力和创新能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=6NwK-uq16U8"&gt;Where is AI Taking Us? | Sam Altman &amp;amp; Vinod Khosla&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Khosla Ventures&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-08&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AI未来深谈 | 山姆·奥特曼 × Vinod Khosla</title><link>https://linguista.cn/static/ai_future_magazine/</link><pubDate>Thu, 11 Sep 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/ai_future_magazine/</guid><description>在这场关于 AGI 未来的深度对话中，山姆·奥特曼与 Vinod Khosla 探讨了人工智能将在未来十年内如何重塑软件世界，以及十年后对实体世界的深远变革。他们预测，企业的适应性将成为生存关键，小规模团队将有能力创造巨大的经济价值，而人类在情感与关怀领域的独特价值将变得愈发珍贵。</description></item><item><title>科赫联合创始人Nick Frosst如何在OpenAI与Anthropic夹缝中竞争</title><link>https://linguista.cn/curated/henrinotes-2025_p2/cohere-nick-frosst-compete-openai-anthropic/</link><pubDate>Thu, 04 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/cohere-nick-frosst-compete-openai-anthropic/</guid><description>&lt;h1 id="科赫联合创始人nick-frosst如何在openai与anthropic夹缝中竞争"&gt;科赫联合创始人Nick Frosst：如何在OpenAI与Anthropic夹缝中竞争&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文是20VC播客对Cohere联合创始人Nick Frosst的深度访谈。作为前谷歌大脑研究员，Nick坦率剖析了Cohere如何在OpenAI、Anthropic等巨头夹缝中找到生存空间——专注企业级AI应用，强调ROI和实际价值而非AGI幻想。他批评Sam Altman过度渲染AI威胁，质疑规模化定律，主张AI应成为提升生产力的工具而非取代人类的魔法。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先介绍了Cohere的核心定位：与OpenAI、Anthropic一样致力于基础大模型研发，但独特聚焦企业客户市场。Nick强调Cohere通过让模型熟悉企业内部工具API、流程和数据集成，真正帮助企业解决工作中的实际问题。在训练策略上，Cohere大量采用合成数据来模拟企业真实场景，同时依赖人类注释者生产高质量数据以应对行业数据瓶颈。&lt;/p&gt;
&lt;p&gt;接着Nick深入分析了AI发展的&amp;quot;三大支柱&amp;quot;：算力、数据和算法。他直言算法创新趋缓，算力提升不再是唯一动力，真正卡脖子的是如何获取足够多的高质量、能直接应用于具体任务的数据。他对&amp;quot;规模化定律&amp;quot;提出鲜明质疑，认为单纯砸算力并非持续进步的灵药。Nick批评Sam Altman四处宣扬AI威胁论是&amp;quot;学术上不严谨，实际上伤害了AI技术本身&amp;quot;。&lt;/p&gt;
&lt;p&gt;在产品策略上，Nick指出当前大模型评测基准普遍浮夸脱离实际，企业客户从不关心模型能否解数学题，而在乎能否自动化日常办公任务。Cohere将核心能力定位在训练与部署效率上，只需两块GPU即可运行，大大降低企业落地门槛。面对人才争夺，Nick认为顶薪固然重要，但真正留住人才的是有意义的工作环境和文化认同。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;合成数据&lt;/strong&gt;：Cohere采用的核心训练策略，通过模拟公司内部邮件、API调用等日常流程生成针对性强的训练集。这既补足了企业真实数据的瓶颈，也提升了模型与实际场景的贴合度。Nick认为高质量数据依然是行业核心难题，合成数据是务实解决方案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;务实主义企业观&lt;/strong&gt;：与其沉溺于与OpenAI、Anthropic的直接竞争，不如专注解决客户实际问题。企业家应建立独特价值主张，坚持自己的主航道。Nick强调真正的竞争不是融资额最大，而是谁最懂客户、最能把AI落地到客户场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;效率优先框架&lt;/strong&gt;：Cohere团队处处追求最优成本效能，不断优化模型结构与推理引擎，让企业客户能低成本部署。与消费级AI不同，企业级AI是否有用的唯一标准是能否提升企业效率和收益，而不是模型是否更像人。Nick主张放下对分数排名的执着，专心倾听客户痛点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI批判&lt;/strong&gt;：Nick对AGI炒作持强烈批评态度，认为Sam Altman的AI威胁论是行业误导。他指出AGI定义含糊，大多数人对何为AGI并无清晰标准。真正需要警惕的是AI在职场带来的结构性分化和收入不均，应通过政策和教育管控而非妄想阻止技术进步。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半开放路线&lt;/strong&gt;：Cohere选择中间路线，自研模型权重完全开放用于科研和非商用，企业商用则需洽谈合作。这既争取AI生态社区认可，也保障自身商业化安全。Nick预测未来AI基础设施会更像国家级底座，各国必然推动主权模型以确保技术自主可控。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Sw2chzwWLbQ"&gt;Cohere Founder, Nick Frosst: How To Compete with OpenAI &amp;amp; Anthropic, and Sam Altman&amp;rsquo;s AI Disservice&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;20VC with Harry Stebbings&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-04&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AGI已成伪命题？Sam Altman与专家对通用人工智能概念的再思考</title><link>https://linguista.cn/curated/henrinotes_2025_p3/agi-meaningless-term-sam-altman-rethink/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/agi-meaningless-term-sam-altman-rethink/</guid><description>&lt;h1 id="agi已成伪命题sam-altman与专家对通用人工智能概念的再思考"&gt;AGI已成伪命题？Sam Altman与专家对&amp;quot;通用人工智能&amp;quot;概念的再思考&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;OpenAI CEO Sam Altman在CNBC采访中直言，AGI（人工通用智能）已&amp;quot;不是一个特别有用的术语&amp;quot;。本文结合多位计算机科学专家的观点，深入探讨AGI定义的模糊性、行业内外对其的不同解读，以及为何越来越多的业内人士认为，与其执着于&amp;quot;AGI&amp;quot;这一模糊目标，不如关注AI在各专业领域的实际进展。文章同时梳理了OpenAI最新发布的GPT-5模型的市场反响，以及行业对AI发展路径的理性反思。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先围绕Sam Altman在CNBC&amp;quot;Squawk Box&amp;quot;节目中的言论展开，他坦言AGI这一概念在当前的技术讨论中已经失去了实际意义。AGI通常被定义为&amp;quot;能够完成任何人类智力任务的人工智能&amp;quot;，但Altman指出，业界和学界对AGI的定义各不相同，有人将其理解为&amp;quot;能完成世界上大量工作的AI&amp;quot;，而&amp;quot;工作&amp;quot;的内涵本身在不断变化，这使得AGI的标准变得愈发模糊。他强调，AI能力的提升是一个持续的、指数级的过程，社会将越来越多地依赖AI完成各类任务，与其纠结于&amp;quot;是否达到AGI&amp;quot;，不如关注AI能力的实际扩展和应用。&lt;/p&gt;
&lt;p&gt;这一观点得到了多位专家的认同。The Futurum Group副总裁Nick Patience认为，AGI虽然是一个激励人心的&amp;quot;北极星&amp;quot;，但其模糊、科幻色彩浓厚的定义，反而掩盖了AI在专业领域的真实进展。他指出，AGI概念更多地被用来吸引资金和公众关注，而非推动技术本身的落地。事实上，OpenAI等初创公司正是凭借&amp;quot;终将实现AGI&amp;quot;的承诺，获得了数十亿美元的投资和高估值，OpenAI最近一次估值高达3000亿美元。&lt;/p&gt;
&lt;p&gt;文章进一步分析了资本炒作与技术现实之间的落差。2025年8月，OpenAI发布了最新的GPT-5模型，声称其在写作、编程、医疗健康等领域&amp;quot;更聪明、更快、更有用&amp;quot;，但市场反应褒贬不一，许多评论认为这只是对前代产品的&amp;quot;渐进式升级&amp;quot;，并未带来革命性突破。南安普顿大学计算机科学教授Wendy Hall批评当前行业&amp;quot;如同蛮荒西部&amp;quot;，缺乏统一的衡量标准，容易滋生虚假宣传。她呼吁AI公司在发布新产品时应公开其在全球公认标准下的表现指标。&lt;/p&gt;
&lt;p&gt;最后，Altman提出了一种新的思考框架。他坦言，OpenAI最新模型尚未达到他个人对AGI的定义——即系统能够自主、持续学习。他认为，与其用&amp;quot;是否AGI&amp;quot;这种二元划分，不如用&amp;quot;能力层级&amp;quot;来描述AI距离&amp;quot;通用智能&amp;quot;还有多远。在2024年FinRegLab AI Symposium上，Altman表示，OpenAI现在更倾向于用不同的&amp;quot;能力层级&amp;quot;来衡量AI进展。他预测，未来两年内，AI将在某些专业领域（如数学定理、科学发现）实现关键突破，但距离真正意义上的&amp;quot;通用智能&amp;quot;仍有距离。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI定义的模糊性&lt;/strong&gt;：AGI（人工通用智能）通常被定义为&amp;quot;能够完成任何人类智力任务的人工智能&amp;quot;，但这一概念在实践中缺乏清晰的边界。Sam Altman指出，业界对AGI的理解各不相同——有人将其理解为能够完成&amp;quot;世界上大量工作&amp;quot;的AI，但&amp;quot;工作&amp;quot;的内涵本身在不断演进，这使得AGI的标准变得愈发主观和模糊。这种定义上的不一致，导致技术讨论常常陷入无谓的争论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能力层级 vs. 二元划分&lt;/strong&gt;：Altman提出，AI的发展应该用&amp;quot;能力层级&amp;quot;（progress levels）来衡量，而不是&amp;quot;是否达到AGI&amp;quot;这种非黑即白的标准。每一代AI模型都在某些领域实现了突破，行业应该关注这些具体进展，而非执着于一个模糊的终极目标。这种框架转变反映了业界对AI发展的更理性、更务实的态度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;北极星 vs. 分散注意力的噱头&lt;/strong&gt;：专家们对AGI概念的价值存在分歧。Nick Patience认为，AGI可以作为一个激励行业前行的&amp;quot;北极星&amp;quot;，但其过度炒作和模糊定义，反而使其成为&amp;quot;分散注意力的噱头&amp;quot;，主要被用来吸引巨额融资。这种炒作现象分散了公众和投资者对AI实际能力和应用价值的关注。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;蛮荒西部与蛇油推销&lt;/strong&gt;：南安普顿大学教授Wendy Hall用&amp;quot;蛮荒西部&amp;quot;来形容当前AI行业缺乏统一标准的现状。她批评行业中存在&amp;quot;蛇油推销&amp;quot;（snake oil salesmen）现象，即公司通过夸大宣传来吸引投资和用户。她呼吁建立全球公认的评估标准，让AI产品的表现能够被客观衡量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;专业突破 vs. 通用智能&lt;/strong&gt;：Altman预测，未来两年内，AI将在某些专业领域（如数学定理证明、科学发现）实现关键突破，但距离真正意义上的&amp;quot;通用智能&amp;quot;仍有距离。这一判断与许多专家的观点一致——AI的真正价值在于其在各专业领域的落地能力，而非追求一个遥不可及的&amp;quot;通用&amp;quot;目标。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.cnbc.com/2025/08/11/sam-altman-says-agi-is-a-pointless-term-experts-agree.html"&gt;Sam Altman now says AGI, or human-level AI, is &amp;rsquo;not a super useful term&amp;rsquo; — and he&amp;rsquo;s not alone&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;CNBC&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-11&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Demis Hassabis专访 从游戏AI到世界模型 AGI进化的真实路径</title><link>https://linguista.cn/curated/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</guid><description>&lt;h1 id="demis-hassabis专访从游戏ai到世界模型agi进化的真实路径"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Google DeepMind CEO Demis Hassabis在《Release Notes》播客中系统梳理了从游戏AI到思考型模型、世界模型的技术演进。他分享了DeepMind如何通过Genie 3等项目推动AI理解现实世界，阐述了&amp;quot;多模态+工具+系统&amp;quot;的AGI路径，并介绍了以Kaggle Game Arena为代表的新型AI评测体系。Demis强调，未来AI不仅要能感知和输出，更要具备深度思考、世界理解和自我进化能力。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次访谈围绕DeepMind的技术演进路径展开，首先梳理了从AlphaGo、AlphaZero等游戏AI到&amp;quot;思考型模型&amp;quot;的发展脉络。Demis指出，DeepMind近期发布节奏极快，几乎每天都有新突破，包括Deep Think、IMO金牌、Genie 3等。这种&amp;quot;agent+思考&amp;quot;范式被认为是迈向AGI的必经之路，AI不仅要能做出第一个反应，更要能反复自我修正和优化思路。&lt;/p&gt;
&lt;p&gt;核心技术突破集中在Genie 3与世界模型方向。所谓世界模型，就是AI不仅理解语言和数学，还能理解物理世界的结构、规律、材料、流体、生命体等。Genie 3的突破在于保证了&amp;quot;世界一致性&amp;quot;——比如你离开房间再回来，物体还在原位。这种物理一致性是AI理解现实的关键标志，已被用于训练SIMA等游戏智能体，实现&amp;quot;AI在AI生成世界中自主探索&amp;quot;。&lt;/p&gt;
&lt;p&gt;在AI评测方面，传统评测如AIME数学题已接近饱和，Deep Think已达99.2%。Demis认为需要更难、更广、更真实的评测体系。Kaggle Game Arena采用&amp;quot;AI对AI竞技&amp;quot;思路，通过多样化游戏自动生成难度和评分，避免传统题库泄题、过拟合等问题。游戏作为评测场景具有客观可量化、自动扩展难度、可引入多智能体挑战等优势。&lt;/p&gt;
&lt;p&gt;关于AI产品化，Demis指出AI正从&amp;quot;单一大模型&amp;quot;向&amp;quot;系统化&amp;quot;演进，未来AI产品将是&amp;quot;模型+工具+系统&amp;quot;的组合。产品化挑战在于AI能力进化极快，产品设计需&amp;quot;可插拔&amp;quot;，能随时替换底层引擎。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;omni model&amp;quot;（全能模型），实现&amp;quot;一个模型做所有事&amp;quot;。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型（World Model）&lt;/strong&gt;：AI必须理解物理世界的结构、规律和一致性，才能实现通用智能和现实应用。这不仅包括语言和数学，还包括物理、材料、流体、生命体等现实世界要素。世界模型是AI&amp;quot;走出屏幕&amp;quot;、在现实中自主行动的前提。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考型模型（Thinking Models）&lt;/strong&gt;：从游戏AI演化而来的一条主线，强调AI不仅要感知和输出，还能自主规划、推理和决策。类似人类的深度思考过程，AI需要&amp;quot;反复自我修正和优化思路&amp;quot;，而不仅仅是做出第一个反应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统化AI（From Model to System）&lt;/strong&gt;：未来AI产品将由&amp;quot;模型+工具+系统&amp;quot;组成，能力边界动态扩展。模型不仅能推理，还能调用外部工具（如搜索、代码、物理模拟器等），实现更强的复合能力。部分能力应内置于主模型，部分则以外部工具形式存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;新型评测体系（Game Arena）&lt;/strong&gt;：AI能力评测需覆盖推理、物理智能、多目标权衡、安全性等多维度。Kaggle Game Arena通过&amp;quot;AI对AI竞技&amp;quot;自动生成难度，避免传统题库泄题和过拟合问题，推动AI能力全面进化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Omni Model愿景&lt;/strong&gt;：未来AGI是多模态、全能型模型，能在语言、视觉、物理、推理等各领域均衡表现。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;一个模型做所有事&amp;quot;的全能智能体。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=njDochQ2zHs&amp;amp;list=WL&amp;amp;index=5"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Google for Developers&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Deepseek与免费工具组合提前感受AGI逼近</title><link>https://linguista.cn/curated/henrinotes-2025_p2/deepseek-cline-agi-free-tools/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/deepseek-cline-agi-free-tools/</guid><description>&lt;h1 id="deepseek与免费工具组合提前感受agi逼近"&gt;Deepseek与免费工具组合提前感受AGI逼近&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文详细介绍了如何通过Deepseek配合VS Code和Cline插件两个免费工具，构建强大的AI编程和自动化环境。作者通过多个实用场景展示了这套组合的强大功能，包括AI自动操作浏览器发送邮件、查找删除重复文件、网页内容抓取翻译、本地笔记改写发布等。文章还提供了详细的工具安装配置步骤，以及火山引擎等替代API方案，并介绍了MCP协议扩展AI能力的原理和资源。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先通过引人入胜的应用场景展示了AI工具的强大潜力，让读者感受到AGI（通用人工智能）的逼近。这些看似遥不可及的功能实际上可以通过三个工具的组合实现：VS Code作为基础开发环境、Cline插件提供AI编程能力、Deepseek API提供强大的语言模型支持。&lt;/p&gt;
&lt;p&gt;在工具介绍部分，作者详细说明了VS Code作为开源代码编辑器的地位，它是目前AI编程工具的基础，许多知名工具如Cursor、Windsurf等都是基于VS Code二次开发的。Cline插件则被作者推荐为最好用的AI编程工具之一，支持本地模型和云端主流大模型，在Open Router的各项排行榜中都名列前茅。&lt;/p&gt;
&lt;p&gt;关于API配置，文章提供了多种选择。除了Deepseek官网API外，还介绍了火山引擎、硅基流动、Openrouter、TogetherAI等第三方服务。特别推荐了火山引擎的新用户活动，并提供邀请码和详细的配置步骤指南。&lt;/p&gt;
&lt;p&gt;最后，文章深入介绍了MCP（Model Calling Protocol）协议，这是Anthropic公司推出的让大模型能够调用外部插件的标准。通过Smithery.ai服务和GitHub上的Awesome MCP Server库，用户可以轻松为AI添加网页搜索、数据库操作、本地文件编辑等功能，极大拓展了AI的实用能力。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;VS Code生态系统&lt;/strong&gt;：VS Code是微软开源的代码编辑器，已发展成为AI编程时代的基础设施。它不仅自身功能强大，更重要的是提供了丰富的插件生态系统，成为众多AI编程工具的底层平台。选择VS Code意味着获得最大的灵活性和自定义空间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cline插件&lt;/strong&gt;：这是一个AI编程助手插件，在专业排行榜中表现优异。它的核心价值在于支持多种模型接入方式，包括本地Ollama部署和云端API服务，为用户提供了灵活的模型选择。Cline的高频使用证明其实用性和可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;API服务多样化&lt;/strong&gt;：Deepseek官网API可能不稳定，但市场上存在丰富的替代方案。火山引擎等第三方服务商提供免费Token额度，降低了用户试用成本。这种竞争格局为用户提供了更多选择和更好的服务体验。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MCP协议&lt;/strong&gt;：Model Calling Protocol是解决大模型闭塞性问题的关键技术。它允许AI模型调用外部工具和服务，突破知识局限性和操作能力限制。这标志着AI从单纯的语言处理向真正的智能代理演进。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI能力体现&lt;/strong&gt;：文章展示的多个场景——自动发邮件、文件管理、内容改写等——体现了AI的通用性问题解决能力。这些跨越不同领域的能力组合，正是AGI的重要特征，预示着人工智能正在向更通用、更自主的方向发展。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/PuHwfJk3EZv8eR4y10EAvQ"&gt;一秒超神：Deepseek + 这两个免费工具！提前感受 AGI 逼近&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>ChatGPT的可靠性问题：两年投资后的现状</title><link>https://linguista.cn/curated/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</guid><description>&lt;h1 id="chatgpt的可靠性问题两年投资后的现状"&gt;ChatGPT的可靠性问题：两年投资后的现状&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文记录了作者对ChatGPT最新版本的测试结果，展示了其在处理基本任务时仍然存在的可靠性问题。通过美国各州收入与人口表格、加拿大省份元音计数等测试，暴露出ChatGPT在计数、完整性、基础事实判断等方面的不足。作者质疑在如此多错误存在的情况下，通用人工智能（AGI）是否真如某些预测所言即将实现。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从软银集团孙正义对AGI的乐观预测切入，引出作者对ChatGPT实际表现的测试。测试内容包括两个主要案例：生成美国各州收入与人口表格，以及统计加拿大省份名称中的元音数量。&lt;/p&gt;
&lt;p&gt;在美国各州测试中，ChatGPT初始输出遗漏了多个州，补充人口密度列时出现计算错误，甚至将阿拉斯加完全遗漏。经过多次修正才最终得到正确结果。在加拿大省份元音计数测试中，ChatGPT将字母&amp;quot;h&amp;quot;误认为元音，计数多次出错，修正过程同样曲折。&lt;/p&gt;
&lt;p&gt;文章还引用了Sayash Kapoor对OpenAI新Operator代理的测试结果，显示即使是新发布的AI代理也存在可靠性问题。作者最后引用1841年经典著作中的论述，反思当前AI热潮中可能存在的盲目性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI预测与现实的差距&lt;/strong&gt;：软银孙正义预测AGI将在未来几年内实现，但基础测试显示当前AI模型连简单任务都无法可靠完成，这种预测与实际能力之间存在巨大鸿沟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性问题的具体表现&lt;/strong&gt;：ChatGPT在计数、列表完整性、基础事实判断等方面频发错误，包括无法准确计数到50、遗漏美国州、错误识别元音字母等，这些问题在经过两年大规模投资后仍然存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI模型的盲目自信&lt;/strong&gt;：ChatGPT在犯错时并未表现出不确定性，而是自信地给出错误答案，只有在被明确指出后才进行修正，这种特性增加了用户被误导的风险。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修正过程的繁琐性&lt;/strong&gt;：即使是简单任务，也需要用户多次指出错误才能得到正确结果，这种交互方式大大降低了AI工具的实用性和可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史警示的当代意义&lt;/strong&gt;：作者引用1841年关于群体盲目性的论述，暗示当前AI热潮可能存在类似的非理性现象，提醒人们需要更客观地评估AI技术的实际发展水平。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/chatgpt-in-shambles?utm_source=post-email-title&amp;amp;publication_id=888615&amp;amp;post_id=156479923&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=208yzy&amp;amp;triedRedirect=true&amp;amp;utm_medium=email"&gt;ChatGPT in Shambles&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>中国AI初创企业：超越DeepSeek的四大值得关注的公司</title><link>https://linguista.cn/curated/henrinotes-2025_p2/four-chinese-ai-startups-beyond-deepseek/</link><pubDate>Wed, 05 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/four-chinese-ai-startups-beyond-deepseek/</guid><description>&lt;h1 id="中国ai初创企业超越deepseek的四大值得关注的公司"&gt;中国AI初创企业：超越DeepSeek的四大值得关注的公司&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;自2022年ChatGPT发布以来，中国科技界一直在努力开发本土的AI替代品，催生了众多初创企业和数十亿美元的投资。DeepSeek作为中国AI初创企业的代表，其快速崛起震惊了全球。本文介绍了四家除了DeepSeek之外值得关注的中国AI初创企业——Stepfun、ModelBest、Zhipu和Infinigence AI，它们各自在不同的技术方向上展现出独特优势，从基础模型开发到小型化部署，再到异构计算基础设施，构成了中国AI生态系统的重要组成部分。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;中国AI初创企业的发展已经进入了一个新的阶段，从最初的快速冲刺逐渐转变为一场高风险的马拉松。目前，中国的AI赛道由阿里巴巴、字节跳动等科技巨头以及一些资金雄厚的竞争对手主导。然而，随着AI技术的发展，一些小型创新企业也开始崭露头角，它们需要找到自己的独特定位，否则可能会被市场淘汰。&lt;/p&gt;
&lt;p&gt;文章重点介绍了四家各具特色的AI初创企业。Stepfun由前微软高管创立，以开发人工通用智能（AGI）为目标，在2024年发布了11个基础AI模型，其Step-2模型在LiveBench排名中仅次于顶级国际模型。ModelBest则走小型化路线，专注于效率导向的小型语言模型，其MiniCPM系列专为设备端实时处理设计，在降低成本和增强隐私保护方面具有优势。Zhipu起源于清华大学，与政府和学术界联系紧密，正在开发对话模型ChatGLM和视频生成器Ying，但已成为美国出口管制的目标。Infinigence AI专注于基础设施建设，其异构计算集群技术能够优化不同芯片架构之间的协同工作，为中国AI企业在芯片受限环境下提供了新的解决方案。&lt;/p&gt;
&lt;p&gt;这些公司的发展路径反映了中国AI初创企业的多元化趋势。一些公司如Minimax和Moonshot放弃了成本高昂的基础模型训练，转而专注于面向消费者的应用程序开发；而像Stepfun和Infinigence AI这样的公司则加倍投入研究，部分原因是受到美国半导体限制的影响。这种分化既是对市场现实的回应，也是在技术封锁下的创新探索。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;人工通用智能（AGI）&lt;/strong&gt;：Stepfun仍将AGI作为其发展目标，这在中国初创企业中已经不多见。AGI指的是具备与人类相当或超越人类水平通用智能的AI系统，能够在各种任务中表现出类人的学习和推理能力。随着AI竞争的加剧，许多中国初创企业已经转向更务实的应用开发，Stepfun的坚持使其在基础模型研究领域保持了独特定位。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小型语言模型（SLM）&lt;/strong&gt;：ModelBest专注于小型语言模型的开发，其MiniCPM 3.0只有40亿个参数，但在各种基准测试中的表现与GPT-3.5相当。小型语言模型的优势在于可以在智能手机、PC、汽车系统等设备上进行实时处理，降低成本并增强隐私保护。这种&amp;quot;小而美&amp;quot;的路线代表了中国AI企业在算力受限环境下的一种务实选择。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异构计算集群&lt;/strong&gt;：Infinigence AI的核心技术是将不同品牌的芯片组合起来执行AI任务，形成&amp;quot;异构计算集群&amp;quot;。由于美国芯片制裁，中国AI公司无法获得最先进的英伟达芯片，因此需要学会使用AMD、华为等多种芯片。Infinigence AI的技术通过优化不同芯片架构之间的协同工作，声称可以将AI模型训练时间缩短30%，这为中国AI企业提供了一条在技术封锁下维持创新能力的路径。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;六虎&amp;rdquo;&lt;/strong&gt;：这是对中国AI领域六家领先初创企业的统称，包括Stepfun、智谱、Minimax、Moonshot、01.AI和百川。这些公司被认为是中国AI领域的佼佼者，获得了大量投资和政府支持。然而，随着竞争加剧和市场分化，&amp;ldquo;六虎&amp;quot;之间的发展路径也开始出现差异。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;出口管制与技术主权&lt;/strong&gt;：Zhipu成为新一批中国AI初创企业中第一个受到美国政府关注的公司，其10家子公司被列入限制贸易名单。美国声称Zhipu的技术正在帮助中国的军事，但该公司对此予以否认。这一事件凸显了AI技术竞争背后的地缘政治因素，也迫使中国AI企业加快技术自主化的步伐。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.technologyreview.com/2025/02/04/1110942/four-chinese-ai-startups-deepseek/"&gt;Four Chinese AI startups to watch beyond DeepSeek&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;MIT Technology Review&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-02-04&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>DeepSeek R1发布引发的思考 AI发展路径与未来趋势</title><link>https://linguista.cn/curated/henrinotes-2025_p2/deepseek-r1-ai-development-questions/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/deepseek-r1-ai-development-questions/</guid><description>&lt;h1 id="deepseek-r1发布引发的思考ai发展路径与未来趋势"&gt;DeepSeek R1发布引发的思考：AI发展路径与未来趋势&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;MIT经济学家Daron Acemoglu针对DeepSeek R1的发布提出了四个关键问题：美国科技行业是否在AI投资方向上出现群体思维、中国模式是否证明威权制度下的创新潜力、美国对华出口管制政策是否失效，以及DeepSeek是否真正推动我们接近AGI。这些问题直指当前AI发展的核心争议。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Acemoglu首先指出美国AI投资规模已达1万亿美元，但科技行业可能陷入&amp;quot;群体思维&amp;quot;，忽视了更经济、更有前景的技术路径。DeepSeek以550万美元的训练成本实现了与数亿美元投资的美国模型相当的效果，其技术路径更依赖强化学习和混合专家模型，有效完善了思路链推理。这种差异化路径本应被美国工业界探索，却因炒作和从众心理被集体忽视。&lt;/p&gt;
&lt;p&gt;关于中美科技竞争，Acemoglu承认DeepSeek的成功令人思考威权主义制度下的创新潜力。但他强调，DeepSeek的所有技术方法均源于美国和欧洲多年的研究成果，中国企业的核心贡献在于将这些现有技术以创新方式组合。与其他依赖政府资助的中国AI公司不同，DeepSeek的&amp;quot;不为人知&amp;quot;的独立性可能是其成功的关键因素，但这种状态能否在未来持续仍是未知数。&lt;/p&gt;
&lt;p&gt;在出口管制政策方面，作者认为完全零和博弈的策略是错误的。这种策略只有在确信AGI即将实现且先行者将获得巨大地缘政治优势的前提下才有意义，而这两个假设本身就值得质疑。中美两国在AI领域存在广泛的合作空间，尤其是在能提高人类生产力的技术创新方面。&lt;/p&gt;
&lt;p&gt;关于AGI愿景，Acemoglu对近期实现AGI持怀疑态度。他认为DeepSeek确实证明了现有技术路径的优化潜力，但已知方法的改进和成本降低并不能奇迹般地在几年内实现AGI。Yann LeCun的评论进一步补充了重要观点：AGI不会是一个突发的单一事件，而是渐进过程；创新一旦开源发表就能惠及整个行业，地理起源并非决定性因素。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;群体思维与路径依赖&lt;/strong&gt;：美国科技行业在AI投资上表现出惊人的同质化，所有领先公司都采用相同的&amp;quot;海量数据预训练+下一个词预测&amp;quot;基础模型策略。这种集体忽视替代性路径的现象正是Acemoglu在《权力与进步》中预言的&amp;quot;群体思维+炒作&amp;quot;循环，导致对更经济有效方案（如DeepSeek的强化学习优先路径）的系统性盲视。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;榨取性制度与创新的悖论&lt;/strong&gt;：Acemoglu在《国家为何失败》中论证自上而下的&amp;quot;榨取性制度&amp;quot;阻碍创新，但DeepSeek的案例迫使学界重新思考这一命题。然而深入分析显示，DeepSeek的技术基础完全建立在西方学术研究成果之上，其创新本质是&amp;quot;组合式创新&amp;quot;而非&amp;quot;原创性突破&amp;quot;，这反而印证了开放社会在基础研究领域的长期优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;零和博弈的错误假设&lt;/strong&gt;：美国对华AI出口管制政策建立在一个隐含前提上：AGI竞赛是赢家通吃的零和游戏。Acemoglu犀利地指出这个双重假设本身存疑——既不能确定AGI的可行性，也无法证明先行者必然获得持久优势。这种地缘政治思维忽视了技术扩散的客观规律和合作的潜在收益。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI的渐进本质&lt;/strong&gt;：Yann LeCun的评论纠正了AGI认知的根本误区。AGI不应被想象为某个特定时刻的&amp;quot;奇点事件&amp;quot;，而是一个技术能力渐进累积的过程。一旦关键技术突破发生并公开，它将在短时间内被多方复制，这意味着地理先发优势在开源时代被显著削弱。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://x.com/DAcemogluMIT/status/1885755575289417919"&gt;Daron Acemoglu的推文&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Daron Acemoglu（MIT经济学家）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月20日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;评论者&lt;/td&gt;
 &lt;td&gt;Yann LeCun（Meta AI首席科学家）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Gary Marcus对Sam Altman AGI基本已解决观点的反驳</title><link>https://linguista.cn/curated/henrinotes_2025_p3/gary-marcus-challenges-sam-altman-agi-confidence/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/gary-marcus-challenges-sam-altman-agi-confidence/</guid><description>&lt;h1 id="gary-marcus对sam-altman-agi基本已解决观点的反驳"&gt;Gary Marcus对Sam Altman AGI基本已解决观点的反驳&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Gary Marcus针对Sam Altman声称AGI基本已解决的观点进行了系统性反驳。Marcus指出，大型语言模型在分布偏移、常识推理、模型脆弱性等方面仍存在根本性缺陷，纯LLM扩展已进入边际收益递减期，且幻觉问题依然未解。他认为这些长期存在的问题缺乏原理性解决方案，因此对AGI的前景持谨慎态度。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Sam Altman近期在其博客中声称，我们已经知道如何构建传统意义上的AGI。这一观点立即引发了AI领域的广泛讨论。作为AI领域的知名批评家和认知科学家，Gary Marcus对此表示强烈反对，并列举了八个关键问题来支撑他的论点。&lt;/p&gt;
&lt;p&gt;Marcus首先从分布偏移问题入手，指出LLMs在相似任务上表现良好，但在不熟悉领域中的可靠性仍然存在问题。他引用了苹果2024年的推理论文验证了这一观点，并强调自己早在1998年就提出了类似问题。更值得注意的是，即便是数学问题这样的看似确定性领域，变量名称等微小变化也会导致问题解决能力下降30%，这充分说明了分布偏移问题的普遍性。&lt;/p&gt;
&lt;p&gt;在常识推理方面，Marcus与Ernie Davis的回顾研究表明，常识推理的不稳定性仍然是一个棘手问题。即便是像o1这样的先进模型，在某些基准测试中的结果也可能很脆弱或难以复制。Marcus强调，在o1的最佳表现案例中可能进行了大量数据增强，但这种策略在更开放的领域中是不可行的，这也限制了模型的实际泛化能力。&lt;/p&gt;
&lt;p&gt;Marcus进一步指出，纯LLM扩展已经进入边际收益递减期，这一观点得到了许多领域内领先人物的认同。更严重的是，由于缺乏明确、可访问、可靠的数据库式记录，幻觉问题依然存在，导致不准确的新闻摘要、诽谤、虚构来源、错误建议和不可靠性。他认为，尽管不能100%确定AGI不在眼前，但目前还没有看到对这些长期存在的问题的原理性解决方案。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;分布偏移问题&lt;/strong&gt;：这是指AI模型在训练数据分布之外的领域表现显著下降的现象。Marcus指出，LLMs在相似任务上泛化良好，但遇到不熟悉的领域时，即使是微小的变化也可能破坏其性能。这一问题在1998年就被Marcus提出，至今仍未得到有效解决。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常识推理的脆弱性&lt;/strong&gt;：常识推理是人类智能的核心特征，但对AI系统来说仍然是一个巨大挑战。Marcus与Ernie Davis的研究表明，即使是最先进的LLMs，在常识推理任务上也表现出明显的不稳定性，这限制了它们在实际应用中的可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;边际收益递减&lt;/strong&gt;：Marcus指出，许多领域内领先人物已经承认，纯LLM扩展可能已经进入边际收益递减期。这意味着单纯通过扩大模型规模来提升性能的策略越来越难以奏效，AI发展可能需要寻找新的技术路径。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幻觉问题的根源&lt;/strong&gt;：LLMs缺乏明确、可访问、可靠的数据库式记录，这导致它们经常生成看似合理但实际错误的内容。这一问题不仅影响新闻摘要、建议系统等应用，还可能导致诽谤和虚假信息的传播。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;科学的可验证性标准&lt;/strong&gt;：Marcus在文章末尾引用评论指出，除非有可以独立验证的、符合科学标准的演示，否则AGI仍然是科幻小说。这反映了AI研究中科学严谨性与商业宣传之间的张力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/sam-altman-thinks-that-agi-is-basically"&gt;Why I don&amp;rsquo;t share Sam Altman&amp;rsquo;s confidence that AGI is basically a solved problem&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未注明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>人工智能通用智能的五个哀悼阶段</title><link>https://linguista.cn/curated/henrinotes_2025_p3/five-stages-agi-grief-marcus/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/five-stages-agi-grief-marcus/</guid><description>&lt;h1 id="人工智能通用智能的五个哀悼阶段"&gt;人工智能通用智能的五个哀悼阶段&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文探讨了人们对人工智能通用智能（AGI）的期望与现实之间的差距，以及面对这种差距时的不同心理反应。作者Gary Marcus借用悲伤的五个阶段理论，分析了当前AI领域对AGI的认知偏差，呼吁回归对AGI的严肃定义，避免通过重新定义标准来过早宣布胜利。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章开篇明确了AGI的定义，引用Ben Goertzel和Shane Legg的经典定义，将AGI描述为一种灵活且通用的智能，其资源性和可靠性与人类智能相当或超越。作者提供了具体的衡量标准，包括观看电影并描述情节、在任意厨房胜任厨师工作、将自然语言中的数学证明转化为符号形式等实际应用场景。&lt;/p&gt;
&lt;p&gt;随后，作者运用悲伤的五个阶段理论框架，系统性地分析了人们对AGI现状的不同反应：否认阶段的人们拒绝承认当前AI与AGI之间的巨大差距；讨价还价阶段的人试图通过重新定义AGI标准来降低期望；愤怒阶段针对那些过早宣称AGI已实现的观点；抑郁阶段面对AGI目标的遥远而感到沮丧；最终达到接受阶段，承认差距并继续努力。&lt;/p&gt;
&lt;p&gt;文章还详细剖析了三种典型的AGI目标重新定义方式：经济重新定义（以完成80%有价值工作或盈利1000亿美元为标准）、提前宣布胜利（声称当前语言模型已能完成几乎所有人类信息任务）、以及回避定义（在讨论AGI影响时拒绝明确标准）。作者强调坚持原始AGI定义的重要性，指出当前AI技术虽然在某些方面表现出色，但在灵活性和通用性上仍距真正的通用智能有相当长的路要走。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI的严格定义&lt;/strong&gt;：Gary Marcus坚持使用Ben Goertzel和Shane Legg的经典定义，即AGI应是一种灵活且通用的智能，其能力在资源性和可靠性上与人类智能相当或超越。这个定义强调智能的通用性和可靠性，而非单一任务的出色表现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;悲伤理论在技术认知中的应用&lt;/strong&gt;：借用悲伤的五个阶段理论（否认、讨价还价、愤怒、抑郁、接受）来描述技术社区对AGI发展现状的心理反应，这种比喻揭示了人们对技术突破的渴望与现实之间的认知失调。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目标重定义的认知偏差&lt;/strong&gt;：通过经济标准（完成80%经济工作、盈利1000亿美元）或能力宣称（当前语言模型已完成大部分信息任务）来重新定义AGI，反映了人们试图通过降低标准来缩短现实与理想的距离，这种做法可能导致对真实进展的误判。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;灵活性与通用性的核心地位&lt;/strong&gt;：真正的AGI不仅需要在特定任务上表现出色，更重要的是具备跨领域的灵活适应能力和通用解决问题的能力，这是当前AI系统的主要短板所在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;认知失调的心理机制&lt;/strong&gt;：从否认到接受的心理过程，反映了技术社区在面对AGI遥远目标时的集体心理调适，承认差距并非否定进步，而是为更清晰的发展路径奠定基础。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/the-five-stages-of-agi-grief"&gt;The Five Stages of AGI Grief&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-08&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AI领袖对2025年的展望与期待</title><link>https://linguista.cn/curated/henrinotes_2025_p3/ai-leaders-hopes-2025-predictions/</link><pubDate>Tue, 07 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/ai-leaders-hopes-2025-predictions/</guid><description>&lt;h1 id="ai领袖对2025年的展望与期待"&gt;AI领袖对2025年的展望与期待&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文汇集了Andrew Ng、Mustafa Suleyman、Audrey Tang等多位AI领域领军人物对2025年的展望与期待。主要观点包括：AI将进一步降低软件开发成本，使快速原型开发成为常态；生成式AI将帮助艺术家从重复性工作中解放，专注于创造性工作；视频生成模型将实现音视频一体化创作；数据效率将成为关键研究方向；AI将具备视觉能力和代理行动能力，进入真正的人机协作时代。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以七位AI专家的观点为主线，勾勒出2025年AI技术发展的多元化前景。Andrew Ng强调AI辅助编程在原型开发中的优势，指出Bolt、Replit Agent、Vercel V0等平台正在通过生成式AI和代理工作流提高代码质量，这为开发者提供了前所未有的便利。他建议从业者制定学习计划，积极参与课程和原型开发实践。&lt;/p&gt;
&lt;p&gt;在创造性领域，Hanno Basse期待生成式AI能让艺术家从机械性工作中解脱，同时强调安全、完整性、可访问性和定制化的重要性。David Ding则预测视频生成模型将实现音频音轨的同步生成，包括语音、音乐和音效，这将开启电影创作的新时代。&lt;/p&gt;
&lt;p&gt;关于通用智能的讨论，Joseph Gonzalez认为我们已经实现了AGI，AI的通用性正在改变人机协作模式。Albert Gu则聚焦于数据效率这一根本问题，指出模型应该像人类一样从更少的数据中学习更多，这涉及数据整理、特征工程、多模态学习等多个子领域。&lt;/p&gt;
&lt;p&gt;Mustafa Suleyman展望了AI的视觉能力和代理智能，预测2025年AI将与用户协同浏览网页，实现真正的双向互动，并开始代表用户采取具体行动。Audrey Tang从社会治理角度提出，AI系统设计应优先考虑促进共情、理解和协作，推荐算法应引导用户走向&amp;quot;桥梁内容&amp;quot;，揭示共同点。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI辅助原型开发&lt;/strong&gt;：AI降低了软件开发的成本和门槛，使开发者能够快速构建各种应用原型。由于原型开发所需的上下文和软件集成较少，且在测试阶段不需要高度可靠性，因此特别适合AI辅助编码。开发者可以利用AI快速制作闪卡应用、监控汇率工具或分析用户评论的系统，而Bolt、Replit Agent、Vercel V0等平台的代理工作流进一步提升了代码质量和部署效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;生成式AI与艺术创作&lt;/strong&gt;：生成式AI的使命不是取代艺术家，而是帮助他们从重复性、机械性的工作中解放出来，专注于真正的创造性工作。Hanno Basse强调技术发展必须从初期就嵌入安全性和完整性，同时提高可访问性，让更广泛的受众能够使用这些工具。未来的生成式AI将更加专业化，出现更多针对特定用例的小型、微调模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多模态视频生成&lt;/strong&gt;：David Ding期待的视频生成模型将实现音视频一体化创作，包含对话、音乐和音效的完整视频剪辑将成为可能。虽然现有的视频和音频模型已经具备了技术基础，但真正的突破在于用户对输出的精细控制，例如指定音乐的调性、对话的情感色彩等。这将彻底改变电影和视频内容的创作方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据效率问题&lt;/strong&gt;：Albert Gu提出的核心问题是，当前AI模型消耗的数据远多于人类学习所需，提高数据效率是解决数据获取成本和训练成本问题的关键。这一目标与数据整理、特征工程、多模态学习、可解释性、推理能力和民主化等AI基础问题密切相关。如果模型能够从更少的数据中学习更多，将大大降低AI应用的门槛。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI代理与视觉交互&lt;/strong&gt;：Mustafa Suleyman预测2025年AI将具备视觉能力，能够与用户共同浏览网页，实现真正的双向互动。随着模型质量和检索能力的提高，幻觉现象将减少，用户信任度将提升。更重要的是，AI将开始代表用户采取具体行动，进入&amp;quot;行动代理&amp;quot;时代，这需要极高的安全性和责任感标准。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;社会价值导向的AI设计&lt;/strong&gt;：Audrey Tang提出的核心理念是AI系统应该促进社会团结而非分裂。推荐算法应该引导用户走向&amp;quot;桥梁内容&amp;quot;，即揭示不同群体之间共同点的内容，而不是强化极化。AI的发展应该采用包容和民主的方法，确保技术真正符合社会的价值观和需求，促进共情、理解和协作。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.deeplearning.ai/the-batch/issue-282/?utm_campaign=The%20Batch&amp;amp;utm_medium=email&amp;amp;_hsenc=p2ANqtz--ehToF1V6cEe_pSj4Juw6Rj0QGzs7cnaPT7x9jaBdNEdGQ_XDfaGbPu2TGTy_JL4bfus40Rn1TBoR0pbzYrS-hpvSnSw&amp;amp;_hsmi=341008988&amp;amp;utm_content=341008988&amp;amp;utm_source=hs_email"&gt;Happy New Year! Hopes For 2025 With Mustafa Suleyman, Audrey Tang, Albert Gu, Hanno Basse, and more&amp;hellip;&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Andrew Ng, Mustafa Suleyman, Audrey Tang, Albert Gu, Hanno Basse, David Ding, Joseph Gonzalez&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;文章类型&lt;/td&gt;
 &lt;td&gt;博客文章&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>2025年人工智能预测总结</title><link>https://linguista.cn/curated/henrinotes-2025-p1/2025-ai-predictions-marcus/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/2025-ai-predictions-marcus/</guid><description>&lt;h1 id="2025年人工智能预测总结"&gt;2025年人工智能预测总结&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Gary Marcus发布了针对2025年的25项人工智能预测，回顾了2024年预测的验证情况，并从高、中、低三个信心等级对2025年的AI发展进行了展望。预测内容涵盖技术发展、商业应用、监管政策、可靠性问题等多个维度，整体体现出对AI发展的审慎态度和对技术局限性的清醒认识。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先回顾了2024年的预测表现，指出大部分预测得到了验证。主要关注点包括对GPT-4模型的持续依赖、GPT-5未能如期出现、以及AI公司盈利能力普遍不佳等问题，这些趋势在2024年确实得到了验证。&lt;/p&gt;
&lt;p&gt;在高信心预测部分，Marcus提出了多项核心观点。他认为2025年仍然不会出现真正的人工通用智能（AGI），AI模型的盈利状况将持续低迷。同时，美国对生成性AI的监管将保持薄弱态势，而其他国家可能会转向欧洲学习更严格的监管模式。技术可靠性问题，特别是模型的幻觉现象和推理错误，将继续困扰行业发展。在硬件应用方面，人形机器人虽然会持续受到关注，但实际能力提升有限；真正的无人驾驶汽车应用范围将受到限制。OpenAI可能会继续提前预览产品，但实际发布的产品数量仍会有限。&lt;/p&gt;
&lt;p&gt;中等信心预测主要集中在行业发展趋势上。Marcus认为技术壁垒将难以建立，AI模型会趋向同质化。企业对AI的实验性应用会继续，但大规模部署将保持谨慎态度。2025年可能成为AI公司估值开始回调的重要转折点。&lt;/p&gt;
&lt;p&gt;低信心但值得讨论的预测涉及安全风险和技术路线。Marcus警告可能发生大规模网络攻击，生成性AI可能在其中扮演重要角色。同时，他认为可能不会出现所谓的GPT-5级别模型，未来的模型发展可能更加专注于特定任务的优化。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI延期论&lt;/strong&gt;：Marcus坚持认为2025年仍不会出现真正的人工通用智能，这一观点体现了他对当前AI技术路线的持续批评。他认为当前的深度学习方法虽然取得了显著进展，但在真正理解、推理和通用性方面仍然存在根本性局限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;盈利困境&lt;/strong&gt;：AI公司盈利能力持续低迷的预测反映了行业的现实挑战。尽管AI技术受到广泛关注，但商业化落地仍然困难重重，特别是在非硬件领域。这一预测与2024年的观察相呼应，许多AI公司未能实现预期收益。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性危机&lt;/strong&gt;：生成性AI的幻觉问题和推理错误将持续存在，这指出了当前大语言模型的核心缺陷。这些问题不仅影响用户体验，也制约了AI在关键领域的应用，是技术发展必须解决的重要挑战。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监管分化&lt;/strong&gt;：美国监管薄弱而其他国家向欧洲学习的预测，反映了全球AI治理格局的分化趋势。这种监管环境的不确定性，可能会影响AI技术的全球发展和应用布局。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;估值回调&lt;/strong&gt;：2025年可能成为AI公司估值下降的拐点，这一预测基于对行业泡沫的判断。Marcus认为市场对AI的期望可能过度乐观，随着技术局限性逐渐显现，资本市场的态度可能会趋于理性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/25-ai-predictions-for-2025-from-marcus?utm_source=post-email-title&amp;amp;publication_id=888615&amp;amp;post_id=153910147&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=208yzy&amp;amp;triedRedirect=true&amp;amp;utm_medium=email"&gt;25 AI Predictions for 2025, from Marcus on AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月2日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>If You Can’t Program It, You Haven't Understood It</title><link>https://linguista.cn/naval/orig/if-you-cant-program-it-you-havent-understood-it/</link><pubDate>Wed, 10 Nov 2021 18:36:16 +0000</pubDate><guid>https://linguista.cn/naval/orig/if-you-cant-program-it-you-havent-understood-it/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/zh/if-you-cant-program-it-you-havent-understood-it.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/program"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/program"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/program
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="if-you-cant-program-it-you-havent-understood-it"&gt;If You Can’t Program It, You Haven&amp;rsquo;t Understood It&lt;/h1&gt;
&lt;p&gt;Nov 10 2021&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Brett:&lt;br&gt;
These are all uncertain hypotheses, but we also have to keep in mind that there&amp;rsquo;s so much about evolution by natural selection that we don&amp;rsquo;t know.&lt;/p&gt;</description></item><item><title>More Compute Power Doesn’t Produce AGI</title><link>https://linguista.cn/naval/orig/more-compute-power-doesnt-produce-agi/</link><pubDate>Wed, 27 Oct 2021 19:28:41 +0000</pubDate><guid>https://linguista.cn/naval/orig/more-compute-power-doesnt-produce-agi/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/zh/more-compute-power-doesnt-produce-agi.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/agi"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/agi"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/agi
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="more-compute-power-doesnt-produce-agi"&gt;More Compute Power Doesn’t Produce AGI&lt;/h1&gt;
&lt;p&gt;Oct 27 2021&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Even the most powerful computers can’t answer ‘why?’&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Naval:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The artificial general intelligence crew gets it completely wrong, too: &amp;ldquo;Just add more compute power and you&amp;rsquo;ll get intelligence,&amp;rdquo; when we don&amp;rsquo;t know what it is underneath that makes us creative and allows us to come up with good explanations.&lt;/p&gt;</description></item></channel></rss>