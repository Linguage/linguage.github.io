<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AGI on Linguista</title><link>https://linguista.cn/tags/agi/</link><description>Recent content in AGI on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 23 Jan 2026 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/agi/index.xml" rel="self" type="application/rss+xml"/><item><title>AGI NEXT：范式裂变与中国机遇</title><link>https://linguista.cn/static/china-agi-next-chat-20260111-thu/</link><pubDate>Fri, 23 Jan 2026 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/china-agi-next-chat-20260111-thu/</guid><description>2026年初闭门圆桌讨论AGI的范式裂变与中国机遇。核心议题包括：硅谷与中国AI生态分化、ToB与ToC价值分野、从Scaling Law到自主进化、智能效率突围、长时程Agent、产学边界消融，以及中国在20%概率下的超越可能。</description></item><item><title>Most Books Should Be Skimmed, A Few Should Be Devoured</title><link>https://linguista.cn/naval/orig/most-books-should-be-skimmed-a-few-should-be-devoured/</link><pubDate>Fri, 26 Sep 2025 22:05:38 +0000</pubDate><guid>https://linguista.cn/naval/orig/most-books-should-be-skimmed-a-few-should-be-devoured/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/zh/most-books-should-be-skimmed-a-few-should-be-devoured.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/get"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/get"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/get
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="most-books-should-be-skimmed-a-few-should-be-devoured"&gt;Most Books Should Be Skimmed, A Few Should Be Devoured&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Sep 26 2025&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Nivi:&lt;/strong&gt; For the state of the art on the philosophy of knowledge, which people call &lt;strong&gt;epistemology&lt;/strong&gt;, you can basically skip everything and jump straight to &lt;strong&gt;David Deutsch&lt;/strong&gt;.&lt;/p&gt;</description></item><item><title>山姆·奥特曼与Vinod Khosla深谈AI前沿与AGI未来</title><link>https://linguista.cn/curated/summary-2025-p1/sam-altman-khosla-ai-future-agi-society/</link><pubDate>Sat, 13 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/summary-2025-p1/sam-altman-khosla-ai-future-agi-society/</guid><description>&lt;h1 id="山姆奥特曼与vinod-khosla深谈ai前沿与agi未来"&gt;山姆·奥特曼与Vinod Khosla深谈AI前沿与AGI未来&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文整理自OpenAI CEO山姆·奥特曼与知名投资人Vinod Khosla于2025年9月的深度对谈。两人围绕AI从聊天机器人迈向通用人工智能（AGI）的技术跃迁展开讨论，涵盖未来企业形态演变、职业替代与新生、创业投资范式转移、社会公平与财富分配、政府角色与全球协作等核心议题。核心结论是AI变革速度将超乎想象，社会需在价值观、制度和个人能力层面持续适应与创新。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次对谈以&amp;quot;AI将把我们带向何方&amp;quot;为主线，从技术演进、商业重构、社会治理三个维度展开。奥特曼认为ChatGPT的发布是AI&amp;quot;从零到一&amp;quot;的震撼时刻，而后续向AGI的跃迁虽然技术跨度更大，但社会已逐渐适应这种预期。未来AI系统将具备持续学习和自我进化能力，推动科研与产业创新进入指数级加速通道。&lt;/p&gt;
&lt;p&gt;在企业与商业层面，两人描绘了一个&amp;quot;10人团队创造十亿美元收入&amp;quot;的新型企业图景。AI将率先变革软件行业，&amp;ldquo;任何你想要的软件都能即时生成&amp;rdquo;，SaaS模式面临根本性颠覆。奥特曼分享了OpenAI自身从研究实验室到产品公司的转型历程，强调产品哪怕初期仅有极低留存率，也可能成为未来变革的种子。&lt;/p&gt;
&lt;p&gt;在社会影响层面，对谈深入讨论了AI对高智力职业的替代可能性，同时指出人类在情感交流和关怀方面的独特价值难以被AI取代。在资源分配问题上，奥特曼认为&amp;quot;让算力极大丰富&amp;quot;是唯一持久的解决方案，政府需承担基础设施建设和规则制定的责任，推动AI红利向全社会普及。&lt;/p&gt;
&lt;p&gt;两人还就创业者如何应对极端不确定性给出了务实建议：默认AI模型每年进步10倍，不要试图预测哪一点会停滞，而应将精力集中于新机会窗口。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI非线性跃迁与指数型进化&lt;/strong&gt;：奥特曼提出理解AI发展的根本范式是&amp;quot;指数型进化&amp;quot;，建议在个人和组织决策中默认AI能力以年均10倍速度自我加强，放弃线性预测思维。从ChatGPT到AGI的过程并非匀速推进，而是由更好的算法、更大的算力和更多优质数据三股力量共同驱动的加速过程，最终实现AI自主提出假设、验证并自我提升的闭环。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人机共同加速模型（Joint Acceleration）&lt;/strong&gt;：这一路径描述了AI与人类协作的演化方向——初期AI辅助科学家和工程师，逐渐过渡到AI独立提出并验证假设。衡量标准不是人与AI的工作占比，而是科研创新速率的整体提升。这意味着企业和研究机构应建立弹性架构，能够快速集成AI新工具并适配未知的加速节奏。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI后的新价值空间&lt;/strong&gt;：奥特曼明确告诫资本和创业者&amp;quot;不要追逐上一个AI赢家&amp;quot;，而应专注于&amp;quot;AI普及后诞生的全新价值空间&amp;quot;。核心思路不是成为&amp;quot;下一个OpenAI&amp;quot;，而是发现因为AGI存在才被激发出来的全新业态。这一观点重新定义了AI时代的创业逻辑——真正的机会在于AGI所开启的可能性边界之外。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算力作为新时代公平的关键基础设施&lt;/strong&gt;：在AI红利分配问题上，奥特曼将&amp;quot;算力&amp;quot;定位为新的稀缺资源，认为唯一持久的解决方案是让算力极大丰富。如果算力资源集中在少数国家或企业手中，全球社会将面临严重的分配失衡。因此政府应承担平台与规则塑造责任，在电力、数据中心等基础设施领域加大投入。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人类不可替代的情感与创造价值&lt;/strong&gt;：尽管AI在智力任务上的能力日益强大，奥特曼强调人类对他人关照和情感交流的本能需求很难被完全替代。一位真人教师对学生的激励效果远超算法教师。个人职业发展应聚焦于人类独特的情感、创造与共情能力，同时主动学习AI工具来优化生产力和创新能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=6NwK-uq16U8"&gt;Where is AI Taking Us? | Sam Altman &amp;amp; Vinod Khosla&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Khosla Ventures&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-08&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AI未来深谈 | 山姆·奥特曼 × Vinod Khosla</title><link>https://linguista.cn/static/ai_future_magazine/</link><pubDate>Thu, 11 Sep 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/ai_future_magazine/</guid><description>在这场关于 AGI 未来的深度对话中，山姆·奥特曼与 Vinod Khosla 探讨了人工智能将在未来十年内如何重塑软件世界，以及十年后对实体世界的深远变革。他们预测，企业的适应性将成为生存关键，小规模团队将有能力创造巨大的经济价值，而人类在情感与关怀领域的独特价值将变得愈发珍贵。</description></item><item><title>2025年人工智能预测总结</title><link>https://linguista.cn/curated/summary-2025-p1/2025-ai-predictions-marcus/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/summary-2025-p1/2025-ai-predictions-marcus/</guid><description>&lt;h1 id="2025年人工智能预测总结"&gt;2025年人工智能预测总结&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Gary Marcus发布了针对2025年的25项人工智能预测，回顾了2024年预测的验证情况，并从高、中、低三个信心等级对2025年的AI发展进行了展望。预测内容涵盖技术发展、商业应用、监管政策、可靠性问题等多个维度，整体体现出对AI发展的审慎态度和对技术局限性的清醒认识。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先回顾了2024年的预测表现，指出大部分预测得到了验证。主要关注点包括对GPT-4模型的持续依赖、GPT-5未能如期出现、以及AI公司盈利能力普遍不佳等问题，这些趋势在2024年确实得到了验证。&lt;/p&gt;
&lt;p&gt;在高信心预测部分，Marcus提出了多项核心观点。他认为2025年仍然不会出现真正的人工通用智能（AGI），AI模型的盈利状况将持续低迷。同时，美国对生成性AI的监管将保持薄弱态势，而其他国家可能会转向欧洲学习更严格的监管模式。技术可靠性问题，特别是模型的幻觉现象和推理错误，将继续困扰行业发展。在硬件应用方面，人形机器人虽然会持续受到关注，但实际能力提升有限；真正的无人驾驶汽车应用范围将受到限制。OpenAI可能会继续提前预览产品，但实际发布的产品数量仍会有限。&lt;/p&gt;
&lt;p&gt;中等信心预测主要集中在行业发展趋势上。Marcus认为技术壁垒将难以建立，AI模型会趋向同质化。企业对AI的实验性应用会继续，但大规模部署将保持谨慎态度。2025年可能成为AI公司估值开始回调的重要转折点。&lt;/p&gt;
&lt;p&gt;低信心但值得讨论的预测涉及安全风险和技术路线。Marcus警告可能发生大规模网络攻击，生成性AI可能在其中扮演重要角色。同时，他认为可能不会出现所谓的GPT-5级别模型，未来的模型发展可能更加专注于特定任务的优化。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI延期论&lt;/strong&gt;：Marcus坚持认为2025年仍不会出现真正的人工通用智能，这一观点体现了他对当前AI技术路线的持续批评。他认为当前的深度学习方法虽然取得了显著进展，但在真正理解、推理和通用性方面仍然存在根本性局限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;盈利困境&lt;/strong&gt;：AI公司盈利能力持续低迷的预测反映了行业的现实挑战。尽管AI技术受到广泛关注，但商业化落地仍然困难重重，特别是在非硬件领域。这一预测与2024年的观察相呼应，许多AI公司未能实现预期收益。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性危机&lt;/strong&gt;：生成性AI的幻觉问题和推理错误将持续存在，这指出了当前大语言模型的核心缺陷。这些问题不仅影响用户体验，也制约了AI在关键领域的应用，是技术发展必须解决的重要挑战。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监管分化&lt;/strong&gt;：美国监管薄弱而其他国家向欧洲学习的预测，反映了全球AI治理格局的分化趋势。这种监管环境的不确定性，可能会影响AI技术的全球发展和应用布局。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;估值回调&lt;/strong&gt;：2025年可能成为AI公司估值下降的拐点，这一预测基于对行业泡沫的判断。Marcus认为市场对AI的期望可能过度乐观，随着技术局限性逐渐显现，资本市场的态度可能会趋于理性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/25-ai-predictions-for-2025-from-marcus?utm_source=post-email-title&amp;amp;publication_id=888615&amp;amp;post_id=153910147&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=208yzy&amp;amp;triedRedirect=true&amp;amp;utm_medium=email"&gt;25 AI Predictions for 2025, from Marcus on AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月2日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>If You Can’t Program It, You Haven't Understood It</title><link>https://linguista.cn/naval/orig/if-you-cant-program-it-you-havent-understood-it/</link><pubDate>Wed, 10 Nov 2021 18:36:16 +0000</pubDate><guid>https://linguista.cn/naval/orig/if-you-cant-program-it-you-havent-understood-it/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/zh/if-you-cant-program-it-you-havent-understood-it.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/program"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/program"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/program
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="if-you-cant-program-it-you-havent-understood-it"&gt;If You Can’t Program It, You Haven&amp;rsquo;t Understood It&lt;/h1&gt;
&lt;p&gt;Nov 10 2021&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Brett:&lt;br&gt;
These are all uncertain hypotheses, but we also have to keep in mind that there&amp;rsquo;s so much about evolution by natural selection that we don&amp;rsquo;t know.&lt;/p&gt;</description></item><item><title>More Compute Power Doesn’t Produce AGI</title><link>https://linguista.cn/naval/orig/more-compute-power-doesnt-produce-agi/</link><pubDate>Wed, 27 Oct 2021 19:28:41 +0000</pubDate><guid>https://linguista.cn/naval/orig/more-compute-power-doesnt-produce-agi/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/zh/more-compute-power-doesnt-produce-agi.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/agi"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/agi"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/agi
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="more-compute-power-doesnt-produce-agi"&gt;More Compute Power Doesn’t Produce AGI&lt;/h1&gt;
&lt;p&gt;Oct 27 2021&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Even the most powerful computers can’t answer ‘why?’&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Naval:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The artificial general intelligence crew gets it completely wrong, too: &amp;ldquo;Just add more compute power and you&amp;rsquo;ll get intelligence,&amp;rdquo; when we don&amp;rsquo;t know what it is underneath that makes us creative and allows us to come up with good explanations.&lt;/p&gt;</description></item></channel></rss>