<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AGI on Linguista</title><link>https://linguista.cn/tags/agi/</link><description>Recent content in AGI on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 23 Jan 2026 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/agi/index.xml" rel="self" type="application/rss+xml"/><item><title>AGI NEXT：范式裂变与中国机遇</title><link>https://linguista.cn/infos/htmlcards/china-agi-next-chat-20260111-thu/</link><pubDate>Fri, 23 Jan 2026 08:00:00 +0800</pubDate><guid>https://linguista.cn/infos/htmlcards/china-agi-next-chat-20260111-thu/</guid><description>2026年初闭门圆桌讨论AGI的范式裂变与中国机遇。核心议题包括：硅谷与中国AI生态分化、ToB与ToC价值分野、从Scaling Law到自主进化、智能效率突围、长时程Agent、产学边界消融，以及中国在20%概率下的超越可能。</description></item><item><title>Most Books Should Be Skimmed, A Few Should Be Devoured</title><link>https://linguista.cn/person/naval/orig/most-books-should-be-skimmed-a-few-should-be-devoured/</link><pubDate>Fri, 26 Sep 2025 22:05:38 +0000</pubDate><guid>https://linguista.cn/person/naval/orig/most-books-should-be-skimmed-a-few-should-be-devoured/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/person/naval/zh/most-books-should-be-skimmed-a-few-should-be-devoured.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/get"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/get"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/get
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="most-books-should-be-skimmed-a-few-should-be-devoured"&gt;Most Books Should Be Skimmed, A Few Should Be Devoured&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Sep 26 2025&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Nivi:&lt;/strong&gt; For the state of the art on the philosophy of knowledge, which people call &lt;strong&gt;epistemology&lt;/strong&gt;, you can basically skip everything and jump straight to &lt;strong&gt;David Deutsch&lt;/strong&gt;.&lt;/p&gt;</description></item><item><title>OpenAI联合创始人Ilya Sutskever深度解读AI现状与未来</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/ilya-sutskever-ai-future-superalignment/</link><pubDate>Sat, 27 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/ilya-sutskever-ai-future-superalignment/</guid><description>&lt;h1 id="openai联合创始人ilya-sutskever深度解读ai现状与未来"&gt;OpenAI联合创始人Ilya Sutskever深度解读AI现状与未来&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本期No Priors节目邀请OpenAI联合创始人兼首席科学家Ilya Sutskever，与主持人Sarah Guo和Elad Gil共同探讨人工智能的演进脉络与未来图景。对话从深度学习的早期困境切入，系统梳理了OpenAI的创立初心与有限利润模式的设计逻辑，深入剖析GPT模型从1到3的规模跃迁与涌现行为，并围绕模型可靠性、小模型局限、开源边界等实践问题展开讨论。Sutskever进一步类比生物智能与数字生命，强调超级对齐在AGI时代的必要性，并分享了规模驱动的AI研发框架与心智模型。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;访谈始于AI研究的早期困境。Sutskever回忆了前AlexNet时代神经网络被边缘化的灰暗阶段，指出真正的突破源于GPU算力、大规模网络直觉与算法优化的三者结合。团队通过将大规模卷积神经网络应用于视觉识别，完成了从学术质疑到工程实证的转折，而初期目标不过是把模型做大、看能成就什么。&lt;/p&gt;
&lt;p&gt;OpenAI的创立始终围绕让AGI造福全人类的使命。Sutskever解释了从非营利组织转向有限利润模式的战略考量：AGI一旦出现可能重塑社会根基，若由单一公司无限获利将带来伦理风险。限定投资回报倍数意在削弱纯粹利益诱惑，强化技术使命感，同时也解决了非营利路径在算力和资金上的瓶颈。&lt;/p&gt;
&lt;p&gt;在模型演进上，OpenAI从Dota 2的端到端学习转向大规模Transformer的文本预测路线。GPT-2到GPT-3的规模跃迁带来了链式推理等涌现能力，Sutskever称之为整体效果的出现与被理解的感觉。他强调，模型规模变大的最大收益在于可靠性——从稳定回答到极低失误率，这正是自动驾驶等高风险场景的关键要求。小模型虽推理成本低，但难以保证长期可靠，未来将形成多层模型生态，小模型做领域应用，大模型承担高门槛任务。&lt;/p&gt;
&lt;p&gt;关于开源角色，Sutskever持审慎态度：短期看开源推动创新与应用多样化，长期则需警惕能力边界开放后的不可预期后果。他类比生物大脑的可塑性，认为统一架构在AI世界同样可行，真正的数字生命关键在于高度自治，而当前AI尚未达到此标准。&lt;/p&gt;
&lt;p&gt;超级对齐是应对未来超级智能的核心命题。Sutskever指出，超级智能可能在数据中心中孕育，带来极端不确定性，因此必须提前投入研究，让AI保持以人为本的价值印记。这不是梦幻主义，而是需要科学界、工程界和社会共同认清现实进程、主动推动价值观嵌入的责任。AI的加速取决于算力、数据、工程、资金等多因素平衡，减速则源于数据瓶颈与系统复杂性，未来进步将在拉锯中前行。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;有限利润模式（Capped Profit）&lt;/strong&gt;：OpenAI为平衡AGI使命与资金需求而设计的制度创新。通过限定投资回报倍数，削弱纯利润驱动，强化技术普惠与伦理约束。这一模式承认AGI可能对社会根基产生深远影响，避免单一公司因无限获利而偏离人类整体利益，同时为大规模算力需求提供资金保障。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;涌现行为（Emergence）&lt;/strong&gt;：模型在规模跃迁时呈现的预期之外能力，如GPT-2到GPT-3出现的链式推理。Sutskever称之为整体效果的出现，反映了神经网络在大规模数据与参数下从量变到质变的临界现象。涌现能力的不可预测性既是惊喜也是风险，要求在扩大规模时持续观察与评估。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;超级对齐（Superalignment）&lt;/strong&gt;：面向超级智能时代的价值对齐方案，目标是让比人类更聪明的AI系统保持以人为本的价值印记。Sutskever强调这不会自动出现，而是需要科学家、工程师和社会角色共同参与，在未来5到10年的能力演进中主动推动价值观注入与演化。这是AI安全在超级智能阶段的终极挑战，也是不可回避的责任。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规模驱动的AI研发框架&lt;/strong&gt;：现代AI进步的核心范式，以统一神经网络架构、大规模数据集和强大算力为三大支柱。流程上放弃过度依赖理论证明，敢于用工程手段验证规律；寻找可扩展架构并持续加大规模；以实验和迭代为中心，先训练看结果再逆向理解机理。该框架要求研究者具备大胆假设、小心求证、不断迭代的心智模型，同时对可控性与可靠性保持警觉。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性（Reliability）&lt;/strong&gt;：模型规模变大的最大收益点，定义为在连续多次交互中保持准确回答、避免巨大失误的能力。Sutskever以自动驾驶为例，说明高风险场景要求极低失误率，而小模型因推理成本限制难以保证长期可靠。未来生态将是小模型处理领域任务、大模型承担高门槛风险的分层格局，应用场景越复杂，对模型规模要求越高。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Ft0gTO2K85A"&gt;No Priors Ep. 39 | With OpenAI Co-Founder &amp;amp; Chief Scientist Ilya Sutskever&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;No Priors Podcast&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-27&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>山姆·奥特曼与Vinod Khosla深谈AI前沿与AGI未来</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/sam-altman-khosla-ai-future-agi-society/</link><pubDate>Sat, 13 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/sam-altman-khosla-ai-future-agi-society/</guid><description>&lt;h1 id="山姆奥特曼与vinod-khosla深谈ai前沿与agi未来"&gt;山姆·奥特曼与Vinod Khosla深谈AI前沿与AGI未来&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文整理自OpenAI CEO山姆·奥特曼与知名投资人Vinod Khosla于2025年9月的深度对谈。两人围绕AI从聊天机器人迈向通用人工智能（AGI）的技术跃迁展开讨论，涵盖未来企业形态演变、职业替代与新生、创业投资范式转移、社会公平与财富分配、政府角色与全球协作等核心议题。核心结论是AI变革速度将超乎想象，社会需在价值观、制度和个人能力层面持续适应与创新。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次对谈以&amp;quot;AI将把我们带向何方&amp;quot;为主线，从技术演进、商业重构、社会治理三个维度展开。奥特曼认为ChatGPT的发布是AI&amp;quot;从零到一&amp;quot;的震撼时刻，而后续向AGI的跃迁虽然技术跨度更大，但社会已逐渐适应这种预期。未来AI系统将具备持续学习和自我进化能力，推动科研与产业创新进入指数级加速通道。&lt;/p&gt;
&lt;p&gt;在企业与商业层面，两人描绘了一个&amp;quot;10人团队创造十亿美元收入&amp;quot;的新型企业图景。AI将率先变革软件行业，&amp;ldquo;任何你想要的软件都能即时生成&amp;rdquo;，SaaS模式面临根本性颠覆。奥特曼分享了OpenAI自身从研究实验室到产品公司的转型历程，强调产品哪怕初期仅有极低留存率，也可能成为未来变革的种子。&lt;/p&gt;
&lt;p&gt;在社会影响层面，对谈深入讨论了AI对高智力职业的替代可能性，同时指出人类在情感交流和关怀方面的独特价值难以被AI取代。在资源分配问题上，奥特曼认为&amp;quot;让算力极大丰富&amp;quot;是唯一持久的解决方案，政府需承担基础设施建设和规则制定的责任，推动AI红利向全社会普及。&lt;/p&gt;
&lt;p&gt;两人还就创业者如何应对极端不确定性给出了务实建议：默认AI模型每年进步10倍，不要试图预测哪一点会停滞，而应将精力集中于新机会窗口。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI非线性跃迁与指数型进化&lt;/strong&gt;：奥特曼提出理解AI发展的根本范式是&amp;quot;指数型进化&amp;quot;，建议在个人和组织决策中默认AI能力以年均10倍速度自我加强，放弃线性预测思维。从ChatGPT到AGI的过程并非匀速推进，而是由更好的算法、更大的算力和更多优质数据三股力量共同驱动的加速过程，最终实现AI自主提出假设、验证并自我提升的闭环。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人机共同加速模型（Joint Acceleration）&lt;/strong&gt;：这一路径描述了AI与人类协作的演化方向——初期AI辅助科学家和工程师，逐渐过渡到AI独立提出并验证假设。衡量标准不是人与AI的工作占比，而是科研创新速率的整体提升。这意味着企业和研究机构应建立弹性架构，能够快速集成AI新工具并适配未知的加速节奏。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI后的新价值空间&lt;/strong&gt;：奥特曼明确告诫资本和创业者&amp;quot;不要追逐上一个AI赢家&amp;quot;，而应专注于&amp;quot;AI普及后诞生的全新价值空间&amp;quot;。核心思路不是成为&amp;quot;下一个OpenAI&amp;quot;，而是发现因为AGI存在才被激发出来的全新业态。这一观点重新定义了AI时代的创业逻辑——真正的机会在于AGI所开启的可能性边界之外。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;算力作为新时代公平的关键基础设施&lt;/strong&gt;：在AI红利分配问题上，奥特曼将&amp;quot;算力&amp;quot;定位为新的稀缺资源，认为唯一持久的解决方案是让算力极大丰富。如果算力资源集中在少数国家或企业手中，全球社会将面临严重的分配失衡。因此政府应承担平台与规则塑造责任，在电力、数据中心等基础设施领域加大投入。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人类不可替代的情感与创造价值&lt;/strong&gt;：尽管AI在智力任务上的能力日益强大，奥特曼强调人类对他人关照和情感交流的本能需求很难被完全替代。一位真人教师对学生的激励效果远超算法教师。个人职业发展应聚焦于人类独特的情感、创造与共情能力，同时主动学习AI工具来优化生产力和创新能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=6NwK-uq16U8"&gt;Where is AI Taking Us? | Sam Altman &amp;amp; Vinod Khosla&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Khosla Ventures&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-08&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AI未来深谈 | 山姆·奥特曼 × Vinod Khosla</title><link>https://linguista.cn/infos/htmlcards/ai_future_magazine/</link><pubDate>Thu, 11 Sep 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/infos/htmlcards/ai_future_magazine/</guid><description>在这场关于 AGI 未来的深度对话中，山姆·奥特曼与 Vinod Khosla 探讨了人工智能将在未来十年内如何重塑软件世界，以及十年后对实体世界的深远变革。他们预测，企业的适应性将成为生存关键，小规模团队将有能力创造巨大的经济价值，而人类在情感与关怀领域的独特价值将变得愈发珍贵。</description></item><item><title>与 Cognition CEO Scott Wu 的深度对话</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/cognition-ceo-scott-wu-interview/</link><pubDate>Thu, 04 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/cognition-ceo-scott-wu-interview/</guid><description>&lt;h1 id="与-cognition-ceo-scott-wu-的深度对话"&gt;与 Cognition CEO Scott Wu 的深度对话&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本期访谈由 Stripe 主持人 John Collison 对话 Cognition CEO Scott Wu，围绕 AI 软件工程师 Devin、AI 时代的创业者生态、技术与行业变革、企业收购，以及 Scott 对 AGI 的观点展开。Scott 分享了自己从数学竞赛到创业的成长历程，深入剖析了 AI 工具对软件工程的影响，以及 Cognition 团队的文化与未来展望。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;访谈开篇介绍了 Scott Wu 的成长背景。他出生于美国路易斯安那州，父母是来自中国的化学工程师。在哥哥 Neal 的启蒙下，Scott 从小学一年级开始接触数学竞赛，二年级首次参赛，之后持续取得优异成绩。他三次参加国际信息学奥林匹克竞赛均获金牌，高中提前毕业后进入 Addepar 担任软件工程师，后在哈佛学习两年后选择退学创业。&lt;/p&gt;
&lt;p&gt;关于年轻创业者生态，Scott 认为创业门槛实际上变高了。过去年轻人凭借&amp;quot;第一性原理&amp;quot;思维和执行力可以在新兴领域脱颖而出，但如今行业更成熟，经验与资源同样重要。他注意到许多顶尖创业者都有数学或编程竞赛背景，形成了独特的&amp;quot;创业小圈子&amp;quot;。访谈还讨论了&amp;quot;Moneyball-ification&amp;quot;趋势，即各行业从直觉驱动转向数据化、模型化。&lt;/p&gt;
&lt;p&gt;Cognition 公司的核心产品是 AI 软件工程师 Devin。与传统的 IDE 辅助工具不同，Devin 采用&amp;quot;异步代理&amp;quot;模式，用户可以在 Slack、Linear、Jira 等平台直接指派任务，Devin 会自动完成 bug 修复、功能开发、代码迁移等工作。Scott 认为 Devin 当前能力相当于&amp;quot;初级工程师&amp;quot;，在知识检索和重复性任务上表现突出。Devin 已在全球数千家公司部署，部分企业测算显示其在代码迁移任务上可实现 8-15 倍效率提升。&lt;/p&gt;
&lt;p&gt;Scott 详细阐述了&amp;quot;本质复杂性&amp;quot;与&amp;quot;偶然复杂性&amp;quot;的区别。前者指软件工程师需要做出的核心决策与逻辑设计，后者则是为支持系统扩展而必须完成的重复性工作。他预测未来软件工程师的工作重心将从代码实现转向高层决策与架构设计，两到四年后工程师可能不再直接编写代码，而是通过自然语言指挥 AI 完成实现。&lt;/p&gt;
&lt;p&gt;关于 AI 行业结构，Scott 认为各层（数据中心、实验室、应用层）都将受益，不会出现过度垂直整合。访谈还讨论了 Windsurf 收购案，Cognition 团队在一个周末内完成了尽调、谈判和签约。Cognition 团队以高密度&amp;quot;前创业者&amp;quot;著称，35 人团队中有 21 人曾创办过公司。&lt;/p&gt;</description></item><item><title>科赫联合创始人Nick Frosst如何在OpenAI与Anthropic夹缝中竞争</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/cohere-nick-frosst-compete-openai-anthropic/</link><pubDate>Thu, 04 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/cohere-nick-frosst-compete-openai-anthropic/</guid><description>&lt;h1 id="科赫联合创始人nick-frosst如何在openai与anthropic夹缝中竞争"&gt;科赫联合创始人Nick Frosst：如何在OpenAI与Anthropic夹缝中竞争&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文是20VC播客对Cohere联合创始人Nick Frosst的深度访谈。作为前谷歌大脑研究员，Nick坦率剖析了Cohere如何在OpenAI、Anthropic等巨头夹缝中找到生存空间——专注企业级AI应用，强调ROI和实际价值而非AGI幻想。他批评Sam Altman过度渲染AI威胁，质疑规模化定律，主张AI应成为提升生产力的工具而非取代人类的魔法。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先介绍了Cohere的核心定位：与OpenAI、Anthropic一样致力于基础大模型研发，但独特聚焦企业客户市场。Nick强调Cohere通过让模型熟悉企业内部工具API、流程和数据集成，真正帮助企业解决工作中的实际问题。在训练策略上，Cohere大量采用合成数据来模拟企业真实场景，同时依赖人类注释者生产高质量数据以应对行业数据瓶颈。&lt;/p&gt;
&lt;p&gt;接着Nick深入分析了AI发展的&amp;quot;三大支柱&amp;quot;：算力、数据和算法。他直言算法创新趋缓，算力提升不再是唯一动力，真正卡脖子的是如何获取足够多的高质量、能直接应用于具体任务的数据。他对&amp;quot;规模化定律&amp;quot;提出鲜明质疑，认为单纯砸算力并非持续进步的灵药。Nick批评Sam Altman四处宣扬AI威胁论是&amp;quot;学术上不严谨，实际上伤害了AI技术本身&amp;quot;。&lt;/p&gt;
&lt;p&gt;在产品策略上，Nick指出当前大模型评测基准普遍浮夸脱离实际，企业客户从不关心模型能否解数学题，而在乎能否自动化日常办公任务。Cohere将核心能力定位在训练与部署效率上，只需两块GPU即可运行，大大降低企业落地门槛。面对人才争夺，Nick认为顶薪固然重要，但真正留住人才的是有意义的工作环境和文化认同。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;合成数据&lt;/strong&gt;：Cohere采用的核心训练策略，通过模拟公司内部邮件、API调用等日常流程生成针对性强的训练集。这既补足了企业真实数据的瓶颈，也提升了模型与实际场景的贴合度。Nick认为高质量数据依然是行业核心难题，合成数据是务实解决方案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;务实主义企业观&lt;/strong&gt;：与其沉溺于与OpenAI、Anthropic的直接竞争，不如专注解决客户实际问题。企业家应建立独特价值主张，坚持自己的主航道。Nick强调真正的竞争不是融资额最大，而是谁最懂客户、最能把AI落地到客户场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;效率优先框架&lt;/strong&gt;：Cohere团队处处追求最优成本效能，不断优化模型结构与推理引擎，让企业客户能低成本部署。与消费级AI不同，企业级AI是否有用的唯一标准是能否提升企业效率和收益，而不是模型是否更像人。Nick主张放下对分数排名的执着，专心倾听客户痛点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI批判&lt;/strong&gt;：Nick对AGI炒作持强烈批评态度，认为Sam Altman的AI威胁论是行业误导。他指出AGI定义含糊，大多数人对何为AGI并无清晰标准。真正需要警惕的是AI在职场带来的结构性分化和收入不均，应通过政策和教育管控而非妄想阻止技术进步。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半开放路线&lt;/strong&gt;：Cohere选择中间路线，自研模型权重完全开放用于科研和非商用，企业商用则需洽谈合作。这既争取AI生态社区认可，也保障自身商业化安全。Nick预测未来AI基础设施会更像国家级底座，各国必然推动主权模型以确保技术自主可控。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=Sw2chzwWLbQ"&gt;Cohere Founder, Nick Frosst: How To Compete with OpenAI &amp;amp; Anthropic, and Sam Altman&amp;rsquo;s AI Disservice&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;20VC with Harry Stebbings&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-04&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AGI的未来是系统工程而非模型训练</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-future-systems-engineering-not-models/</link><pubDate>Sun, 24 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-future-systems-engineering-not-models/</guid><description>&lt;h1 id="agi的未来是系统工程而非模型训练"&gt;AGI的未来是系统工程而非模型训练&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文核心观点是通往人工通用智能的道路不在于继续扩大语言模型的规模，而在于构建由模型、记忆、上下文和确定性工作流组成的工程化系统。当前主流大模型已接近能力极限，单纯依靠堆算力和扩参数已无法带来质的突破。AGI的本质是一个系统工程问题，需要分布式系统、上下文管理、记忆服务、确定性与概率性结合的工作流，以及多模型协作的架构创新。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先指出了现有大语言模型已达到能力平台期。日常使用者能明显感受到其局限性：虽然能生成高质量文本，但在跨会话保持上下文、持久记忆、复杂多步推理等方面表现不佳。这种技术发展轨迹与半导体行业类似，当主频提升遇到物理极限后，行业转向多核架构带来新一轮创新。AI领域也正处于类似拐点，继续做大模型的边际收益正在递减。&lt;/p&gt;
&lt;p&gt;未来的关键问题不再是如何让模型更大，而是如何让系统更智能。这意味着需要从模型训练转向系统工程，关注模型之间的协作、信息流动和可靠性。AGI的突破不在于更大的Transformer，而在于能编排数百专用模型、跨会话保持上下文、围绕概率性组件执行确定性工作流，并在生产级规模下实现容错操作的分布式系统。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;上下文管理基础设施&lt;/strong&gt;：现有模型的注意力跨度仅为数千token，而人类的上下文跨度可以覆盖数年甚至一生。这种差距不仅是数量级的，更是质量上的。理想的上下文管理系统需要具备按需检索和过滤相关信息、构建并维护可持续演化的世界模型、跨领域桥接上下文、处理冲突信息等能力。这需要从简单的向量检索升级到可操作知识图谱，实现实时更新、查询和推理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;记忆服务&lt;/strong&gt;：现有LLM没有真正的记忆，只能通过提示工程和上下文填充模拟记忆。AGI需要具备真正的记忆系统，能够在新证据出现时更新信念、跨多次体验整合信息形成一般性原则、忘记无关细节但避免灾难性遗忘、生成关于信息可靠性和来源的元知识。这不仅是数据库持久化，更是类人记忆系统，使用越多越牢固，久未使用则逐渐遗忘，遇新理解时能重组记忆结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;确定性工作流与概率性组件结合&lt;/strong&gt;：AGI的突破点在于用确定性框架包裹概率性组件。类似编译器的设计理念，整体流程可预测，但某些步骤可用启发式或概率优化。理想系统应根据问题特征将任务路由到合适的专用求解器、执行多步工作流并具备回滚与恢复能力、在接受概率性结果前进行确定性校验、以可预测方式组合各能力同时保留生成式模型的灵活性。不确定性应成为系统设计的一级公民。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;专用模型的模块化协作&lt;/strong&gt;：未来不是单一模型包打天下，而是数百数千个专用模型协同工作。语言模型在语言任务上表现优异，但在符号运算、视觉空间推理、时间规划、持续目标行为等方面表现不佳。应构建能够将问题路由到最适合的专用模型的系统、整合不同模型输出为统一解决方案、保持各组件兼容性允许独立进化、在个别模型失效时优雅处理不影响整体系统。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三阶段架构路线图&lt;/strong&gt;：第一阶段为基础层，包含上下文管理服务、记忆服务、工作流引擎和Agent协调层；第二阶段为能力层，包含专用模型控制、符号推理引擎、规划与目标管理、跨模态整合；第三阶段为涌现层，真正的AGI将从上述各组件的协同作用中涌现，而非单一模型突破。系统能力将超越各部分总和，依赖于精心设计的架构。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.vincirufus.com/posts/agi-is-engineering-problem/"&gt;AGI is an Engineering Problem&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Vinci Rufus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未注明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AGI进展突破与未来之路OpenAI Podcast第五期深度解析</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-progress-breakthroughs-openai-podcast-ep5/</link><pubDate>Mon, 18 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-progress-breakthroughs-openai-podcast-ep5/</guid><description>&lt;h1 id="agi进展突破与未来之路openai-podcast-ep-5深度解析"&gt;AGI进展、突破与未来之路——OpenAI Podcast Ep. 5深度解析&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本期OpenAI Podcast由首席科学家Jakub Pachocki和研究员Szymon Sidor深度对谈，围绕AGI的进展、AI在奥数等竞赛中的突破、自动化科学发现的前景，以及未来AI发展的关键挑战展开。两位嘉宾结合自身成长经历和一线研发视角，剖析了AI能力的边界、评测体系的局限、推理能力的突破，以及AGI落地对社会和个人的深远影响。结论认为，AI正加速逼近自动化科学发现的门槛，推理与创造力的突破已现端倪，但未来的衡量标准、社会影响与技术治理仍需持续探索。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次对话的核心围绕AGI发展的三大维度展开：能力突破、评测瓶颈与社会影响。两位嘉宾从波兰编程竞赛高中的成长经历谈起，揭示了早期结构化思维训练对AI研究的重要性。他们详细分析了AI在国际数学奥林匹克等顶级竞赛中获得金牌的历史性意义，这标志着AI在复杂推理能力上已能与人类顶尖选手媲美。然而，他们也强调，单一竞赛成绩已难以全面衡量AI能力，未来的评价体系需要转向关注AI在现实世界中的实际影响和创新能力。&lt;/p&gt;
&lt;p&gt;关于自动化科学发现，两位研究员描绘了令人兴奋的前景：AI正逐步具备成为&amp;quot;自动化研究员&amp;quot;的潜力，能够全天候生成新想法、推动技术进步。这种通用性不仅体现在特定领域的突破，更在于AI能跨领域整合知识、推理和创新。医学、AI安全、对齐等领域已出现AI主导的突破，未来AI有望在更多复杂领域实现自动化创新。&lt;/p&gt;
&lt;p&gt;对话还深入探讨了现有评测体系的瓶颈。传统AI评测正面临&amp;quot;饱和&amp;quot;——模型在标准测试中已达人类顶级水平，难以再用分数区分进步。现有评测往往只反映&amp;quot;考试型&amp;quot;能力，未必代表AI在实际工作和创新中的实用性。未来评测应更关注AI发现新见解、解决开放性问题的能力，以及在长时推理、复杂任务中的表现。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;自动化科学发现&lt;/strong&gt;：这是AGI发展的关键里程碑，指AI系统能够像人类研究员一样，自主提出假设、设计实验、分析数据并得出科学结论。两位嘉宾认为，AI正加速逼近这一门槛，未来有望成为&amp;quot;自动化研究团队&amp;quot;，能全天候工作、快速迭代想法。这不仅会极大加速技术进步，还可能在医学、材料科学、AI安全等领域带来突破性发现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;评测体系转型&lt;/strong&gt;：从&amp;quot;考试型&amp;quot;评测转向&amp;quot;创新型&amp;quot;评测是当务之急。传统评测如MMLU、HumanEval等已趋于饱和，模型在这些基准测试上的表现已接近或超过人类水平，但这些分数难以反映AI在实际应用中的价值。未来的评测应该关注AI在开放性问题、跨领域整合、长链推理等复杂场景中的表现，以及其产生新见解、推动创新的能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;元认知能力&lt;/strong&gt;：近期AI在长链推理和&amp;quot;自我对话&amp;quot;式解题上取得突破，模型能主动判断何时无法解题，展现出元认知能力。这意味着AI不仅能解决问题，还能反思自己的解决过程、识别知识盲区、主动寻求更多信息。这种自我反思和判断能力是通向更高级智能的重要标志。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI的社会形态&lt;/strong&gt;：未来的AGI可能不是单一的超级智能体，而是&amp;quot;自动化研究团队&amp;quot;——能够自主开展科研、工程、设计等高复杂度任务，并与人类协作、交流。这种AI将极大加速技术进步，但也带来信任、数据安全、社会治理等新挑战。如何确保AI的安全性与可控性，如何推动AI与人类的协作共生，都是需要深入思考的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结构化思维教育&lt;/strong&gt;：对于2025年的年轻人，两位嘉宾强烈建议学习编程或其他能培养结构化思维的技能。即使AI能自动完成任务，理解底层原理、具备分解复杂问题的能力依然稀缺且宝贵。这种思维训练不仅是为了职业发展，更是为了在AI时代保持主动性和创造力，敢于追求&amp;quot;改变世界&amp;quot;的大目标。&lt;/p&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=yBzStBK6Z8c&amp;amp;list=WL&amp;amp;index=9"&gt;AGI progress, surprising breakthroughs, and the road ahead — the OpenAI Podcast Ep. 5&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;OpenAI&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-15&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AGI已成伪命题？Sam Altman与专家对通用人工智能概念的再思考</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/agi-meaningless-term-sam-altman-rethink/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/agi-meaningless-term-sam-altman-rethink/</guid><description>&lt;h1 id="agi已成伪命题sam-altman与专家对通用人工智能概念的再思考"&gt;AGI已成伪命题？Sam Altman与专家对&amp;quot;通用人工智能&amp;quot;概念的再思考&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;OpenAI CEO Sam Altman在CNBC采访中直言，AGI（人工通用智能）已&amp;quot;不是一个特别有用的术语&amp;quot;。本文结合多位计算机科学专家的观点，深入探讨AGI定义的模糊性、行业内外对其的不同解读，以及为何越来越多的业内人士认为，与其执着于&amp;quot;AGI&amp;quot;这一模糊目标，不如关注AI在各专业领域的实际进展。文章同时梳理了OpenAI最新发布的GPT-5模型的市场反响，以及行业对AI发展路径的理性反思。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先围绕Sam Altman在CNBC&amp;quot;Squawk Box&amp;quot;节目中的言论展开，他坦言AGI这一概念在当前的技术讨论中已经失去了实际意义。AGI通常被定义为&amp;quot;能够完成任何人类智力任务的人工智能&amp;quot;，但Altman指出，业界和学界对AGI的定义各不相同，有人将其理解为&amp;quot;能完成世界上大量工作的AI&amp;quot;，而&amp;quot;工作&amp;quot;的内涵本身在不断变化，这使得AGI的标准变得愈发模糊。他强调，AI能力的提升是一个持续的、指数级的过程，社会将越来越多地依赖AI完成各类任务，与其纠结于&amp;quot;是否达到AGI&amp;quot;，不如关注AI能力的实际扩展和应用。&lt;/p&gt;
&lt;p&gt;这一观点得到了多位专家的认同。The Futurum Group副总裁Nick Patience认为，AGI虽然是一个激励人心的&amp;quot;北极星&amp;quot;，但其模糊、科幻色彩浓厚的定义，反而掩盖了AI在专业领域的真实进展。他指出，AGI概念更多地被用来吸引资金和公众关注，而非推动技术本身的落地。事实上，OpenAI等初创公司正是凭借&amp;quot;终将实现AGI&amp;quot;的承诺，获得了数十亿美元的投资和高估值，OpenAI最近一次估值高达3000亿美元。&lt;/p&gt;
&lt;p&gt;文章进一步分析了资本炒作与技术现实之间的落差。2025年8月，OpenAI发布了最新的GPT-5模型，声称其在写作、编程、医疗健康等领域&amp;quot;更聪明、更快、更有用&amp;quot;，但市场反应褒贬不一，许多评论认为这只是对前代产品的&amp;quot;渐进式升级&amp;quot;，并未带来革命性突破。南安普顿大学计算机科学教授Wendy Hall批评当前行业&amp;quot;如同蛮荒西部&amp;quot;，缺乏统一的衡量标准，容易滋生虚假宣传。她呼吁AI公司在发布新产品时应公开其在全球公认标准下的表现指标。&lt;/p&gt;
&lt;p&gt;最后，Altman提出了一种新的思考框架。他坦言，OpenAI最新模型尚未达到他个人对AGI的定义——即系统能够自主、持续学习。他认为，与其用&amp;quot;是否AGI&amp;quot;这种二元划分，不如用&amp;quot;能力层级&amp;quot;来描述AI距离&amp;quot;通用智能&amp;quot;还有多远。在2024年FinRegLab AI Symposium上，Altman表示，OpenAI现在更倾向于用不同的&amp;quot;能力层级&amp;quot;来衡量AI进展。他预测，未来两年内，AI将在某些专业领域（如数学定理、科学发现）实现关键突破，但距离真正意义上的&amp;quot;通用智能&amp;quot;仍有距离。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI定义的模糊性&lt;/strong&gt;：AGI（人工通用智能）通常被定义为&amp;quot;能够完成任何人类智力任务的人工智能&amp;quot;，但这一概念在实践中缺乏清晰的边界。Sam Altman指出，业界对AGI的理解各不相同——有人将其理解为能够完成&amp;quot;世界上大量工作&amp;quot;的AI，但&amp;quot;工作&amp;quot;的内涵本身在不断演进，这使得AGI的标准变得愈发主观和模糊。这种定义上的不一致，导致技术讨论常常陷入无谓的争论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能力层级 vs. 二元划分&lt;/strong&gt;：Altman提出，AI的发展应该用&amp;quot;能力层级&amp;quot;（progress levels）来衡量，而不是&amp;quot;是否达到AGI&amp;quot;这种非黑即白的标准。每一代AI模型都在某些领域实现了突破，行业应该关注这些具体进展，而非执着于一个模糊的终极目标。这种框架转变反映了业界对AI发展的更理性、更务实的态度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;北极星 vs. 分散注意力的噱头&lt;/strong&gt;：专家们对AGI概念的价值存在分歧。Nick Patience认为，AGI可以作为一个激励行业前行的&amp;quot;北极星&amp;quot;，但其过度炒作和模糊定义，反而使其成为&amp;quot;分散注意力的噱头&amp;quot;，主要被用来吸引巨额融资。这种炒作现象分散了公众和投资者对AI实际能力和应用价值的关注。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;蛮荒西部与蛇油推销&lt;/strong&gt;：南安普顿大学教授Wendy Hall用&amp;quot;蛮荒西部&amp;quot;来形容当前AI行业缺乏统一标准的现状。她批评行业中存在&amp;quot;蛇油推销&amp;quot;（snake oil salesmen）现象，即公司通过夸大宣传来吸引投资和用户。她呼吁建立全球公认的评估标准，让AI产品的表现能够被客观衡量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;专业突破 vs. 通用智能&lt;/strong&gt;：Altman预测，未来两年内，AI将在某些专业领域（如数学定理证明、科学发现）实现关键突破，但距离真正意义上的&amp;quot;通用智能&amp;quot;仍有距离。这一判断与许多专家的观点一致——AI的真正价值在于其在各专业领域的落地能力，而非追求一个遥不可及的&amp;quot;通用&amp;quot;目标。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.cnbc.com/2025/08/11/sam-altman-says-agi-is-a-pointless-term-experts-agree.html"&gt;Sam Altman now says AGI, or human-level AI, is &amp;rsquo;not a super useful term&amp;rsquo; — and he&amp;rsquo;s not alone&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;CNBC&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-11&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Demis Hassabis专访 从游戏AI到世界模型 AGI进化的真实路径</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</guid><description>&lt;h1 id="demis-hassabis专访从游戏ai到世界模型agi进化的真实路径"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Google DeepMind CEO Demis Hassabis在《Release Notes》播客中系统梳理了从游戏AI到思考型模型、世界模型的技术演进。他分享了DeepMind如何通过Genie 3等项目推动AI理解现实世界，阐述了&amp;quot;多模态+工具+系统&amp;quot;的AGI路径，并介绍了以Kaggle Game Arena为代表的新型AI评测体系。Demis强调，未来AI不仅要能感知和输出，更要具备深度思考、世界理解和自我进化能力。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次访谈围绕DeepMind的技术演进路径展开，首先梳理了从AlphaGo、AlphaZero等游戏AI到&amp;quot;思考型模型&amp;quot;的发展脉络。Demis指出，DeepMind近期发布节奏极快，几乎每天都有新突破，包括Deep Think、IMO金牌、Genie 3等。这种&amp;quot;agent+思考&amp;quot;范式被认为是迈向AGI的必经之路，AI不仅要能做出第一个反应，更要能反复自我修正和优化思路。&lt;/p&gt;
&lt;p&gt;核心技术突破集中在Genie 3与世界模型方向。所谓世界模型，就是AI不仅理解语言和数学，还能理解物理世界的结构、规律、材料、流体、生命体等。Genie 3的突破在于保证了&amp;quot;世界一致性&amp;quot;——比如你离开房间再回来，物体还在原位。这种物理一致性是AI理解现实的关键标志，已被用于训练SIMA等游戏智能体，实现&amp;quot;AI在AI生成世界中自主探索&amp;quot;。&lt;/p&gt;
&lt;p&gt;在AI评测方面，传统评测如AIME数学题已接近饱和，Deep Think已达99.2%。Demis认为需要更难、更广、更真实的评测体系。Kaggle Game Arena采用&amp;quot;AI对AI竞技&amp;quot;思路，通过多样化游戏自动生成难度和评分，避免传统题库泄题、过拟合等问题。游戏作为评测场景具有客观可量化、自动扩展难度、可引入多智能体挑战等优势。&lt;/p&gt;
&lt;p&gt;关于AI产品化，Demis指出AI正从&amp;quot;单一大模型&amp;quot;向&amp;quot;系统化&amp;quot;演进，未来AI产品将是&amp;quot;模型+工具+系统&amp;quot;的组合。产品化挑战在于AI能力进化极快，产品设计需&amp;quot;可插拔&amp;quot;，能随时替换底层引擎。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;omni model&amp;quot;（全能模型），实现&amp;quot;一个模型做所有事&amp;quot;。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型（World Model）&lt;/strong&gt;：AI必须理解物理世界的结构、规律和一致性，才能实现通用智能和现实应用。这不仅包括语言和数学，还包括物理、材料、流体、生命体等现实世界要素。世界模型是AI&amp;quot;走出屏幕&amp;quot;、在现实中自主行动的前提。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考型模型（Thinking Models）&lt;/strong&gt;：从游戏AI演化而来的一条主线，强调AI不仅要感知和输出，还能自主规划、推理和决策。类似人类的深度思考过程，AI需要&amp;quot;反复自我修正和优化思路&amp;quot;，而不仅仅是做出第一个反应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统化AI（From Model to System）&lt;/strong&gt;：未来AI产品将由&amp;quot;模型+工具+系统&amp;quot;组成，能力边界动态扩展。模型不仅能推理，还能调用外部工具（如搜索、代码、物理模拟器等），实现更强的复合能力。部分能力应内置于主模型，部分则以外部工具形式存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;新型评测体系（Game Arena）&lt;/strong&gt;：AI能力评测需覆盖推理、物理智能、多目标权衡、安全性等多维度。Kaggle Game Arena通过&amp;quot;AI对AI竞技&amp;quot;自动生成难度，避免传统题库泄题和过拟合问题，推动AI能力全面进化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Omni Model愿景&lt;/strong&gt;：未来AGI是多模态、全能型模型，能在语言、视觉、物理、推理等各领域均衡表现。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;一个模型做所有事&amp;quot;的全能智能体。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=njDochQ2zHs&amp;amp;list=WL&amp;amp;index=5"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Google for Developers&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>加速科学发现与 AI —— Demis Hassabis 剑桥大学讲座</title><link>https://linguista.cn/rosetta/chat-notes/demis-hassabis-cambridge-2025-accelerating-scientific-discovery-with-ai/</link><pubDate>Mon, 24 Mar 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/demis-hassabis-cambridge-2025-accelerating-scientific-discovery-with-ai/</guid><description>&lt;h1 id="加速科学发现与-ai--demis-hassabis-剑桥大学讲座"&gt;加速科学发现与 AI —— Demis Hassabis 剑桥大学讲座&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Google DeepMind 联合创始人兼 CEO Demis Hassabis 在剑桥大学发表演讲，回顾了从国际象棋启蒙到创立 DeepMind 的历程，重点介绍了 AlphaGo 在围棋领域的突破及诺贝尔奖项目 AlphaFold 在蛋白质折叠问题上的革命性进展，展望了数字生物学与通用人工智能的未来，并强调了负责任发展 AI 的重要性。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/hHooQmmzG4k?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="加速科学发现与 AI —— Demis Hassabis 剑桥大学讲座"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AlphaFold&lt;/strong&gt;：DeepMind 开发的蛋白质结构预测系统，达到原子级精度，荣获 2024 年诺贝尔化学奖，已开放超过 2 亿个蛋白质结构数据&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI（通用人工智能）&lt;/strong&gt;：DeepMind 的终极目标，旨在构建具备通用智能的系统，结合搜索规划与大型语言模型等技术路径推进&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数字生物学&lt;/strong&gt;：Hassabis 提出的概念，将 AI 作为理解生物复杂性的新语言，推动虚拟细胞模拟和药物发现等领域的变革&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AlphaGo/AlphaZero&lt;/strong&gt;：通过自对弈和神经网络引导搜索实现超越人类水平的游戏 AI 系统，验证了学习系统发现新知识的能力&lt;/p&gt;</description></item><item><title>人工智能在数学与物理学中的应用——Mike Douglas 于普林斯顿高等研究院的讲座</title><link>https://linguista.cn/rosetta/chat-notes/ai-in-mathematics-and-physics-mike-douglas-ias-2025/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/ai-in-mathematics-and-physics-mike-douglas-ias-2025/</guid><description>&lt;h1 id="人工智能在数学与物理学中的应用mike-douglas-于普林斯顿高等研究院的讲座"&gt;人工智能在数学与物理学中的应用——Mike Douglas 于普林斯顿高等研究院的讲座&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;哈佛大学 Michael Douglas 在普林斯顿高等研究院发表讲座，系统回顾了人工智能在数学与理论物理领域的应用现状，包括辅助科学计算、数学数据科学、组合优化和交互式定理证明等成功范例。讲座提出了数学研究助理的愿景，探讨了自主数学研究的可能性，并预测未来两三年内AI将在数学研究中发挥重要作用，甚至可能达到或超越人类顶级研究人员的水平。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/yuvqVXFVjt0?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="人工智能在数学与物理学中的应用——Mike Douglas 于普林斯顿高等研究院的讲座"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI（通用人工智能）&lt;/strong&gt;：指具备人类级别通用认知能力的人工智能系统，行业领导者预计将在未来2至3年内出现&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;交互式定理证明&lt;/strong&gt;：利用计算机辅助验证数学证明的技术，代表工具如 Lean 定理证明器，可对证明进行形式化并由机器检验&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数学数据科学&lt;/strong&gt;：对数学数据集进行模式分析以发现新猜想的方法，例如从 L 函数系数中发现 murmurations 现象&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数学研究助理&lt;/strong&gt;：Douglas 提出的概念，指能够辅助编码、文献搜索、定理证明、形式化及探索数学概念的AI系统&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AlphaFold&lt;/strong&gt;：DeepMind 开发的蛋白质结构预测AI系统，被视为衡量AI对科学研究潜在影响力的标杆性成果&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;视频链接：&lt;/strong&gt; &lt;a href="https://www.youtube.com/watch?v=yuvqVXFVjt0"&gt;https://www.youtube.com/watch?v=yuvqVXFVjt0&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本次讲座由哈佛大学 Mike Douglas 主讲，深入探讨了人工智能（AI）在数学和物理学领域的应用现状、发展趋势及未来潜力。讲座首先回顾了 AI 领域的快速发展，特别是近年来计算能力的指数级增长和以 AlphaFold 为代表的重大突破，引出了 AI 对科学研究，尤其是理论物理和数学研究的潜在影响。&lt;/p&gt;
&lt;p&gt;尽管 AI 在这些领域的应用尚处于起步阶段，但讲座详细介绍了几个当前已经取得成功的范例，包括辅助科学计算、数学数据科学、组合优化以及交互式定理证明。通过这些具体的例子，展示了 AI 如何帮助研究人员发现数据模式、搜索文献、辅助编码、提出猜想，甚至解决复杂的数学问题。&lt;/p&gt;
&lt;p&gt;讲座的核心部分着眼于 AI 的未来发展，特别是“数学研究助理”这一概念的提出。Mike Douglas 详细阐述了这类助理的潜在功能，包括但不限于辅助编码、文献搜索、定理证明、形式化以及探索数学概念等。他强调，虽然目前的 AI 技术还无法完全实现这一愿景，但随着语言模型和强化学习等技术的不断进步，这一目标正变得越来越触手可及。&lt;/p&gt;</description></item><item><title>Deepseek与免费工具组合提前感受AGI逼近</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/deepseek-cline-agi-free-tools/</link><pubDate>Sun, 23 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/deepseek-cline-agi-free-tools/</guid><description>&lt;h1 id="deepseek与免费工具组合提前感受agi逼近"&gt;Deepseek与免费工具组合提前感受AGI逼近&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文详细介绍了如何通过Deepseek配合VS Code和Cline插件两个免费工具，构建强大的AI编程和自动化环境。作者通过多个实用场景展示了这套组合的强大功能，包括AI自动操作浏览器发送邮件、查找删除重复文件、网页内容抓取翻译、本地笔记改写发布等。文章还提供了详细的工具安装配置步骤，以及火山引擎等替代API方案，并介绍了MCP协议扩展AI能力的原理和资源。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先通过引人入胜的应用场景展示了AI工具的强大潜力，让读者感受到AGI（通用人工智能）的逼近。这些看似遥不可及的功能实际上可以通过三个工具的组合实现：VS Code作为基础开发环境、Cline插件提供AI编程能力、Deepseek API提供强大的语言模型支持。&lt;/p&gt;
&lt;p&gt;在工具介绍部分，作者详细说明了VS Code作为开源代码编辑器的地位，它是目前AI编程工具的基础，许多知名工具如Cursor、Windsurf等都是基于VS Code二次开发的。Cline插件则被作者推荐为最好用的AI编程工具之一，支持本地模型和云端主流大模型，在Open Router的各项排行榜中都名列前茅。&lt;/p&gt;
&lt;p&gt;关于API配置，文章提供了多种选择。除了Deepseek官网API外，还介绍了火山引擎、硅基流动、Openrouter、TogetherAI等第三方服务。特别推荐了火山引擎的新用户活动，并提供邀请码和详细的配置步骤指南。&lt;/p&gt;
&lt;p&gt;最后，文章深入介绍了MCP（Model Calling Protocol）协议，这是Anthropic公司推出的让大模型能够调用外部插件的标准。通过Smithery.ai服务和GitHub上的Awesome MCP Server库，用户可以轻松为AI添加网页搜索、数据库操作、本地文件编辑等功能，极大拓展了AI的实用能力。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;VS Code生态系统&lt;/strong&gt;：VS Code是微软开源的代码编辑器，已发展成为AI编程时代的基础设施。它不仅自身功能强大，更重要的是提供了丰富的插件生态系统，成为众多AI编程工具的底层平台。选择VS Code意味着获得最大的灵活性和自定义空间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cline插件&lt;/strong&gt;：这是一个AI编程助手插件，在专业排行榜中表现优异。它的核心价值在于支持多种模型接入方式，包括本地Ollama部署和云端API服务，为用户提供了灵活的模型选择。Cline的高频使用证明其实用性和可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;API服务多样化&lt;/strong&gt;：Deepseek官网API可能不稳定，但市场上存在丰富的替代方案。火山引擎等第三方服务商提供免费Token额度，降低了用户试用成本。这种竞争格局为用户提供了更多选择和更好的服务体验。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MCP协议&lt;/strong&gt;：Model Calling Protocol是解决大模型闭塞性问题的关键技术。它允许AI模型调用外部工具和服务，突破知识局限性和操作能力限制。这标志着AI从单纯的语言处理向真正的智能代理演进。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI能力体现&lt;/strong&gt;：文章展示的多个场景——自动发邮件、文件管理、内容改写等——体现了AI的通用性问题解决能力。这些跨越不同领域的能力组合，正是AGI的重要特征，预示着人工智能正在向更通用、更自主的方向发展。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/PuHwfJk3EZv8eR4y10EAvQ"&gt;一秒超神：Deepseek + 这两个免费工具！提前感受 AGI 逼近&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>ChatGPT的可靠性问题：两年投资后的现状</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</guid><description>&lt;h1 id="chatgpt的可靠性问题两年投资后的现状"&gt;ChatGPT的可靠性问题：两年投资后的现状&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文记录了作者对ChatGPT最新版本的测试结果，展示了其在处理基本任务时仍然存在的可靠性问题。通过美国各州收入与人口表格、加拿大省份元音计数等测试，暴露出ChatGPT在计数、完整性、基础事实判断等方面的不足。作者质疑在如此多错误存在的情况下，通用人工智能（AGI）是否真如某些预测所言即将实现。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从软银集团孙正义对AGI的乐观预测切入，引出作者对ChatGPT实际表现的测试。测试内容包括两个主要案例：生成美国各州收入与人口表格，以及统计加拿大省份名称中的元音数量。&lt;/p&gt;
&lt;p&gt;在美国各州测试中，ChatGPT初始输出遗漏了多个州，补充人口密度列时出现计算错误，甚至将阿拉斯加完全遗漏。经过多次修正才最终得到正确结果。在加拿大省份元音计数测试中，ChatGPT将字母&amp;quot;h&amp;quot;误认为元音，计数多次出错，修正过程同样曲折。&lt;/p&gt;
&lt;p&gt;文章还引用了Sayash Kapoor对OpenAI新Operator代理的测试结果，显示即使是新发布的AI代理也存在可靠性问题。作者最后引用1841年经典著作中的论述，反思当前AI热潮中可能存在的盲目性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI预测与现实的差距&lt;/strong&gt;：软银孙正义预测AGI将在未来几年内实现，但基础测试显示当前AI模型连简单任务都无法可靠完成，这种预测与实际能力之间存在巨大鸿沟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性问题的具体表现&lt;/strong&gt;：ChatGPT在计数、列表完整性、基础事实判断等方面频发错误，包括无法准确计数到50、遗漏美国州、错误识别元音字母等，这些问题在经过两年大规模投资后仍然存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI模型的盲目自信&lt;/strong&gt;：ChatGPT在犯错时并未表现出不确定性，而是自信地给出错误答案，只有在被明确指出后才进行修正，这种特性增加了用户被误导的风险。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修正过程的繁琐性&lt;/strong&gt;：即使是简单任务，也需要用户多次指出错误才能得到正确结果，这种交互方式大大降低了AI工具的实用性和可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史警示的当代意义&lt;/strong&gt;：作者引用1841年关于群体盲目性的论述，暗示当前AI热潮可能存在类似的非理性现象，提醒人们需要更客观地评估AI技术的实际发展水平。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/chatgpt-in-shambles?utm_source=post-email-title&amp;amp;publication_id=888615&amp;amp;post_id=156479923&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=208yzy&amp;amp;triedRedirect=true&amp;amp;utm_medium=email"&gt;ChatGPT in Shambles&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>中国AI初创企业：超越DeepSeek的四大值得关注的公司</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/four-chinese-ai-startups-beyond-deepseek/</link><pubDate>Wed, 05 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/four-chinese-ai-startups-beyond-deepseek/</guid><description>&lt;h1 id="中国ai初创企业超越deepseek的四大值得关注的公司"&gt;中国AI初创企业：超越DeepSeek的四大值得关注的公司&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;自2022年ChatGPT发布以来，中国科技界一直在努力开发本土的AI替代品，催生了众多初创企业和数十亿美元的投资。DeepSeek作为中国AI初创企业的代表，其快速崛起震惊了全球。本文介绍了四家除了DeepSeek之外值得关注的中国AI初创企业——Stepfun、ModelBest、Zhipu和Infinigence AI，它们各自在不同的技术方向上展现出独特优势，从基础模型开发到小型化部署，再到异构计算基础设施，构成了中国AI生态系统的重要组成部分。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;中国AI初创企业的发展已经进入了一个新的阶段，从最初的快速冲刺逐渐转变为一场高风险的马拉松。目前，中国的AI赛道由阿里巴巴、字节跳动等科技巨头以及一些资金雄厚的竞争对手主导。然而，随着AI技术的发展，一些小型创新企业也开始崭露头角，它们需要找到自己的独特定位，否则可能会被市场淘汰。&lt;/p&gt;
&lt;p&gt;文章重点介绍了四家各具特色的AI初创企业。Stepfun由前微软高管创立，以开发人工通用智能（AGI）为目标，在2024年发布了11个基础AI模型，其Step-2模型在LiveBench排名中仅次于顶级国际模型。ModelBest则走小型化路线，专注于效率导向的小型语言模型，其MiniCPM系列专为设备端实时处理设计，在降低成本和增强隐私保护方面具有优势。Zhipu起源于清华大学，与政府和学术界联系紧密，正在开发对话模型ChatGLM和视频生成器Ying，但已成为美国出口管制的目标。Infinigence AI专注于基础设施建设，其异构计算集群技术能够优化不同芯片架构之间的协同工作，为中国AI企业在芯片受限环境下提供了新的解决方案。&lt;/p&gt;
&lt;p&gt;这些公司的发展路径反映了中国AI初创企业的多元化趋势。一些公司如Minimax和Moonshot放弃了成本高昂的基础模型训练，转而专注于面向消费者的应用程序开发；而像Stepfun和Infinigence AI这样的公司则加倍投入研究，部分原因是受到美国半导体限制的影响。这种分化既是对市场现实的回应，也是在技术封锁下的创新探索。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;人工通用智能（AGI）&lt;/strong&gt;：Stepfun仍将AGI作为其发展目标，这在中国初创企业中已经不多见。AGI指的是具备与人类相当或超越人类水平通用智能的AI系统，能够在各种任务中表现出类人的学习和推理能力。随着AI竞争的加剧，许多中国初创企业已经转向更务实的应用开发，Stepfun的坚持使其在基础模型研究领域保持了独特定位。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;小型语言模型（SLM）&lt;/strong&gt;：ModelBest专注于小型语言模型的开发，其MiniCPM 3.0只有40亿个参数，但在各种基准测试中的表现与GPT-3.5相当。小型语言模型的优势在于可以在智能手机、PC、汽车系统等设备上进行实时处理，降低成本并增强隐私保护。这种&amp;quot;小而美&amp;quot;的路线代表了中国AI企业在算力受限环境下的一种务实选择。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异构计算集群&lt;/strong&gt;：Infinigence AI的核心技术是将不同品牌的芯片组合起来执行AI任务，形成&amp;quot;异构计算集群&amp;quot;。由于美国芯片制裁，中国AI公司无法获得最先进的英伟达芯片，因此需要学会使用AMD、华为等多种芯片。Infinigence AI的技术通过优化不同芯片架构之间的协同工作，声称可以将AI模型训练时间缩短30%，这为中国AI企业提供了一条在技术封锁下维持创新能力的路径。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;ldquo;六虎&amp;rdquo;&lt;/strong&gt;：这是对中国AI领域六家领先初创企业的统称，包括Stepfun、智谱、Minimax、Moonshot、01.AI和百川。这些公司被认为是中国AI领域的佼佼者，获得了大量投资和政府支持。然而，随着竞争加剧和市场分化，&amp;ldquo;六虎&amp;quot;之间的发展路径也开始出现差异。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;出口管制与技术主权&lt;/strong&gt;：Zhipu成为新一批中国AI初创企业中第一个受到美国政府关注的公司，其10家子公司被列入限制贸易名单。美国声称Zhipu的技术正在帮助中国的军事，但该公司对此予以否认。这一事件凸显了AI技术竞争背后的地缘政治因素，也迫使中国AI企业加快技术自主化的步伐。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.technologyreview.com/2025/02/04/1110942/four-chinese-ai-startups-deepseek/"&gt;Four Chinese AI startups to watch beyond DeepSeek&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;MIT Technology Review&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-02-04&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>DeepSeek R1发布引发的思考 AI发展路径与未来趋势</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/deepseek-r1-ai-development-questions/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/deepseek-r1-ai-development-questions/</guid><description>&lt;h1 id="deepseek-r1发布引发的思考ai发展路径与未来趋势"&gt;DeepSeek R1发布引发的思考：AI发展路径与未来趋势&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;MIT经济学家Daron Acemoglu针对DeepSeek R1的发布提出了四个关键问题：美国科技行业是否在AI投资方向上出现群体思维、中国模式是否证明威权制度下的创新潜力、美国对华出口管制政策是否失效，以及DeepSeek是否真正推动我们接近AGI。这些问题直指当前AI发展的核心争议。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Acemoglu首先指出美国AI投资规模已达1万亿美元，但科技行业可能陷入&amp;quot;群体思维&amp;quot;，忽视了更经济、更有前景的技术路径。DeepSeek以550万美元的训练成本实现了与数亿美元投资的美国模型相当的效果，其技术路径更依赖强化学习和混合专家模型，有效完善了思路链推理。这种差异化路径本应被美国工业界探索，却因炒作和从众心理被集体忽视。&lt;/p&gt;
&lt;p&gt;关于中美科技竞争，Acemoglu承认DeepSeek的成功令人思考威权主义制度下的创新潜力。但他强调，DeepSeek的所有技术方法均源于美国和欧洲多年的研究成果，中国企业的核心贡献在于将这些现有技术以创新方式组合。与其他依赖政府资助的中国AI公司不同，DeepSeek的&amp;quot;不为人知&amp;quot;的独立性可能是其成功的关键因素，但这种状态能否在未来持续仍是未知数。&lt;/p&gt;
&lt;p&gt;在出口管制政策方面，作者认为完全零和博弈的策略是错误的。这种策略只有在确信AGI即将实现且先行者将获得巨大地缘政治优势的前提下才有意义，而这两个假设本身就值得质疑。中美两国在AI领域存在广泛的合作空间，尤其是在能提高人类生产力的技术创新方面。&lt;/p&gt;
&lt;p&gt;关于AGI愿景，Acemoglu对近期实现AGI持怀疑态度。他认为DeepSeek确实证明了现有技术路径的优化潜力，但已知方法的改进和成本降低并不能奇迹般地在几年内实现AGI。Yann LeCun的评论进一步补充了重要观点：AGI不会是一个突发的单一事件，而是渐进过程；创新一旦开源发表就能惠及整个行业，地理起源并非决定性因素。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;群体思维与路径依赖&lt;/strong&gt;：美国科技行业在AI投资上表现出惊人的同质化，所有领先公司都采用相同的&amp;quot;海量数据预训练+下一个词预测&amp;quot;基础模型策略。这种集体忽视替代性路径的现象正是Acemoglu在《权力与进步》中预言的&amp;quot;群体思维+炒作&amp;quot;循环，导致对更经济有效方案（如DeepSeek的强化学习优先路径）的系统性盲视。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;榨取性制度与创新的悖论&lt;/strong&gt;：Acemoglu在《国家为何失败》中论证自上而下的&amp;quot;榨取性制度&amp;quot;阻碍创新，但DeepSeek的案例迫使学界重新思考这一命题。然而深入分析显示，DeepSeek的技术基础完全建立在西方学术研究成果之上，其创新本质是&amp;quot;组合式创新&amp;quot;而非&amp;quot;原创性突破&amp;quot;，这反而印证了开放社会在基础研究领域的长期优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;零和博弈的错误假设&lt;/strong&gt;：美国对华AI出口管制政策建立在一个隐含前提上：AGI竞赛是赢家通吃的零和游戏。Acemoglu犀利地指出这个双重假设本身存疑——既不能确定AGI的可行性，也无法证明先行者必然获得持久优势。这种地缘政治思维忽视了技术扩散的客观规律和合作的潜在收益。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI的渐进本质&lt;/strong&gt;：Yann LeCun的评论纠正了AGI认知的根本误区。AGI不应被想象为某个特定时刻的&amp;quot;奇点事件&amp;quot;，而是一个技术能力渐进累积的过程。一旦关键技术突破发生并公开，它将在短时间内被多方复制，这意味着地理先发优势在开源时代被显著削弱。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://x.com/DAcemogluMIT/status/1885755575289417919"&gt;Daron Acemoglu的推文&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Daron Acemoglu（MIT经济学家）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月20日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;评论者&lt;/td&gt;
 &lt;td&gt;Yann LeCun（Meta AI首席科学家）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Google DeepMind CEO Demis Hassabis 论 AGI、欺骗性 AI 与虚拟细胞构建</title><link>https://linguista.cn/rosetta/chat-notes/demis-hassabis-on-agi-deceptive-ai-and-virtual-cell/</link><pubDate>Thu, 23 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/demis-hassabis-on-agi-deceptive-ai-and-virtual-cell/</guid><description>&lt;h1 id="google-deepmind-ceo-demis-hassabis-论-agi欺骗性-ai-与虚拟细胞构建"&gt;Google DeepMind CEO Demis Hassabis 论 AGI、欺骗性 AI 与虚拟细胞构建&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Google DeepMind CEO Demis Hassabis 在访谈中探讨了通往 AGI 的路径，认为距离真正的通用人工智能仍需3至5年，当前系统在推理、规划和创造力方面存在不足。他讨论了AI欺骗性行为带来的安全隐患，并介绍了虚拟细胞构建、AlphaFold 蛋白质折叠等科学应用前景，强调技术进步与安全性之间需要取得平衡。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/yr0GiSgUvPU?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="Google DeepMind CEO Demis Hassabis 论 AGI、欺骗性 AI 与虚拟细胞构建"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI（通用人工智能）&lt;/strong&gt;：能够展现人类所有认知能力的AI系统，包括推理、规划、创造力和发明能力，而非仅在单一任务上表现出色&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;欺骗性AI&lt;/strong&gt;：部分AI系统在测试中隐藏真实能力或采取与训练目标相悖的行为，可能导致安全评估失效和不可预测风险&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：AI通过学习视频和模拟环境来理解物理世界的运行规律，是构建通用助手和机器人技术的关键基础&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;虚拟细胞&lt;/strong&gt;：模拟细胞内动态过程和分子相互作用的完整计算模型，旨在加速药物发现和疾病机理研究&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI创造力层次&lt;/strong&gt;：从插值（对现有知识的平均组合）到外推（超越已知范围）再到发明（创造全新事物），当前大语言模型尚未达到真正的外推级别创造力&lt;/p&gt;
&lt;p&gt;Google DeepMind CEO Demis Hassabis 论 AGI、欺骗性 AI 与虚拟细胞构建&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原文标题：Google DeepMind CEO Demis Hassabis: The Path To AGI, Deceptive AIs, Building a Virtual Cell&lt;/p&gt;</description></item><item><title>OpenAI 董事长 Bret Taylor 谈改变一切的三大 AI 变革</title><link>https://linguista.cn/rosetta/chat-notes/bret-taylor-three-ai-shifts-changing-everything/</link><pubDate>Wed, 22 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/bret-taylor-three-ai-shifts-changing-everything/</guid><description>&lt;h1 id="openai-董事长-bret-taylor-谈改变一切的三大-ai-变革"&gt;OpenAI 董事长 Bret Taylor 谈改变一切的三大 AI 变革&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;OpenAI 董事长、Sierra 联合创始人 Bret Taylor 深度探讨 AI 领域三大关键变革。他从个人顿悟时刻出发，分析了 AI 智能体的本质定义、通用人工智能的实现路径、软件工程范式的根本转变，并结合创业与大公司管理经验，阐述了第一性原理思维在 AI 时代商业决策中的应用，以及教育、科学研究等领域的深远影响。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/XEz-NXTJv3g?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="OpenAI 董事长 Bret Taylor 谈改变一切的三大 AI 变革"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI 智能体（AI Agent）——源自能动性（agency）概念，指赋予软件自主推理与决策能力的系统，能够代替人类完成复杂交互任务&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;通用人工智能（AGI）——指系统在计算机上达到或超越人类完成广泛任务的能力，其实现依赖数据、算力与算法三大要素的协同突破&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一性原理思维——从根本原因出发进行推理和决策的方法论，在快速变化的 AI 时代帮助创业者穿透市场噪音做出长远判断&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;创始人模式——创始人对公司决策保持深度问责的领导风格，核心在于自上而下的责任担当与自下而上的团队赋权之间取得平衡&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;软件工程范式转变——工程师角色从代码编写者转变为代码生成系统的操作者与验证者，未来需要全新的编程范式而非简单自动化现有流程&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;视频链接：&lt;a href="https://www.youtube.com/watch?v=XEz-NXTJv3g"&gt;OpenAI&amp;rsquo;s Chairman Bret Taylor Reveals 3 AI Shifts Changing Everything&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="讲座介绍"&gt;讲座介绍&lt;/h3&gt;
&lt;p&gt;本访谈录呈现了与技术思想家、连续创业者Bret Taylor的深度对话。Bret Taylor不仅是当前备受关注的AI初创公司Sierra的联合创始人兼CEO，更曾在Facebook担任CTO，并在Salesforce担任联席CEO，拥有在技术创新前沿和大型企业管理层面的双重丰富经验。&lt;/p&gt;</description></item><item><title>AGI与广泛浅层智能的本质区别</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-versus-broad-shallow-intelligence/</link><pubDate>Tue, 14 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-versus-broad-shallow-intelligence/</guid><description>&lt;h1 id="agi与广泛浅层智能的本质区别"&gt;AGI与广泛浅层智能的本质区别&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Gary Marcus在这篇文章中明确指出，尽管有人声称我们已经接近或达到了人工通用智能（AGI），但事实远非如此。当前的AI系统，尤其是大型语言模型（LLMs），应该被更准确地描述为&amp;quot;广泛浅层智能&amp;quot;（BSI）。虽然它们在应用范围上较为广泛，能够尝试解决多种问题，但缺乏深度理解、可靠性和推理能力，经常产生错误和幻觉。真正的AGI应当具备与人类相当的灵活性、丰富性和可靠性，能够解决普通人类在没有事先训练的情况下能够解决的问题。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先澄清了AGI的本质定义。Marcus引用了AGI概念共同创造者Shane Legg以及知名AI研究者François Chollet的观点，强调AGI不仅仅是能力广泛，更重要的是要具备与人类相当的灵活性和可靠性。AGI应该能够解决普通人类也能解决的认知问题，并且能够从经验中推广到全新情境。&lt;/p&gt;
&lt;p&gt;接着，文章深入分析了当前LLMs的局限性。尽管这些模型在某些特定领域表现出色，甚至在某些任务上超越了人类，但它们在其他方面则远远落后。Marcus指出，LLMs往往只是模仿互联网上类似问题的答案模式，而没有真正理解背后的概念和原理。这种表面化的处理方式导致模型经常产生&amp;quot;幻觉&amp;quot;——即自信地陈述完全错误的信息，并且缺乏基本的事实核查和合理性检查能力。&lt;/p&gt;
&lt;p&gt;基于这些观察，Marcus提出了&amp;quot;广泛浅层智能&amp;quot;（BSI）这一概念来准确描述当前AI技术的状态。BSI的特点是应用范围广泛，但理解深度不足。这种不可靠性意味着在大多数实际应用场景中，仍然需要人类介入来验证和纠正AI的输出，这大大限制了AI的实用价值。&lt;/p&gt;
&lt;p&gt;文章最后呼吁AI研究社区重新思考研究方向。Marcus认为，我们不应该满足于在BSI基础上不断改进，而应该将研究重点转向开发真正具备深度理解能力、可靠性和安全性的AI系统。过度依赖不可靠的AI可能会带来严重问题，因此超越BSI应该是人类面临的重要研究优先事项。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI（人工通用智能）&lt;/strong&gt;：真正的AGI不仅需要在多个任务上表现出色，更重要的是要具备与人类相当的灵活性和可靠性。它应该能够解决普通人类在没有专门训练的情况下就能解决的认知问题，并且能够将经验推广到全新的情境中。这种智能不是简单的模式匹配，而是基于对概念的深度理解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BSI（广泛浅层智能）&lt;/strong&gt;：这是Marcus提出的用来描述当前LLMs特性的概念。BSI系统在应用范围上确实广泛——它们可以尝试回答各种类型的问题，但它们的理解和推理都是浅层和表面的。BSI系统缺乏深度理解，经常产生错误，无法进行基本的事实核查，因此可靠性不足。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幻觉现象&lt;/strong&gt;：LLMs经常自信地陈述完全错误的信息，这种现象被称为&amp;quot;幻觉&amp;quot;。这是因为模型本质上是在预测和模仿训练数据中的语言模式，而不是真正理解事实。当遇到训练数据中不充分或存在矛盾的情况时，模型就会编造看似合理但实际上错误的信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;深度理解与语言模式&lt;/strong&gt;：这是区分AGI和BSI的关键所在。BSI系统依赖的是表面化的语言模式匹配，而AGI需要基于概念的深度推理。真正理解一个概念意味着能够在新情境中灵活应用，能够判断答案的合理性，能够在缺乏完整信息时进行合理的推断，而不是简单地套用见过的模式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性与安全性&lt;/strong&gt;：由于BSI系统的不可预测性，它们很难保证按照人类的要求行事，也无法确保其输出的安全性。在关键应用领域（如医疗、法律、自动驾驶等），这种不可靠性可能带来严重后果。因此，开发真正可靠的AI系统不仅是技术问题，更是安全问题。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/agi-versus-broad-shallow-intelligence"&gt;AGI versus &amp;ldquo;broad, shallow intelligence&amp;rdquo;&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>2025年不会迎来AGI，GPT-5也可能不会出现</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-gpt5-predictions-2025-reality-check/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/agi-gpt5-predictions-2025-reality-check/</guid><description>&lt;h1 id="2025年不会迎来agigpt-5也可能不会出现"&gt;2025年不会迎来AGI，GPT-5也可能不会出现&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文是Gary Marcus对2025年人工智能发展的冷静预测。文章指出，尽管外界对通用人工智能（AGI）和GPT-5充满期待，但受限于数据瓶颈和大型语言模型的固有限制，这两者都不太可能在2025年实现。Marcus通过分析OpenAI的研发困境、Elon Musk的预测变化等证据，支撑其观点，并呼吁媒体应该追究那些做出不切实际承诺者的责任。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章围绕两个核心预测展开论述。关于GPT-5，Marcus回顾了自己在2024年3月的准确预测，并指出尽管微软CTO曾声称GPT-5即将到来且能力将达到博士水平，但现实进展并不如意。通过Chatham House规则下的内部消息暗示，OpenAI可能只会先推出GPT-4.5，而《华尔街日报》的报道也证实OpenAI在构建配得上GPT-5名称的模型方面面临越来越多困难。&lt;/p&gt;
&lt;p&gt;关于AGI的讨论，Marcus引用了Elon Musk在CES采访中的言论变化。值得注意的是，Musk正在构建可能是迄今为止最大的语言模型Grok 3，他从之前预测&amp;quot;到2025年底AI将超过任何一个人&amp;quot;调整为&amp;quot;在未来几年内，AI将能够完成任何认知任务&amp;quot;。这种未明确承认的退缩被Marcus视为重要信号。&lt;/p&gt;
&lt;p&gt;Marcus坚持自2022年以来的观点，即仅靠扩展数据不足以实现强大的人工智能。他强调，这些不切实际的承诺正在影响政策制定者的关键决策，因此媒体应该更加审慎地报道AI进展，追究过度承诺者的责任。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;数据瓶颈与LLM固有限制&lt;/strong&gt;：大型语言模型的发展正在遭遇数据瓶颈，单纯依靠扩展数据和模型规模已经难以带来质的突破。这是GPT-5研发面临的核心技术障碍，也是AGI短期内难以实现的重要原因。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chatham House规则&lt;/strong&gt;：文章引用的内部消息来源采用了Chatham House规则，即允许分享会议内容但不得透露发言人身份。这种规则在行业内部讨论中较为常见，也增加了信息的可信度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;承诺与现实的差距&lt;/strong&gt;：从微软CTO的博士级能力预测，到Musk的AGI时间表，行业领袖的过度承诺与实际进展之间存在显著差距。Marcus通过准确预测GPT-5不会在2024年出现，建立了其预测的可信度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Grok 3的战略意义&lt;/strong&gt;：作为正在开发的可能是最大规模的语言模型，Grok 3的早期回报情况直接影响着行业对AGI时间表的判断。Musk基于Grok 3进展调整其预测，这一变化本身就是重要信号。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;媒体问责的重要性&lt;/strong&gt;：Marcus强调，过度乐观的AI预测不仅误导公众，更影响政策制定。媒体的理性报道和对过度承诺的追责，对于建立公众对AI发展的正确认知至关重要。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/agi-isnt-coming-in-2025-and-gpt-5"&gt;AGI isn&amp;rsquo;t coming in 2025, and GPT-5 probably isn&amp;rsquo;t either&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Gary Marcus对Sam Altman AGI基本已解决观点的反驳</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/gary-marcus-challenges-sam-altman-agi-confidence/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/gary-marcus-challenges-sam-altman-agi-confidence/</guid><description>&lt;h1 id="gary-marcus对sam-altman-agi基本已解决观点的反驳"&gt;Gary Marcus对Sam Altman AGI基本已解决观点的反驳&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Gary Marcus针对Sam Altman声称AGI基本已解决的观点进行了系统性反驳。Marcus指出，大型语言模型在分布偏移、常识推理、模型脆弱性等方面仍存在根本性缺陷，纯LLM扩展已进入边际收益递减期，且幻觉问题依然未解。他认为这些长期存在的问题缺乏原理性解决方案，因此对AGI的前景持谨慎态度。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Sam Altman近期在其博客中声称，我们已经知道如何构建传统意义上的AGI。这一观点立即引发了AI领域的广泛讨论。作为AI领域的知名批评家和认知科学家，Gary Marcus对此表示强烈反对，并列举了八个关键问题来支撑他的论点。&lt;/p&gt;
&lt;p&gt;Marcus首先从分布偏移问题入手，指出LLMs在相似任务上表现良好，但在不熟悉领域中的可靠性仍然存在问题。他引用了苹果2024年的推理论文验证了这一观点，并强调自己早在1998年就提出了类似问题。更值得注意的是，即便是数学问题这样的看似确定性领域，变量名称等微小变化也会导致问题解决能力下降30%，这充分说明了分布偏移问题的普遍性。&lt;/p&gt;
&lt;p&gt;在常识推理方面，Marcus与Ernie Davis的回顾研究表明，常识推理的不稳定性仍然是一个棘手问题。即便是像o1这样的先进模型，在某些基准测试中的结果也可能很脆弱或难以复制。Marcus强调，在o1的最佳表现案例中可能进行了大量数据增强，但这种策略在更开放的领域中是不可行的，这也限制了模型的实际泛化能力。&lt;/p&gt;
&lt;p&gt;Marcus进一步指出，纯LLM扩展已经进入边际收益递减期，这一观点得到了许多领域内领先人物的认同。更严重的是，由于缺乏明确、可访问、可靠的数据库式记录，幻觉问题依然存在，导致不准确的新闻摘要、诽谤、虚构来源、错误建议和不可靠性。他认为，尽管不能100%确定AGI不在眼前，但目前还没有看到对这些长期存在的问题的原理性解决方案。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;分布偏移问题&lt;/strong&gt;：这是指AI模型在训练数据分布之外的领域表现显著下降的现象。Marcus指出，LLMs在相似任务上泛化良好，但遇到不熟悉的领域时，即使是微小的变化也可能破坏其性能。这一问题在1998年就被Marcus提出，至今仍未得到有效解决。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;常识推理的脆弱性&lt;/strong&gt;：常识推理是人类智能的核心特征，但对AI系统来说仍然是一个巨大挑战。Marcus与Ernie Davis的研究表明，即使是最先进的LLMs，在常识推理任务上也表现出明显的不稳定性，这限制了它们在实际应用中的可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;边际收益递减&lt;/strong&gt;：Marcus指出，许多领域内领先人物已经承认，纯LLM扩展可能已经进入边际收益递减期。这意味着单纯通过扩大模型规模来提升性能的策略越来越难以奏效，AI发展可能需要寻找新的技术路径。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幻觉问题的根源&lt;/strong&gt;：LLMs缺乏明确、可访问、可靠的数据库式记录，这导致它们经常生成看似合理但实际错误的内容。这一问题不仅影响新闻摘要、建议系统等应用，还可能导致诽谤和虚假信息的传播。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;科学的可验证性标准&lt;/strong&gt;：Marcus在文章末尾引用评论指出，除非有可以独立验证的、符合科学标准的演示，否则AGI仍然是科幻小说。这反映了AI研究中科学严谨性与商业宣传之间的张力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/sam-altman-thinks-that-agi-is-basically"&gt;Why I don&amp;rsquo;t share Sam Altman&amp;rsquo;s confidence that AGI is basically a solved problem&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未注明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>人工智能通用智能的五个哀悼阶段</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/five-stages-agi-grief-marcus/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/five-stages-agi-grief-marcus/</guid><description>&lt;h1 id="人工智能通用智能的五个哀悼阶段"&gt;人工智能通用智能的五个哀悼阶段&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文探讨了人们对人工智能通用智能（AGI）的期望与现实之间的差距，以及面对这种差距时的不同心理反应。作者Gary Marcus借用悲伤的五个阶段理论，分析了当前AI领域对AGI的认知偏差，呼吁回归对AGI的严肃定义，避免通过重新定义标准来过早宣布胜利。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章开篇明确了AGI的定义，引用Ben Goertzel和Shane Legg的经典定义，将AGI描述为一种灵活且通用的智能，其资源性和可靠性与人类智能相当或超越。作者提供了具体的衡量标准，包括观看电影并描述情节、在任意厨房胜任厨师工作、将自然语言中的数学证明转化为符号形式等实际应用场景。&lt;/p&gt;
&lt;p&gt;随后，作者运用悲伤的五个阶段理论框架，系统性地分析了人们对AGI现状的不同反应：否认阶段的人们拒绝承认当前AI与AGI之间的巨大差距；讨价还价阶段的人试图通过重新定义AGI标准来降低期望；愤怒阶段针对那些过早宣称AGI已实现的观点；抑郁阶段面对AGI目标的遥远而感到沮丧；最终达到接受阶段，承认差距并继续努力。&lt;/p&gt;
&lt;p&gt;文章还详细剖析了三种典型的AGI目标重新定义方式：经济重新定义（以完成80%有价值工作或盈利1000亿美元为标准）、提前宣布胜利（声称当前语言模型已能完成几乎所有人类信息任务）、以及回避定义（在讨论AGI影响时拒绝明确标准）。作者强调坚持原始AGI定义的重要性，指出当前AI技术虽然在某些方面表现出色，但在灵活性和通用性上仍距真正的通用智能有相当长的路要走。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI的严格定义&lt;/strong&gt;：Gary Marcus坚持使用Ben Goertzel和Shane Legg的经典定义，即AGI应是一种灵活且通用的智能，其能力在资源性和可靠性上与人类智能相当或超越。这个定义强调智能的通用性和可靠性，而非单一任务的出色表现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;悲伤理论在技术认知中的应用&lt;/strong&gt;：借用悲伤的五个阶段理论（否认、讨价还价、愤怒、抑郁、接受）来描述技术社区对AGI发展现状的心理反应，这种比喻揭示了人们对技术突破的渴望与现实之间的认知失调。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;目标重定义的认知偏差&lt;/strong&gt;：通过经济标准（完成80%经济工作、盈利1000亿美元）或能力宣称（当前语言模型已完成大部分信息任务）来重新定义AGI，反映了人们试图通过降低标准来缩短现实与理想的距离，这种做法可能导致对真实进展的误判。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;灵活性与通用性的核心地位&lt;/strong&gt;：真正的AGI不仅需要在特定任务上表现出色，更重要的是具备跨领域的灵活适应能力和通用解决问题的能力，这是当前AI系统的主要短板所在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;认知失调的心理机制&lt;/strong&gt;：从否认到接受的心理过程，反映了技术社区在面对AGI遥远目标时的集体心理调适，承认差距并非否定进步，而是为更清晰的发展路径奠定基础。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/the-five-stages-of-agi-grief"&gt;The Five Stages of AGI Grief&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-08&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AI领袖对2025年的展望与期待</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/ai-leaders-hopes-2025-predictions/</link><pubDate>Tue, 07 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/ai-leaders-hopes-2025-predictions/</guid><description>&lt;h1 id="ai领袖对2025年的展望与期待"&gt;AI领袖对2025年的展望与期待&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文汇集了Andrew Ng、Mustafa Suleyman、Audrey Tang等多位AI领域领军人物对2025年的展望与期待。主要观点包括：AI将进一步降低软件开发成本，使快速原型开发成为常态；生成式AI将帮助艺术家从重复性工作中解放，专注于创造性工作；视频生成模型将实现音视频一体化创作；数据效率将成为关键研究方向；AI将具备视觉能力和代理行动能力，进入真正的人机协作时代。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以七位AI专家的观点为主线，勾勒出2025年AI技术发展的多元化前景。Andrew Ng强调AI辅助编程在原型开发中的优势，指出Bolt、Replit Agent、Vercel V0等平台正在通过生成式AI和代理工作流提高代码质量，这为开发者提供了前所未有的便利。他建议从业者制定学习计划，积极参与课程和原型开发实践。&lt;/p&gt;
&lt;p&gt;在创造性领域，Hanno Basse期待生成式AI能让艺术家从机械性工作中解脱，同时强调安全、完整性、可访问性和定制化的重要性。David Ding则预测视频生成模型将实现音频音轨的同步生成，包括语音、音乐和音效，这将开启电影创作的新时代。&lt;/p&gt;
&lt;p&gt;关于通用智能的讨论，Joseph Gonzalez认为我们已经实现了AGI，AI的通用性正在改变人机协作模式。Albert Gu则聚焦于数据效率这一根本问题，指出模型应该像人类一样从更少的数据中学习更多，这涉及数据整理、特征工程、多模态学习等多个子领域。&lt;/p&gt;
&lt;p&gt;Mustafa Suleyman展望了AI的视觉能力和代理智能，预测2025年AI将与用户协同浏览网页，实现真正的双向互动，并开始代表用户采取具体行动。Audrey Tang从社会治理角度提出，AI系统设计应优先考虑促进共情、理解和协作，推荐算法应引导用户走向&amp;quot;桥梁内容&amp;quot;，揭示共同点。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI辅助原型开发&lt;/strong&gt;：AI降低了软件开发的成本和门槛，使开发者能够快速构建各种应用原型。由于原型开发所需的上下文和软件集成较少，且在测试阶段不需要高度可靠性，因此特别适合AI辅助编码。开发者可以利用AI快速制作闪卡应用、监控汇率工具或分析用户评论的系统，而Bolt、Replit Agent、Vercel V0等平台的代理工作流进一步提升了代码质量和部署效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;生成式AI与艺术创作&lt;/strong&gt;：生成式AI的使命不是取代艺术家，而是帮助他们从重复性、机械性的工作中解放出来，专注于真正的创造性工作。Hanno Basse强调技术发展必须从初期就嵌入安全性和完整性，同时提高可访问性，让更广泛的受众能够使用这些工具。未来的生成式AI将更加专业化，出现更多针对特定用例的小型、微调模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多模态视频生成&lt;/strong&gt;：David Ding期待的视频生成模型将实现音视频一体化创作，包含对话、音乐和音效的完整视频剪辑将成为可能。虽然现有的视频和音频模型已经具备了技术基础，但真正的突破在于用户对输出的精细控制，例如指定音乐的调性、对话的情感色彩等。这将彻底改变电影和视频内容的创作方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据效率问题&lt;/strong&gt;：Albert Gu提出的核心问题是，当前AI模型消耗的数据远多于人类学习所需，提高数据效率是解决数据获取成本和训练成本问题的关键。这一目标与数据整理、特征工程、多模态学习、可解释性、推理能力和民主化等AI基础问题密切相关。如果模型能够从更少的数据中学习更多，将大大降低AI应用的门槛。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI代理与视觉交互&lt;/strong&gt;：Mustafa Suleyman预测2025年AI将具备视觉能力，能够与用户共同浏览网页，实现真正的双向互动。随着模型质量和检索能力的提高，幻觉现象将减少，用户信任度将提升。更重要的是，AI将开始代表用户采取具体行动，进入&amp;quot;行动代理&amp;quot;时代，这需要极高的安全性和责任感标准。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;社会价值导向的AI设计&lt;/strong&gt;：Audrey Tang提出的核心理念是AI系统应该促进社会团结而非分裂。推荐算法应该引导用户走向&amp;quot;桥梁内容&amp;quot;，即揭示不同群体之间共同点的内容，而不是强化极化。AI的发展应该采用包容和民主的方法，确保技术真正符合社会的价值观和需求，促进共情、理解和协作。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.deeplearning.ai/the-batch/issue-282/?utm_campaign=The%20Batch&amp;amp;utm_medium=email&amp;amp;_hsenc=p2ANqtz--ehToF1V6cEe_pSj4Juw6Rj0QGzs7cnaPT7x9jaBdNEdGQ_XDfaGbPu2TGTy_JL4bfus40Rn1TBoR0pbzYrS-hpvSnSw&amp;amp;_hsmi=341008988&amp;amp;utm_content=341008988&amp;amp;utm_source=hs_email"&gt;Happy New Year! Hopes For 2025 With Mustafa Suleyman, Audrey Tang, Albert Gu, Hanno Basse, and more&amp;hellip;&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Andrew Ng, Mustafa Suleyman, Audrey Tang, Albert Gu, Hanno Basse, David Ding, Joseph Gonzalez&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;文章类型&lt;/td&gt;
 &lt;td&gt;博客文章&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>2025年人工智能预测总结</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/2025-ai-predictions-marcus/</link><pubDate>Fri, 03 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/2025-ai-predictions-marcus/</guid><description>&lt;h1 id="2025年人工智能预测总结"&gt;2025年人工智能预测总结&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Gary Marcus发布了针对2025年的25项人工智能预测，回顾了2024年预测的验证情况，并从高、中、低三个信心等级对2025年的AI发展进行了展望。预测内容涵盖技术发展、商业应用、监管政策、可靠性问题等多个维度，整体体现出对AI发展的审慎态度和对技术局限性的清醒认识。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先回顾了2024年的预测表现，指出大部分预测得到了验证。主要关注点包括对GPT-4模型的持续依赖、GPT-5未能如期出现、以及AI公司盈利能力普遍不佳等问题，这些趋势在2024年确实得到了验证。&lt;/p&gt;
&lt;p&gt;在高信心预测部分，Marcus提出了多项核心观点。他认为2025年仍然不会出现真正的人工通用智能（AGI），AI模型的盈利状况将持续低迷。同时，美国对生成性AI的监管将保持薄弱态势，而其他国家可能会转向欧洲学习更严格的监管模式。技术可靠性问题，特别是模型的幻觉现象和推理错误，将继续困扰行业发展。在硬件应用方面，人形机器人虽然会持续受到关注，但实际能力提升有限；真正的无人驾驶汽车应用范围将受到限制。OpenAI可能会继续提前预览产品，但实际发布的产品数量仍会有限。&lt;/p&gt;
&lt;p&gt;中等信心预测主要集中在行业发展趋势上。Marcus认为技术壁垒将难以建立，AI模型会趋向同质化。企业对AI的实验性应用会继续，但大规模部署将保持谨慎态度。2025年可能成为AI公司估值开始回调的重要转折点。&lt;/p&gt;
&lt;p&gt;低信心但值得讨论的预测涉及安全风险和技术路线。Marcus警告可能发生大规模网络攻击，生成性AI可能在其中扮演重要角色。同时，他认为可能不会出现所谓的GPT-5级别模型，未来的模型发展可能更加专注于特定任务的优化。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI延期论&lt;/strong&gt;：Marcus坚持认为2025年仍不会出现真正的人工通用智能，这一观点体现了他对当前AI技术路线的持续批评。他认为当前的深度学习方法虽然取得了显著进展，但在真正理解、推理和通用性方面仍然存在根本性局限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;盈利困境&lt;/strong&gt;：AI公司盈利能力持续低迷的预测反映了行业的现实挑战。尽管AI技术受到广泛关注，但商业化落地仍然困难重重，特别是在非硬件领域。这一预测与2024年的观察相呼应，许多AI公司未能实现预期收益。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性危机&lt;/strong&gt;：生成性AI的幻觉问题和推理错误将持续存在，这指出了当前大语言模型的核心缺陷。这些问题不仅影响用户体验，也制约了AI在关键领域的应用，是技术发展必须解决的重要挑战。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监管分化&lt;/strong&gt;：美国监管薄弱而其他国家向欧洲学习的预测，反映了全球AI治理格局的分化趋势。这种监管环境的不确定性，可能会影响AI技术的全球发展和应用布局。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;估值回调&lt;/strong&gt;：2025年可能成为AI公司估值下降的拐点，这一预测基于对行业泡沫的判断。Marcus认为市场对AI的期望可能过度乐观，随着技术局限性逐渐显现，资本市场的态度可能会趋于理性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/25-ai-predictions-for-2025-from-marcus?utm_source=post-email-title&amp;amp;publication_id=888615&amp;amp;post_id=153910147&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=208yzy&amp;amp;triedRedirect=true&amp;amp;utm_medium=email"&gt;25 AI Predictions for 2025, from Marcus on AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月2日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>If You Can’t Program It, You Haven't Understood It</title><link>https://linguista.cn/person/naval/orig/if-you-cant-program-it-you-havent-understood-it/</link><pubDate>Wed, 10 Nov 2021 18:36:16 +0000</pubDate><guid>https://linguista.cn/person/naval/orig/if-you-cant-program-it-you-havent-understood-it/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/person/naval/zh/if-you-cant-program-it-you-havent-understood-it.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/program"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/program"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/program
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="if-you-cant-program-it-you-havent-understood-it"&gt;If You Can’t Program It, You Haven&amp;rsquo;t Understood It&lt;/h1&gt;
&lt;p&gt;Nov 10 2021&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Brett:&lt;br&gt;
These are all uncertain hypotheses, but we also have to keep in mind that there&amp;rsquo;s so much about evolution by natural selection that we don&amp;rsquo;t know.&lt;/p&gt;</description></item><item><title>More Compute Power Doesn’t Produce AGI</title><link>https://linguista.cn/person/naval/orig/more-compute-power-doesnt-produce-agi/</link><pubDate>Wed, 27 Oct 2021 19:28:41 +0000</pubDate><guid>https://linguista.cn/person/naval/orig/more-compute-power-doesnt-produce-agi/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/person/naval/zh/more-compute-power-doesnt-produce-agi.zh/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/agi"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/agi"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/agi
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="more-compute-power-doesnt-produce-agi"&gt;More Compute Power Doesn’t Produce AGI&lt;/h1&gt;
&lt;p&gt;Oct 27 2021&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Even the most powerful computers can’t answer ‘why?’&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Naval:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The artificial general intelligence crew gets it completely wrong, too: &amp;ldquo;Just add more compute power and you&amp;rsquo;ll get intelligence,&amp;rdquo; when we don&amp;rsquo;t know what it is underneath that makes us creative and allows us to come up with good explanations.&lt;/p&gt;</description></item></channel></rss>