<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLMs on Linguista</title><link>https://linguista.cn/tags/llms/</link><description>Recent content in LLMs on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 22 Feb 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/llms/index.xml" rel="self" type="application/rss+xml"/><item><title>大型语言模型与世界模型以奥赛罗游戏为例的探讨</title><link>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-othello-case/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-othello-case/</guid><description>&lt;h1 id="大型语言模型与世界模型以奥赛罗游戏为例的探讨"&gt;大型语言模型与世界模型：以奥赛罗游戏为例的探讨&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文通过奥赛罗游戏（Othello）的经典案例，深入探讨大型语言模型是否能够通过训练数据自发形成对世界的抽象模型。研究者训练了名为OthelloGPT的Transformer网络，通过探针技术分析其内部激活，发现该模型确实编码了棋盘状态信息。然而，关于这种编码是否构成真正的&amp;quot;世界模型&amp;quot;仍存在争议，文章进一步分析了线性与非线性探针的对比结果，以及对人类与机器模型构建方式的思考。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以奥赛罗游戏为实验平台，介绍了OthelloGPT的训练过程：该模型在2000万种合法棋步序列上进行训练，仅学习棋步合法性而无关策略优劣，训练后在预测合法棋步上达到近乎完美的表现。研究者通过&amp;quot;探针&amp;quot;技术——一种用于解码Transformer内部激活的分类器——来分析模型是否形成了世界模型。&lt;/p&gt;
&lt;p&gt;实验过程中出现了有趣的转折：最初的线性探针无法有效预测棋盘状态，而非线性探针虽能达到98%的准确率，却可能归功于探针本身的能力而非Transformer的编码。Neel Nanda等研究者通过调整探针分类方式，将分类从&amp;quot;黑、白、空&amp;quot;改为&amp;quot;我的、你的、空&amp;quot;，使线性探针在第7层激活上的准确率提升至99.5%，这为OthelloGPT确实编码了棋盘状态提供了有力证据。&lt;/p&gt;
&lt;p&gt;然而，高准确率的探针结果并不等同于&amp;quot;世界模型&amp;quot;的存在。文章指出，OthelloGPT的内部表示更像是一个&amp;quot;启发式规则集&amp;quot;——某些神经元的激活代表非常具体的规则，这些规则能产生正确预测但缺乏抽象性和泛化能力。真正的世界模型应该具有连贯性和抽象性，能够应对未曾见过的情境。&lt;/p&gt;
&lt;p&gt;文章最后从认知科学角度对比了人类与机器的模型构建方式。人类受到工作记忆、处理速度和能量限制的约束，这些限制迫使我们形成更抽象、更具泛化的内部模型。机器可能也需要类似的限制和挑战，才能形成真正抽象的模型，从而更好地泛化到新情境中。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：指智能体内部形成的对外部世界的抽象表征，它不仅仅是对输入-输出模式的记忆，而是对世界运作方式的理解和模拟。真正的世界模型具有抽象性和泛化能力，能够处理未曾遇到的情况。在OthelloGPT的案例中，尽管模型编码了棋盘状态，但这是否构成真正的世界模型仍存争议。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;探针技术&lt;/strong&gt;：一种用于分析神经网络内部表征的技术，通过训练分类器来预测网络内部激活所编码的信息。线性探针简单直接，能够揭示网络本身的编码能力；非线性探针功能更强大，但可能掩盖网络的真实编码情况，因其自身具有强大的信息提取能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启发式规则集&lt;/strong&gt;：与抽象的世界模型相对，指由大量具体规则组成的知识表示方式。在OthelloGPT中，某些神经元可能编码了非常具体的规则（如&amp;quot;当某个位置被占据时采取某种行动&amp;quot;），这些规则能产生正确预测，但缺乏抽象性和泛化能力，无法应对规则之外的情况。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;认知限制与抽象化&lt;/strong&gt;：人类在构建模型时受到工作记忆容量、处理速度和能量消耗等限制，这些限制反而促使我们形成更抽象、更具泛化的内部模型。这为AI研究提供了启示：或许需要给机器模型添加类似的限制，促使其发展出真正的抽象理解能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表征与理解的区别&lt;/strong&gt;：神经网络能够表征信息（如OthelloGPT编码了棋盘状态），并不等同于它理解了这些信息背后的因果关系和抽象结构。这是当前AI研究面临的核心挑战之一——如何让模型从数据记忆走向真正的理解。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://aiguide.substack.com/p/llms-and-world-models-part-2"&gt;LLMs and World Models, Part 2&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;AI Guide&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未标注&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>大型语言模型与世界模型第一部分LLMs如何理解它们的世界</title><link>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-part-1/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-part-1/</guid><description>&lt;h1 id="大型语言模型与世界模型第一部分llms-如何理解它们的世界"&gt;大型语言模型与世界模型（第一部分）：LLMs 如何理解它们的&amp;quot;世界&amp;quot;&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文由 Melanie Mitchell 撰写，深入探讨了大型语言模型（LLMs）是否发展出了类似人类的&amp;quot;世界模型&amp;quot;以理解其运作的&amp;quot;世界&amp;quot;。文章回顾了早期机器学习系统的脆弱性问题，介绍了世界模型的概念定义与分类方法，并围绕 LLMs 是否真正具备世界模型能力展开了学术界的重要辩论。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先通过多个经典案例揭示了早期 AI 系统的根本局限性——它们依赖于训练数据中的启发式规则和表面特征，而非真正的概念理解。从皮肤病变分类错误地依赖尺子存在，到语言模型仅凭词汇重叠判断逻辑关系，再到强化学习系统在游戏设置微小变化下的性能崩溃，这些案例都指向同一个问题：缺乏对世界因果结构的理解。&lt;/p&gt;
&lt;p&gt;接着文章转向当前备受争议的话题——大型语言模型是否突破了这一局限。OpenAI 联合创始人 Ilya Sutskever 认为，通过预测下一个词的训练目标，LLMs 确实学习了世界的压缩表征，包括人类的情感和动机。然而，包括 Yann LeCun 在内的多位研究者对此表示强烈怀疑，认为仅靠语言训练无法达到真正的理解。2022 年的一项调查显示，NLP 研究者群体在这一问题上几乎呈现对半分的分裂态势。&lt;/p&gt;
&lt;p&gt;为了厘清这一辩论，文章详细梳理了&amp;quot;世界模型&amp;quot;的多种定义。从最基础的内部表征到保留因果结构的复杂模型，再到能够支持反事实推理的完整模拟器。MIT 教授 Jacob Andreas 提出了一个清晰的分类框架，从静态查找表、地图、机械天体仪到完整的模拟器，每种类型代表了对世界理解的不同深度。人类正是通过这样的世界模型，才能快速理解复杂场景、预测因果关系并规划行动。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：指智能体内部形成的、对外部世界的压缩且可模拟的表征，它不仅能够存储信息，还能捕捉世界的因果结构，支持预测、规划和回答反事实问题。人类的世界模型使我们能够在瞬间理解街景照片中的复杂场景，推断行为者的意图和可能的后续发展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启发式规则与表面特征&lt;/strong&gt;：早期机器学习系统依赖的捷径思维，它们通过发现训练数据中的统计关联来解决问题，但这种方式缺乏真正的理解。就像皮肤病变分类器记住&amp;quot;尺子=恶性&amp;quot;这样的关联，当环境变化时就会失效，因为系统并不理解尺子和病变之间的真实关系。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;情境模型&lt;/strong&gt;：LLMs 可能具备的一种中间层次世界模型，能够跟踪文本中的行为者、状态和动作变化。这类似于一个机械天体仪，可以模拟特定场景中的动态过程，但可能缺乏对更广泛世界因果知识的整合。目前尚不清楚 LLMs 的情境模型能否推广到训练数据之外的全新场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因果模拟模型&lt;/strong&gt;：世界模型的最高层次，能够回答复杂的&amp;quot;如果-那么&amp;quot;类型反事实问题，需要对世界的深层因果结构有精确理解。目前缺乏证据表明 LLMs 具备这种能力，这是判断它们是否真正&amp;quot;理解&amp;quot;世界的关键检验标准。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://aiguide.substack.com/p/llms-and-world-models-part-1"&gt;LLMs and World Models, Part 1 - How do Large Language Models Make Sense of Their &amp;ldquo;Worlds&amp;rdquo;?&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Melanie Mitchell&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未明确说明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>