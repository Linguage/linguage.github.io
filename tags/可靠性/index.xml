<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>可靠性 on Linguista</title><link>https://linguista.cn/tags/%E5%8F%AF%E9%9D%A0%E6%80%A7/</link><description>Recent content in 可靠性 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 14 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E5%8F%AF%E9%9D%A0%E6%80%A7/index.xml" rel="self" type="application/rss+xml"/><item><title>AGI与广泛浅层智能的本质区别</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/agi-versus-broad-shallow-intelligence/</link><pubDate>Tue, 14 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/agi-versus-broad-shallow-intelligence/</guid><description>&lt;h1 id="agi与广泛浅层智能的本质区别"&gt;AGI与广泛浅层智能的本质区别&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Gary Marcus在这篇文章中明确指出，尽管有人声称我们已经接近或达到了人工通用智能（AGI），但事实远非如此。当前的AI系统，尤其是大型语言模型（LLMs），应该被更准确地描述为&amp;quot;广泛浅层智能&amp;quot;（BSI）。虽然它们在应用范围上较为广泛，能够尝试解决多种问题，但缺乏深度理解、可靠性和推理能力，经常产生错误和幻觉。真正的AGI应当具备与人类相当的灵活性、丰富性和可靠性，能够解决普通人类在没有事先训练的情况下能够解决的问题。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先澄清了AGI的本质定义。Marcus引用了AGI概念共同创造者Shane Legg以及知名AI研究者François Chollet的观点，强调AGI不仅仅是能力广泛，更重要的是要具备与人类相当的灵活性和可靠性。AGI应该能够解决普通人类也能解决的认知问题，并且能够从经验中推广到全新情境。&lt;/p&gt;
&lt;p&gt;接着，文章深入分析了当前LLMs的局限性。尽管这些模型在某些特定领域表现出色，甚至在某些任务上超越了人类，但它们在其他方面则远远落后。Marcus指出，LLMs往往只是模仿互联网上类似问题的答案模式，而没有真正理解背后的概念和原理。这种表面化的处理方式导致模型经常产生&amp;quot;幻觉&amp;quot;——即自信地陈述完全错误的信息，并且缺乏基本的事实核查和合理性检查能力。&lt;/p&gt;
&lt;p&gt;基于这些观察，Marcus提出了&amp;quot;广泛浅层智能&amp;quot;（BSI）这一概念来准确描述当前AI技术的状态。BSI的特点是应用范围广泛，但理解深度不足。这种不可靠性意味着在大多数实际应用场景中，仍然需要人类介入来验证和纠正AI的输出，这大大限制了AI的实用价值。&lt;/p&gt;
&lt;p&gt;文章最后呼吁AI研究社区重新思考研究方向。Marcus认为，我们不应该满足于在BSI基础上不断改进，而应该将研究重点转向开发真正具备深度理解能力、可靠性和安全性的AI系统。过度依赖不可靠的AI可能会带来严重问题，因此超越BSI应该是人类面临的重要研究优先事项。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI（人工通用智能）&lt;/strong&gt;：真正的AGI不仅需要在多个任务上表现出色，更重要的是要具备与人类相当的灵活性和可靠性。它应该能够解决普通人类在没有专门训练的情况下就能解决的认知问题，并且能够将经验推广到全新的情境中。这种智能不是简单的模式匹配，而是基于对概念的深度理解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BSI（广泛浅层智能）&lt;/strong&gt;：这是Marcus提出的用来描述当前LLMs特性的概念。BSI系统在应用范围上确实广泛——它们可以尝试回答各种类型的问题，但它们的理解和推理都是浅层和表面的。BSI系统缺乏深度理解，经常产生错误，无法进行基本的事实核查，因此可靠性不足。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幻觉现象&lt;/strong&gt;：LLMs经常自信地陈述完全错误的信息，这种现象被称为&amp;quot;幻觉&amp;quot;。这是因为模型本质上是在预测和模仿训练数据中的语言模式，而不是真正理解事实。当遇到训练数据中不充分或存在矛盾的情况时，模型就会编造看似合理但实际上错误的信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;深度理解与语言模式&lt;/strong&gt;：这是区分AGI和BSI的关键所在。BSI系统依赖的是表面化的语言模式匹配，而AGI需要基于概念的深度推理。真正理解一个概念意味着能够在新情境中灵活应用，能够判断答案的合理性，能够在缺乏完整信息时进行合理的推断，而不是简单地套用见过的模式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性与安全性&lt;/strong&gt;：由于BSI系统的不可预测性，它们很难保证按照人类的要求行事，也无法确保其输出的安全性。在关键应用领域（如医疗、法律、自动驾驶等），这种不可靠性可能带来严重后果。因此，开发真正可靠的AI系统不仅是技术问题，更是安全问题。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/agi-versus-broad-shallow-intelligence"&gt;AGI versus &amp;ldquo;broad, shallow intelligence&amp;rdquo;&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>