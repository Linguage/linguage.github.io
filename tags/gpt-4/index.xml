<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GPT-4 on Linguista</title><link>https://linguista.cn/tags/gpt-4/</link><description>Recent content in GPT-4 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Wed, 15 Mar 2023 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/gpt-4/index.xml" rel="self" type="application/rss+xml"/><item><title>AI大师Ilya Sutskever谈GPT-4与AI的未来</title><link>https://linguista.cn/rosetta/chat-notes/ilya-sutskever-gpt4-future-of-ai/</link><pubDate>Wed, 15 Mar 2023 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/ilya-sutskever-gpt4-future-of-ai/</guid><description>&lt;h1 id="ai大师ilya-sutskever谈gpt-4与ai的未来"&gt;AI大师Ilya Sutskever谈GPT-4与AI的未来&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Eye on AI主持人Craig Smith与OpenAI联合创始人兼首席科学家Ilya Sutskever的深度对话。Sutskever回顾了从与Geoffrey Hinton合作研究神经网络到推动AlexNet突破再到领导GPT系列模型演进的历程，探讨了大型语言模型的能力与局限、RLHF对齐方法、多模态学习的必要性，以及AI规模化发展对社会的深远影响。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/SjhIlw3Iffs?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="AI大师Ilya Sutskever谈GPT-4与AI的未来"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AlexNet&lt;/strong&gt;：2012年由Alex Krizhevsky等人开发的卷积神经网络，在ImageNet竞赛中取得突破性表现，被视为深度学习革命的里程碑事件&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RLHF（从人类反馈中强化学习）&lt;/strong&gt;：一种通过人类评估反馈来优化模型输出行为的训练方法，旨在提升模型可靠性并对齐人类意图，被用于解决幻觉等问题&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幻觉（Hallucination）&lt;/strong&gt;：大型语言模型生成看似合理但实际不正确或虚构内容的现象，是当前LLM面临的主要局限性之一&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Transformer&lt;/strong&gt;：2017年提出的基于自注意力机制的神经网络架构，解决了循环神经网络的长期依赖问题，成为GPT等大型语言模型的核心基础&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规模化定律（Scaling）&lt;/strong&gt;：指通过持续扩大模型参数量、训练数据和计算资源来提升模型性能的方法论，是GPT系列从GPT-1发展到GPT-4的核心驱动力&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=SjhIlw3Iffs"&gt;The Mastermind Behind GPT-4 and the Future of AI | Ilya Sutskever&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;官方频道：&lt;a href="https://www.youtube.com/@eyeonai3425"&gt;Eye on AI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;日期：2023年3月15日&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="内容介绍"&gt;内容介绍&lt;/h3&gt;
&lt;p&gt;本次访谈录呈现了 Eye on AI 的 Craig Smith 与 OpenAI 联合创始人兼首席科学家 Ilya Sutskever 的深度对话。作为深度学习领域，尤其是大型语言模型 GPT 系列背后的关键人物，Sutskever 在本次访谈中分享了他从早期与 Geoffrey Hinton 合作研究神经网络，到推动 AlexNet 突破，再到领导 GPT 模型演进的心路历程与核心见解。&lt;/p&gt;</description></item></channel></rss>