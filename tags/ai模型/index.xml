<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI模型 on Linguista</title><link>https://linguista.cn/tags/ai%E6%A8%A1%E5%9E%8B/</link><description>Recent content in AI模型 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 15 Aug 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/ai%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>DeepSeek新一代AI模型因华为芯片问题推迟发布</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/deepseek-huawei-chip-delay-model-r2/</link><pubDate>Fri, 15 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/deepseek-huawei-chip-delay-model-r2/</guid><description>&lt;h1 id="deepseek新一代ai模型因华为芯片问题推迟发布"&gt;DeepSeek新一代AI模型因华为芯片问题推迟发布&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;DeepSeek原计划于2025年5月发布其新一代AI模型R2，但由于在使用华为Ascend（昇腾）芯片进行训练时遭遇持续性技术难题，项目进展严重受阻。最终，DeepSeek被迫转用Nvidia H20芯片完成模型训练，仅在推理阶段使用Ascend芯片。这一事件集中体现了中国AI企业在&amp;quot;去美化&amp;quot;进程中面临的技术瓶颈，以及在中美科技竞争背景下的产业链自主化困境。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本文围绕DeepSeek R2模型推迟发布这一事件，揭示了三个层面的核心问题。首先，从技术层面看，DeepSeek原本计划采用华为Ascend芯片进行AI模型训练，但在高强度计算需求面前遇到了难以克服的技术障碍，不得不回归Nvidia H20芯片。这表明国产芯片在高端AI训练场景下的性能和生态成熟度仍有显著差距。&lt;/p&gt;
&lt;p&gt;其次，从产业政策层面看，尽管美国政府对中国高端芯片实施出口限制，中国政府也鼓励本土企业采用国产芯片，但市场主体的实际选择反映出政策导向与技术现实之间的张力。DeepSeek R1模型、字节跳动、腾讯、阿里巴巴等中国主要AI开发者普遍依赖Nvidia芯片，这一现状短期内难以根本改变。&lt;/p&gt;
&lt;p&gt;最后，从市场竞争层面看，R2模型的推迟使DeepSeek在国内外AI&amp;quot;军备竞赛&amp;quot;中暂时处于不利地位。尽管R2预计将在未来数周内发布，但已错过新品发布的关键窗口期。这一事件也促使外界更加关注中国AI产业链自主化的真实进展，以及在&amp;quot;短期依赖&amp;quot;与&amp;quot;长期自主&amp;quot;之间的平衡路径。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;训练与推理的算力差异&lt;/strong&gt;：AI模型开发分为训练和推理两个阶段。训练阶段需要利用海量数据反复迭代优化模型参数，对算力要求极高；推理阶段则是模型在实际应用中生成响应的过程，算力需求相对较低。DeepSeek的案例显示，华为Ascend芯片目前能够支撑推理任务，但在高强度训练环节仍存在明显短板，这反映了国产芯片在不同应用场景下的技术成熟度差异。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;去美化进程的现实困境&lt;/strong&gt;：在中美科技竞争背景下，减少对美国技术的依赖是中国AI产业的重要战略方向。然而，DeepSeek被迫在训练环节放弃华为芯片、转而使用Nvidia产品的决策，凸显了这一进程中的现实挑战。技术选型最终仍需以产品性能和市场竞争力为依归，政策导向不能完全替代技术规律。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;渐进式自主化路径&lt;/strong&gt;：从DeepSeek、字节跳动等企业的实践来看，中国AI芯片自主化必然是一个渐进过程。短期内，Nvidia等美制芯片仍是高端AI训练的主力选择；中长期则需要国产芯片厂商在硬件性能、软件生态、产业链协同等多方面持续投入。这一过程需要企业和政策制定者保持战略定力，在保障技术竞争力与推动自主可控之间找到动态平衡。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.investing.com/news/stock-market-news/deepseek-delays-new-ai-model-amid-huawei-chip-issues-ft-4190691"&gt;DeepSeek delays new AI model amid Huawei chip issues- FT&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Investing.com / Reuters&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>GPT-5核心特性与定价策略全面解析</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/gpt-5-characteristics-pricing-features/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/gpt-5-characteristics-pricing-features/</guid><description>&lt;h1 id="gpt-5核心特性与定价策略全面解析"&gt;GPT-5核心特性与定价策略全面解析&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;GPT-5是OpenAI最新发布的大型语言模型，在保持现有架构的基础上显著提升了稳定性、推理能力和安全性。本文基于作者两周的深度体验，全面梳理GPT-5的核心特性、混合模型架构、定价策略、系统卡披露细节，以及在OpenAI产品线中的定位。GPT-5虽非范式革命，但日常表现可靠稳定，已成为作者的新首选模型。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先介绍了GPT-5在ChatGPT和API端的不同实现方式。ChatGPT端采用创新的&amp;quot;混合模型&amp;quot;架构，包含智能快速的主模型和深度推理模型，通过实时路由器根据任务复杂度动态分配资源。当配额用尽后，自动切换至对应的mini版本。API端则更为直接，提供regular、mini和nano三种模型，每种支持minimal、low、medium、high四个推理等级。&lt;/p&gt;
&lt;p&gt;文章详细阐述了GPT-5在OpenAI产品线中的定位。GPT-5系列意在取代大部分现有模型，包括GPT-4o、GPT-4o-mini、OpenAI o3等，但音频输入输出和图像生成能力仍由其他模型负责。知识截止日期方面，GPT-5为2024年9月30日，mini和nano版本为2024年5月30日。&lt;/p&gt;
&lt;p&gt;在定价策略方面，GPT-5展现出极强的市场竞争力。输入价格为GPT-4o的一半，输出价格持平。更重要的是，OpenAI引入了高达90%的token缓存折扣，这对需要频繁回放历史对话的聊天UI场景尤为有利。文章还提供了与主流竞品（Claude、Grok、Gemini等）的详细价格对比。&lt;/p&gt;
&lt;p&gt;最后，文章深入解读了系统卡披露的技术细节。GPT-5在减少幻觉、提升指令遵循、降低谄媚方面取得显著进展，引入了&amp;quot;安全补全&amp;quot;机制作为新的安全训练方法。团队针对写作、编程和健康咨询三大常见用例进行了重点优化。安全性方面，GPT-5在提示注入攻击测试中表现优于同类模型，但成功率仍超过50%，提示注入仍是未解难题。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;混合模型架构&lt;/strong&gt;：GPT-5在ChatGPT端采用&amp;quot;主模型+深度推理模型+实时路由器&amp;quot;三位一体设计。路由器根据对话类型、复杂度、工具需求和用户意图（如提示中要求&amp;quot;认真思考这个问题&amp;quot;）动态分配最合适的模型。这种&amp;quot;按需分配&amp;quot;理念既保证了日常响应速度，又能处理复杂推理任务，体现了资源优化的产品思路。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;安全补全机制&lt;/strong&gt;：传统LLM安全策略多为&amp;quot;有害即拒绝&amp;quot;，但在生物学、网络安全等双用途场景下并不适用。GPT-5引入的safe-completions机制转而关注输出内容本身的安全性，在保证安全政策约束下最大化有用性，强调&amp;quot;有条件地提供高层次安全信息&amp;quot;而非简单拒绝。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;谄媚治理&lt;/strong&gt;：GPT-5通过后训练阶段的奖励机制系统性降低谄媚行为。团队用真实对话数据评估模型输出的谄媚程度，将评分作为奖励信号参与训练，鼓励模型&amp;quot;真实反馈优先于表面迎合&amp;quot;。这一机制避免了模型对用户观点的无脑迎合，提升了输出的客观性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Token经济与缓存&lt;/strong&gt;：GPT-5采用极低的token价格（输入$1.25/百万，输出$10/百万）配合高达90%的缓存折扣，鼓励开发者优化输入复用。这种&amp;quot;成本敏感+高效复用&amp;quot;的策略显著降低了部署成本，特别是对需要频繁处理历史对话的应用场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;提示注入防御&lt;/strong&gt;：尽管GPT-5在安全性测试中优于同类模型（gpt-5-thinking的k=10攻击成功率为56.8%，低于其他模型70%以上的水平），但作者强调这一比例仍然很高，开发者应始终假设&amp;quot;提示注入风险未消除&amp;quot;，在应用层面持续加固防护。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://simonwillison.net/2025/Aug/7/gpt-5/"&gt;GPT-5: Key characteristics, pricing and model card&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Simon Willison&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-07&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>2024年AI发展亮点综述</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/ai-2024-agents-prices-video-models/</link><pubDate>Tue, 07 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/ai-2024-agents-prices-video-models/</guid><description>&lt;h1 id="2024年ai发展亮点综述"&gt;2024年AI发展亮点综述&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;2024年是人工智能快速发展的重要一年。本文总结了AI领域的关键进展，包括智能代理系统的崛起、模型价格的显著下降、视频生成技术的突破、模型小型化趋势，以及大型科技公司通过创新合作方式获取人才和技术的行业现象。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;2024年，AI技术在应用层面取得实质性突破。智能代理系统（Agentic AI）成为最大亮点，通过迭代提示大型语言模型，AI系统获得了更强的推理、工具使用和应用程序控制能力。微软、Meta、LangChain等公司纷纷推出代理工作流开发工具，如Autogen、CrewAI、LangGraph和Llama Stack，为开发者构建多代理协作系统提供了强大支持。&lt;/p&gt;
&lt;p&gt;价格竞争是另一重要趋势。OpenAI在2023年3月至2024年11月期间将模型token价格降低近90%，这得益于激烈的市场竞争、开放权重模型的普及以及更高效计算模型的出现。这种价格下降使得先进的AI技术更加普及和可负担。&lt;/p&gt;
&lt;p&gt;视频生成技术在2024年迎来爆发式增长。OpenAI的Sora、Runway的Gen 3 Alpha和Adobe的Firefly Video等强大工具相继推出，文本到视频生成技术达到新的高度，正在重塑电影和视频产业。同时，模型小型化趋势明显，通过知识蒸馏、参数修剪和量化技术，微软Phi-3、谷歌Gemma 2等小型模型已可在智能手机上运行，而不显著损失性能。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;智能代理系统（Agentic AI）&lt;/strong&gt;：这是2024年最重要的AI发展趋势。智能代理不仅能理解自然语言，还能进行推理、使用工具、控制桌面应用程序，并通过多代理协作完成复杂任务。底层研究技术包括链式思维、自一致性、ReAct、Self-Refine和Reflexion等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型价格战&lt;/strong&gt;：AI市场进入激烈竞争阶段，主要厂商通过降价争夺用户。90%的价格下降幅度反映了技术成熟度和竞争强度，开放权重模型的普及进一步加速了这一趋势。这将使更多企业和个人能够接触到先进的AI技术。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;视频生成革命&lt;/strong&gt;：文本到视频生成技术从实验室走向实用。Sora设定了高质量场景生成的新标准，Adobe将Firefly Video整合到Premiere Pro中，使视频艺术家能够直接在专业工作流中生成和增强视频内容。这正在改变传统媒体制作流程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型小型化技术&lt;/strong&gt;：通过知识蒸馏（让小模型学习大模型的行为）、参数修剪（移除不重要的参数）、量化（降低数值精度）等技术，大型语言模型可以在保持大部分性能的同时大幅缩小体积，实现在移动设备和边缘设备上的本地运行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;收购替代模式&lt;/strong&gt;：面对反垄断监管压力，大型科技公司采用&amp;quot;投资+雇佣大部分员工&amp;quot;的创新合作方式获取技术和人才。微软与Inflection AI的650百万美元协议就是典型案例，这种模式可能成为行业新常态。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.deeplearning.ai/the-batch/issue-281/"&gt;Top AI Stories of 2024! Agents Rise, Prices Fall, Models Shrink, and more&amp;hellip;&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;deeplearning.ai&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-12-26&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>