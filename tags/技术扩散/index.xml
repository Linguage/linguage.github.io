<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>技术扩散 on Linguista</title><link>https://linguista.cn/tags/%E6%8A%80%E6%9C%AF%E6%89%A9%E6%95%A3/</link><description>Recent content in 技术扩散 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 15 Apr 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%8A%80%E6%9C%AF%E6%89%A9%E6%95%A3/index.xml" rel="self" type="application/rss+xml"/><item><title>作为普通技术的人工智能</title><link>https://linguista.cn/rosetta/technology/ai-as-normal-technology/</link><pubDate>Tue, 15 Apr 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/ai-as-normal-technology/</guid><description>&lt;h1 id="作为普通技术的人工智能"&gt;作为普通技术的人工智能&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文提出将人工智能视为一种普通技术而非超级智能实体的分析框架。作者从技术扩散速度、人机协作分工、风险分类与政策韧性四个维度展开论述，指出AI的经济社会变革将以数十年为尺度渐进发生，主张拒绝技术决定论，通过韧性导向的政策应对不确定性，而非诉诸激进干预或末日叙事。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;普通技术框架&lt;/strong&gt;：将AI与电力、互联网等通用技术类比，强调其发展遵循可循规律而非神秘力量，拒绝将AI视为自主超级智能实体&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;创新-扩散滞后&lt;/strong&gt;：AI方法的发明、应用创新与社会扩散发生在不同时间尺度上，尤其在安全关键领域，扩散可能落后创新数十年&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术决定论批判&lt;/strong&gt;：反对AI自身作为决定未来的能动者的观念，强调人类、组织和制度在塑造技术轨迹中的主导作用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;韧性政策方法&lt;/strong&gt;：面对AI不确定性，主张以韧性为核心政策目标，优先减少不确定性，避免基于极端假设的激进干预&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能力-可靠性差距&lt;/strong&gt;：AI在基准测试上的表现与现实世界效用之间存在显著鸿沟，安全关键应用中尤为突出&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;原文链接：&lt;a href="https://www.aisnakeoil.com/p/ai-as-normal-technology?utm_source=multiple-personal-recommendations-email&amp;amp;utm_medium=email&amp;amp;triedRedirect=true"&gt;AI as Normal Technology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一篇我们将扩展为下一本书的新论文&lt;/li&gt;
&lt;li&gt;作者：Arvind Narayanan 和 Sayash Kapoor&lt;/li&gt;
&lt;li&gt;日期2025年4月15日&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id="文章导言"&gt;文章导言&lt;/h3&gt;
&lt;p&gt;人工智能（AI）正以前所未有的速度渗透到我们生活的方方面面，引发了从根本性社会变革到生存威胁的各种讨论。在众多激动人心或令人忧虑的预测中，本文旨在提供一个更为审慎和贴近现实的视角：将AI视为一种“普通技术”。这并非贬低其潜在影响力，而是强调它与其他改变历史的通用技术（如电力或互联网）一样，其发展和融入社会的过程遵循着可循的规律，而非某种神秘力量的降临。&lt;/p&gt;
&lt;p&gt;本文认为，当前围绕AI，特别是“超级智能”的许多讨论，往往脱离了技术发展的实际路径和社会采纳的复杂现实。我们将探讨为何AI带来的经济和社会变革可能比预期更为缓慢，需要数十年时间；在一个人与AI共存的未来，人类的角色将如何演变为对AI的控制和引导；以及如何从“普通技术”的角度重新审视AI风险，将焦点从科幻式的“失控”场景，更多地转向事故、滥用以及加剧现有社会问题的系统性风险。最后，基于这一视角，我们将讨论更具韧性和适应性的政策方针，主张在不确定性中优先考虑稳健性、减少极端干预，并积极创造条件以公平地实现AI的潜在益处。希望通过这种冷静、务实的分析，为理解和应对AI的未来提供一个更坚实的基础。&lt;/p&gt;
&lt;h3 id="内容纲要"&gt;内容纲要&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;人工智能万灵药 (AI Snake Oil)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 引言：将AI视为普通技术的愿景
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 定义：描述、预测与规范
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 核心观点：AI是工具，应由人控制，拒绝技术决定论
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 文章结构概述 (Part I-IV)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part I: 进步的速度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── AI方法、应用、采纳与扩散的区别与时间尺度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── AI在安全关键领域的扩散缓慢 (原因：安全限制)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 扩散受人类、组织和制度变革速度限制 (历史对比：电气化)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 外部世界对AI创新设置速度限制 (能力-可靠性差距、隐性知识、实验成本)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 基准测试不能衡量现实世界效用 (结构效度问题)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 经济影响可能是渐进的 (反馈循环、价值下降、目标转移)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── AI方法进步本身也存在速度限制 (羊群效应、硬件/成本、基准局限)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part II: 拥有先进AI的世界可能是什么样子
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 重新定义核心概念：从“智能”到“能力”与“权力”
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 人类能力并非受限于生物学 (技术增强视角)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 游戏提供了关于超级智能的误导性直觉 (速度 vs 其他、不可约误差)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 控制的多样性：超越对齐与人机回圈 (审计、监控、系统安全、网络安全原则等)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 预测：人类工作转向AI控制与任务规范 (卡车司机例子，市场与监管驱动)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part III: 风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 风险分类：事故、军备竞赛、滥用、失控、系统性风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 事故：主要责任在部署者/开发者，市场与监管可缓解
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 军备竞赛：历史常见，行业 специфичн, 可通过监管解决 (公司/国家层面分析)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 滥用：主要防御应在下游，模型对齐效果有限 (情境依赖性)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── AI对防御亦有助益 (攻防平衡视角)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 灾难性失控 (Misalignment)：推测性风险 (下游防御、现实部署过滤器、欺骗性对齐是工程问题)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 系统性风险：若AI为普通技术则更重要 (偏见、就业、不平等、权力集中等)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part IV: 政策
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 政策制定的挑战：不确定性与世界观分歧 (超级智能 vs 普通技术)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 对妥协与成本效益分析的批判 (概率问题、量化困难、正当性原则)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 政策目标：减少不确定性 (研究资助、监控、证据指导、证据收集)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 核心政策方法：韧性 (Resilience)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 定义与目标
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 四类韧性策略 (社会韧性、先决条件、无悔干预、促进竞争/多中心治理)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 对不扩散 (Nonproliferation) 的批判
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 执行困难、导致单点故障与脆弱性
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 不扩散作为一种有害心态及其干预措施
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 政策目标：实现AI的益处
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 扩散需要实验与灵活监管
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 监管可促进扩散 (法律确定性)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 投资于自动化的补充品 (素养、数据、基础设施)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 关注公平分配与补偿
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 公共部门需谨慎平衡采纳速度与风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└── 最终思考
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; └── 重申“AI作为普通技术”的世界观及其构成要素，呼吁相互理解
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="作为普通技术的人工智能-ai-as-normal-technology"&gt;作为普通技术的人工智能 (AI as Normal Technology)&lt;/h2&gt;
&lt;p&gt;我们阐述了一种将人工智能（AI）视为普通技术的愿景。将AI视为普通技术并非低估其影响——即使是像电力和互联网这样具有变革性的通用技术，在我们的概念中也是“普通的”。但这与关于AI未来的乌托邦和反乌托邦愿景形成对比，后者普遍倾向于将其视为一个独立的物种，一个高度自主、可能具有超级智能的实体。¹&lt;/p&gt;</description></item></channel></rss>