<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>DeepMind on Linguista</title><link>https://linguista.cn/tags/deepmind/</link><description>Recent content in DeepMind on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 19 Sep 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/deepmind/index.xml" rel="self" type="application/rss+xml"/><item><title>以AI之力攻克癌症——Demis Hassabis的愿景与实践</title><link>https://linguista.cn/curated/henrinotes-2025_p2/demis-hassabis-ai-cancer-drug-discovery/</link><pubDate>Fri, 19 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/demis-hassabis-ai-cancer-drug-discovery/</guid><description>&lt;h1 id="以ai之力攻克癌症demis-hassabis的愿景与实践"&gt;以AI之力攻克癌症——Demis Hassabis的愿景与实践&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文梳理了Google DeepMind联合创始人兼CEO、Isomorphic Labs负责人Demis Hassabis的深度专访。他详述了利用人工智能驱动药物研发、攻克癌症等重大疾病的宏大目标与现实进展，并披露Isomorphic Labs的战略、突破点与未来展望。Isomorphic Labs的使命是解决所有疾病，当前聚焦打造能够理解生物学与化学底层规律的通用AI平台，已与诺华、礼来等大型药企建立合作，将传统药物发现3-6年的耗时有望缩短至数月甚至数周。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Demis Hassabis在采访中系统阐述了Isomorphic Labs的战略定位与技术路线。作为AlphaFold的延续，该团队正在构建比AlphaFold 3更先进的AI平台，不仅建模蛋白质结构和分子互作，还涵盖化合物设计、毒性评估、药代动力学等全流程能力，实现算法-实验一体化的药物研发范式变革。&lt;/p&gt;
&lt;p&gt;当前平台已进入临床前阶段，团队正在将AI系统能力从蛋白质预测拓展到更广阔的生物化学空间。Demis强调，这一平台的独特之处在于其通用性——不是针对单一疾病或靶点，而是构建&amp;quot;能力普世化&amp;quot;的基础设施，让AI支撑所有病种、靶点的药物研发，目标是发现数百种新疗法，让新药研发成为可预测、可反复标准化推进的工程问题。&lt;/p&gt;
&lt;p&gt;在商业化路径上，Isomorphic Labs采取与制药巨头合作与自研并行的双轨策略。一方面与诺华、礼来等公司在多个靶点开展技术合作，帮助明确平台产业级需求；另一方面持续探索自研药物项目，未来不排除全栈生物科技自有药物管线开发的可能性。Demis坦言，虽然AI能极大提速药物发现阶段，但后续的临床验证和监管审批仍需依靠合作与创新，保持科学审慎与推动产业协作是其反复强调的核心原则。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;通用AI平台化药物研发&lt;/strong&gt;：Demis提出的&amp;quot;通用AI平台&amp;quot;思想，本质是用强大的AI模型建模生物化学规律，为所有药物类别、靶点和机制提供统一的计算-实验一体化平台。这一框架强调系统建模（用深度学习、蛋白质预测等AI方法对分子相互作用、代谢机制、毒性进行可解释、可泛化的预测）、平台思维（AI的任务不是攻克某一个疾病，而是构建能力普世化的基础设施）与合作开放（与制药巨头联合，以技术能力为核心，让产业链资源与AI能力最大程度融合）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数量级提速目标&lt;/strong&gt;：Demis展望成熟平台有希望将传统药物发现动辄3-6年的耗时缩短至数月甚至数周，实现数量级提速。但他同时警觉地指出，行业评价新技术不可被秒变的预期带节奏，AI药物研发虽能极大提速，但临床及监管本身高度复杂，需要合作与耐心。当前团队专注于核心平台和算法的研发，短期内以临床前成果为主，通过平台与药企合作在药物研发早期取得创新效率优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;科学与技术同驱心智模型&lt;/strong&gt;：Demis反复强调&amp;quot;解决智能，就能解决一切科学难题&amp;quot;这一第一性原理观点，具体体现在科学与技术同驱（AI模型既带动理论创新，也用新技术工具扩展实验范式）、多模态与多学科协作（融合生物、化学、医学、物理等众多学科知识综合攻克难题）、规模化实验与数据驱动迭代（通过平台化一次性推动上百个新药管线同步评估，极大提高创新效率）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;智能赋能所有科学领域&lt;/strong&gt;：Demis提出，人工智能的智能本质将赋能所有科学领域——医学、生物、材料、能源，AI需要与专业、细分的科学模型深度融合，形成多层专业适应系统。未来5-10年，专业化AI模型将在各行业落地，带来全新科学范式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;健康寿命优先的延寿观&lt;/strong&gt;：个人层面，Demis坦言自己工作极度繁重，为攻克疾病、创新科技充满激情。对人类健康的终极愿景是首先攻克当前最令人痛苦的疾病，提高健康寿命，在人类寿命极限探索上仍保持科学审慎——延寿能否实现，目前依旧有赖于更大规模的科学突破与实证来确认。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=sDZ1j0J-fe8"&gt;Demis Hassabis: The CEO Working to Solve Cancer With AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Bloomberg Technology&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>CMU和DeepMind新方法让视觉语言模型自生成记忆以应对数据不足</title><link>https://linguista.cn/curated/henrinotes-2025-p1/vlm-self-generated-memory-ical-scaling-law/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/vlm-self-generated-memory-ical-scaling-law/</guid><description>&lt;h1 id="cmu和deepmind新方法让视觉语言模型自生成记忆以应对数据不足"&gt;CMU和DeepMind新方法让视觉语言模型自生成记忆以应对数据不足&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;随着AI领域Scaling Law面临高质量数据耗尽的挑战，CMU与Google DeepMind联合提出了一种名为ICAL（In-Context Abstraction Learning）的创新方法。该方法通过让大型视觉语言模型利用低质量数据与人工反馈自主生成认知抽象记忆，显著减少了对专家演示的依赖，并在TEACh、VisualWebArena和Ego4D等多个基准测试中取得了优异表现。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本文关注AI社区当前热议的Scaling Law瓶颈问题。预计到2028年左右，现有高质量数据储量将被全部利用完毕，这迫使研究者寻找新的突破路径。人类具备出色的少样本学习能力，能够通过观察与内部世界模型结合快速泛化，这一特性为AI研究提供了重要启示。&lt;/p&gt;
&lt;p&gt;CMU与Google DeepMind的研究团队提出的ICAL方法，核心思路是让LLM和VLM根据次优演示和人工反馈创建有效的提示词，从而改善决策能力。该方法可处理四种类型的认知抽象：任务和因果关系、对象状态变化、时间抽象以及任务建构。每轮迭代从有噪声的轨迹出发，经过抽象阶段和人类参与阶段两个步骤完成学习。&lt;/p&gt;
&lt;p&gt;实验结果令人瞩目。在TEACh家庭环境对话式教学任务中，ICAL的成功率比原始演示提高了17.9%；在VisualWebArena网络自动化任务中取得了SOTA性能，使用GPT-4V时从14.3%提升至22.7%；在Ego4D视频动作预测任务中，使用的领域内训练数据减少了639倍，表现仍与完全监督式方法相差无几。&lt;/p&gt;
&lt;p&gt;研究表明，ICAL不仅显著减少了对专家示例的依赖，而且随着示例数量增长性能持续提升，展现出良好的Scaling能力，为突破数据瓶颈提供了全新思路。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;ICAL（上下文抽象学习）&lt;/strong&gt;：这是本文提出的核心方法，全称In-Context Abstraction Learning。其创新之处在于不依赖大量高质量专家数据，而是让视觉语言模型通过低质量数据与人工反馈自主生成四种认知抽象——任务因果关系、对象状态变化、时间抽象和任务建构，从而构建可复用的&amp;quot;记忆&amp;quot;来指导后续决策。这种方法模拟了人类从少量经验中快速学习和泛化的能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Scaling Law瓶颈与数据耗尽&lt;/strong&gt;：Scaling Law是指模型性能随数据量和计算量增长而持续提升的规律，但当前面临的核心挑战是高质量数据即将耗尽。ICAL方法通过利用低质量、有噪声的数据来生成高质量的抽象表示，为突破这一瓶颈提供了可行路径，将数据依赖从&amp;quot;量&amp;quot;转向了&amp;quot;质的转化&amp;quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;认知抽象与具身思维程序&lt;/strong&gt;：ICAL将学习过程分解为两个关键阶段——抽象阶段由VLM借助语言评论纠正错误并丰富序列，人类参与阶段则通过执行、监控、反馈整合和轨迹修正实现闭环优化。最终生成的&amp;quot;具身思维程序&amp;quot;（Embodied Programs of Thought）可作为上下文示例在新任务中复用，实现了经验的高效蒸馏与迁移。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;少样本学习与数据效率&lt;/strong&gt;：ICAL在Ego4D基准测试中的表现尤为突出——使用的领域内训练数据减少了639倍，性能仍与完全监督式方法相当。这证明了该方法在极端数据稀缺场景下的实用价值，为资源受限条件下的AI应用开拓了空间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;跨领域泛化能力&lt;/strong&gt;：ICAL在三个差异显著的任务领域（家庭环境对话教学、网页自动化操作、视频动作预测）中均取得了显著提升，表明该方法具备良好的跨领域泛化能力，不局限于特定应用场景，具有广泛的适用性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s?src=11&amp;amp;timestamp=1735955552&amp;amp;ver=5729&amp;amp;signature=B4gIeSxsH0mHdChOk7-uEV1vyxv2QswU26en8b31Iu0DUtOE13hntWN26xoZeyjVC9TL5ilvhNGAsv56Kio5FfxiKib6Y-LQ49KwJz9cufOiWQ3TnwipbeEWQtCQiFwk&amp;amp;new=1"&gt;数据不够致Scaling Law撞墙？CMU和DeepMind新方法可让VLM自己生成记忆&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;机器之心&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;论文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://openreview.net/pdf?id=5G7MRfPngt"&gt;VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;项目主页&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://ical-learning.github.io/"&gt;ical-learning.github.io&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;代码仓库&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://github.com/Gabesarch/ICAL"&gt;GitHub - Gabesarch/ICAL&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-04&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>