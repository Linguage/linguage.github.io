<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>代码生成 on Linguista</title><link>https://linguista.cn/tags/%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/</link><description>Recent content in 代码生成 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 17 Aug 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/index.xml" rel="self" type="application/rss+xml"/><item><title>为什么大语言模型无法真正构建软件</title><link>https://linguista.cn/curated/henrinotes_2025_p3/why-llms-cant-really-build-software/</link><pubDate>Sun, 17 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/why-llms-cant-really-build-software/</guid><description>&lt;h1 id="为什么大语言模型无法真正构建软件"&gt;为什么大语言模型无法真正构建软件&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文基于作者丰富的软件工程师面试经验，深入分析了大语言模型在软件开发领域的现状与局限。虽然LLM在代码生成方面表现出色，但缺乏人类工程师最核心的能力——构建和维护清晰的心智模型。这使得LLM在面对复杂、非线性的问题时，难以像人类一样有效地迭代和解决问题。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先阐述了软件工程师的核心工作循环，即从理解需求、编写代码、构建代码行为的心智模型，到识别差异并持续修正的完整过程。作者强调，优秀工程师的关键在于能够持续维护清晰的心智模型，并在测试失败时做出合理判断。&lt;/p&gt;
&lt;p&gt;接着，文章分析了LLM的能力与局限。虽然LLM能够生成代码、运行测试、使用调试工具，但它们无法维护清晰的心智模型。当测试失败时，LLM往往无法判断是代码还是测试有问题，只能猜测如何修复，甚至会选择推倒重来而非有针对性地调整。&lt;/p&gt;
&lt;p&gt;最后，作者探讨了LLM未来的可能性。人类在解决问题时能够灵活管理上下文，在全局与局部之间自由切换，而当前LLM存在新近性偏见和幻觉等问题。虽然业界正在尝试为模型增加记忆能力，但LLM仍无法真正理解全局，也无法像人类一样判断是该修改代码还是需求。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;心智模型&lt;/strong&gt;：这是软件工程师最核心的能力，包括对需求的理解和对代码实际行为的把握。工程师通过不断构建和维护清晰的心智模型，能够在复杂系统中准确判断问题所在并做出合理调整。LLM缺乏这种能力，容易混淆自己生成的代码与实际需求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;需求-实现-验证-修正循环&lt;/strong&gt;：这是软件工程师的核心工作流程。从理解需求、编写代码、构建对代码行为的心智模型，到识别差异并持续修正，这是一个不断迭代的非线性过程。LLM在这个循环中只能完成部分环节，缺乏对全局的理解和判断能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上下文管理&lt;/strong&gt;：人类在解决问题时能够灵活管理上下文，可以暂时搁置细节专注于当前问题，也能在全局与局部之间自由切换。而当前LLM存在新近性偏见，更关注最近输入的信息，容易忽略前文重要内容，也无法像人类一样避免信息过载。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;新近性偏见与幻觉&lt;/strong&gt;：这是LLM面临的两个主要问题。新近性偏见使模型更关注最近输入的信息，幻觉则让模型凭空编造不存在的细节。这些问题限制了LLM在复杂任务中的表现，使其难以准确维护足够的上下文。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人机协作&lt;/strong&gt;：尽管LLM存在局限，但它们在快速生成代码片段、合成文档、处理简单明确需求等方面仍然很有价值。现阶段，工程师必须承担起确保需求清晰、代码正确的责任，主导权仍掌握在工程师手中。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://zed.dev/blog/why-llms-cant-build-software"&gt;Why LLMs Can&amp;rsquo;t Really Build Software&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Zed Blog 团队&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>GPT-5 编程能力深度对谈：与 Cursor CEO 的现场演示与分析</title><link>https://linguista.cn/curated/henrinotes_2025_p3/gpt5-coding-capabilities-cursor-ceo-interview/</link><pubDate>Sat, 16 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/gpt5-coding-capabilities-cursor-ceo-interview/</guid><description>&lt;h1 id="gpt-5-编程能力深度对谈与-cursor-ceo-的现场演示与分析"&gt;GPT-5 编程能力深度对谈：与 Cursor CEO 的现场演示与分析&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文是对 OpenAI Greg Brockman 与 Cursor 联合创始人兼 CEO Michael Truell 对谈的深度总结。视频聚焦 GPT-5 在代码生成、调试、重构等方面的突破性能力，现场演示了从零构建完整软件应用的过程，并讨论了 AI 赋能下软件开发范式的变革，以及对未来开发者角色和生产力的影响。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次对谈展示了 GPT-5 在编程领域的重大突破。两位嘉宾首先分享了 GPT-5 在实际开发中的体验，指出其在理解复杂任务、交互式编程、代码重构等方面展现出前所未有的智能。GPT-5 能够在极短时间内完成以往需要开发者数周熟悉代码库的工作，极大降低了新成员上手大型项目的门槛。&lt;/p&gt;
&lt;p&gt;视频的核心亮点是现场演示环节，展示了如何使用 GPT-5 和 Cursor 从零构建完整软件应用。与传统 AI 编程工具不同，GPT-5 不再局限于写一小段代码或修复单个 bug，而是可以根据线框图等高层描述，自动生成完整、可交互的软件应用，并支持多轮对话式开发和持续迭代。&lt;/p&gt;
&lt;p&gt;在对谈中，两位嘉宾深入探讨了 AI 赋能下的软件开发新范式。他们指出，编程正从&amp;quot;人类将想法翻译成代码&amp;quot;转变为&amp;quot;人类描述目标，AI 负责实现&amp;quot;。未来开发环境可能像即时战略游戏一样，开发者通过指挥多个 AI agent 并行工作，实时查看进度和状态。开发者将更多地关注需求、架构、用户体验和高层决策，而 AI 负责繁琐的实现细节。&lt;/p&gt;
&lt;p&gt;关于生产力提升，实际体验显示 GPT-5 能让开发者的日常工作效率提升 20% 甚至更多。部分任务可直接交由 AI 完成，开发者只需提供监督和关键决策。GPT-5 在定位和修复复杂、隐蔽的 bug 方面表现突出，能自动分析上下文、提出修复建议并实现代码更改，甚至在企业级代码迁移、跨文件重构等高难度场景下表现出色。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;端到端开发能力&lt;/strong&gt;：GPT-5 具备根据高层描述（如线框图、需求文档）自动生成完整应用的能力，包括前端、后端、交互逻辑等。这意味着开发者可以通过自然语言或视觉设计稿直接描述产品需求，AI 自动完成从架构设计到代码实现的全过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多智能体协作&lt;/strong&gt;：未来编程范式将从单一 AI 辅助转向多个 AI agent 并行协作。开发者扮演指挥官角色，负责 orchestrating（编排）和 oversight（监督），不同 agent 可能同时负责前端开发、后端实现、测试、文档编写等任务，形成类似即时战略游戏的开发体验。&lt;/p&gt;</description></item><item><title>子代理与上下文窗口扩展 AI编程代理的突破与实践</title><link>https://linguista.cn/curated/henrinotes_2025_p3/subagents-multiple-context-windows-ai-agents/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/subagents-multiple-context-windows-ai-agents/</guid><description>&lt;h1 id="子代理与上下文窗口扩展ai编程代理的突破与实践"&gt;子代理与上下文窗口扩展：AI编程代理的突破与实践&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文基于Sourcegraph工程师Thorsten Ball的技术分享，系统阐述了AI编程代理面临的核心挑战——上下文窗口限制，并提出了创新的&amp;quot;子代理（Subagents）&amp;ldquo;解决方案。通过多窗口协作机制，主代理可以调用独立的子代理处理特定任务，从而突破单一窗口的容量约束，实现更高效的代码生成与自动化操作。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;上下文窗口是大语言模型处理信息的&amp;quot;记忆空间&amp;rdquo;，所有用户消息、AI回复、工具调用及其结果都必须容纳其中。然而在实际应用中，随着对话深入、工具调用增多以及文件读取操作，窗口很快会被填满，导致token溢出或关键信息丢失。传统解决方案如对话压缩虽能缓解问题，但会损失重要细节和信号。&lt;/p&gt;
&lt;p&gt;子代理机制提供了一种全新的解决思路。子代理本质上是拥有独立上下文窗口的AI代理，可被主代理按需调用处理特定任务。当主代理遇到复杂任务时，会唤起子代理在独立窗口内处理大量信息，最后只将精炼结果返回。这种多窗口协作模式使主代理的上下文窗口只需存储最终答案，所有中间过程和冗余token都被隔离在子代理窗口中。&lt;/p&gt;
&lt;p&gt;子代理机制的应用场景十分广泛。在代码搜索场景中，搜索子代理可以并行抓取分析大量文件，主代理只接收最终定位结果；在复杂推理场景中，可调用采用高质量推理模型（如OpenAI o3）的oracle子代理；在并行编辑场景中，主代理可同时唤起多个子代理处理不同文件的批量编辑任务。这种机制还能实现错误隔离，子代理处理失败不会污染主窗口。&lt;/p&gt;
&lt;p&gt;未来，多窗口协作机制还有更多可能性，包括窗口信息合并、窗口冻结与缓存、窗口分片与重组、窗口跨任务复用等。子代理机制为AI代理系统的&amp;quot;分布式智能&amp;quot;奠定了基础，有望支持更大规模、更复杂的自动化任务。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;上下文窗口（Context Window）&lt;/strong&gt;：大语言模型的&amp;quot;记忆空间&amp;quot;，所有输入输出都必须容纳其中。当窗口被填满时，AI代理会丢失关键信息或直接报错。理解上下文窗口的限制是设计高效AI代理系统的前提。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;子代理（Subagents）&lt;/strong&gt;：拥有独立上下文窗口的AI代理单元，可被主代理按需调用处理特定任务。子代理机制通过多窗口协作突破了单一窗口的容量限制，是AI代理系统实现规模化扩展的关键创新。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异构模型调度&lt;/strong&gt;：主代理和子代理可以采用不同的模型，根据任务需求灵活选择不同能力、速度、成本的模型组合。例如主代理使用快速响应用的模型，子代理使用推理能力强但较慢的模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分布式代理协作&lt;/strong&gt;：主代理负责任务分解与结果整合，子代理专注于子任务的高效处理。这种分工协作模式极大提升了AI代理系统的处理能力和可扩展性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;错误隔离与健壮性&lt;/strong&gt;：子代理在独立窗口中运行，处理失败或报错不会影响主窗口。主代理可以灵活重试、替换或扩展子代理，提升了整个系统的健壮性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=p9Kuk_Fr1Xk"&gt;Subagents &amp;amp; the Multiplication of Context Windows&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Thorsten Ball (Sourcegraph)&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>专有技术困境与AI代码生成</title><link>https://linguista.cn/static/ai-know-how-dilemma/</link><pubDate>Thu, 03 Jul 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/ai-know-how-dilemma/</guid><description>深入探讨 AI 在软件工程中的“专有技术困境”。尽管 AI 擅长处理可编码的事实知识，但在涉及经验、直觉和情境理解的复杂任务中，其局限性暴露无遗。本分析通过交互式图表，揭示了 AI 代码生成中存在的复合错误累积、安全漏洞风险以及领域性能衰减等核心问题，并对比了人类专家与 AI 在知识处理机制上的本质差异。</description></item></channel></rss>