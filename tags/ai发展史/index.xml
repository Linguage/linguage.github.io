<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI发展史 on Linguista</title><link>https://linguista.cn/tags/ai%E5%8F%91%E5%B1%95%E5%8F%B2/</link><description>Recent content in AI发展史 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Wed, 08 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/ai%E5%8F%91%E5%B1%95%E5%8F%B2/index.xml" rel="self" type="application/rss+xml"/><item><title>人工智能在常识推理上的不足与70年来的反思</title><link>https://linguista.cn/curated/henrinotes_2025_p3/ai-common-sense-reasoning-challenges/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/ai-common-sense-reasoning-challenges/</guid><description>&lt;h1 id="人工智能在常识推理上的不足与70年来的反思"&gt;人工智能在常识推理上的不足与70年来的反思&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文由Gary Marcus和Ernest Davis共同撰写，深入探讨了人工智能在常识推理方面持续存在的根本性挑战。自1959年John McCarthy首次指出常识推理的复杂性以来，该领域经历了70年的研究，但AI系统在理解和运用日常常识方面仍然存在显著缺陷。文章回顾了从早期符号AI到现代深度学习的技术演进，分析了物理模拟、基础模型自动涌现和视频生成系统等三种主要解决方案的局限性，并通过具体案例揭示了当前AI技术在空间关系理解、因果关系推理等方面的不足。作者强调，尽管AI领域取得了诸多进展，但要真正实现常识推理能力，仍需要新的技术突破和更深入的理论探索。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以Bob Dylan的歌词开篇，巧妙地引出了当前人工智能领域面临的根本性问题：为什么经过70年的研究，AI系统仍然缺乏人类与生俱来的常识推理能力？作者首先追溯了这一问题的历史渊源，指出人工智能奠基人John McCarthy早在1959年就预见性地强调了常识推理的复杂性和重要性。这一历史视角为读者理解整个问题的发展脉络提供了重要背景。&lt;/p&gt;
&lt;p&gt;在主体部分，文章系统性地梳理了常识推理研究的三个主要方向。物理模拟方法试图通过构建精确的物理模型来模拟现实世界的运行规律，但在处理复杂、多变的日常场景时表现出明显的局限性。以大型语言模型为代表的深度学习技术，其支持者曾期待模型能够通过海量数据训练自动&amp;quot;涌现&amp;quot;出常识理解能力，但作者通过大量实际案例证明，这种方法在处理需要深层理解的任务时仍然经常出错。而像Sora这样的视频生成系统，虽然声称能够理解三维物理现实，但在实际应用中也面临着严重的推理错误问题。&lt;/p&gt;
&lt;p&gt;文章的核心论点在于，无论采用何种单一技术路线，当前AI系统在常识推理方面都存在根本性缺陷。作者强调，常识推理不是简单的模式匹配或统计关联，而是需要对世界运行机制的深层理解，包括因果关系、空间关系、时间序列、社会常识等多个维度。通过展示具体的错误案例，作者有力地证明了即使是当前最先进的AI系统，在面对需要常识推理的任务时仍然经常失败。&lt;/p&gt;
&lt;p&gt;最后，文章对未来的研究方向提出了展望。作者认为，解决常识推理问题可能需要融合多种技术路线，既包括符号推理的精确性，也包含连接主义的学习能力。同时，还需要更好的评估基准和更深入的理论框架来指导研究。整个论述既回顾了历史，也指出了未来，为理解人工智能发展的挑战和机遇提供了重要视角。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;常识推理（Common Sense Reasoning）&lt;/strong&gt;：指人类在日常生活中自然而然具备的知识和理解能力，包括对物理世界的基本认知、社会交往的隐含规则、因果关系的基本理解等。这种能力对人类来说如此基础和直观，以至于我们经常意识不到自己在使用它，但正是这种能力构成了人类智能的基础。对于AI系统而言，常识推理的挑战在于它无法通过简单的规则或数据训练来获得，而是需要对世界运行机制的深层理解和建模。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;符号AI与连接主义&lt;/strong&gt;：符号AI主张通过显式的符号表示和逻辑推理来实现智能，强调知识的结构化表示和推理过程的可解释性；连接主义则通过神经网络等模型从数据中学习模式，强调知识的隐式表示和统计学习。文章指出，这两种方法在常识推理方面都面临挑战：符号AI难以处理不确定性和模糊性，而连接主义缺乏对因果机制和逻辑关系的深层理解。这表明，真正解决常识推理问题可能需要融合两种方法的优点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;涌现（Emergence）&lt;/strong&gt;：在深度学习领域，涌现指的是大型模型在训练过程中自发产生预料之外的能力。一些研究者认为，随着模型规模和训练数据的增大，LLMs可能会自动获得常识理解能力。然而，文章通过大量证据质疑这一观点，指出即使是最先进的语言模型，在需要真正理解常识的任务中仍然经常失败，这表明规模本身并不能解决常识推理的根本问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;物理模拟与 grounded AI&lt;/strong&gt;：这种方法主张通过构建与物理世界直接交互的AI系统来获得常识理解，例如通过视觉系统感知三维空间，通过机器人系统学习物体操作等。文章指出，虽然这种方法在理论上更加符合人类获得常识的方式，但在实际应用中面临巨大挑战：构建精确的物理模型极其困难，而简化的模型又无法捕捉现实世界的复杂性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基准测试与评估&lt;/strong&gt;：文章强调，要推动常识推理研究的发展，需要建立更加科学和全面的评估体系。当前的基准测试往往过于简化，无法真正反映AI系统的常识理解能力。作者呼吁开发更加复杂、更加贴近现实场景的测试集，以准确评估AI系统在常识推理方面的真实水平。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/ai-still-lacks-common-sense-70-years"&gt;AI still lacks &amp;ldquo;common&amp;rdquo; sense, 70 years later&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus 和 Ernest Davis&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月6日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>