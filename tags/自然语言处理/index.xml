<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>自然语言处理 on Linguista</title><link>https://linguista.cn/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/</link><description>Recent content in 自然语言处理 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 08 Jul 2025 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/index.xml" rel="self" type="application/rss+xml"/><item><title>扩散语言模型解析</title><link>https://linguista.cn/info/htmlcards/zed-diffustion-model/</link><pubDate>Tue, 08 Jul 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/info/htmlcards/zed-diffustion-model/</guid><description>本文深入探讨了扩散语言模型这一文本生成的新范式。文章通过交互式图表和对比分析，阐述了非自回归模型如何通过迭代去噪过程生成文本，并重点分析了模型在生成质量与推理速度之间的关键权衡，以及其在文本生成领域的独特优势与潜在挑战。</description></item><item><title>大型语言模型面临根本性局限</title><link>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/llms-fundamental-limitations-compositional-reasoning/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/llms-fundamental-limitations-compositional-reasoning/</guid><description>&lt;h1 id="大型语言模型面临根本性局限"&gt;大型语言模型面临根本性局限&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文深入分析了大型语言模型在复杂推理任务中表现出的根本性局限性。通过爱因斯坦谜题等经典案例，揭示了变换器架构在组合推理方面的数学约束，并探讨了尽管模型规模不断扩大，但这些根本性限制依然存在的现实。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以著名的爱因斯坦谜题作为切入点，展示了大型语言模型在处理需要多步逻辑推理的任务时表现出的明显不足。研究表明，LLMs的训练方式主要通过预测下一个单词来学习，这种方法在处理组合推理任务时存在本质上的限制。&lt;/p&gt;
&lt;p&gt;在成功引发审视部分，文章指出LLMs在自然语言处理的某些领域表现出色，但在其他任务中却显得能力有限。研究团队通过实验发现，即使对模型进行大量数据的微调，其在未见过的复杂任务中仍然无法取得良好表现。这种表现的差异性引发了研究界对LLMs本质能力的深入思考。&lt;/p&gt;
&lt;p&gt;关于根本性限制，研究人员通过理论分析发现，变换器架构的单层模型在处理组合任务时存在数学上的限制。即使扩展到多层变换器，其计算能力仍然无法完全解决复杂的组合问题。这一发现表明，变换器架构本身存在根本性的设计约束。&lt;/p&gt;
&lt;p&gt;尽管存在这些局限性，研究人员仍在探索多种方法来增强LLMs的表现。通过在训练中嵌入额外的位置信息，或者采用链式思考提示技术，将复杂问题分解为多个小问题，可以在一定程度上改善模型在复杂组合任务中的表现。然而，这些方法并不能从根本上消除变换器架构的限制。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;组合推理&lt;/strong&gt;：指需要通过多个逻辑步骤组合才能解决的推理任务，如爱因斯坦谜题。这类任务要求模型能够理解并整合多个约束条件，进行多步推导，而LLMs在这方面表现出明显不足，因为它们主要学习的是模式匹配而非真正的逻辑推理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;变换器架构限制&lt;/strong&gt;：研究团队通过理论分析发现，变换器架构在处理组合任务时存在数学上的根本性约束。单层变换器的能力有限，即使扩展到多层，其计算复杂性仍然无法完全解决复杂的组合问题，这是架构设计本身带来的限制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;链式思考提示&lt;/strong&gt;：这是一种通过将复杂问题分解为多个小问题来帮助LLMs更好地处理任务的方法。虽然这种方法能在一定程度上提升模型表现，但它并不能解决变换器架构的根本性限制，只是一种缓解策略。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下一个词预测训练&lt;/strong&gt;：LLMs主要通过预测句子中的下一个单词来学习，这种训练方式使得模型在模式识别任务中表现出色，但在需要真正理解和推理的任务中则显得能力不足，这是导致其局限性存在的根本原因之一。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;位置信息嵌入&lt;/strong&gt;：研究人员发现，通过在训练中嵌入额外的位置信息，可以显著提高模型在某些任务中的表现。这种方法虽然能增强模型能力，但同样无法克服变换器架构在组合推理方面的根本性限制。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/"&gt;Chatbot Software Begins to Face Fundamental Limitations&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Quanta Magazine&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-31&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AI模型如何揭示人类学习语言的方式</title><link>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/ai-models-language-learning-impossible-languages/</link><pubDate>Tue, 28 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/ai-models-language-learning-impossible-languages/</guid><description>&lt;h1 id="ai模型如何揭示人类学习语言的方式"&gt;AI模型如何揭示人类学习语言的方式&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文探讨了AI模型在揭示人类语言学习机制方面的潜力。通过构建和测试&amp;quot;不可能的语言&amp;quot;——即违反人类普遍语法的语言结构——研究者们试图验证大型语言模型是否真正以类似人类的方式学习语言。文章从Chomsky的普遍语法理论出发，介绍了相关实验的进展与争议，最终指向一个核心问题：AI模型能否帮助我们理解人类语言学习的本质。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先从语言学习的核心难题切入。人类如何学习语言一直是语言学和认知科学的核心问题。Noam Chomsky提出的普遍语法理论认为，人类生来就具有语言学习的内在机制，这套机制限制了可能的人类语言结构。然而，现代大型语言模型的崛起对这一传统理论构成了挑战——这些模型仅仅通过统计学习就能掌握复杂的语言模式，似乎不需要先天的语言结构。&lt;/p&gt;
&lt;p&gt;接着，文章介绍了&amp;quot;不可能的语言&amp;quot;这一研究方法。研究者构建违反普遍语法规则的人造语言，然后测试AI模型是否能学习这些语言。如果AI模型能学习这些人类无法掌握的语言，说明它们的学习机制与人类不同；反之，如果它们也面临困难，则可能暗示它们在某种程度上模拟了人类的学习过程。&lt;/p&gt;
&lt;p&gt;文章详细介绍了相关研究的进展。早期的研究发现，某些语言模型能够学习不可能的语言，这似乎与Chomsky的理论相悖。然而，更近期的研究表明，现代大型语言模型在学习某些不可能语言时确实面临显著困难，这为理解语言学习机制提供了新的线索。&lt;/p&gt;
&lt;p&gt;最后，文章展望了这一研究方向的意义。通过对比AI模型和人类在不可能语言任务上的表现，研究者们希望能够揭示语言学习的普遍原理，回答人类是否拥有独特的语言学习机制这一根本问题。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;普遍语法&lt;/strong&gt;：Chomsky提出的理论，认为人类生来就具有一套先天的语言结构知识，这套知识限制了所有人类可能的语言形式。这套理论解释了为什么儿童能够在有限的语言输入下快速掌握复杂的语言规则，以及为什么某些语言结构在人类语言中从未出现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;不可能的语言&lt;/strong&gt;：违反普遍语法约束的人造语言。这些语言在逻辑上是自洽的，但违反了人类语言的结构限制。通过测试AI模型是否能学习这些语言，研究者可以推断它们的学习机制是否与人类相似。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;信息局部性原则&lt;/strong&gt;：近期研究中发现的一个关键原则，它限制语言依赖关系的作用范围。这一原则在人类语言中普遍存在，而现代AI模型在学习违反这一原则的语言时确实面临困难，这可能暗示模型在某种程度上捕捉到了人类语言的结构特征。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;统计学习 vs 结构学习&lt;/strong&gt;：AI模型主要通过统计模式识别学习语言，而人类学习可能涉及更深层的结构表征。研究的核心争议在于，统计学习是否足以解释人类语言能力，还是需要额外的先天结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;语言模型作为认知科学工具&lt;/strong&gt;：AI模型为研究人类语言学习提供了新的实验平台。与传统语言学研究不同，研究者可以精确控制模型的训练过程和输入，从而分离出影响语言学习的各种因素。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.quantamagazine.org/can-ai-models-show-us-how-they-learn-impossible-languages-point-a-way-20250113"&gt;Can AI Models Show Us How People Learn? Impossible Languages Point a Way&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Quanta Magazine&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-13&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>N-Gram模型与自然语言处理入门</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/n-gram-model-natural-language-processing-introduction/</link><pubDate>Thu, 09 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/n-gram-model-natural-language-processing-introduction/</guid><description>&lt;h1 id="n-gram模型与自然语言处理入门"&gt;N-Gram模型与自然语言处理入门&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文系统介绍了N-Gram模型的基本原理及其在自然语言处理中的重要作用。作为理解概率语言模型的基础和深入理解现代语言模型如GPT的重要前奏，文章详细阐述了N-Gram模型的定义、构建过程、优缺点以及实际应用场景。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先强调N-Gram模型在自然语言处理学习路径中的核心地位，指出理解N-Gram是迈向GPT等现代语言模型的第一步。GPT的核心思想正是对N-Gram思想的深度拓展和优化。&lt;/p&gt;
&lt;p&gt;文章详细介绍了N-Gram模型的基本概念：通过将文本分割成连续的N个词的组合来近似描述词序列的联合概率。根据N的不同取值，可以分为Unigram（一元组）、Bigram（二元组）和Trigram（三元组）等不同类型。每种类型都有其特定的上下文依赖假设，从仅考虑当前词到依赖前面N-1个词的序列。&lt;/p&gt;
&lt;p&gt;在实现方面，文章阐述了N-Gram模型的构建过程，包括文本分割、词频统计、条件概率计算和预测生成四个步骤。通过训练语料中的频率统计，可以近似得到条件概率，从而预测下一个词出现的可能性。文章还特别强调了&amp;quot;词&amp;quot;的定义在不同语言中的差异，以及子词分词算法在处理未登录词等问题上的优势。&lt;/p&gt;
&lt;p&gt;文章客观分析了N-Gram模型的优点和局限性。优点包括简单高效、广泛适用和灵活可调；缺点主要体现在数据稀疏性、上下文局限和维度增长等方面。尽管存在这些限制，N-Gram模型仍在拼写检查、机器翻译和文本生成等实际应用场景中发挥着重要作用。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;N-Gram定义&lt;/strong&gt;：N-Gram是指文本中连续的N个词的组合。它的核心思想是用有限的上下文信息（N-1个词）来近似预测下一个词的概率。这种简化使得概率计算成为可能，是构建统计语言模型的基础方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;条件概率估计&lt;/strong&gt;：通过训练语料中的频率统计来近似计算条件概率。具体公式为给定前N-1个词时，下一个词出现的条件概率等于该N-gram在语料中的共现次数除以前缀的出现次数。这种基于统计的方法简单直接，不需要复杂的参数学习。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据稀疏性&lt;/strong&gt;：N-Gram模型面临的主要挑战之一。当N值较大时，很多可能的N-gram组合在训练语料中从未出现，导致概率为零，这在实际应用中会造成问题。平滑技术是解决这一问题的常用方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上下文局限&lt;/strong&gt;：N-Gram模型只能捕获有限长度（N-1个词）的上下文信息，无法理解文本中的长距离依赖关系。这是相对于现代深度学习语言模型的一个主要限制，也是GPT等模型通过注意力机制试图突破的瓶颈。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;子词分词&lt;/strong&gt;：将单词切分成更小有意义部分的算法。对于处理未登录词、拼写错误和词汇变化等问题非常有效。比如将&amp;quot;embedding&amp;quot;切分为[&amp;ldquo;em&amp;rdquo;, &amp;ldquo;bed&amp;rdquo;, &amp;ldquo;ding&amp;rdquo;]，能够在保证语义完整性的同时提高模型的泛化能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/itcpsLv6x-4Thk9B2-BtTQ"&gt;入门GPT（一）| N-Gram 带你了解自然语言处理（1）&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;原作者&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-09&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>利用词袋模型提升餐厅满意度分析</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/bag-of-words-restaurant-satisfaction-analysis/</link><pubDate>Thu, 09 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/bag-of-words-restaurant-satisfaction-analysis/</guid><description>&lt;h1 id="利用词袋模型提升餐厅满意度分析"&gt;利用词袋模型提升餐厅满意度分析&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文详细介绍了自然语言处理中的词袋模型（Bag of Words，BoW）技术，阐述了其将文本转化为数值向量的基本原理。文章以餐厅满意度分析为实际案例，完整演示了从文本预处理、中文分词、构建词汇表、向量化表示到词频统计和相似度分析的完整流程。通过分析客户评论数据，识别出食物质量满意而配送速度不足的核心问题，为餐厅运营改进提供了数据支持。同时，文章也客观分析了词袋模型在忽略词序和上下文语义方面的局限性。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章开篇介绍了词袋模型的核心概念，即将文本视为由单词构成的无序集合，通过统计词频来表示文本信息。这种模型将文本转化为固定长度的数值向量，每个维度对应词汇表中的一个单词，其值表示该词在文本中出现的次数。这种表示方法为后续的文本分析任务奠定了基础。&lt;/p&gt;
&lt;p&gt;接着，文章详细阐述了实现词袋模型的四个关键步骤。首先是文本预处理，包括清理标点符号、去除停用词、统一大小写等操作；对于中文文本，还需要进行分词处理。其次是构建词汇表，收集所有文本中出现的唯一单词作为特征维度。第三步是向量化转换，将每条文本转化为对应的词频向量。最后，基于这些向量表示，可以进行余弦相似度计算等分析任务，衡量不同文本之间的相似程度。&lt;/p&gt;
&lt;p&gt;在实践应用部分，文章以餐厅客户评论分析为例，展示了如何通过词频统计识别客户关注的核心问题。分析发现，正面评论中&amp;quot;美味&amp;quot;、&amp;ldquo;值得&amp;rdquo;、&amp;ldquo;惊喜&amp;quot;等词汇出现频率较高，而负面评论中&amp;quot;太慢&amp;quot;更为突出，这表明用户对食物质量普遍满意，但配送速度是影响满意度的关键因素。基于这些洞察，餐厅可以有针对性地改进服务，提升整体客户满意度。&lt;/p&gt;
&lt;p&gt;文章最后也指出了词袋模型的技术局限性，包括高维稀疏表示带来的计算效率问题，以及忽略词序和上下文语义导致的语义理解不足。这些局限性在需要精细语义理解的任务中尤为明显，如机器翻译和命名实体识别等。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;词袋模型&lt;/strong&gt;：一种基础但重要的文本表示方法，将文本简化为单词频率的统计模型。它不考虑单词的顺序和语法结构，只关注单词出现的频率。这种简单的表示方法在很多任务中出人意料地有效，特别是情感分析和文本分类等不需要复杂语义理解的应用场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;中文分词&lt;/strong&gt;：中文自然语言处理的特有挑战，由于中文没有天然的单词分隔符，需要借助算法如jieba将连续的汉字序列切分成有意义的词语。分词质量直接影响后续文本分析的效果，是中文NLP流程中不可或缺的预处理步骤。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;余弦相似度&lt;/strong&gt;：衡量两个向量之间相似性的指标，通过计算向量夹角的余弦值来实现。在文本分析中，基于词袋表示的余弦相似度可以有效反映两段文本在词汇使用上的相似程度，常用于文本聚类、推荐系统和相似文档检索等任务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;停用词&lt;/strong&gt;：指在文本中频繁出现但对文本主题贡献较小的常用词，如&amp;quot;的&amp;rdquo;、&amp;ldquo;是&amp;rdquo;、&amp;ldquo;在&amp;quot;等。去除停用词可以减少噪声，突出文本的关键信息，提高后续分析的准确性和效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;稀疏向量&lt;/strong&gt;：词袋模型产生的文本向量通常维度很高（等于词汇表大小），但大部分元素值为0，这种向量被称为稀疏向量。稀疏表示虽然在存储和计算上带来挑战，但也反映了自然语言的基本特性，即任何给定文本通常只使用整个语言词汇的一小部分。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/ppdgC62OH8haLF37qLFe1w"&gt;入门GPT（二）| 词袋模型（Bag of Words）辅助提升餐厅满意度&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;佚名&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未注明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>