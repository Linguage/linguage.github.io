<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Model Architecture on Linguista</title><link>https://linguista.cn/tags/model-architecture/</link><description>Recent content in Model Architecture on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 30 Sep 2025 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/model-architecture/index.xml" rel="self" type="application/rss+xml"/><item><title>DeepSeek-V3.2-Exp 深度解析</title><link>https://linguista.cn/infos/htmlcards/deepseek-v3-2-report-magazine/</link><pubDate>Tue, 30 Sep 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/infos/htmlcards/deepseek-v3-2-report-magazine/</guid><description>DeepSeek-V3.2-Exp 通过引入稀疏注意力和闪电索引器技术，成功将长文本处理的计算复杂度从 O(L²) 显著降低至 O(Lk)，实现了高达 128K 上下文窗口的高效推理。本文深入解析了其多查询注意力机制背后的设计理念，展示了在保持高性能的同时，如何通过算法创新优化大模型的效率瓶颈，为下一代 AI 基础设施的构建提供了重要的技术参考。</description></item></channel></rss>