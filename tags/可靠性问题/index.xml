<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>可靠性问题 on Linguista</title><link>https://linguista.cn/tags/%E5%8F%AF%E9%9D%A0%E6%80%A7%E9%97%AE%E9%A2%98/</link><description>Recent content in 可靠性问题 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 09 Feb 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E5%8F%AF%E9%9D%A0%E6%80%A7%E9%97%AE%E9%A2%98/index.xml" rel="self" type="application/rss+xml"/><item><title>ChatGPT的可靠性问题：两年投资后的现状</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</guid><description>&lt;h1 id="chatgpt的可靠性问题两年投资后的现状"&gt;ChatGPT的可靠性问题：两年投资后的现状&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文记录了作者对ChatGPT最新版本的测试结果，展示了其在处理基本任务时仍然存在的可靠性问题。通过美国各州收入与人口表格、加拿大省份元音计数等测试，暴露出ChatGPT在计数、完整性、基础事实判断等方面的不足。作者质疑在如此多错误存在的情况下，通用人工智能（AGI）是否真如某些预测所言即将实现。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从软银集团孙正义对AGI的乐观预测切入，引出作者对ChatGPT实际表现的测试。测试内容包括两个主要案例：生成美国各州收入与人口表格，以及统计加拿大省份名称中的元音数量。&lt;/p&gt;
&lt;p&gt;在美国各州测试中，ChatGPT初始输出遗漏了多个州，补充人口密度列时出现计算错误，甚至将阿拉斯加完全遗漏。经过多次修正才最终得到正确结果。在加拿大省份元音计数测试中，ChatGPT将字母&amp;quot;h&amp;quot;误认为元音，计数多次出错，修正过程同样曲折。&lt;/p&gt;
&lt;p&gt;文章还引用了Sayash Kapoor对OpenAI新Operator代理的测试结果，显示即使是新发布的AI代理也存在可靠性问题。作者最后引用1841年经典著作中的论述，反思当前AI热潮中可能存在的盲目性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI预测与现实的差距&lt;/strong&gt;：软银孙正义预测AGI将在未来几年内实现，但基础测试显示当前AI模型连简单任务都无法可靠完成，这种预测与实际能力之间存在巨大鸿沟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性问题的具体表现&lt;/strong&gt;：ChatGPT在计数、列表完整性、基础事实判断等方面频发错误，包括无法准确计数到50、遗漏美国州、错误识别元音字母等，这些问题在经过两年大规模投资后仍然存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI模型的盲目自信&lt;/strong&gt;：ChatGPT在犯错时并未表现出不确定性，而是自信地给出错误答案，只有在被明确指出后才进行修正，这种特性增加了用户被误导的风险。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修正过程的繁琐性&lt;/strong&gt;：即使是简单任务，也需要用户多次指出错误才能得到正确结果，这种交互方式大大降低了AI工具的实用性和可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史警示的当代意义&lt;/strong&gt;：作者引用1841年关于群体盲目性的论述，暗示当前AI热潮可能存在类似的非理性现象，提醒人们需要更客观地评估AI技术的实际发展水平。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/chatgpt-in-shambles?utm_source=post-email-title&amp;amp;publication_id=888615&amp;amp;post_id=156479923&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=208yzy&amp;amp;triedRedirect=true&amp;amp;utm_medium=email"&gt;ChatGPT in Shambles&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>