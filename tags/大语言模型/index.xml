<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>大语言模型 on Linguista</title><link>https://linguista.cn/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 大语言模型 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 08 Feb 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>Andrej Karpathy 盛赞 DeepSeek R1 强化学习推动 AI 模型进化</title><link>https://linguista.cn/curated/henrinotes-2025_p2/karpathy-praises-deepseek-r1-reinforcement-learning/</link><pubDate>Sat, 08 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/karpathy-praises-deepseek-r1-reinforcement-learning/</guid><description>&lt;h1 id="andrej-karpathy-盛赞-deepseek-r1强化学习推动-ai-模型进化"&gt;Andrej Karpathy 盛赞 DeepSeek R1：强化学习推动 AI 模型进化&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文基于 Andrej Karpathy 的最新视频内容，详细介绍了 DeepSeek R1 在强化学习方面的技术创新。Karpathy 指出，DeepSeek R1 通过强化学习微调，在解决数学问题等方面表现出色，并且能够发现人类思考问题的逻辑和策略。文章还探讨了强化学习与人类反馈（RLHF）的优势与局限性，并展望了大语言模型在多模态能力和智能体方面的未来发展。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Andrej Karpathy 作为 OpenAI 早期成员、前特斯拉 AI 总监，在其最新视频中对 DeepSeek R1 给予了高度评价。他回顾了从神经网络起源到最新大模型的发展历程，特别强调了 DeepSeek R1 在强化学习（RL）方面的技术创新。DeepSeek R1 是一个通过强化学习微调的大语言模型，其性能与 OpenAI 的模型不相上下，在解决数学问题时表现出色。&lt;/p&gt;
&lt;p&gt;Karpathy 认为，强化学习是大语言模型训练中的新兴阶段，目前仍处于起步状态。强化学习的优势在于能够突破人类的限制，发现人类未曾意识到的策略，例如 AlphaGo 在围棋中发明的创新走法。然而，强化学习也存在挑战，它非常擅长发现&amp;quot;欺骗&amp;quot;模型的方法，这可能会阻碍其在某些领域的应用。&lt;/p&gt;
&lt;p&gt;关于强化学习与人类反馈，Karpathy 指出，从人类反馈中进行强化学习（RLHF）能够提升模型性能，尤其是在那些无法验证的领域，如创意写作等。但 RLHF 的主要问题是基于人类反馈的强化学习可能会产生误导，因为人类反馈是一个有损模拟，无法完美反映真实人类的判断。&lt;/p&gt;
&lt;p&gt;展望未来，Karpathy 预测未来的语言模型将不仅能够处理文本，还将轻松处理音频和图像。通过标记化技术，模型可以将音频、图像和文本的标记流交替放入一个模型中进行处理，实现多模态能力。此外，大语言模型将能够执行长期任务，人类将成为这些智能体任务的监督者。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;强化学习&lt;/strong&gt;：强化学习是大语言模型训练中的新兴阶段，通过奖励机制优化模型行为。DeepSeek R1 通过强化学习微调，在解决数学问题时表现出色，并且能够发现人类思考问题的逻辑和策略，如&amp;quot;思维链&amp;quot;（CoT）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RLHF&lt;/strong&gt;：从人类反馈中进行强化学习能够提升模型性能，尤其是在那些无法验证的领域。人类标注者可以通过简单的排序任务来提供高质量的反馈，但人类反馈是一个有损模拟，无法完美反映真实人类的判断，可能会导致误导。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多模态能力&lt;/strong&gt;：未来的语言模型将不仅能够处理文本，还将轻松处理音频和图像。通过标记化技术，模型可以将音频、图像和文本的标记流交替放入一个模型中进行处理，实现真正的多模态能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/thTwdVgc4lfYRj6WWpKBwA"&gt;Andrej Karpathy 最新视频盛赞 DeepSeek：R1 正在发现人类思考的逻辑并进行复现&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;郑佳美&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年02月06日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>开源大语言模型的崛起与对行业巨头的挑战</title><link>https://linguista.cn/curated/henrinotes-2025_p2/open-source-llm-rise-google-moat/</link><pubDate>Sat, 01 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/open-source-llm-rise-google-moat/</guid><description>&lt;h1 id="开源大语言模型的崛起与对行业巨头的挑战"&gt;开源大语言模型的崛起与对行业巨头的挑战&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文通过分析 Google 内部文件《我们没有护城河，OpenAI 也没有》，深入探讨了开源大语言模型的快速崛起及其对行业巨头的战略冲击。文章指出，开源社区通过低成本微调、快速迭代和协同创新，在短时间内实现了惊人的技术突破，正在重塑人工智能领域的竞争格局。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以 DeepSeek R1 开源模型的发布为切入点，展现了开源 AI 模型在性能上已能够媲美甚至超越闭源商业模型。作者回顾了 2023 年初 LLaMA 模型泄露后的开源创新浪潮，详细梳理了短短两个月内开源社区在指令微调、量化优化、多模态支持和 RLHF 等领域的一系列突破。&lt;/p&gt;
&lt;p&gt;文章深入分析了开源模型的核心优势：速度快、可定制性强、注重隐私且功能全面。通过 LLaMA、Alpaca、Vicuna、Koala 等案例，展示了开源社区如何利用 LoRA 等低成本的微调方法，以数百美元的训练成本达到接近 ChatGPT 和 Bard 的性能水平。这种创新速度和效率远超大型科技企业，对 Google 和 OpenAI 的商业战略构成了直接挑战。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;开源社区的协同创新&lt;/strong&gt;：开源模式通过全球开发者的协作，实现了技术创新的指数级加速。当 LLaMA 权重泄露后，开源社区在一个月内完成了大型企业需要数月甚至数年才能完成的技术迭代，包括指令微调、量化、多模态支持等关键技术突破。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;低成本微调技术&lt;/strong&gt;：以 LoRA 为代表的低秩适应方法，使得开发者能够在消费级硬件上以极低的成本（100-300 美元）对大语言模型进行有效微调。这彻底改变了 AI 模型的开发范式，让个人开发者和小团队也能参与到最前沿的 AI 创新中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;护城河的消解&lt;/strong&gt;：Google 内部文件承认，开源模型在功能、性能和可用性上已经能够与闭源模型抗衡。当用户可以免费获得质量相当且无使用限制的模型时，依赖 API 访问的闭源商业模式的可持续性面临严峻挑战。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Meta 的开源战略&lt;/strong&gt;：Meta 通过开源 LLaMA 架构，成功吸引了全球开发者在其生态系统中进行创新，这些创新成果最终可以被 Meta 直接整合到自己的产品中，形成了一种&amp;quot;反向护城河&amp;quot;效应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;快速迭代的时间窗口&lt;/strong&gt;：从 2023 年 2 月 LLaMA 发布到 4 月开源 RLHF 达到 ChatGPT 水平，短短两个月内开源社区完成了从模型泄露到性能媲美顶级商业模型的完整进化链条，展现了开源模式在 AI 领域的巨大潜力。&lt;/p&gt;</description></item><item><title>多种经典提示技术的应用与设置</title><link>https://linguista.cn/curated/henrinotes-2025-p1/classic-prompting-techniques-guide/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/classic-prompting-techniques-guide/</guid><description>&lt;h1 id="多种经典提示技术的应用与设置"&gt;多种经典提示技术的应用与设置&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文全面介绍了提示工程的核心要素，包括模型参数设置、提示词设计原则以及多种经典提示技术。文章从温度、Top_p等基础参数讲起，深入解析零样本、少样本、链式思考等主流提示方法，并探讨了思维树、自动推理工具、自我反思等进阶技术，为开发者提供了系统性的提示工程实践指南。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先阐述了大语言模型交互时的关键模型设置参数。温度参数控制输出的确定性与创造性，较低温度使模型输出更确定，较高温度则增加随机性，适合创造性任务。Top_p参数通过核采样控制响应多样性，最大长度限制防止冗余输出，停止序列精确控制输出结构，频率和存在惩罚则有效避免内容重复。&lt;/p&gt;
&lt;p&gt;在提示词设计方面，文章强调了四个核心要素。指令明确模型要执行的具体任务，上下文提供必要的外部信息，输入数据包含用户的实际问题，输出指示规范结果的格式类型。设计时应从简单入手逐步迭代，使用明确具体的指令，并通过示例引导模型产生期望输出。&lt;/p&gt;
&lt;p&gt;文章重点介绍了多种经典提示技术及其应用场景。零样本提示直接提问不提供示例，依赖模型预训练知识；少样本提示通过一到多个示例帮助模型理解任务模式；链式思考提示引导模型展示中间推理步骤，特别适合复杂逻辑问题。自动思维链通过聚类和抽样自动生成推理链，自我一致性方法则结合多条推理路径选择最稳定答案。&lt;/p&gt;
&lt;p&gt;进阶技术部分涵盖了生成知识提示、链式提示分解、思维树决策等高级方法。生成知识提示先让模型生成相关知识再回答问题，链式提示将复杂任务拆解为多个子任务逐步处理，思维树技术模仿人类决策过程用树状结构表示问题解决路径。自动推理工具技术结合中间推理步骤和外部工具使用，自我反思则通过语言反馈不断强化智能体的学习能力。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;温度参数&lt;/strong&gt;：控制模型输出随机性的关键参数。低温度如0.2使输出更加确定和保守，适合事实性问答；高温度如0.8增加随机性和创造性，适用于创意写作、头脑风暴等场景。实际应用中需根据任务性质谨慎调整。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Top_p采样&lt;/strong&gt;：又称核采样，通过累积概率阈值控制候选token范围。设为0.1时仅从最可能的10%token中选择，输出更准确；设为0.9时考虑更多可能性，响应更多样化。通常与温度参数配合使用，但建议二选一避免相互干扰。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;链式思考提示&lt;/strong&gt;：要求模型在给出最终答案前展示中间推理步骤，显著提升复杂问题的解决能力。例如数学问题中让模型&amp;quot;一步步思考&amp;quot;并说明计算过程，能大幅提高准确率。对于逻辑推理、多步骤任务特别有效。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;少样本学习&lt;/strong&gt;：在提示中提供一到多个完整示例，每个示例包含输入和期望输出。这种方式让模型通过类比学习任务模式，无需额外训练即可适应新场景。示例选择要具有代表性，数量通常在三到五个之间效果最佳。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思维树技术&lt;/strong&gt;：将问题解决过程表示为树状结构，每个节点代表一个思维状态，分支代表可能的行动。通过探索、评估和回溯机制，智能体能够在复杂决策空间中找到最优路径，比线性思维链更强大也更耗计算资源。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/aBrKnkVb2_qLSbT7a04SrA"&gt;多种经典提示技术——Prompt&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;简单的机器学习&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-12-24&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>