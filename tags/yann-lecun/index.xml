<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yann LeCun on Linguista</title><link>https://linguista.cn/tags/yann-lecun/</link><description>Recent content in Yann LeCun on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Mon, 17 Mar 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/yann-lecun/index.xml" rel="self" type="application/rss+xml"/><item><title>NVIDIA GTC 2025 AI与计算前沿 - Yann LeCun与Bill Dally对话</title><link>https://linguista.cn/rosetta/chat-notes/nvidia-gtc-2025-yann-lecun-bill-dally-conversation-ai-frontiers/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/nvidia-gtc-2025-yann-lecun-bill-dally-conversation-ai-frontiers/</guid><description>&lt;h1 id="nvidia-gtc-2025-ai与计算前沿---yann-lecun与bill-dally对话"&gt;NVIDIA GTC 2025 AI与计算前沿 - Yann LeCun与Bill Dally对话&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Meta首席AI科学家Yann LeCun在NVIDIA GTC 2025上与Bill Dally展开对话，对当前大型语言模型热潮持审慎态度，认为LLM并非通向真正机器智能的终点。他提出未来研究应聚焦四大方向——理解物理世界、持久记忆、推理与规划，并介绍了联合嵌入预测架构JEPA作为替代方案，同时倡导开源战略推动AI多样化发展。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/eyrDM3A_YFc?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="NVIDIA GTC 2025 AI与计算前沿 - Yann LeCun与Bill Dally对话"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;JEPA（联合嵌入预测架构）——LeCun团队提出的新型学习架构，通过在抽象表示空间中预测高维数据的演变来学习世界模型，避免了像素级重建的高成本与低效率问题&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;世界模型（World Model）——指让AI系统像人类一样建立对物理世界运作方式的内隐理解，能够预测物体行为和物理现象，是实现高级机器智能的关键基础&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AMI（高级机器智能）——LeCun倾向使用的术语，用以替代AGI（通用人工智能），因为他认为人类智能本身就是高度特化的，该目标预计需要十年或更长时间才能实现&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LLaMA——Meta开源的大型语言模型系列，源自巴黎小团队的创新项目，下载量超过十亿次，其成功印证了开源策略在推动AI生态建设和全球协作中的巨大价值&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Token空间推理的局限性——LeCun批评当前LLM通过生成大量词元序列来进行推理的方式过于简单，主张真正的推理应在连续的抽象表示空间中进行而非离散的符号空间&lt;/strong&gt;：&lt;/p&gt;
&lt;h2 id="meta首席ai科学家yann-lecun对当前ai热潮发出审慎之声"&gt;Meta首席AI科学家Yann LeCun对当前AI热潮发出审慎之声&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;这位深度学习先驱认为，大型语言模型虽有价值，但并非通往真正机器智能的终点，呼吁业界关注更深层次挑战&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在人工智能（AI）以前所未有的速度渗透商业和社会之际，科技巨头们正斥巨资竞相开发更大、更强的语言模型。然而，作为该领域最具影响力的奠基人之一，Meta Platforms Inc.的首席AI科学家Yann LeCun却发出了不同的声音，对当前围绕大型语言模型（LLM）的狂热持审慎态度，并指出通往更高级机器智能的道路需要克服更为根本的障碍。&lt;/p&gt;
&lt;p&gt;LeCun教授是2018年图灵奖得主，其在卷积神经网络（ConvNets）上的开创性工作为现代AI的诸多突破奠定了基础。这位在AI领域经历过数次起伏周期的资深科学家，如今对业界普遍认为仅靠扩展LLM就能实现通用人工智能（AGI）的观点表示明确怀疑。“我现在对LLM不那么感兴趣了，”他在近期NVIDIA GTC大会与该公司首席科学家Bill Dally的对话中表示，“它们现在掌握在行业产品人员手中，进行着边际改进，试图获取更多数据、更多算力。”&lt;/p&gt;
&lt;p&gt;他将当前LLM通过生成海量词元序列并从中筛选最优解的推理方式比作“在不知道如何编写程序的情况下编写随机程序，然后测试所有程序……这完全是没希望的。” 他认为这种方法“过于简单”，并坚信存在更好的路径。对于甚嚣尘上的“AGI即将到来”论调，LeCun更是毫不留情地斥之为“胡说八道”，并引用某位匿名人士的说法——“几年内你将在一个数据中心里拥有‘一个由天才组成的国度’”——称其为“完全是胡说八道”。他提醒道，AI历史上每隔十年左右就会出现一波类似的过度乐观浪潮，“当前的浪潮也是错误的。”&lt;/p&gt;
&lt;p&gt;LeCun的研究重心已转向他认为更基础且更具挑战性的四大领域：让机器理解物理世界、拥有持久记忆、掌握真正的推理能力以及具备规划能力。他强调，理解现实世界远比处理离散的语言符号困难得多。“我们每个人头脑中都有世界模型，”他以推瓶子的简单物理现象为例解释道，“你知道从顶部推它可能会翻倒，但从底部推它会滑动。” 当前AI缺乏这种对物理世界运作方式的内隐理解。&lt;/p&gt;
&lt;p&gt;为此，LeCun及其团队正致力于开发“联合嵌入预测架构”（JEPA/JAPA）。这种架构旨在让AI像婴儿观察世界一样学习——通过预测高维数据（如视频）在抽象“表示空间”中的演变，而非试图在像素层面进行无法实现的精确重建。“每一次试图让系统通过被训练来预测像素级的视频来理解世界……基本上都失败了，”他指出，“它会把所有的资源都花在试图构思那些它根本无法创造出来的细节上。” 他分享了其团队在视频理解上的尝试：基于像素重建的MAE模型扩展到视频时，计算成本高昂到需要“烧开一个小湖来冷却GPU集群”，且效果不彰，最终项目被停止；而基于JEPA的V-JEPA模型则在学习视频中的物理可能性方面展现出更好的效果和效率，如同婴儿通过观察区分合理与异常现象。&lt;/p&gt;</description></item></channel></rss>