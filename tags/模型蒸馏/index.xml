<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>模型蒸馏 on Linguista</title><link>https://linguista.cn/tags/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/</link><description>Recent content in 模型蒸馏 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 07 Sep 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/index.xml" rel="self" type="application/rss+xml"/><item><title>Anthropic对华AI禁令背后的意识形态挂帅与商业求生</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/anthropic-china-ban-ideology-commerce/</link><pubDate>Sun, 07 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/anthropic-china-ban-ideology-commerce/</guid><description>&lt;h1 id="anthropic对华ai禁令背后的意识形态挂帅与商业求生"&gt;Anthropic对华AI禁令背后的意识形态挂帅与商业求生&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本期视频深度剖析Anthropic公司2025年9月出台的&amp;quot;对华最严AI禁令&amp;quot;。该政策要求全球范围内中国资本控股超过50%的企业及其子公司立即停止使用Claude及相关服务，采用&amp;quot;股权穿透&amp;quot;原则直指中国企业。视频揭示，这一举措既是CEO达里奥·阿莫戴伊及其家族&amp;quot;AI安全主义&amp;quot;和&amp;quot;有效利他&amp;quot;理念的价值观体现，也是Anthropic面对中国AI厂商通过API兼容和模型蒸馏技术激烈竞争的被迫防守。失去占据全球开发者40%以上的中国程序员市场，Anthropic在编程AI领域正面临被边缘化的严峻挑战。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;事件始于2025年9月，Anthropic突然发布针对中国企业的最严新规。与OpenAI、谷歌等公司采取&amp;quot;合规审查&amp;quot;的模糊限制不同，Anthropic直截了当以&amp;quot;威权国家安全威胁&amp;quot;为由点名中国、俄罗斯、朝鲜、伊朗，强调这些国家的企业受法律要求需配合数据共享，无论在哪里运营都是高风险客户。政策创新性地采用&amp;quot;股权穿透&amp;quot;原则，不仅针对中国大陆企业，还包括境外中资控股机构，字节跳动海外版应用等典型客户首当其冲。&lt;/p&gt;
&lt;p&gt;深层原因在于Anthropic高管的意识形态背景。CEO达里奥·阿莫戴伊被解读为追求&amp;quot;更高道德标准&amp;quot;的革命者，其职业生涯从百度、谷歌到OpenAI，终创Anthropic，每次转型都为实现更高的AI安全和公益目标。更关键的是其家族成员：妹妹丹尼拉·阿莫戴伊曾在政界、Stripe、OpenAI积累经验，主导公共事务与对华战略，惯用&amp;quot;民主价值&amp;quot;&amp;ldquo;威权地区&amp;quot;叙事；妹夫霍尔顿·卡诺夫斯基创办&amp;quot;有效利他基金会&amp;rdquo;，将&amp;quot;失控AI&amp;quot;&amp;ldquo;中国AI公司&amp;quot;归为人类灭绝重大威胁，从哲学层面为政策构筑理论基础。&lt;/p&gt;
&lt;p&gt;商业层面，Claude编程AI被认为是当前顶尖代码生成模型，而全球中文程序员占开发者总量40%以上，中国是AI编程领域不可忽视的市场。中国厂商采取API兼容策略，将Kimi K2、千问-coder、Deepseek等国产模型接口仿真成Claude标准，开发者可零迁移直接替用，价格仅为1/10。更严峻的是模型蒸馏技术——中国AI公司通过调用Claude服务，将其数据和能力反哺国产模型。Anthropic缺乏流量入口，失去中国程序员后基本被挤出编程AI主战场，只能靠道德旗帜做&amp;quot;小而美&amp;rdquo;，但终局更可能是被收购或彻底消失。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;股权穿透原则&lt;/strong&gt;：Anthropic此次禁令的创新之处在于不限于企业注册地，而是追溯资本控制结构，凡中国资本控股超过50%的企业及其子公司，无论注册在何处，均在封禁之列。这一原则直指中国企业通过境外主体规避限制的做法，体现了比其他美国AI厂商更为激进和彻底的封堵策略。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型蒸馏&lt;/strong&gt;：指中国AI公司通过调用Claude等国际顶尖模型的服务，将其生成的数据、模式和创新能力用于训练和优化自己的模型，实现技术追赶甚至反超。Anthropic在声明中特别警惕这一技术，认为它使中国企业能够以较低成本快速缩短与国际领先模型的差距，这成为禁令的重要技术理由。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;API兼容策略&lt;/strong&gt;：中国厂商通过技术手段将国产大模型的API接口仿真成Claude等国际主流标准，使开发者可以无缝切换，无需修改代码即可从昂贵的国际模型转向价格仅1/10的国产模型。这一策略使中国AI企业在编程助手领域快速获得市场份额，严重动摇了Anthropic等国际厂商的商业基础。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有效利他主义&lt;/strong&gt;：由CEO妹夫霍尔顿·卡诺夫斯基倡导的哲学运动，主张理性评估如何最大化人类福祉，将&amp;quot;减少存在性风险&amp;quot;视为核心目标。在这一框架下，失控的AI和威权国家的AI发展被视为对人类生存的重大威胁，为Anthropic的对华政策提供了道德和哲学层面的正当性论证。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI安全主义&lt;/strong&gt;：以达里奥·阿莫戴伊及其家族成员为代表的价值理念，强调AI技术必须服务于民主价值和人类安全，反对将先进AI能力提供给&amp;quot;威权国家&amp;quot;。这一理念将技术问题高度意识形态化，把&amp;quot;价值观对立&amp;quot;置于商业利益之上，成为Anthropic区别于其他商业导向AI公司的核心特征。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=n7tWzKl5_sM"&gt;别只当成科技八卦Anthropic反华禁令背后的意识形态挂帅商商业求生&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;老范讲故事&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年9月&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>理解推理型大型语言模型的构建与优化</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/understanding-reasoning-llms-optimization/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/understanding-reasoning-llms-optimization/</guid><description>&lt;h1 id="理解推理型大型语言模型的构建与优化"&gt;理解推理型大型语言模型的构建与优化&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文由AI专家Sebastian Raschka撰写，系统介绍了推理型大型语言模型的核心概念与构建方法。文章详细分析了推理模型的定义、优势与劣势，并以DeepSeek R1为例，阐述了纯强化学习、监督微调、模型蒸馏等四种主要的训练优化方法。作者还探讨了低预算下开发推理模型的可行性，为研究者和开发者提供了实用的技术路线参考。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从LLM领域的发展趋势切入，指出2024年以来专门化应用方向的快速发展。推理模型作为一类能够通过多步中间步骤解决复杂任务的特殊模型，在数学证明、逻辑谜题和高级编程等场景中具有重要价值，但在简单任务中可能因&amp;quot;过度思考&amp;quot;而降低效率。&lt;/p&gt;
&lt;p&gt;DeepSeek R1系列模型作为典型案例，展示了三种不同的训练范式：R1-Zero采用纯强化学习，无需监督微调即可自动生成推理步骤；R1结合了监督微调与强化学习，引入一致性奖励机制；R1-Distill则通过模型蒸馏技术，将大型模型的推理能力迁移到较小的模型中。&lt;/p&gt;
&lt;p&gt;构建推理模型的四种主要方法各具特色：推理时扩展通过增加计算资源提高性能；纯强化学习展示了无需监督数据的可能性；监督微调结合强化学习能够充分发挥两者优势；模型蒸馏则在效率和成本方面具有显著优势。对于资源有限的开发者，Sky-T1和TinyZero等项目证明了低预算开发推理模型的可行性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;推理模型&lt;/strong&gt;：指需要通过复杂、多步生成中间步骤来回答问题的语言模型。这类模型能够解决需要逻辑推理的任务，如数学计算、编程挑战等，但在简单任务中可能导致效率低下和成本增加。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;纯强化学习&lt;/strong&gt;：DeepSeek R1-Zero证明了推理能力可以通过纯强化学习而无需监督微调来实现。模型通过准确性和格式奖励自动生成推理步骤，这为理解AI推理能力的本质提供了新的视角。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型蒸馏&lt;/strong&gt;：通过将大型模型生成的推理数据用于训练较小的模型，以提高推理能力。这种方法在效率和成本方面具有优势，使得资源有限的团队也能开发出性能可观的推理模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;推理时扩展&lt;/strong&gt;：通过增加推理时的计算资源来提高模型性能，包括链式思考提示、投票和搜索策略等。这种方法不需要重新训练模型，但会增加推理时间和成本。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;旅程学习&lt;/strong&gt;：一种新的训练策略，通过在训练数据中包含错误的解决方案路径，让模型从错误中学习。这种方法可能在低预算下开发推理模型时具有优势。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://magazine.sebastianraschka.com/p/understanding-reasoning-llms"&gt;Understanding Reasoning LLMs&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Sebastian Raschka, PhD&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>以DeepSeek R1为例学习推理型大语言模型</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/reasoning-llm-deepseek-r1-training-methods/</link><pubDate>Sat, 08 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/reasoning-llm-deepseek-r1-training-methods/</guid><description>&lt;h1 id="以deepseek-r1为例学习推理型大语言模型"&gt;以DeepSeek R1为例学习推理型大语言模型&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文以DeepSeek R1为核心案例，系统梳理了推理型大语言模型的概念、适用场景与优劣势。文章详细解读了DeepSeek R1三个版本（R1-Zero、R1、R1-Distill）的训练流程，归纳了构建推理模型的四种主要方法，并介绍了Sky-T1和TinyZero等低成本推理模型的探索实践，为研究者和开发者理解与构建推理模型提供了全面指引。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从推理型大语言模型的定义出发，指出其核心特征是能够通过多步推理回答复杂问题，区别于常规LLM在于包含中间推理步骤和&amp;quot;思考&amp;quot;过程。作者首先分析了推理模型的适用场景——主要针对解谜、高级数学和编程挑战等需要复杂中间推理的任务，同时也坦诚指出其资源消耗大、输出冗长和&amp;quot;过度思考&amp;quot;等局限。&lt;/p&gt;
&lt;p&gt;文章的核心内容围绕DeepSeek R1的训练流程展开，详细介绍了三个版本的演进路径：R1-Zero通过纯强化学习涌现推理能力，R1在此基础上叠加监督微调和多轮RL训练以获得更强性能，R1-Distill则通过蒸馏将能力迁移到更小模型。这一递进式的技术路线清晰展示了推理模型的构建逻辑。&lt;/p&gt;
&lt;p&gt;在方法论层面，文章系统归纳了推理阶段扩展、纯强化学习、监督微调+强化学习、纯监督微调与蒸馏四种主要构建路径，并对比了各自的适用场景和优劣。此外，文章还介绍了Sky-T1（450美元训练成本）和TinyZero（不到30美元）等低成本方案，展示了推理模型平民化的可能性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;推理型大语言模型（Reasoning LLMs）&lt;/strong&gt;：指能够通过多步推理回答复杂问题的模型，与常规LLM的关键区别在于包含中间推理步骤，展现出&amp;quot;思考&amp;quot;过程。这类模型主要适用于解谜、数学证明、代码生成等需要复杂推理链的任务，而对摘要、翻译等简单任务可能并无优势，甚至因&amp;quot;过度思考&amp;quot;而产生错误。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DeepSeek R1的三阶段训练流程&lt;/strong&gt;：R1-Zero基于671B参数的DeepSeek-V3通过纯RL训练，使用准确性奖励和格式奖励使模型涌现推理能力；R1在此基础上增加SFT和多轮RL，引入语言一致性奖励，性能显著提升；R1-Distill则利用R1生成的SFT数据微调Llama和Qwen等小模型，以更低成本获得推理能力。这三个版本体现了从探索到优化再到普及的技术路线。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;四种推理模型构建方法&lt;/strong&gt;：推理阶段扩展通过增加推理时计算资源提升输出质量，无需额外训练但增加推理成本；纯RL可涌现推理能力但性能有限，更适合理论研究；SFT+RL是性能最强的方案，DeepSeek R1即为典型代表；SFT+蒸馏适用于资源有限场景，通过大模型数据微调小模型实现能力迁移，但无法达到最前沿性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;强化学习中的奖励机制设计&lt;/strong&gt;：DeepSeek R1训练中采用了准确性奖励（如LeetCode编译器判定编程答案正确性）和格式奖励（LLM评估器判断回答格式），以及语言一致性奖励（防止模型在回答中切换语言）。这种多维度奖励设计是推理能力涌现和提升的关键，展示了RL在LLM训练中的精细化应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;低成本推理模型的可行性&lt;/strong&gt;：Sky-T1仅用1.7万条SFT数据和450美元训练出性能与o1相当的32B模型，TinyZero用不到30美元通过纯RL训练出3B参数的推理模型并展现出自我验证能力。这些探索表明，推理模型的构建门槛正在快速降低，为资源有限的研究者开辟了新路径。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/DG8-bENYNji8qg4SwexEmg"&gt;以DeepSeek R1为例学习推理型大语言模型&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;—&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-02-08&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>