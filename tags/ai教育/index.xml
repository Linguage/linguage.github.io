<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI教育 on Linguista</title><link>https://linguista.cn/tags/ai%E6%95%99%E8%82%B2/</link><description>Recent content in AI教育 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 18 Oct 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/ai%E6%95%99%E8%82%B2/index.xml" rel="self" type="application/rss+xml"/><item><title>Andrej Karpathy 论人工智能的下一个十年</title><link>https://linguista.cn/curated/henrinotes-2025_p2/andrej-karpathy-ai-next-decade-agents/</link><pubDate>Sat, 18 Oct 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/andrej-karpathy-ai-next-decade-agents/</guid><description>&lt;h1 id="andrej-karpathy-论人工智能的下一个十年"&gt;Andrej Karpathy 论人工智能的下一个十年&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文综合分析了著名人工智能专家 Andrej Karpathy 的核心观点，他基于在 AI 领域近二十年的经验，对当前的人工智能发展、未来趋势及社会影响提出了深刻而务实的见解。Karpathy 认为，实现功能完备的智能体需要十年而非一年，当前的模型在智能、多模态和持续学习等方面存在显著的认知缺陷。他将强化学习的奖励机制比作通过吸管吸取监督信号，效率低下且充满噪声，并指出依赖模型自身生成的数据训练会导致模型坍塌问题。在 AI 工程实践方面，他认为当前的编码智能体对于新颖、复杂的任务来说更像是残次品，其作用更接近于高级自动补全，而非真正的程序员替代品。他强调从演示到可靠产品的巨大鸿沟，预示着高风险领域的自动化将是一个漫长过程。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Karpathy 首先对行业内普遍存在的智能体之年过度乐观预测进行了校准，提出了智能体十年的说法。他详细分析了当前智能体无法被广泛应用的核心原因，包括智能水平不足、多模态能力有限、缺乏持续学习等关键瓶颈。这些缺陷使得目前的模型无法被雇佣为实习生，因为它们在实际工作场景中表现不可靠。&lt;/p&gt;
&lt;p&gt;在回顾 AI 范式演进时，Karpathy 分享了他亲身经历的数次地震式转变。他从深度学习的兴起谈起，以 AlexNet 的成功为标志，深度学习从少数人研究的小众领域转变为 AI 的主流。他反思了早期智能体探索中的一次失误，即 2013 年左右以 Atari 游戏为代表的深度强化学习热潮。他认为对游戏的过度关注是错误的路径，真正的智能体应能处理现实世界的知识工作。LLM 的成功揭示了必须首先通过大规模预训练获得强大的表征能力和语言基础，然后才能在其之上构建有效的智能体。&lt;/p&gt;
&lt;p&gt;关于 AI 与动物智能的辨析，Karpathy 指出动物是演化的产物，其大脑中集成了大量内置硬件，而 AI 是通过模仿人类在互联网上留下的数据进行训练的，更像是数字世界中的幽灵或灵魂。他将 LLM 的预训练过程比作一种蹩脚的演化，这是在当前技术条件下能够实现的、为智能体提供一个知识和能力起点的最实用方法。他提出了一个重要的研究方向，即设法剥离模型的知识和记忆，保留其纯粹的认知核心。&lt;/p&gt;
&lt;p&gt;在深入剖析 LLM 的内部工作方式及其根本性限制时，Karpathy 指出模型表现出的智能在很大程度上依赖于其上下文窗口。上下文窗口中的信息就像人类的工作记忆，模型可以非常直接地访问，而存储在模型权重中的知识更像是对互联网文档的模糊回忆。他直言强化学习是糟糕的，并将 RL 的奖励机制比作通过吸管吸取监督信号，这种方法噪声极大。让模型通过反思来学习面临着模型坍塌的风险，模型生成的任何内容其分布都是悄然坍塌的，看似合理但缺乏多样性和熵。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;智能体十年&lt;/strong&gt;：Karpathy 提出这一概念旨在对行业内过度乐观的时间表进行校准。他认为虽然当前出现了一些令人印象深刻的早期智能体，但要实现真正可靠、能像人类实习生或员工一样工作的智能体，仍有大量艰巨工作尚待完成。这一预测基于他在 AI 领域近二十年的从业经验和直觉，他认为当前面临的问题虽然棘手且困难，但可以解决，综合来看十年是一个比较合理的时间框架。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表征能力&lt;/strong&gt;：这是 LLM 成功的关键所在，也是构建有效智能体的先决条件。早期在游戏环境中过度依赖强化学习之所以是一次失误，正是因为当时的神经网络缺乏强大的表征能力，导致智能体在稀疏奖励的环境中无法有效学习，只会燃烧森林般的计算资源。必须首先通过大规模预训练获得强大的表征能力和语言基础，然后才能在其之上构建有效的智能体。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型坍塌&lt;/strong&gt;：这是指当持续用模型自身生成的数据进行训练时，模型会变得越来越糟，最终完全丧失能力。模型生成的任何内容其分布都是悄然坍塌的，它们看似合理，但缺乏多样性和熵，仅仅占据了所有可能输出中的一个极小流形。人类通过与他人交流等方式不断寻求外部熵来避免类似的思想固化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;九的进军&lt;/strong&gt;：Karpathy 用这一概念来形容将 AI 技术从演示转化为产品的难度。产品化的过程是九的进军，即实现 90% 的可靠性只是第一步，之后每提升一个数量级都需要付出同等甚至更多的努力。自动驾驶从 1980 年代就有演示，但至今仍未完全实现，这揭示了巨大的演示到产品差距，尤其是在安全攸关的领域。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;知识坡道&lt;/strong&gt;：这是 Karpathy 在其教育项目 Eureka 中核心理念的一部分。教育的核心是技术性的，即为复杂的知识构建平滑的学习路径，确保学习者在任何时候都面临恰到好处的挑战，既不感到无聊也不感到挫败。他追求的是最大化学习者每秒钟获得的顿悟感，这要求教学内容经过精心设计，从最简单的第一性原理出发，逐步引入复杂性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://twitter.com/karpathy"&gt;Andrej Karpathy on AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Andrej Karpathy&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>GoogleX首席科学家谈冒名顶替综合症、职业成长与项目品味</title><link>https://linguista.cn/curated/henrinotes_2025_p3/googlex-carey-nachenberg-imposter-syndrome-career-growth/</link><pubDate>Sun, 17 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/googlex-carey-nachenberg-imposter-syndrome-career-growth/</guid><description>&lt;h1 id="googlex首席科学家谈冒名顶替综合症职业成长与项目品味"&gt;GoogleX首席科学家谈冒名顶替综合症、职业成长与项目品味&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本期访谈深入探讨了一位技术领袖的职业成长历程。Carey Nachenberg从实习生成长为Symantec Fellow，再到GoogleX首席科学家和UCLA教授，分享了他的真实经历与反思。访谈重点讨论了冒名顶替综合症对职业发展的影响、高阶工程师的晋升机制、项目品味的重要性，以及AI时代工程师能力模型的演变。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;访谈围绕Carey Nachenberg的多重身份展开，他在Symantec担任了20余年Fellow级别工程师，后加入GoogleX参与网络安全项目，同时还在UCLA任教。这种技术、管理、教育三重身份的独特视角，为访谈提供了丰富的讨论维度。&lt;/p&gt;
&lt;p&gt;Carey坦诚地分享了自己的职业心路历程，特别是冒名顶替综合症如何影响他长达十余年的职业选择。尽管在Symantec已达到最高技术级别，但他始终担心自己的成就仅因长期在同一家公司积累，害怕无法胜任其他大厂的工作。这种心理导致他在成长停滞后仍未离开舒适区，直到外部机会主动找上门才尝试改变。&lt;/p&gt;
&lt;p&gt;访谈的核心议题包括高阶IC的晋升机制、项目品味的培养、沟通协作与影响力的重要性，以及AI对学生学习的冲击。Carey强调，技术能力只是基础，真正的职业成功需要影响力、沟通协作、业务结果导向和项目品味等软技能。他观察到许多智商极高的工程师因缺乏这些能力而晋升缓慢。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;冒名顶替综合症&lt;/strong&gt;：尽管在Symantec获得Fellow级别的高度认可，Carey始终担心自己的成就只是因长期在同一公司积累，害怕换到Google、Meta等大厂后无法胜任。这种心理导致他在不再快乐、成长停滞的情况下仍迟迟未离开。突破的关键在于勇于跳出舒适区，实际能力往往超出自我设限。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;项目品味&lt;/strong&gt;：指识别公司真正需要但无人涉足的难题的能力。Carey的晋升并非靠接手更大项目，而是主动发现公司的&amp;quot;空白地带&amp;quot;，承担高影响力项目。优秀的工程师要能站在公司和团队角度思考，关注最重要的业务结果，而非只满足个人兴趣或技术挑战。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;影响力与沟通协作&lt;/strong&gt;：晋升到高阶IC后，单靠技术能力已远远不够。Carey在GoogleX观察到极聪明但晋升缓慢的工程师，原因在于沟通不畅、项目选择脱离业务需求、缺乏团队协作。高阶工程师必须具备卓越的沟通、协作和影响力，能推动团队共识、协调多方资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以学生为中心的教学理念&lt;/strong&gt;：Carey在UCLA的教学强调同理心和知识可达性，课程设计以&amp;quot;30-50百分位学生&amp;quot;为基准，力求让大多数学生都能理解核心概念。他曾允许学生在项目中使用AI工具，但发现这反而削弱了学生的独立思考和动手能力，未来将限制AI的使用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI时代的工程师能力模型&lt;/strong&gt;：未来AI可自动完成大部分编码工作，工程师需转向&amp;quot;定义问题、理解用户、澄清需求、沟通协作&amp;quot;等软技能。懂得如何与AI协作、如何定义和衡量业务结果，将成为核心竞争力。Carey强调，持续成长和自我反思至关重要，一旦发现停滞或不再快乐，应及时调整。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch"&gt;GoogleX Chief Scientist On Imposter Syndrome, Career Growth, Project Taste | Carey Nachenberg&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Ryan Peterman&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年7月18日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>