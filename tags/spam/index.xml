<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Spam on Linguista</title><link>https://linguista.cn/tags/spam/</link><description>Recent content in Spam on Linguista</description><generator>Hugo</generator><language>zh-cn</language><atom:link href="https://linguista.cn/tags/spam/index.xml" rel="self" type="application/rss+xml"/><item><title>A Plan for Spam</title><link>https://linguista.cn/paul_graham/essays_en/spam/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://linguista.cn/paul_graham/essays_en/spam/</guid><description>&lt;p&gt;→ &lt;a href="https://linguista.cn/paul_graham/essays_zh/spam/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://www.paulgraham.com/spam.html"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://www.paulgraham.com/spam.html"
 target="_blank"
 rel="noopener"
 &gt;
 https://www.paulgraham.com/spam.html
 &lt;/a&gt;
&lt;/div&gt;

&lt;h1 id="a-plan-for-spam"&gt;A Plan for Spam&lt;/h1&gt;
&lt;p&gt;August 2002&lt;/p&gt;
&lt;p&gt;(This article describes the spam-filtering techniques used in the spamproof web-based mail reader we built to exercise Arc. An improved algorithm is described in Better Bayesian Filtering.)&lt;/p&gt;
&lt;p&gt;I think it&amp;rsquo;s possible to stop spam, and that content-based filters are the way to do it. The Achilles heel of the spammers is their message. They can circumvent any other barrier you set up. They have so far, at least. But they have to deliver their message, whatever it is. If we can write software that recognizes their messages, there is no way they can get around that.&lt;/p&gt;</description></item><item><title>Better Bayesian Filtering</title><link>https://linguista.cn/paul_graham/essays_en/better/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://linguista.cn/paul_graham/essays_en/better/</guid><description>&lt;p&gt;→ &lt;a href="https://linguista.cn/paul_graham/essays_zh/better/"&gt;中文版本&lt;/a&gt;&lt;/p&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://www.paulgraham.com/better.html"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://www.paulgraham.com/better.html"
 target="_blank"
 rel="noopener"
 &gt;
 https://www.paulgraham.com/better.html
 &lt;/a&gt;
&lt;/div&gt;

&lt;h1 id="better-bayesian-filtering"&gt;Better Bayesian Filtering&lt;/h1&gt;
&lt;p&gt;January 2003&lt;/p&gt;
&lt;p&gt;(This article was given as a talk at the 2003 Spam Conference. It describes the work I&amp;rsquo;ve done to improve the performance of the algorithm described in A Plan for Spam, and what I plan to do in the future.)&lt;/p&gt;
&lt;p&gt;The first discovery I&amp;rsquo;d like to present here is an algorithm for lazy evaluation of research papers. Just write whatever you want and don&amp;rsquo;t cite any previous work, and indignant readers will send you references to all the papers you should have cited. I discovered this algorithm after &amp;ldquo;A Plan for Spam&amp;rdquo; [1] was on Slashdot.&lt;/p&gt;</description></item></channel></rss>