<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>通用人工智能 on Linguista</title><link>https://linguista.cn/tags/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</link><description>Recent content in 通用人工智能 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Mon, 14 Jul 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml" rel="self" type="application/rss+xml"/><item><title>AI的过去与未来 - 规模化时代、未来展望与人类角色</title><link>https://linguista.cn/rosetta/chat-notes/ai-scaling-era-past-future-human-role/</link><pubDate>Mon, 14 Jul 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/ai-scaling-era-past-future-human-role/</guid><description>&lt;h1 id="ai的过去与未来---规模化时代未来展望与人类角色"&gt;AI的过去与未来 - 规模化时代、未来展望与人类角色&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;EconTalk主持人Russ Roberts与《规模化时代》合著者Dwarkesh Patel深度对话，探讨2019至2025年间AI发展的核心驱动力——算力与数据的指数级增长，分析Transformer架构与规模化的内在关联，讨论AI当前能力边界与常识推理局限，并就通用人工智能路径、蜂巢思维构想及AI对人类生活意义的深远影响展开思辨。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/l8PLdeCO850?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="AI的过去与未来 - 规模化时代、未来展望与人类角色"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;规模化(Scaling)&lt;/strong&gt;：指通过指数级增长的算力和数据投入来提升AI模型性能的核心策略，是2019至2025年AI突破的主要驱动力，算力投入约以每年四倍的速度增长&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Moravec悖论&lt;/strong&gt;：机器人学者Hans Moravec提出的观察，即对人类困难的抽象任务对AI相对容易，而人类凭直觉完成的感知和常识任务对AI异常困难，揭示了当前AI能力的结构性局限&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;蜂巢思维(Hive Mind)&lt;/strong&gt;：Patel提出的未来AI图景，非单一超级智能，而是数十亿AI个体以超人速度思考、高效通信、任意复制合并所形成的集体智能，其优势源于数字生命的协同能力&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;推理扩展(Inference Scaling)&lt;/strong&gt;：让模型在推理阶段投入更多计算时间以提升输出质量的技术方向，被视为预训练扩展边际递减后的新前沿&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;跨人类主义(Transhumanism)&lt;/strong&gt;：人类利用技术增强自身能力、开启新体验维度的理念，Patel将其视为人类适应AI时代的一种可能路径&lt;/p&gt;
&lt;h2 id="简报ai的规模化浪潮算力驱动下的飞跃与未解之谜"&gt;「简报」AI的“规模化”浪潮：算力驱动下的飞跃与未解之谜&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;在人工智能领域，一场由计算能力指数级增长驱动的变革正在重塑技术格局，但其底层原理的神秘面纱仍未完全揭开，引发了关于未来机遇与深刻社会影响的激烈讨论。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;近年来，人工智能（AI）取得了令人瞩目的进展，从大型语言模型（LLM）如ChatGPT的惊艳亮相，到不断涌现的新能力，公众和业界的目光往往聚焦于算法的创新。然而，播客作者、与Gavin Leech合著《规模化时代：人工智能口述史 2019-2025》的Dwarkesh Patel在与EconTalk主持人Russ Roberts的深度对话中指出，一个更根本、或许被低估的趋势是过去六年（2019-2025）的主旋律——“规模化”（Scaling）。&lt;/p&gt;
&lt;p&gt;Patel认为，近期AI突破的真正基石，在于计算能力（Compute）和数据量的爆炸式增长。他提到，AI领域的算力投入大约以每年翻两番 ($4 \times$) 的速度增长，投资规模从十年前的学术爱好飙升至如今的数千亿美元级别。这种规模的扩张并非线性，模型性能的代际飞跃，如从GPT-2到GPT-3，再到GPT-4，往往伴随着大约百倍 ($100 \times$) 的算力投入增加。&lt;/p&gt;
&lt;p&gt;“这就像一个进化过程，”Patel解释道，“有了更多的算力进行实验，你才能尝试不同的想法，才能发现为什么像Transformer这样的架构比之前的更好。”Transformer架构由谷歌研究人员在2018年左右提出，其关键优势在于易于在大型GPU集群上并行训练，这使其极度契合“规模化”的需求。将其与简单的“预测下一个词”训练目标相结合，产生了出乎意料的智能涌现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;进展背后的经验主义与认知鸿沟&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;尽管成果斐然，AI研究者们，包括构建这些复杂系统的顶尖科学家，对于规模化为何有效的根本原因仍缺乏令人满意的理论解释。Patel引用了Anthropic公司CEO Dario Amodei的坦诚之言：“事实是，我们仍然不知道。这几乎完全只是一个偶然的经验事实。”这种状况凸显了当前AI发展在很大程度上依赖于经验性的试错和扩展，而非完全的理论指导——投入更多算力、更多数据，观察会发生什么。&lt;/p&gt;
&lt;p&gt;这种“黑箱”特性也体现在AI能力的矛盾表现上。当前的LLM可以在某些认知任务（如前沿数学、编程）上表现出色，但在看似更简单的常识推理和与物理世界交互的能力上却步履蹒跚。Patel指出了所谓的“计算机使用”难题：模型难以可靠地执行需要多步骤、与外部系统交互的现实任务，如预订航班或组织活动。这呼应了Hans Moravec早在数十年前提出的悖论：对人类来说困难的抽象任务对AI相对容易，而人类凭直觉就能完成的感知、运动和常识性任务，对AI来说却异常困难。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;“蜂巢思维”与未来的不确定性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;展望未来，Patel对单一超级智能（ASI）通过纯粹思考解决所有问题的设想表示怀疑。他更倾向于一种“蜂巢思维”（Hive Mind）的图景：数十亿个AI以超人速度思考、高效通信、任意复制和合并，形成一种前所未有的集体智能。这种集体优势并非源于个体IQ的无限拔高，而是数字生命特有的协同能力，可能带来指数级的经济增长和知识积累，但也可能引发关于控制权和中心化风险的担忧。&lt;/p&gt;
&lt;p&gt;在讨论通用人工智能（AGI）的路径时，Patel预测，首个AGI可能效率低下、成本高昂（他形象地比喻为“耗资相当于蒙大拿州的基础设施”），依赖于如“推理扩展”（让模型思考更长时间以提升性能）等技巧。其最终目标是达到或超越人脑约20瓦 ($20$ W)的能效水平，但这将是一个漫长的过程。&lt;/p&gt;</description></item><item><title>如果你无法编程实现它，你就没有理解它</title><link>https://linguista.cn/naval/zh/if-you-cant-program-it-you-havent-understood-it.zh/</link><pubDate>Wed, 10 Nov 2021 18:36:16 +0000</pubDate><guid>https://linguista.cn/naval/zh/if-you-cant-program-it-you-havent-understood-it.zh/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/orig/if-you-cant-program-it-you-havent-understood-it/"&gt;原文(English)&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/program"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/program"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/program
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="如果你无法编程实现它你就没有理解它"&gt;如果你无法编程实现它，你就没有理解它&lt;/h1&gt;
&lt;p&gt;2021年11月10日&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;布雷特：&lt;br&gt;
这些都是不确定的假设，但我们也必须记住，关于自然选择进化论，我们还有很多不了解的地方。&lt;/p&gt;
&lt;p&gt;大卫·多伊奇有句名言，&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;如果你无法编程实现它，你就没有理解它。&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在通用人工智能的情况下，这意味着我们无法编程实现它，因为我们不理解通用智能这个概念。&lt;/p&gt;
&lt;p&gt;自然选择进化论也是如此。有一种叫做&lt;strong&gt;进化算法&lt;/strong&gt;的东西，但这并不是对自然选择进化进行编程。这并不能在计算机中创建人工实体，使其在受到实际环境压力时能够朝着日益复杂的方向进化。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;进化算法无法产生生命体&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;获取播客&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apple&lt;/li&gt;
&lt;li&gt;Google&lt;/li&gt;
&lt;li&gt;Overcast&lt;/li&gt;
&lt;li&gt;Spotify&lt;/li&gt;
&lt;li&gt;YouTube&lt;/li&gt;
&lt;li&gt;下载&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;0:42&lt;/p&gt;</description></item><item><title>更多计算能力并不会产生通用人工智能</title><link>https://linguista.cn/naval/zh/more-compute-power-doesnt-produce-agi.zh/</link><pubDate>Wed, 27 Oct 2021 19:28:41 +0000</pubDate><guid>https://linguista.cn/naval/zh/more-compute-power-doesnt-produce-agi.zh/</guid><description>&lt;p&gt;&lt;a href="https://linguista.cn/naval/orig/more-compute-power-doesnt-produce-agi/"&gt;原文(English)&lt;/a&gt;&lt;/p&gt;
&lt;div class="grid grid-cols-2 gap-4 md:grid-cols-2"&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://nav.al/agi"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://nav.al/agi"
 target="_blank"
 rel="noopener"
 &gt;
 https://nav.al/agi
 &lt;/a&gt;
&lt;/div&gt;

&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://x.com/naval/status/1002103360646823936"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://x.com/naval/status/1002103360646823936"
 target="_blank"
 rel="noopener"
 &gt;
 https://x.com/naval/status/1002103360646823936
 &lt;/a&gt;
&lt;/div&gt;

&lt;/div&gt;
&lt;h1 id="更多计算能力并不会产生通用人工智能"&gt;更多计算能力并不会产生通用人工智能&lt;/h1&gt;
&lt;p&gt;2021年10月27日&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;即使最强大的计算机也无法回答&amp;quot;为什么？&amp;quot;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Naval:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通用人工智能团队也完全搞错了：&amp;ldquo;只要增加更多计算能力，你就能获得智能&amp;rdquo;，而我们并不知道是什么底层机制让我们具有创造力，并能够提出好的解释。&lt;/p&gt;
&lt;p&gt;人们经常谈论&lt;strong&gt;GPT-3&lt;/strong&gt;，这是&lt;strong&gt;OpenAI&lt;/strong&gt;推出的文本匹配引擎，是一个非常令人印象深刻的软件。他们说：&amp;ldquo;嘿，我可以用GPT-3生成很棒的推文。&amp;ldquo;这是因为，首先，作为人类，你从它生成的所有垃圾中挑选出好的推文。其次，它使用某种抄袭和同义词匹配等的组合来产生听起来合理的内容。&lt;/p&gt;
&lt;p&gt;最容易看出它生成的内容实际上没有任何意义的方法是问它一个后续问题。拿一个GPT-3生成的输出，问它：&amp;ldquo;为什么会这样？&amp;ldquo;或者基于此做出预测，然后看着它完全崩溃，因为没有底层的解释。&lt;/p&gt;
&lt;p&gt;它是在模仿。这是出色的贝叶斯推理。它从网络上人类已经生成的内容中进行推断，但它没有能够用未见的来解释已见的现实底层模型。我认为这很关键。&lt;/p&gt;
&lt;p&gt;这是人类独特的能力，没有其他生物、没有其他计算机、没有我们遇到过的任何其他智能——无论是生物的还是人工的——能做到这一点。&lt;/p&gt;
&lt;p&gt;而且不仅我们是唯一能做到这一点的，如果我们遇到一个也有能力产生这些好解释的外星物种，他们产生的任何解释我们都能理解。&lt;/p&gt;
&lt;p&gt;我们的理解能力是最大化的。在这个物理现实中，不存在人类在给予足够时间、资源和教育的情况下无法理解的概念。&lt;/p&gt;</description></item></channel></rss>