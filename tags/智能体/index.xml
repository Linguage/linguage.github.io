<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>智能体 on Linguista</title><link>https://linguista.cn/tags/%E6%99%BA%E8%83%BD%E4%BD%93/</link><description>Recent content in 智能体 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 18 Oct 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%99%BA%E8%83%BD%E4%BD%93/index.xml" rel="self" type="application/rss+xml"/><item><title>Andrej Karpathy 论人工智能的下一个十年</title><link>https://linguista.cn/curated/henrinotes-2025_p2/andrej-karpathy-ai-next-decade-agents/</link><pubDate>Sat, 18 Oct 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/andrej-karpathy-ai-next-decade-agents/</guid><description>&lt;h1 id="andrej-karpathy-论人工智能的下一个十年"&gt;Andrej Karpathy 论人工智能的下一个十年&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文综合分析了著名人工智能专家 Andrej Karpathy 的核心观点，他基于在 AI 领域近二十年的经验，对当前的人工智能发展、未来趋势及社会影响提出了深刻而务实的见解。Karpathy 认为，实现功能完备的智能体需要十年而非一年，当前的模型在智能、多模态和持续学习等方面存在显著的认知缺陷。他将强化学习的奖励机制比作通过吸管吸取监督信号，效率低下且充满噪声，并指出依赖模型自身生成的数据训练会导致模型坍塌问题。在 AI 工程实践方面，他认为当前的编码智能体对于新颖、复杂的任务来说更像是残次品，其作用更接近于高级自动补全，而非真正的程序员替代品。他强调从演示到可靠产品的巨大鸿沟，预示着高风险领域的自动化将是一个漫长过程。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Karpathy 首先对行业内普遍存在的智能体之年过度乐观预测进行了校准，提出了智能体十年的说法。他详细分析了当前智能体无法被广泛应用的核心原因，包括智能水平不足、多模态能力有限、缺乏持续学习等关键瓶颈。这些缺陷使得目前的模型无法被雇佣为实习生，因为它们在实际工作场景中表现不可靠。&lt;/p&gt;
&lt;p&gt;在回顾 AI 范式演进时，Karpathy 分享了他亲身经历的数次地震式转变。他从深度学习的兴起谈起，以 AlexNet 的成功为标志，深度学习从少数人研究的小众领域转变为 AI 的主流。他反思了早期智能体探索中的一次失误，即 2013 年左右以 Atari 游戏为代表的深度强化学习热潮。他认为对游戏的过度关注是错误的路径，真正的智能体应能处理现实世界的知识工作。LLM 的成功揭示了必须首先通过大规模预训练获得强大的表征能力和语言基础，然后才能在其之上构建有效的智能体。&lt;/p&gt;
&lt;p&gt;关于 AI 与动物智能的辨析，Karpathy 指出动物是演化的产物，其大脑中集成了大量内置硬件，而 AI 是通过模仿人类在互联网上留下的数据进行训练的，更像是数字世界中的幽灵或灵魂。他将 LLM 的预训练过程比作一种蹩脚的演化，这是在当前技术条件下能够实现的、为智能体提供一个知识和能力起点的最实用方法。他提出了一个重要的研究方向，即设法剥离模型的知识和记忆，保留其纯粹的认知核心。&lt;/p&gt;
&lt;p&gt;在深入剖析 LLM 的内部工作方式及其根本性限制时，Karpathy 指出模型表现出的智能在很大程度上依赖于其上下文窗口。上下文窗口中的信息就像人类的工作记忆，模型可以非常直接地访问，而存储在模型权重中的知识更像是对互联网文档的模糊回忆。他直言强化学习是糟糕的，并将 RL 的奖励机制比作通过吸管吸取监督信号，这种方法噪声极大。让模型通过反思来学习面临着模型坍塌的风险，模型生成的任何内容其分布都是悄然坍塌的，看似合理但缺乏多样性和熵。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;智能体十年&lt;/strong&gt;：Karpathy 提出这一概念旨在对行业内过度乐观的时间表进行校准。他认为虽然当前出现了一些令人印象深刻的早期智能体，但要实现真正可靠、能像人类实习生或员工一样工作的智能体，仍有大量艰巨工作尚待完成。这一预测基于他在 AI 领域近二十年的从业经验和直觉，他认为当前面临的问题虽然棘手且困难，但可以解决，综合来看十年是一个比较合理的时间框架。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表征能力&lt;/strong&gt;：这是 LLM 成功的关键所在，也是构建有效智能体的先决条件。早期在游戏环境中过度依赖强化学习之所以是一次失误，正是因为当时的神经网络缺乏强大的表征能力，导致智能体在稀疏奖励的环境中无法有效学习，只会燃烧森林般的计算资源。必须首先通过大规模预训练获得强大的表征能力和语言基础，然后才能在其之上构建有效的智能体。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型坍塌&lt;/strong&gt;：这是指当持续用模型自身生成的数据进行训练时，模型会变得越来越糟，最终完全丧失能力。模型生成的任何内容其分布都是悄然坍塌的，它们看似合理，但缺乏多样性和熵，仅仅占据了所有可能输出中的一个极小流形。人类通过与他人交流等方式不断寻求外部熵来避免类似的思想固化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;九的进军&lt;/strong&gt;：Karpathy 用这一概念来形容将 AI 技术从演示转化为产品的难度。产品化的过程是九的进军，即实现 90% 的可靠性只是第一步，之后每提升一个数量级都需要付出同等甚至更多的努力。自动驾驶从 1980 年代就有演示，但至今仍未完全实现，这揭示了巨大的演示到产品差距，尤其是在安全攸关的领域。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;知识坡道&lt;/strong&gt;：这是 Karpathy 在其教育项目 Eureka 中核心理念的一部分。教育的核心是技术性的，即为复杂的知识构建平滑的学习路径，确保学习者在任何时候都面临恰到好处的挑战，既不感到无聊也不感到挫败。他追求的是最大化学习者每秒钟获得的顿悟感，这要求教学内容经过精心设计，从最简单的第一性原理出发，逐步引入复杂性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://twitter.com/karpathy"&gt;Andrej Karpathy on AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Andrej Karpathy&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>超越提示词的艺术：AI 编程的未来是“上下文工程”</title><link>https://linguista.cn/static/context_engineering_cursor/</link><pubDate>Thu, 09 Oct 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/context_engineering_cursor/</guid><description>随着 AI 编程工具如 Cursor 的崛起，软件开发范式正在经历从“提示词工程”到“上下文工程”的根本性转变。文章深入探讨了如何通过构建“字面精确”与“语义相关”的双层检索框架，将代码库转化为 AI 的“记忆宫殿”，使智能体能够从被动补全进化为具备自主分析与决策能力的协作伙伴。开发者不再仅仅是代码的书写者，更晋升为定义上下文环境的认知架构师。</description></item><item><title>Cursor 团队上下文工程与编程智能体演变</title><link>https://linguista.cn/curated/henrinotes-2025-p1/cursor-context-engineering-coding-agents/</link><pubDate>Thu, 09 Oct 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/cursor-context-engineering-coding-agents/</guid><description>&lt;h1 id="cursor-团队上下文工程与编程智能体演变"&gt;Cursor 团队上下文工程与编程智能体演变&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文记录了 Cursor 团队成员 Lee 与 CEO Michael 关于上下文工程与 AI 编程智能体发展的深度对话。内容涵盖编程工具从打孔卡到 AI 智能体的历史演进，Cursor 产品从 Tab 代码补全到自主编程智能体的技术迭代，以及上下文检索优化、多智能体并行管理、人机协作安全机制等核心实践。文章提出上下文工程是提示工程的升级，强调最小化高质量 token 输入与语义检索的重要性，并展望了软件工程彻底自动化的未来愿景。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本文首先梳理了编程工具的发展历程，从 1960 年代打孔卡、早期终端，到 1970 年代 Apple II，1980 年代 GUI，再到 1990、2000 年代的 Front Page、Dreamweaver、Visual Studio 和 Sublime Text 等 IDE。这一演进史显示，每次技术迭代都通过提升 UI/UX 推动更高层次目标的实现。而 AI 技术正在加速重演这一过程，使编程前所未有的易用和强大。&lt;/p&gt;
&lt;p&gt;接着，文章详细介绍了 Cursor 产品演化。Tab 功能起初仅预测下一个单词或一行代码，现在能预测鼠标光标动作。每日 4 亿次请求产生的数据，通过实时在线强化学习优化模型，用户接受或拒绝的建议在 30 分钟内即可反馈更新。团队从通用模型转向专门为&amp;quot;下一步行动预测&amp;quot;训练的自定义模型，在速度与质量间找到平衡点。&lt;/p&gt;
&lt;p&gt;在智能体架构方面，Cursor 从简单补全进化到自主编程智能体，支持工具调用、自主上下文获取。用户可通过 Composer 功能实现多文件编辑与会话式管理。2024 年推出的完全自主编码智能体不再依赖人工提供全部上下文，而是模型自我检索构建上下文。&lt;/p&gt;
&lt;p&gt;上下文工程实践部分强调，随着上下文窗口变大，模型信息回忆质量反而下降，因此目标是使用尽可能少且高质量的 token。团队通过自动索引、创建 embedding 实现语义检索，从通用 embedding 模型迁移到自定向训练模型，通过 AB 测试验证性能提升。语义搜索不仅提升用户追问率，还带来更高的 token 使用量。&lt;/p&gt;
&lt;p&gt;多智能体协作方面，Cursor 探索了从 CLI 到专业智能体如 Bugbot 的发展。智能体长周期任务能力增强，支持规划、前置研究、任务列表管理与工作流打包分享。人机协作保持人类在环机制，关键操作需用户授权，支持自定义 hooks 与团队协作防护。&lt;/p&gt;</description></item><item><title>OpenAI姚顺雨六年Agent研究与智能系统边界全解读</title><link>https://linguista.cn/curated/henrinotes-2025_p2/openai-yaoshunyu-six-years-agent-research/</link><pubDate>Fri, 19 Sep 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/openai-yaoshunyu-six-years-agent-research/</guid><description>&lt;h1 id="openai姚顺雨六年agent研究与智能系统边界全解读"&gt;OpenAI姚顺雨六年Agent研究与智能系统边界全解读&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文基于对OpenAI研究员姚顺雨的三小时深度访谈，系统梳理了他六年来在智能体领域的研究历程。文章从个人成长经历谈到Agent研究的起点，分享了人工智能主线程转向下半场的洞见。姚顺雨围绕&amp;quot;人与系统&amp;quot;&amp;ldquo;智能的边界&amp;quot;&amp;ldquo;单极与多元世界&amp;quot;等核心议题展开讨论，提出人类与机器交互的新范式和心智模型，为正在形成的多元AI世界建立认知框架。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;访谈开篇，姚顺雨回顾了自己人生前28年的成长轨迹——从清华到普林斯顿博士，再到OpenAI早期工作。他坦言自己虽然表面&amp;quot;乖&amp;rdquo;，但始终保有&amp;quot;非共识&amp;quot;的独立思考，立志投身Agent研究。这段经历塑造了他&amp;quot;简单、现实、环境导向&amp;quot;的研究风格，也让他意识到&amp;quot;语言是人类实现泛化的本质工具&amp;quot;这一核心洞见。&lt;/p&gt;
&lt;p&gt;在系统定义与Agent演化部分，姚顺雨给出了Agent的经典定义：&amp;ldquo;能自主决策、与环境交互、追求奖励最优化的系统&amp;rdquo;。他梳理了智能体发展的三波浪潮——从早期符号主义到深度强化学习，再到当前以大模型为特征的第三波浪潮。更重要的是，他强调不应将&amp;quot;方法论&amp;quot;与&amp;quot;任务环境&amp;quot;割裂，二者是并行演化、长期依存的关系。他指出Agent前行的两个主方向：一是&amp;quot;自我奖励&amp;rdquo;，即Agent需拥有自主探索和反馈机制；二是&amp;quot;多智能体系统&amp;quot;，强调多个Agent能协作、博弈、组织，演化出更高阶的智能结构。&lt;/p&gt;
&lt;p&gt;关于AI平台与未来形态，姚顺雨提出了发人深省的观点。他认为初创公司的最大机会在于设计全新的交互方式，而非简单延伸现有产品线。&amp;ldquo;Super App&amp;quot;的兴起既是机遇也是陷阱——平台优势往往带来路径依赖，反而限制创新。他抛出一个开放性课题：能否跳脱&amp;quot;像人&amp;quot;的交互范式，创造出全新的人机交互模式？他引用冯·诺依曼《The Computer and the Brain》中的观点，强调&amp;quot;环境在记忆体系中永远是最外层&amp;rdquo;，这一洞见涉及AI、哲学与认知科学的深刻交叉。&lt;/p&gt;
&lt;p&gt;最后，姚顺雨探讨了人类融入系统的新选择。他提出&amp;quot;Agent到底需不需要像人&amp;quot;不是单一答案的命题，而是一个&amp;quot;效用问题&amp;quot;——需根据任务和目标灵活选择。OpenAI的bottom-up文化鼓励不同方向的探索和创新，只有差异化投入才能超越前浪。他用&amp;quot;如果有500亿美金分配到AGI行业&amp;quot;的假设推演，说明了多元路径的必要性。在快速演化的AI时代，他建议选择高上限的研究方向，鼓励&amp;quot;做最有挑战的事&amp;quot;。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Agent演化的双重线索&lt;/strong&gt;：姚顺雨将Agent的演化视为&amp;quot;方法&amp;quot;与&amp;quot;任务/环境&amp;quot;两条线索的交错前行。真正可泛化的智能体必须既关注模型能力升级（如大模型能力进化），又不断创新环境与任务的设定（如自动生成任务、环境模拟等）。这个框架建议Agent系统不仅追求单点性能突破，更要强调在人类现实世界多样环境下的广泛适应性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;代码作为Affordance&lt;/strong&gt;：代码是AI最重要的&amp;quot;affordance&amp;quot;（环境给予行动者的可能性）。如同人的&amp;quot;手&amp;quot;，代码赋予Agent操控外部世界的基础能力。这个概念揭示了为何代码能力成为大模型竞争的关键——它不是简单的技能，而是Agent与世界交互的根本媒介。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;效用原则与人机边界&lt;/strong&gt;：姚顺雨提出理解Agent需从&amp;quot;效用&amp;quot;角度出发，根据目标、环境、用途灵活选择拟人化和去人化路径。对于通用应用（如Assistant/Her），类人是直觉选择。但未来必定有部分Agent采用冷启动、异构组织和功能前置，打破人机同构的惯性。这是一个实用的决策框架，避免陷入&amp;quot;像人&amp;quot;或&amp;quot;不像人&amp;quot;的二元争论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自我奖励机制&lt;/strong&gt;：Agent需拥有自主探索世界和反馈机制，而不能完全依赖人为设置目标。这个概念指向AGI的关键突破点——如何让AI系统在没有明确人类指令的情况下，依然能够生成有意义的探索方向和学习目标。这是从&amp;quot;执行者&amp;quot;到&amp;quot;自主探索者&amp;quot;的质变。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;差异化下注策略&lt;/strong&gt;：在不确定性极高的前沿领域，姚顺雨提倡多方向下注，在团队、公司、行业中持续探索联动，分散风险、聚合创新。只有借助&amp;quot;差异化下注&amp;quot;与多元文化氛围，才有机会诞生突破性成果。这个策略不仅适用于公司运营，也贯穿个人学术和产业布局决策。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=gQgKkUsx5q0"&gt;115. 对OpenAI姚顺雨3小时访谈：6年Agent研究、人与系统、吞噬的边界、既单极又多元的世界&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;张小珺&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-09-19&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>