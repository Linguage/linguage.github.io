<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>世界模型 on Linguista</title><link>https://linguista.cn/tags/%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 世界模型 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 03 Oct 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>Yann LeCun自监督学习与世界模型：AI未来的深度解析</title><link>https://linguista.cn/curated/henrinotes-2025-p1/yann-lecun-self-supervised-learning-world-models/</link><pubDate>Fri, 03 Oct 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/yann-lecun-self-supervised-learning-world-models/</guid><description>&lt;h1 id="yann-lecun自监督学习与世界模型ai未来的深度解析"&gt;Yann LeCun自监督学习与世界模型：AI未来的深度解析&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文基于Yann LeCun在哈佛CMSA的讲座内容，系统梳理了其对当前AI技术瓶颈的分析及未来发展方向的主张。LeCun指出，尽管大语言模型在文本处理上表现突出，但在物理世界理解、常识推理和复杂规划方面仍远逊于人类甚至动物。他提出通过自监督学习、联合嵌入预测架构（JEPA）和世界模型来突破这些限制，强调AI需要从纯文本驱动转向多模态真实世界信号学习，并构建能够进行分层规划和零样本推理的认知架构。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;LeCun首先剖析了当前AI技术的核心局限。大语言模型虽然在特定任务上超越人类表现，但在日常通用智能方面——如灵巧操作、复杂推理与长期规划——仍无法与人类儿童或动物相比。人类和动物能够在极少数据下展现出惊人学习效率，这得益于他们与生俱来的世界模型和自监督学习能力。相比之下，当前主流的监督学习需要巨量标注数据，强化学习在复杂场景下效率极低，而文本驱动的自回归生成架构容易产生幻觉且缺乏全局规划能力。&lt;/p&gt;
&lt;p&gt;针对这些瓶颈，LeCun提出了基于JEPA和能量函数的新范式。传统生成模型试图直接预测未来的每个像素，这在高维连续信号面前几乎不可能，因为未来充满不确定性，简单的平均预测会导致模糊失真。JEPA的核心创新在于，它只在抽象表征空间中预测未来状态，将感知输入和输出都编码为低维表征，从而规避了高维输出的不可控问题。配合能量函数，系统能够灵活表达输入输出间的兼容性，通过优化搜索找到最佳匹配的预测结果，这种方式天然支持零样本推理，类似人类的理性决策过程。&lt;/p&gt;
&lt;p&gt;在实现路径上，LeCun强调需要构建分层的世界模型和规划系统。人类在规划复杂任务时采用分层策略，从宏观目标逐步分解到具体操作，这要求AI具备高度解耦、可组合的抽象表征。目前基于DINO等自监督学习方法已经在构建通用表征方面取得进展，而新一代视频理解模型甚至能自动检测物理不可能事件，显示出基本的常识推理能力。LeCun团队开发的机器人世界模型能够在未知环境下自主规划行动序列达成目标，展现出从纯文本AI向具备物理世界理解能力的通用智能进化的可能性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;自监督学习&lt;/strong&gt;：这是LeCun认为未来AI突破的关键技术方向。与需要大量标注数据的监督学习不同，自监督学习让系统通过主动感知世界、发现其中的结构和关联来学习，更接近人类和动物的学习方式。当前技术路线主要包括对比学习和正则化方法，后者通过限制低能量分布体积来避免表征空间坍缩。实验表明，用自监督学习预训练的表征进行下游任务微调，性能已全面超越传统监督学习。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JEPA（联合嵌入预测架构）&lt;/strong&gt;：这是LeCun提出的解决AI推理极限的核心架构。传统生成模型在像素空间直接预测未来几乎不可能，因为高维连续信号充满不确定性。JEPA的突破在于，它只在抽象表征空间中预测未来状态，将输入输出都编码为低维表征后再进行推理比较，一举规避了高维输出的不可控和模糊问题。配合能量函数，JEPA能够通过全局优化完成复杂推理，天然支持零样本迁移。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：这是人类和动物能够进行常识推理和高效规划的基础。婴儿很早就理解了物体的持存、支持、坠落等物理规则，建立起能够预测动作后果的世界模型。AI要达到类似的通用智能，也需要构建分层的世界模型——用多层抽象来理解现实，每一层屏蔽细节、聚焦对预测最有用的信息。科学的本质就是在寻找这些能用于预测的高效表征，而AI的发展同样需要这样的分层建模能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能量函数&lt;/strong&gt;：这是JEPA框架中用于衡量输入输出兼容性的关键机制。给定输入，能量函数能够评估怎样的输出才是合理的，搜索输出的过程就变成了找使能量最低的输出。这种方式类似于人类的理性推理过程，能够支持零样本推理和更复杂的动态规划，比传统的单向预测或分类器更加灵活和强大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分层规划&lt;/strong&gt;：这是人类处理复杂任务的高效策略，也是AI需要具备的能力。人类计划从纽约去巴黎时，不是一步步规划到每个动作细节，而是先定宏观目标，再逐级分解到具体操作。AI要做到类似的分层规划，需要拥有高度解耦、可组合的抽象表征，不同层次捕捉不同时间尺度和抽象程度的信息。目前这个问题在AI领域仍未完全解决，但已有研究开始探索如何让AI自主发现有用的抽象层次。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=yUmDRxV0krg"&gt;Yann LeCun | Self-Supervised Learning, JEPA, World Models, and the future of AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Yann LeCun&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;主办方&lt;/td&gt;
 &lt;td&gt;Harvard CMSA&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Demis Hassabis专访 从游戏AI到世界模型 AGI进化的真实路径</title><link>https://linguista.cn/curated/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</guid><description>&lt;h1 id="demis-hassabis专访从游戏ai到世界模型agi进化的真实路径"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Google DeepMind CEO Demis Hassabis在《Release Notes》播客中系统梳理了从游戏AI到思考型模型、世界模型的技术演进。他分享了DeepMind如何通过Genie 3等项目推动AI理解现实世界，阐述了&amp;quot;多模态+工具+系统&amp;quot;的AGI路径，并介绍了以Kaggle Game Arena为代表的新型AI评测体系。Demis强调，未来AI不仅要能感知和输出，更要具备深度思考、世界理解和自我进化能力。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次访谈围绕DeepMind的技术演进路径展开，首先梳理了从AlphaGo、AlphaZero等游戏AI到&amp;quot;思考型模型&amp;quot;的发展脉络。Demis指出，DeepMind近期发布节奏极快，几乎每天都有新突破，包括Deep Think、IMO金牌、Genie 3等。这种&amp;quot;agent+思考&amp;quot;范式被认为是迈向AGI的必经之路，AI不仅要能做出第一个反应，更要能反复自我修正和优化思路。&lt;/p&gt;
&lt;p&gt;核心技术突破集中在Genie 3与世界模型方向。所谓世界模型，就是AI不仅理解语言和数学，还能理解物理世界的结构、规律、材料、流体、生命体等。Genie 3的突破在于保证了&amp;quot;世界一致性&amp;quot;——比如你离开房间再回来，物体还在原位。这种物理一致性是AI理解现实的关键标志，已被用于训练SIMA等游戏智能体，实现&amp;quot;AI在AI生成世界中自主探索&amp;quot;。&lt;/p&gt;
&lt;p&gt;在AI评测方面，传统评测如AIME数学题已接近饱和，Deep Think已达99.2%。Demis认为需要更难、更广、更真实的评测体系。Kaggle Game Arena采用&amp;quot;AI对AI竞技&amp;quot;思路，通过多样化游戏自动生成难度和评分，避免传统题库泄题、过拟合等问题。游戏作为评测场景具有客观可量化、自动扩展难度、可引入多智能体挑战等优势。&lt;/p&gt;
&lt;p&gt;关于AI产品化，Demis指出AI正从&amp;quot;单一大模型&amp;quot;向&amp;quot;系统化&amp;quot;演进，未来AI产品将是&amp;quot;模型+工具+系统&amp;quot;的组合。产品化挑战在于AI能力进化极快，产品设计需&amp;quot;可插拔&amp;quot;，能随时替换底层引擎。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;omni model&amp;quot;（全能模型），实现&amp;quot;一个模型做所有事&amp;quot;。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型（World Model）&lt;/strong&gt;：AI必须理解物理世界的结构、规律和一致性，才能实现通用智能和现实应用。这不仅包括语言和数学，还包括物理、材料、流体、生命体等现实世界要素。世界模型是AI&amp;quot;走出屏幕&amp;quot;、在现实中自主行动的前提。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考型模型（Thinking Models）&lt;/strong&gt;：从游戏AI演化而来的一条主线，强调AI不仅要感知和输出，还能自主规划、推理和决策。类似人类的深度思考过程，AI需要&amp;quot;反复自我修正和优化思路&amp;quot;，而不仅仅是做出第一个反应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统化AI（From Model to System）&lt;/strong&gt;：未来AI产品将由&amp;quot;模型+工具+系统&amp;quot;组成，能力边界动态扩展。模型不仅能推理，还能调用外部工具（如搜索、代码、物理模拟器等），实现更强的复合能力。部分能力应内置于主模型，部分则以外部工具形式存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;新型评测体系（Game Arena）&lt;/strong&gt;：AI能力评测需覆盖推理、物理智能、多目标权衡、安全性等多维度。Kaggle Game Arena通过&amp;quot;AI对AI竞技&amp;quot;自动生成难度，避免传统题库泄题和过拟合问题，推动AI能力全面进化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Omni Model愿景&lt;/strong&gt;：未来AGI是多模态、全能型模型，能在语言、视觉、物理、推理等各领域均衡表现。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;一个模型做所有事&amp;quot;的全能智能体。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=njDochQ2zHs&amp;amp;list=WL&amp;amp;index=5"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Google for Developers&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>马斯克终止Dojo项目与Genie3世界模型发布的技术转向</title><link>https://linguista.cn/curated/henrinotes_2025_p3/tesla-dojo-cancellation-genie3-world-model/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/tesla-dojo-cancellation-genie3-world-model/</guid><description>&lt;h1 id="马斯克终止dojo项目与genie3世界模型发布的技术转向"&gt;马斯克终止Dojo项目与Genie3世界模型发布的技术转向&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文深入剖析了AI领域的两大标志性事件：特斯拉突然终止投入数十亿美元的自研超算项目Dojo，转而采购英伟达算力资源；谷歌DeepMind发布世界模型Genie 3，开启虚拟环境自我探索的新范式。文章从战略转型、技术路线分野、产业格局变化等维度，探讨了AI从大语言模型向世界模型演进的趋势，以及这一转变对AGI发展的深远影响。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本期讨论聚焦AI发展的关键转折点。特斯拉Dojo项目的终止标志着马斯克&amp;quot;全栈自研&amp;quot;战略的重大调整。面对英伟达芯片迭代速度的碾压性优势——约4倍的技术代差——特斯拉选择放弃自研芯片，转向与英伟达、三星等供应商合作。这一决策投入巨大，损失数十亿美元，被比喻为&amp;quot;中年男人丢了一个肾&amp;quot;。股市反应平静，投资者认为此举有助于特斯拉聚焦核心业务、提升资源利用效率。特斯拉机器人项目也受影响，原定量产计划延后，AI架构从&amp;quot;端到端&amp;quot;一体化转向&amp;quot;预训练与推理分离&amp;quot;的新模式。&lt;/p&gt;
&lt;p&gt;技术路线上，大语言模型已显疲态。GPT-5等模型性能提升微弱，各家产品差距缩小，预训练能力触及天花板。真正的突破来自世界模型。DeepMind的Genie 3通过无监督学习在虚拟环境中自我探索，无需人工标注，可生成连续一致的3D场景，支持长时间物理模拟。这为机器人、智能体提供了无限丰富的虚拟训练场地，大幅降低真实世界训练成本。&lt;/p&gt;
&lt;p&gt;产业层面，数据驱动与物理定律驱动两大路线将走向融合。英伟达布局Cosmo等物理世界模型，为工业应用提供高精度仿真；谷歌Genie 3更偏向教学与模拟场景。AI军备竞赛带动算力需求激增，台积电、英伟达成为最大受益者。政府订单成为AI基础设施建设的最大客户，中美两国通过不同方式推动AI产业发展。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：通过无监督学习在虚拟环境中自我探索、学习的AI范式，类似AlphaZero自悟棋艺，无需人类标签或数据。Genie 3作为代表，能生成连续一致的3D虚拟世界，支持长时间物理模拟，每帧回算保证物理一致性。与大语言模型形成互补——LLM擅长抽象、总结、压缩信息，适合做&amp;quot;智能体的大脑&amp;quot;；世界模型负责感知、模拟物理世界，提升具身智能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预训练与推理分离&lt;/strong&gt;：AI架构从&amp;quot;端到端&amp;quot;一体化转向分工协作的新模式。预训练模型（大脑）负责抽象、总结等高层认知任务；推理模型（端侧）负责实时感知与决策。特斯拉的战略调整正是这一趋势的体现，采购成熟算力资源进行预训练，自研硬件专注端侧推理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据驱动vs物理定律驱动&lt;/strong&gt;：AI发展的两大技术路线。数据驱动模型（如Genie 3）易于规模化扩展，智能化程度高，但工业严谨性不足；物理定律模型（如数字孪生、仿真）精度高但扩展性受限。未来趋势是两者融合，形成&amp;quot;数据驱动+物理定律&amp;quot;的混合架构，既保证规模化能力，又满足工业精度要求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术代差与战略聚焦&lt;/strong&gt;：特斯拉终止Dojo项目的核心原因是与英伟达之间存在约4倍的技术代差。当技术变革速度极快，组织难以跟上时，及时止损、聚焦核心业务成为理性选择。这一&amp;quot;聚焦核心、外包非核心&amp;quot;的战略框架，适用于快速变化的行业环境。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;政府订单驱动&lt;/strong&gt;：AI产业初期发展的最大动力来自政府基础设施建设。中国政府主导安防产业，美国政府依托大企业推动超算中心。政府订单成为AI算力的最大客户，带动台积电、英伟达等供应链企业增长。短期内，算力供给方占据优势；长期看，市场将趋于多元化，难以形成绝对垄断。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=KE9ZWk4QGL0"&gt;马斯克挥泪砍Dojo，Genie 3宣告世界模型到来｜是AI进化停滞，还是AGI路线的终极拐点？&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;人民公园说AI&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>大型语言模型与世界模型以奥赛罗游戏为例的探讨</title><link>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-othello-case/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-othello-case/</guid><description>&lt;h1 id="大型语言模型与世界模型以奥赛罗游戏为例的探讨"&gt;大型语言模型与世界模型：以奥赛罗游戏为例的探讨&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文通过奥赛罗游戏（Othello）的经典案例，深入探讨大型语言模型是否能够通过训练数据自发形成对世界的抽象模型。研究者训练了名为OthelloGPT的Transformer网络，通过探针技术分析其内部激活，发现该模型确实编码了棋盘状态信息。然而，关于这种编码是否构成真正的&amp;quot;世界模型&amp;quot;仍存在争议，文章进一步分析了线性与非线性探针的对比结果，以及对人类与机器模型构建方式的思考。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以奥赛罗游戏为实验平台，介绍了OthelloGPT的训练过程：该模型在2000万种合法棋步序列上进行训练，仅学习棋步合法性而无关策略优劣，训练后在预测合法棋步上达到近乎完美的表现。研究者通过&amp;quot;探针&amp;quot;技术——一种用于解码Transformer内部激活的分类器——来分析模型是否形成了世界模型。&lt;/p&gt;
&lt;p&gt;实验过程中出现了有趣的转折：最初的线性探针无法有效预测棋盘状态，而非线性探针虽能达到98%的准确率，却可能归功于探针本身的能力而非Transformer的编码。Neel Nanda等研究者通过调整探针分类方式，将分类从&amp;quot;黑、白、空&amp;quot;改为&amp;quot;我的、你的、空&amp;quot;，使线性探针在第7层激活上的准确率提升至99.5%，这为OthelloGPT确实编码了棋盘状态提供了有力证据。&lt;/p&gt;
&lt;p&gt;然而，高准确率的探针结果并不等同于&amp;quot;世界模型&amp;quot;的存在。文章指出，OthelloGPT的内部表示更像是一个&amp;quot;启发式规则集&amp;quot;——某些神经元的激活代表非常具体的规则，这些规则能产生正确预测但缺乏抽象性和泛化能力。真正的世界模型应该具有连贯性和抽象性，能够应对未曾见过的情境。&lt;/p&gt;
&lt;p&gt;文章最后从认知科学角度对比了人类与机器的模型构建方式。人类受到工作记忆、处理速度和能量限制的约束，这些限制迫使我们形成更抽象、更具泛化的内部模型。机器可能也需要类似的限制和挑战，才能形成真正抽象的模型，从而更好地泛化到新情境中。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：指智能体内部形成的对外部世界的抽象表征，它不仅仅是对输入-输出模式的记忆，而是对世界运作方式的理解和模拟。真正的世界模型具有抽象性和泛化能力，能够处理未曾遇到的情况。在OthelloGPT的案例中，尽管模型编码了棋盘状态，但这是否构成真正的世界模型仍存争议。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;探针技术&lt;/strong&gt;：一种用于分析神经网络内部表征的技术，通过训练分类器来预测网络内部激活所编码的信息。线性探针简单直接，能够揭示网络本身的编码能力；非线性探针功能更强大，但可能掩盖网络的真实编码情况，因其自身具有强大的信息提取能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启发式规则集&lt;/strong&gt;：与抽象的世界模型相对，指由大量具体规则组成的知识表示方式。在OthelloGPT中，某些神经元可能编码了非常具体的规则（如&amp;quot;当某个位置被占据时采取某种行动&amp;quot;），这些规则能产生正确预测，但缺乏抽象性和泛化能力，无法应对规则之外的情况。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;认知限制与抽象化&lt;/strong&gt;：人类在构建模型时受到工作记忆容量、处理速度和能量消耗等限制，这些限制反而促使我们形成更抽象、更具泛化的内部模型。这为AI研究提供了启示：或许需要给机器模型添加类似的限制，促使其发展出真正的抽象理解能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表征与理解的区别&lt;/strong&gt;：神经网络能够表征信息（如OthelloGPT编码了棋盘状态），并不等同于它理解了这些信息背后的因果关系和抽象结构。这是当前AI研究面临的核心挑战之一——如何让模型从数据记忆走向真正的理解。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://aiguide.substack.com/p/llms-and-world-models-part-2"&gt;LLMs and World Models, Part 2&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;AI Guide&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未标注&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>大型语言模型与世界模型第一部分LLMs如何理解它们的世界</title><link>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-part-1/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-part-1/</guid><description>&lt;h1 id="大型语言模型与世界模型第一部分llms-如何理解它们的世界"&gt;大型语言模型与世界模型（第一部分）：LLMs 如何理解它们的&amp;quot;世界&amp;quot;&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文由 Melanie Mitchell 撰写，深入探讨了大型语言模型（LLMs）是否发展出了类似人类的&amp;quot;世界模型&amp;quot;以理解其运作的&amp;quot;世界&amp;quot;。文章回顾了早期机器学习系统的脆弱性问题，介绍了世界模型的概念定义与分类方法，并围绕 LLMs 是否真正具备世界模型能力展开了学术界的重要辩论。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先通过多个经典案例揭示了早期 AI 系统的根本局限性——它们依赖于训练数据中的启发式规则和表面特征，而非真正的概念理解。从皮肤病变分类错误地依赖尺子存在，到语言模型仅凭词汇重叠判断逻辑关系，再到强化学习系统在游戏设置微小变化下的性能崩溃，这些案例都指向同一个问题：缺乏对世界因果结构的理解。&lt;/p&gt;
&lt;p&gt;接着文章转向当前备受争议的话题——大型语言模型是否突破了这一局限。OpenAI 联合创始人 Ilya Sutskever 认为，通过预测下一个词的训练目标，LLMs 确实学习了世界的压缩表征，包括人类的情感和动机。然而，包括 Yann LeCun 在内的多位研究者对此表示强烈怀疑，认为仅靠语言训练无法达到真正的理解。2022 年的一项调查显示，NLP 研究者群体在这一问题上几乎呈现对半分的分裂态势。&lt;/p&gt;
&lt;p&gt;为了厘清这一辩论，文章详细梳理了&amp;quot;世界模型&amp;quot;的多种定义。从最基础的内部表征到保留因果结构的复杂模型，再到能够支持反事实推理的完整模拟器。MIT 教授 Jacob Andreas 提出了一个清晰的分类框架，从静态查找表、地图、机械天体仪到完整的模拟器，每种类型代表了对世界理解的不同深度。人类正是通过这样的世界模型，才能快速理解复杂场景、预测因果关系并规划行动。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：指智能体内部形成的、对外部世界的压缩且可模拟的表征，它不仅能够存储信息，还能捕捉世界的因果结构，支持预测、规划和回答反事实问题。人类的世界模型使我们能够在瞬间理解街景照片中的复杂场景，推断行为者的意图和可能的后续发展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启发式规则与表面特征&lt;/strong&gt;：早期机器学习系统依赖的捷径思维，它们通过发现训练数据中的统计关联来解决问题，但这种方式缺乏真正的理解。就像皮肤病变分类器记住&amp;quot;尺子=恶性&amp;quot;这样的关联，当环境变化时就会失效，因为系统并不理解尺子和病变之间的真实关系。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;情境模型&lt;/strong&gt;：LLMs 可能具备的一种中间层次世界模型，能够跟踪文本中的行为者、状态和动作变化。这类似于一个机械天体仪，可以模拟特定场景中的动态过程，但可能缺乏对更广泛世界因果知识的整合。目前尚不清楚 LLMs 的情境模型能否推广到训练数据之外的全新场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因果模拟模型&lt;/strong&gt;：世界模型的最高层次，能够回答复杂的&amp;quot;如果-那么&amp;quot;类型反事实问题，需要对世界的深层因果结构有精确理解。目前缺乏证据表明 LLMs 具备这种能力，这是判断它们是否真正&amp;quot;理解&amp;quot;世界的关键检验标准。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://aiguide.substack.com/p/llms-and-world-models-part-1"&gt;LLMs and World Models, Part 1 - How do Large Language Models Make Sense of Their &amp;ldquo;Worlds&amp;rdquo;?&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Melanie Mitchell&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未明确说明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>