<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>世界模型 on Linguista</title><link>https://linguista.cn/tags/%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 世界模型 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 03 Oct 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E4%B8%96%E7%95%8C%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>Yann LeCun自监督学习与世界模型：AI未来的深度解析</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/yann-lecun-self-supervised-learning-world-models/</link><pubDate>Fri, 03 Oct 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025-p1/yann-lecun-self-supervised-learning-world-models/</guid><description>&lt;h1 id="yann-lecun自监督学习与世界模型ai未来的深度解析"&gt;Yann LeCun自监督学习与世界模型：AI未来的深度解析&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文基于Yann LeCun在哈佛CMSA的讲座内容，系统梳理了其对当前AI技术瓶颈的分析及未来发展方向的主张。LeCun指出，尽管大语言模型在文本处理上表现突出，但在物理世界理解、常识推理和复杂规划方面仍远逊于人类甚至动物。他提出通过自监督学习、联合嵌入预测架构（JEPA）和世界模型来突破这些限制，强调AI需要从纯文本驱动转向多模态真实世界信号学习，并构建能够进行分层规划和零样本推理的认知架构。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;LeCun首先剖析了当前AI技术的核心局限。大语言模型虽然在特定任务上超越人类表现，但在日常通用智能方面——如灵巧操作、复杂推理与长期规划——仍无法与人类儿童或动物相比。人类和动物能够在极少数据下展现出惊人学习效率，这得益于他们与生俱来的世界模型和自监督学习能力。相比之下，当前主流的监督学习需要巨量标注数据，强化学习在复杂场景下效率极低，而文本驱动的自回归生成架构容易产生幻觉且缺乏全局规划能力。&lt;/p&gt;
&lt;p&gt;针对这些瓶颈，LeCun提出了基于JEPA和能量函数的新范式。传统生成模型试图直接预测未来的每个像素，这在高维连续信号面前几乎不可能，因为未来充满不确定性，简单的平均预测会导致模糊失真。JEPA的核心创新在于，它只在抽象表征空间中预测未来状态，将感知输入和输出都编码为低维表征，从而规避了高维输出的不可控问题。配合能量函数，系统能够灵活表达输入输出间的兼容性，通过优化搜索找到最佳匹配的预测结果，这种方式天然支持零样本推理，类似人类的理性决策过程。&lt;/p&gt;
&lt;p&gt;在实现路径上，LeCun强调需要构建分层的世界模型和规划系统。人类在规划复杂任务时采用分层策略，从宏观目标逐步分解到具体操作，这要求AI具备高度解耦、可组合的抽象表征。目前基于DINO等自监督学习方法已经在构建通用表征方面取得进展，而新一代视频理解模型甚至能自动检测物理不可能事件，显示出基本的常识推理能力。LeCun团队开发的机器人世界模型能够在未知环境下自主规划行动序列达成目标，展现出从纯文本AI向具备物理世界理解能力的通用智能进化的可能性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;自监督学习&lt;/strong&gt;：这是LeCun认为未来AI突破的关键技术方向。与需要大量标注数据的监督学习不同，自监督学习让系统通过主动感知世界、发现其中的结构和关联来学习，更接近人类和动物的学习方式。当前技术路线主要包括对比学习和正则化方法，后者通过限制低能量分布体积来避免表征空间坍缩。实验表明，用自监督学习预训练的表征进行下游任务微调，性能已全面超越传统监督学习。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JEPA（联合嵌入预测架构）&lt;/strong&gt;：这是LeCun提出的解决AI推理极限的核心架构。传统生成模型在像素空间直接预测未来几乎不可能，因为高维连续信号充满不确定性。JEPA的突破在于，它只在抽象表征空间中预测未来状态，将输入输出都编码为低维表征后再进行推理比较，一举规避了高维输出的不可控和模糊问题。配合能量函数，JEPA能够通过全局优化完成复杂推理，天然支持零样本迁移。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：这是人类和动物能够进行常识推理和高效规划的基础。婴儿很早就理解了物体的持存、支持、坠落等物理规则，建立起能够预测动作后果的世界模型。AI要达到类似的通用智能，也需要构建分层的世界模型——用多层抽象来理解现实，每一层屏蔽细节、聚焦对预测最有用的信息。科学的本质就是在寻找这些能用于预测的高效表征，而AI的发展同样需要这样的分层建模能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能量函数&lt;/strong&gt;：这是JEPA框架中用于衡量输入输出兼容性的关键机制。给定输入，能量函数能够评估怎样的输出才是合理的，搜索输出的过程就变成了找使能量最低的输出。这种方式类似于人类的理性推理过程，能够支持零样本推理和更复杂的动态规划，比传统的单向预测或分类器更加灵活和强大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分层规划&lt;/strong&gt;：这是人类处理复杂任务的高效策略，也是AI需要具备的能力。人类计划从纽约去巴黎时，不是一步步规划到每个动作细节，而是先定宏观目标，再逐级分解到具体操作。AI要做到类似的分层规划，需要拥有高度解耦、可组合的抽象表征，不同层次捕捉不同时间尺度和抽象程度的信息。目前这个问题在AI领域仍未完全解决，但已有研究开始探索如何让AI自主发现有用的抽象层次。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=yUmDRxV0krg"&gt;Yann LeCun | Self-Supervised Learning, JEPA, World Models, and the future of AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Yann LeCun&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;主办方&lt;/td&gt;
 &lt;td&gt;Harvard CMSA&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Demis Hassabis专访 从游戏AI到世界模型 AGI进化的真实路径</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/demis-hassabis-agi-world-model-thinking-models/</guid><description>&lt;h1 id="demis-hassabis专访从游戏ai到世界模型agi进化的真实路径"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Google DeepMind CEO Demis Hassabis在《Release Notes》播客中系统梳理了从游戏AI到思考型模型、世界模型的技术演进。他分享了DeepMind如何通过Genie 3等项目推动AI理解现实世界，阐述了&amp;quot;多模态+工具+系统&amp;quot;的AGI路径，并介绍了以Kaggle Game Arena为代表的新型AI评测体系。Demis强调，未来AI不仅要能感知和输出，更要具备深度思考、世界理解和自我进化能力。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次访谈围绕DeepMind的技术演进路径展开，首先梳理了从AlphaGo、AlphaZero等游戏AI到&amp;quot;思考型模型&amp;quot;的发展脉络。Demis指出，DeepMind近期发布节奏极快，几乎每天都有新突破，包括Deep Think、IMO金牌、Genie 3等。这种&amp;quot;agent+思考&amp;quot;范式被认为是迈向AGI的必经之路，AI不仅要能做出第一个反应，更要能反复自我修正和优化思路。&lt;/p&gt;
&lt;p&gt;核心技术突破集中在Genie 3与世界模型方向。所谓世界模型，就是AI不仅理解语言和数学，还能理解物理世界的结构、规律、材料、流体、生命体等。Genie 3的突破在于保证了&amp;quot;世界一致性&amp;quot;——比如你离开房间再回来，物体还在原位。这种物理一致性是AI理解现实的关键标志，已被用于训练SIMA等游戏智能体，实现&amp;quot;AI在AI生成世界中自主探索&amp;quot;。&lt;/p&gt;
&lt;p&gt;在AI评测方面，传统评测如AIME数学题已接近饱和，Deep Think已达99.2%。Demis认为需要更难、更广、更真实的评测体系。Kaggle Game Arena采用&amp;quot;AI对AI竞技&amp;quot;思路，通过多样化游戏自动生成难度和评分，避免传统题库泄题、过拟合等问题。游戏作为评测场景具有客观可量化、自动扩展难度、可引入多智能体挑战等优势。&lt;/p&gt;
&lt;p&gt;关于AI产品化，Demis指出AI正从&amp;quot;单一大模型&amp;quot;向&amp;quot;系统化&amp;quot;演进，未来AI产品将是&amp;quot;模型+工具+系统&amp;quot;的组合。产品化挑战在于AI能力进化极快，产品设计需&amp;quot;可插拔&amp;quot;，能随时替换底层引擎。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;omni model&amp;quot;（全能模型），实现&amp;quot;一个模型做所有事&amp;quot;。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型（World Model）&lt;/strong&gt;：AI必须理解物理世界的结构、规律和一致性，才能实现通用智能和现实应用。这不仅包括语言和数学，还包括物理、材料、流体、生命体等现实世界要素。世界模型是AI&amp;quot;走出屏幕&amp;quot;、在现实中自主行动的前提。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思考型模型（Thinking Models）&lt;/strong&gt;：从游戏AI演化而来的一条主线，强调AI不仅要感知和输出，还能自主规划、推理和决策。类似人类的深度思考过程，AI需要&amp;quot;反复自我修正和优化思路&amp;quot;，而不仅仅是做出第一个反应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统化AI（From Model to System）&lt;/strong&gt;：未来AI产品将由&amp;quot;模型+工具+系统&amp;quot;组成，能力边界动态扩展。模型不仅能推理，还能调用外部工具（如搜索、代码、物理模拟器等），实现更强的复合能力。部分能力应内置于主模型，部分则以外部工具形式存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;新型评测体系（Game Arena）&lt;/strong&gt;：AI能力评测需覆盖推理、物理智能、多目标权衡、安全性等多维度。Kaggle Game Arena通过&amp;quot;AI对AI竞技&amp;quot;自动生成难度，避免传统题库泄题和过拟合问题，推动AI能力全面进化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Omni Model愿景&lt;/strong&gt;：未来AGI是多模态、全能型模型，能在语言、视觉、物理、推理等各领域均衡表现。DeepMind正推动Genie、Veo、Gemini等多条技术线融合，目标是打造&amp;quot;一个模型做所有事&amp;quot;的全能智能体。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=njDochQ2zHs&amp;amp;list=WL&amp;amp;index=5"&gt;Demis Hassabis专访：从游戏AI到世界模型，AGI进化的真实路径&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Google for Developers&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>马斯克终止Dojo项目与Genie3世界模型发布的技术转向</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/tesla-dojo-cancellation-genie3-world-model/</link><pubDate>Thu, 14 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/tesla-dojo-cancellation-genie3-world-model/</guid><description>&lt;h1 id="马斯克终止dojo项目与genie3世界模型发布的技术转向"&gt;马斯克终止Dojo项目与Genie3世界模型发布的技术转向&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文深入剖析了AI领域的两大标志性事件：特斯拉突然终止投入数十亿美元的自研超算项目Dojo，转而采购英伟达算力资源；谷歌DeepMind发布世界模型Genie 3，开启虚拟环境自我探索的新范式。文章从战略转型、技术路线分野、产业格局变化等维度，探讨了AI从大语言模型向世界模型演进的趋势，以及这一转变对AGI发展的深远影响。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本期讨论聚焦AI发展的关键转折点。特斯拉Dojo项目的终止标志着马斯克&amp;quot;全栈自研&amp;quot;战略的重大调整。面对英伟达芯片迭代速度的碾压性优势——约4倍的技术代差——特斯拉选择放弃自研芯片，转向与英伟达、三星等供应商合作。这一决策投入巨大，损失数十亿美元，被比喻为&amp;quot;中年男人丢了一个肾&amp;quot;。股市反应平静，投资者认为此举有助于特斯拉聚焦核心业务、提升资源利用效率。特斯拉机器人项目也受影响，原定量产计划延后，AI架构从&amp;quot;端到端&amp;quot;一体化转向&amp;quot;预训练与推理分离&amp;quot;的新模式。&lt;/p&gt;
&lt;p&gt;技术路线上，大语言模型已显疲态。GPT-5等模型性能提升微弱，各家产品差距缩小，预训练能力触及天花板。真正的突破来自世界模型。DeepMind的Genie 3通过无监督学习在虚拟环境中自我探索，无需人工标注，可生成连续一致的3D场景，支持长时间物理模拟。这为机器人、智能体提供了无限丰富的虚拟训练场地，大幅降低真实世界训练成本。&lt;/p&gt;
&lt;p&gt;产业层面，数据驱动与物理定律驱动两大路线将走向融合。英伟达布局Cosmo等物理世界模型，为工业应用提供高精度仿真；谷歌Genie 3更偏向教学与模拟场景。AI军备竞赛带动算力需求激增，台积电、英伟达成为最大受益者。政府订单成为AI基础设施建设的最大客户，中美两国通过不同方式推动AI产业发展。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：通过无监督学习在虚拟环境中自我探索、学习的AI范式，类似AlphaZero自悟棋艺，无需人类标签或数据。Genie 3作为代表，能生成连续一致的3D虚拟世界，支持长时间物理模拟，每帧回算保证物理一致性。与大语言模型形成互补——LLM擅长抽象、总结、压缩信息，适合做&amp;quot;智能体的大脑&amp;quot;；世界模型负责感知、模拟物理世界，提升具身智能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预训练与推理分离&lt;/strong&gt;：AI架构从&amp;quot;端到端&amp;quot;一体化转向分工协作的新模式。预训练模型（大脑）负责抽象、总结等高层认知任务；推理模型（端侧）负责实时感知与决策。特斯拉的战略调整正是这一趋势的体现，采购成熟算力资源进行预训练，自研硬件专注端侧推理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据驱动vs物理定律驱动&lt;/strong&gt;：AI发展的两大技术路线。数据驱动模型（如Genie 3）易于规模化扩展，智能化程度高，但工业严谨性不足；物理定律模型（如数字孪生、仿真）精度高但扩展性受限。未来趋势是两者融合，形成&amp;quot;数据驱动+物理定律&amp;quot;的混合架构，既保证规模化能力，又满足工业精度要求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术代差与战略聚焦&lt;/strong&gt;：特斯拉终止Dojo项目的核心原因是与英伟达之间存在约4倍的技术代差。当技术变革速度极快，组织难以跟上时，及时止损、聚焦核心业务成为理性选择。这一&amp;quot;聚焦核心、外包非核心&amp;quot;的战略框架，适用于快速变化的行业环境。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;政府订单驱动&lt;/strong&gt;：AI产业初期发展的最大动力来自政府基础设施建设。中国政府主导安防产业，美国政府依托大企业推动超算中心。政府订单成为AI算力的最大客户，带动台积电、英伟达等供应链企业增长。短期内，算力供给方占据优势；长期看，市场将趋于多元化，难以形成绝对垄断。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=KE9ZWk4QGL0"&gt;马斯克挥泪砍Dojo，Genie 3宣告世界模型到来｜是AI进化停滞，还是AGI路线的终极拐点？&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;人民公园说AI&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-08-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>NVIDIA GTC 2025 AI与计算前沿 - Yann LeCun与Bill Dally对话</title><link>https://linguista.cn/rosetta/chat-notes/nvidia-gtc-2025-yann-lecun-bill-dally-conversation-ai-frontiers/</link><pubDate>Thu, 10 Apr 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/nvidia-gtc-2025-yann-lecun-bill-dally-conversation-ai-frontiers/</guid><description>&lt;h1 id="nvidia-gtc-2025-ai与计算前沿---yann-lecun与bill-dally对话"&gt;NVIDIA GTC 2025 AI与计算前沿 - Yann LeCun与Bill Dally对话&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Meta首席AI科学家Yann LeCun在NVIDIA GTC 2025上与Bill Dally展开对话，对当前大型语言模型热潮持审慎态度，认为LLM并非通向真正机器智能的终点。他提出未来研究应聚焦四大方向——理解物理世界、持久记忆、推理与规划，并介绍了联合嵌入预测架构JEPA作为替代方案，同时倡导开源战略推动AI多样化发展。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/eyrDM3A_YFc?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="NVIDIA GTC 2025 AI与计算前沿 - Yann LeCun与Bill Dally对话"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;JEPA（联合嵌入预测架构）——LeCun团队提出的新型学习架构，通过在抽象表示空间中预测高维数据的演变来学习世界模型，避免了像素级重建的高成本与低效率问题&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;世界模型（World Model）——指让AI系统像人类一样建立对物理世界运作方式的内隐理解，能够预测物体行为和物理现象，是实现高级机器智能的关键基础&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AMI（高级机器智能）——LeCun倾向使用的术语，用以替代AGI（通用人工智能），因为他认为人类智能本身就是高度特化的，该目标预计需要十年或更长时间才能实现&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LLaMA——Meta开源的大型语言模型系列，源自巴黎小团队的创新项目，下载量超过十亿次，其成功印证了开源策略在推动AI生态建设和全球协作中的巨大价值&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Token空间推理的局限性——LeCun批评当前LLM通过生成大量词元序列来进行推理的方式过于简单，主张真正的推理应在连续的抽象表示空间中进行而非离散的符号空间&lt;/strong&gt;：&lt;/p&gt;
&lt;h2 id="meta首席ai科学家yann-lecun对当前ai热潮发出审慎之声"&gt;Meta首席AI科学家Yann LeCun对当前AI热潮发出审慎之声&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;这位深度学习先驱认为，大型语言模型虽有价值，但并非通往真正机器智能的终点，呼吁业界关注更深层次挑战&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在人工智能（AI）以前所未有的速度渗透商业和社会之际，科技巨头们正斥巨资竞相开发更大、更强的语言模型。然而，作为该领域最具影响力的奠基人之一，Meta Platforms Inc.的首席AI科学家Yann LeCun却发出了不同的声音，对当前围绕大型语言模型（LLM）的狂热持审慎态度，并指出通往更高级机器智能的道路需要克服更为根本的障碍。&lt;/p&gt;
&lt;p&gt;LeCun教授是2018年图灵奖得主，其在卷积神经网络（ConvNets）上的开创性工作为现代AI的诸多突破奠定了基础。这位在AI领域经历过数次起伏周期的资深科学家，如今对业界普遍认为仅靠扩展LLM就能实现通用人工智能（AGI）的观点表示明确怀疑。“我现在对LLM不那么感兴趣了，”他在近期NVIDIA GTC大会与该公司首席科学家Bill Dally的对话中表示，“它们现在掌握在行业产品人员手中，进行着边际改进，试图获取更多数据、更多算力。”&lt;/p&gt;
&lt;p&gt;他将当前LLM通过生成海量词元序列并从中筛选最优解的推理方式比作“在不知道如何编写程序的情况下编写随机程序，然后测试所有程序……这完全是没希望的。” 他认为这种方法“过于简单”，并坚信存在更好的路径。对于甚嚣尘上的“AGI即将到来”论调，LeCun更是毫不留情地斥之为“胡说八道”，并引用某位匿名人士的说法——“几年内你将在一个数据中心里拥有‘一个由天才组成的国度’”——称其为“完全是胡说八道”。他提醒道，AI历史上每隔十年左右就会出现一波类似的过度乐观浪潮，“当前的浪潮也是错误的。”&lt;/p&gt;
&lt;p&gt;LeCun的研究重心已转向他认为更基础且更具挑战性的四大领域：让机器理解物理世界、拥有持久记忆、掌握真正的推理能力以及具备规划能力。他强调，理解现实世界远比处理离散的语言符号困难得多。“我们每个人头脑中都有世界模型，”他以推瓶子的简单物理现象为例解释道，“你知道从顶部推它可能会翻倒，但从底部推它会滑动。” 当前AI缺乏这种对物理世界运作方式的内隐理解。&lt;/p&gt;
&lt;p&gt;为此，LeCun及其团队正致力于开发“联合嵌入预测架构”（JEPA/JAPA）。这种架构旨在让AI像婴儿观察世界一样学习——通过预测高维数据（如视频）在抽象“表示空间”中的演变，而非试图在像素层面进行无法实现的精确重建。“每一次试图让系统通过被训练来预测像素级的视频来理解世界……基本上都失败了，”他指出，“它会把所有的资源都花在试图构思那些它根本无法创造出来的细节上。” 他分享了其团队在视频理解上的尝试：基于像素重建的MAE模型扩展到视频时，计算成本高昂到需要“烧开一个小湖来冷却GPU集群”，且效果不彰，最终项目被停止；而基于JEPA的V-JEPA模型则在学习视频中的物理可能性方面展现出更好的效果和效率，如同婴儿通过观察区分合理与异常现象。&lt;/p&gt;</description></item><item><title>大型语言模型与世界模型以奥赛罗游戏为例的探讨</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/llms-world-models-othello-case/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/llms-world-models-othello-case/</guid><description>&lt;h1 id="大型语言模型与世界模型以奥赛罗游戏为例的探讨"&gt;大型语言模型与世界模型：以奥赛罗游戏为例的探讨&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文通过奥赛罗游戏（Othello）的经典案例，深入探讨大型语言模型是否能够通过训练数据自发形成对世界的抽象模型。研究者训练了名为OthelloGPT的Transformer网络，通过探针技术分析其内部激活，发现该模型确实编码了棋盘状态信息。然而，关于这种编码是否构成真正的&amp;quot;世界模型&amp;quot;仍存在争议，文章进一步分析了线性与非线性探针的对比结果，以及对人类与机器模型构建方式的思考。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以奥赛罗游戏为实验平台，介绍了OthelloGPT的训练过程：该模型在2000万种合法棋步序列上进行训练，仅学习棋步合法性而无关策略优劣，训练后在预测合法棋步上达到近乎完美的表现。研究者通过&amp;quot;探针&amp;quot;技术——一种用于解码Transformer内部激活的分类器——来分析模型是否形成了世界模型。&lt;/p&gt;
&lt;p&gt;实验过程中出现了有趣的转折：最初的线性探针无法有效预测棋盘状态，而非线性探针虽能达到98%的准确率，却可能归功于探针本身的能力而非Transformer的编码。Neel Nanda等研究者通过调整探针分类方式，将分类从&amp;quot;黑、白、空&amp;quot;改为&amp;quot;我的、你的、空&amp;quot;，使线性探针在第7层激活上的准确率提升至99.5%，这为OthelloGPT确实编码了棋盘状态提供了有力证据。&lt;/p&gt;
&lt;p&gt;然而，高准确率的探针结果并不等同于&amp;quot;世界模型&amp;quot;的存在。文章指出，OthelloGPT的内部表示更像是一个&amp;quot;启发式规则集&amp;quot;——某些神经元的激活代表非常具体的规则，这些规则能产生正确预测但缺乏抽象性和泛化能力。真正的世界模型应该具有连贯性和抽象性，能够应对未曾见过的情境。&lt;/p&gt;
&lt;p&gt;文章最后从认知科学角度对比了人类与机器的模型构建方式。人类受到工作记忆、处理速度和能量限制的约束，这些限制迫使我们形成更抽象、更具泛化的内部模型。机器可能也需要类似的限制和挑战，才能形成真正抽象的模型，从而更好地泛化到新情境中。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：指智能体内部形成的对外部世界的抽象表征，它不仅仅是对输入-输出模式的记忆，而是对世界运作方式的理解和模拟。真正的世界模型具有抽象性和泛化能力，能够处理未曾遇到的情况。在OthelloGPT的案例中，尽管模型编码了棋盘状态，但这是否构成真正的世界模型仍存争议。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;探针技术&lt;/strong&gt;：一种用于分析神经网络内部表征的技术，通过训练分类器来预测网络内部激活所编码的信息。线性探针简单直接，能够揭示网络本身的编码能力；非线性探针功能更强大，但可能掩盖网络的真实编码情况，因其自身具有强大的信息提取能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启发式规则集&lt;/strong&gt;：与抽象的世界模型相对，指由大量具体规则组成的知识表示方式。在OthelloGPT中，某些神经元可能编码了非常具体的规则（如&amp;quot;当某个位置被占据时采取某种行动&amp;quot;），这些规则能产生正确预测，但缺乏抽象性和泛化能力，无法应对规则之外的情况。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;认知限制与抽象化&lt;/strong&gt;：人类在构建模型时受到工作记忆容量、处理速度和能量消耗等限制，这些限制反而促使我们形成更抽象、更具泛化的内部模型。这为AI研究提供了启示：或许需要给机器模型添加类似的限制，促使其发展出真正的抽象理解能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表征与理解的区别&lt;/strong&gt;：神经网络能够表征信息（如OthelloGPT编码了棋盘状态），并不等同于它理解了这些信息背后的因果关系和抽象结构。这是当前AI研究面临的核心挑战之一——如何让模型从数据记忆走向真正的理解。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://aiguide.substack.com/p/llms-and-world-models-part-2"&gt;LLMs and World Models, Part 2&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;AI Guide&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未标注&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>大型语言模型与世界模型第一部分LLMs如何理解它们的世界</title><link>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/llms-world-models-part-1/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes-2025_p2/llms-world-models-part-1/</guid><description>&lt;h1 id="大型语言模型与世界模型第一部分llms-如何理解它们的世界"&gt;大型语言模型与世界模型（第一部分）：LLMs 如何理解它们的&amp;quot;世界&amp;quot;&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文由 Melanie Mitchell 撰写，深入探讨了大型语言模型（LLMs）是否发展出了类似人类的&amp;quot;世界模型&amp;quot;以理解其运作的&amp;quot;世界&amp;quot;。文章回顾了早期机器学习系统的脆弱性问题，介绍了世界模型的概念定义与分类方法，并围绕 LLMs 是否真正具备世界模型能力展开了学术界的重要辩论。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先通过多个经典案例揭示了早期 AI 系统的根本局限性——它们依赖于训练数据中的启发式规则和表面特征，而非真正的概念理解。从皮肤病变分类错误地依赖尺子存在，到语言模型仅凭词汇重叠判断逻辑关系，再到强化学习系统在游戏设置微小变化下的性能崩溃，这些案例都指向同一个问题：缺乏对世界因果结构的理解。&lt;/p&gt;
&lt;p&gt;接着文章转向当前备受争议的话题——大型语言模型是否突破了这一局限。OpenAI 联合创始人 Ilya Sutskever 认为，通过预测下一个词的训练目标，LLMs 确实学习了世界的压缩表征，包括人类的情感和动机。然而，包括 Yann LeCun 在内的多位研究者对此表示强烈怀疑，认为仅靠语言训练无法达到真正的理解。2022 年的一项调查显示，NLP 研究者群体在这一问题上几乎呈现对半分的分裂态势。&lt;/p&gt;
&lt;p&gt;为了厘清这一辩论，文章详细梳理了&amp;quot;世界模型&amp;quot;的多种定义。从最基础的内部表征到保留因果结构的复杂模型，再到能够支持反事实推理的完整模拟器。MIT 教授 Jacob Andreas 提出了一个清晰的分类框架，从静态查找表、地图、机械天体仪到完整的模拟器，每种类型代表了对世界理解的不同深度。人类正是通过这样的世界模型，才能快速理解复杂场景、预测因果关系并规划行动。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：指智能体内部形成的、对外部世界的压缩且可模拟的表征，它不仅能够存储信息，还能捕捉世界的因果结构，支持预测、规划和回答反事实问题。人类的世界模型使我们能够在瞬间理解街景照片中的复杂场景，推断行为者的意图和可能的后续发展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启发式规则与表面特征&lt;/strong&gt;：早期机器学习系统依赖的捷径思维，它们通过发现训练数据中的统计关联来解决问题，但这种方式缺乏真正的理解。就像皮肤病变分类器记住&amp;quot;尺子=恶性&amp;quot;这样的关联，当环境变化时就会失效，因为系统并不理解尺子和病变之间的真实关系。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;情境模型&lt;/strong&gt;：LLMs 可能具备的一种中间层次世界模型，能够跟踪文本中的行为者、状态和动作变化。这类似于一个机械天体仪，可以模拟特定场景中的动态过程，但可能缺乏对更广泛世界因果知识的整合。目前尚不清楚 LLMs 的情境模型能否推广到训练数据之外的全新场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因果模拟模型&lt;/strong&gt;：世界模型的最高层次，能够回答复杂的&amp;quot;如果-那么&amp;quot;类型反事实问题，需要对世界的深层因果结构有精确理解。目前缺乏证据表明 LLMs 具备这种能力，这是判断它们是否真正&amp;quot;理解&amp;quot;世界的关键检验标准。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://aiguide.substack.com/p/llms-and-world-models-part-1"&gt;LLMs and World Models, Part 1 - How do Large Language Models Make Sense of Their &amp;ldquo;Worlds&amp;rdquo;?&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Melanie Mitchell&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未明确说明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>未来人工智能的形态——Yann LeCun在2025年AI行动峰会的演讲</title><link>https://linguista.cn/rosetta/chat-notes/yann-lecun-shape-of-ai-to-come-2025-summit/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/yann-lecun-shape-of-ai-to-come-2025-summit/</guid><description>&lt;h1 id="未来人工智能的形态yann-lecun在2025年ai行动峰会的演讲"&gt;未来人工智能的形态——Yann LeCun在2025年AI行动峰会的演讲&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Yann LeCun在2025年AI行动峰会上探讨了人类水平AI的必要性，指出当前大型语言模型存在自回归生成错误累积、缺乏物理世界理解等局限。他主张放弃生成式模型，转向联合嵌入预测架构（JEPA）和能量基模型，并强调层次化规划、世界模型构建以及开源AI平台对未来发展的关键作用。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/xnFmnU0Pp-8]%28https://www.youtube.com/watch?v=xnFmnU0Pp-8?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="未来人工智能的形态——Yann LeCun在2025年AI行动峰会的演讲"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;联合嵌入预测架构（JEPA）&lt;/strong&gt;：一种通过预测抽象表示而非像素级输出的架构，旨在替代传统生成式模型，提升对视频等复杂数据的预测能力&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能量基模型&lt;/strong&gt;：利用能量函数捕捉变量间依赖关系的模型框架，通过最小化能量函数实现推理，对应人类深度思考的系统二思维模式&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：使AI具备对物理世界运作方式的内在理解，能够预测行动结果并据此进行规划的核心模块&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;层次化规划&lt;/strong&gt;：从高层抽象动作到低层具体动作的多级规划机制，模拟人类处理复杂任务时的分层决策过程&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;开源AI平台&lt;/strong&gt;：LeCun倡导的AI发展路径，主张通过开放研究和多方协作避免技术垄断，确保AI技术的广泛可及性&lt;/p&gt;
&lt;p&gt;《未来人工智能的形态：Yann LeCun在2025年AI行动峰会的演讲》&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原文标题：The Shape of AI to Come! Yann LeCun at AI Action Summit 2025&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;链接：&lt;a href="https://www.youtube.com/watch?v=xnFmnU0Pp-8"&gt;https://www.youtube.com/watch?v=xnFmnU0Pp-8&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;文章类别&lt;/strong&gt;：演讲实录&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id="内容整理"&gt;内容整理&lt;/h2&gt;
&lt;h3 id="演讲主题"&gt;演讲主题&lt;/h3&gt;
&lt;p&gt;Yann LeCun在2025年AI行动峰会上的演讲，探讨了人工智能的未来发展方向，特别是人类水平AI的必要性、当前技术的局限性以及未来可能的技术路径。&lt;/p&gt;
&lt;h3 id="演讲框架"&gt;演讲框架&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 欢迎致辞与演讲者介绍
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 人类水平AI的必要性
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 智能设备与AI助手的未来
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 人类水平AI的市场需求
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 当前机器学习技术的局限性
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 与人类和动物学习能力的差距
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 当前AI系统的缺陷
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 未来AI技术的探索方向
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 能量模型与推理机制
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 世界模型与规划能力
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 层次化规划与抽象表示
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└── 结论与建议
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ├── 放弃生成模型，转向联合嵌入预测架构（JAPA）
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ├── 开源AI平台的重要性
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; └── 未来研究方向的展望
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id="演讲内容要点"&gt;演讲内容要点&lt;/h3&gt;
&lt;h4 id="人类水平ai的必要性"&gt;人类水平AI的必要性&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;智能设备与AI助手的未来&lt;/strong&gt;：LeCun指出，未来我们将佩戴智能设备（如智能眼镜），并依赖AI助手进行日常交互。这些设备需要具备人类水平的智能，以便用户能够自然地与之互动。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;市场需求&lt;/strong&gt;：AI助手需要具备类似人类的智能水平，因为人类更熟悉与人类水平的智能进行交互。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="当前机器学习技术的局限性"&gt;当前机器学习技术的局限性&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;与人类和动物学习能力的差距&lt;/strong&gt;：LeCun强调，当前的机器学习技术在学习能力上远远落后于人类和动物。人类和动物能够快速学习新任务，并基于常识理解物理世界，而AI系统则缺乏这种能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;当前AI系统的缺陷&lt;/strong&gt;：现有的AI系统（如大型语言模型）通过自回归方式生成文本，但这种方式容易导致错误累积，并且缺乏对物理世界的真正理解。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="未来ai技术的探索方向"&gt;未来AI技术的探索方向&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;能量模型与推理机制&lt;/strong&gt;：LeCun提出，未来的AI系统需要采用能量模型进行推理，而不是简单的自回归生成。能量模型可以通过优化过程找到最符合输入的输出，类似于人类的“系统二”思维。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;世界模型与规划能力&lt;/strong&gt;：AI系统需要具备世界模型，能够预测行动的结果，并通过优化过程规划行动序列以实现目标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;层次化规划与抽象表示&lt;/strong&gt;：LeCun强调，AI系统需要能够进行层次化规划，从高层次的抽象动作到低层次的具体动作，类似于人类在复杂任务中的规划方式。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id="结论与建议"&gt;结论与建议&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;放弃生成模型，转向联合嵌入预测架构（JAPA）&lt;/strong&gt;：LeCun建议放弃现有的生成模型，转而采用联合嵌入预测架构，该架构通过预测抽象表示而非像素级输出，从而简化问题并提高预测的准确性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;开源AI平台的重要性&lt;/strong&gt;：LeCun认为，未来的AI平台需要开源，以便全球的研究者和开发者能够共同参与，避免少数公司垄断AI技术。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;未来研究方向的展望&lt;/strong&gt;：LeCun呼吁研究者关注AI的规划能力、层次化学习、成本函数的学习等方向，并强调开源合作的重要性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="文章标签"&gt;文章标签&lt;/h3&gt;
&lt;p&gt;#人工智能， #未来技术， #YannLeCun， #AI行动峰会&lt;/p&gt;</description></item></channel></rss>