<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Google Cloud on Linguista</title><link>https://linguista.cn/tags/google-cloud/</link><description>Recent content in Google Cloud on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Mon, 26 Jan 2026 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/google-cloud/index.xml" rel="self" type="application/rss+xml"/><item><title>宣布推出 Agent2Agent (A2A) 协议</title><link>https://linguista.cn/rosetta/technology/google-agent2agent-a2a-protocol/</link><pubDate>Mon, 26 Jan 2026 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/google-agent2agent-a2a-protocol/</guid><description>&lt;h1 id="宣布推出-agent2agent-a2a-协议"&gt;宣布推出 Agent2Agent (A2A) 协议&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;谷歌联合超过50家技术合作伙伴推出 Agent2Agent（A2A）开放协议，旨在让不同供应商和框架构建的 AI 智能体实现跨平台通信与协作。该协议基于 HTTP、SSE、JSON-RPC 等现有标准，支持能力发现、任务管理、多模态交互和长时间运行任务，为企业级多智能体生态系统提供标准化的互操作方案。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;A2A 协议&lt;/strong&gt;：谷歌推出的开放协议，定义了客户端智能体与远程智能体之间的通信标准，使不同框架和供应商构建的 AI 智能体能够相互发现、协调任务并交换信息&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;智能体卡片（Agent Card）&lt;/strong&gt;：以 JSON 格式描述智能体能力的元数据文件，客户端智能体通过读取智能体卡片来识别并选择最适合执行特定任务的远程智能体&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型上下文协议（MCP）&lt;/strong&gt;：Anthropic 推出的协议，用于为智能体提供工具和上下文信息，A2A 与 MCP 形成互补关系，前者解决智能体间协作问题，后者解决智能体与工具的连接问题&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;智能体互操作性&lt;/strong&gt;：不同技术栈、不同供应商构建的 AI 智能体能够跨平台无缝协作的能力，是实现企业级多智能体生态系统的核心需求&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务生命周期管理&lt;/strong&gt;：A2A 协议中定义的任务对象具有完整的生命周期，支持即时完成和长时间运行两种模式，任务产出称为工件（Artifact），智能体之间可实时同步任务状态&lt;/p&gt;
&lt;p&gt;探索 A2A，谷歌推出的全新开放协议，赋能开发者构建可互操作的 AI 解决方案。&lt;/p&gt;
&lt;p&gt;作者：Rao Surapaneni, Miku Jha, Michael Vakoc, Todd Segal&lt;/p&gt;
&lt;p&gt;阅读时长：12 分钟&lt;/p&gt;
&lt;h2 id="智能体互操作性的新时代"&gt;智能体互操作性的新时代&lt;/h2&gt;
&lt;p&gt;AI 智能体提供了一个独特的机会，通过自主处理许多日常重复性或复杂任务来帮助人们提高生产力。如今，企业越来越多地构建和部署自主智能体，以帮助在整个工作场所扩展、自动化和增强流程——从订购新笔记本电脑，到协助客户服务代表，再到辅助供应链规划。&lt;/p&gt;
&lt;p&gt;为了最大化智能体 AI 的效益，关键在于让这些智能体能够在跨越孤立数据系统和应用程序的动态多智能体生态系统中进行协作。使智能体能够相互操作，即使它们是由不同的供应商或在不同的框架中构建的，也将增加自主性并倍增生产力收益，同时降低长期成本。&lt;/p&gt;
&lt;p&gt;今天，我们推出了一个名为 Agent2Agent (A2A) 的全新开放协议，得到了超过 50 家技术合作伙伴的支持和贡献，例如 Atlassian、Box、Cohere、Intuit、Langchain、MongoDB、PayPal、Salesforce、SAP、ServiceNow、UKG 和 Workday；以及领先的服务提供商，包括 Accenture、BCG、Capgemini、Cognizant、Deloitte、HCLTech、Infosys、KPMG、McKinsey、PwC、TCS 和 Wipro。A2A 协议将允许 AI 智能体相互通信、安全地交换信息，并在各种企业平台或应用程序之上协调行动。我们相信 A2A 框架将为客户带来显著价值，他们的 AI 智能体现在将能够在其整个企业应用领域中工作。&lt;/p&gt;
&lt;p&gt;这项协作努力标志着一个共同的愿景，即未来 AI 智能体，无论其底层技术如何，都可以无缝协作，以自动化复杂的企业工作流，并推动前所未有的效率和创新水平。&lt;/p&gt;</description></item><item><title>Google Cloud Next 2025 AI发布会全景解读</title><link>https://linguista.cn/rosetta/technology/google-cloud-next-2025-ai-infrastructure-and-agents/</link><pubDate>Wed, 09 Apr 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/google-cloud-next-2025-ai-infrastructure-and-agents/</guid><description>&lt;h1 id="google-cloud-next-2025-ai发布会全景解读"&gt;Google Cloud Next 2025 AI发布会全景解读&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;谷歌云在2025年度大会上发布了全栈AI创新成果，涵盖第七代TPU Ironwood芯片、Gemini 2.5系列模型、AI Hypercomputer超算架构、Agent Development Kit智能体开发框架以及Agentspace企业智能体平台，并宣布年度资本支出约750亿美元，全面推进基础设施、模型能力与行业应用落地。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Ironwood TPU&lt;/strong&gt;：谷歌第七代张量处理单元，性能为初代公开TPU的3600倍，单Pod超9000芯片，算力达42.5 exaflops，专为下一代AI模型训练与推理设计&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gemini 2.5 Pro&lt;/strong&gt;：谷歌迄今最智能的大语言模型，具备原生思考推理能力，在ChatbotArena排名第一，支持多模态输出与工具调用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI Hypercomputer&lt;/strong&gt;：谷歌推出的超级计算架构，统一多种硬件平台与软件栈，简化AI部署流程并优化性能与成本&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Agent2Agent Protocol（A2A）&lt;/strong&gt;：一种开放协议，允许不同模型和框架构建的AI智能体之间进行跨系统通信与协作&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Agentspace&lt;/strong&gt;：面向企业员工的智能体应用平台，集成搜索、对话AI、深度研究等能力，可连接企业数据与应用并执行自动化操作&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I. 引言与谷歌云愿景&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;开场强调全球组织正利用创新解决方案推动变革、提升效率、赋能员工、吸引客户和促进增长。&lt;/li&gt;
&lt;li&gt;谷歌云CEO Thomas Kurian回顾过去一年的成就：
&lt;ul&gt;
&lt;li&gt;2024年发布超过3000项产品更新。&lt;/li&gt;
&lt;li&gt;谷歌云区域扩展至42个，并计划进一步扩展。&lt;/li&gt;
&lt;li&gt;扩展了200万英里的陆地和海底光纤网络，并宣布了新的海底光缆项目。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;谷歌AI发展势头强劲：
&lt;ul&gt;
&lt;li&gt;超过400万开发者使用Gemini。&lt;/li&gt;
&lt;li&gt;Vertex AI使用量去年增长 $20$ 倍。&lt;/li&gt;
&lt;li&gt;Google Workspace每月提供超过20亿次AI辅助。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;本次大会将分享超过500个客户利用AI实现业务创新的成功案例。&lt;/li&gt;
&lt;li&gt;谷歌正投资于技术和生态系统，以支持客户的增长和转型。&lt;/li&gt;
&lt;li&gt;谷歌与Alphabet CEO Sundar Pichai发言：
&lt;ul&gt;
&lt;li&gt;AI是推进谷歌及客户使命的最重要方式。&lt;/li&gt;
&lt;li&gt;谷歌投资全栈AI创新，从基础设施到模型和产品。&lt;/li&gt;
&lt;li&gt;计划在2025年投资约 $750$ 亿美元的总资本支出，主要用于服务器和数据中心，支持AI计算和云业务。&lt;/li&gt;
&lt;li&gt;谷歌基础设施支持全球数十亿用户，并用于训练最强大的Gemini模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;II. 基础设施创新&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;推出Cloud Wide Area Network (WAN)：
&lt;ul&gt;
&lt;li&gt;利用谷歌全球规模的网络。&lt;/li&gt;
&lt;li&gt;优化应用性能，性能提升超过 $40\%$，总拥有成本降低高达 $40\%$。&lt;/li&gt;
&lt;li&gt;Citadel Securities和雀巢等公司已在使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;宣布第七代TPU - Ironwood：
&lt;ul&gt;
&lt;li&gt;将于今年晚些时候推出。&lt;/li&gt;
&lt;li&gt;性能是首款公开TPU的 $3600$ 倍，能效提升 $29$ 倍。&lt;/li&gt;
&lt;li&gt;是谷歌有史以来最强大的芯片，支持下一代AI模型。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;量子计算进展：
&lt;ul&gt;
&lt;li&gt;最新量子芯片Willow解决了困扰研究人员三十年的量子纠错关键挑战。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;AI计算需求增长迅猛：
&lt;ul&gt;
&lt;li&gt;过去8年，年复合增长率超过 $10$ 倍，总增长达 $10^8$ 倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ironwood TPU Pods细节：
&lt;ul&gt;
&lt;li&gt;每个Pod拥有超过9000个芯片，计算能力达 $42.5$ exaflops，是世界第一超算的 $24$ 倍以上。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;AI Hypercomputer：
&lt;ul&gt;
&lt;li&gt;旨在简化AI部署、提高性能、优化成本的超级计算系统。&lt;/li&gt;
&lt;li&gt;支持多种硬件平台（包括NVIDIA的GB200, B200 GPU，未来将支持Vera Rubin GPU）和统一软件栈。&lt;/li&gt;
&lt;li&gt;推出Cluster Director管理大规模加速器。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;存储创新：
&lt;ul&gt;
&lt;li&gt;Hyperdisk Exapools：提供业界领先的聚合性能和容量。&lt;/li&gt;
&lt;li&gt;Anywhere Cache：数据靠近加速器，存储延迟降低高达 $70\%$。&lt;/li&gt;
&lt;li&gt;Rapid Storage：区域对象存储，随机读写延迟降低 $5$ 倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;软件与编排增强：
&lt;ul&gt;
&lt;li&gt;Google Kubernetes Engine (GKE) 新增推理能力：降低成本达 $30\%$，尾延迟降低 $60\%$，吞吐量提高 $40\%$。&lt;/li&gt;
&lt;li&gt;Pathways：Google DeepMind开发的分布式机器学习运行时首次向云客户开放，支持多主机推理。&lt;/li&gt;
&lt;li&gt;vLLM on TPUs：支持已为GPU优化PyTorch与vLLM的客户在TPU上运行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;性能与成本效益：
&lt;ul&gt;
&lt;li&gt;Gemini 2.0 Flash 在AI Hypercomputer上实现每美元智能输出比GPT-4o高 $24$ 倍，比DeepSeek R1高 $5$ 倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Google Distributed Cloud (GDC)：
&lt;ul&gt;
&lt;li&gt;将谷歌硬件和软件带到客户环境（本地或气隙环境）。&lt;/li&gt;
&lt;li&gt;宣布Gemini可在GDC上本地运行。&lt;/li&gt;
&lt;li&gt;支持NVIDIA Confidential Computing和Blackwell系统。&lt;/li&gt;
&lt;li&gt;GDC气隙产品已获美国政府Secret和Top Secret任务授权。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;与NVIDIA的合作：
&lt;ul&gt;
&lt;li&gt;Jensen Huang强调双方深度合作，将通过GDC把最先进的AI带给受监管行业和国家。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;III. AI模型与平台&lt;/strong&gt;&lt;/p&gt;</description></item></channel></rss>