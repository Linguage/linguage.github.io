<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>3D建模 on Linguista</title><link>https://linguista.cn/tags/3d%E5%BB%BA%E6%A8%A1/</link><description>Recent content in 3D建模 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 04 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/3d%E5%BB%BA%E6%A8%A1/index.xml" rel="self" type="application/rss+xml"/><item><title>多模态大语言模型CAD-GPT的空间智能探索</title><link>https://linguista.cn/curated/henrinotes-2025-p1/cad-gpt-multimodal-spatial-reasoning/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/cad-gpt-multimodal-spatial-reasoning/</guid><description>&lt;h1 id="多模态大语言模型cad-gpt的空间智能探索"&gt;多模态大语言模型CAD-GPT的空间智能探索&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文介绍了AAAI 2025收录的CAD-GPT研究成果，这是一种创新的多模态大语言模型，通过结合空间推理机制实现了从单张图片或一句话描述自动生成精准CAD建模代码的功能。该模型以LLaVA-1.5 7B为基础，设计了3D建模空间定位机制，通过三个系列的定位token将3D参数映射到1D语言信息维度，成功弥合了语言表达与空间位置之间的语义鸿沟。实验结果表明，CAD-GPT在生成精度和模型质量方面均优于现有技术如DeepCAD和GPT-4，为CAD建模自动化提供了新的技术路径。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本文围绕空间智能在CAD建模领域的应用展开研究，提出了一种融合空间推理能力的多模态大语言模型框架。研究团队首先分析了现有CAD建模方法的局限性，即传统方法缺乏对三维空间关系的深度理解，导致生成的模型精度不足。为此，CAD-GPT创新性地引入了空间定位机制，使模型能够理解并处理复杂的3D空间关系。&lt;/p&gt;
&lt;p&gt;在技术实现层面，研究采用两阶段训练策略，基于DeepCAD数据集构建了包含16万张固定视角CAD模型图像和1.8万条自然语言描述的大规模训练数据。模型架构方面，设计了专门的定位token系统，将3D参数空间有效地映射到语言模型的1D信息空间，这种设计使得模型能够同时处理视觉输入和文本指令，并生成准确的建模序列。&lt;/p&gt;
&lt;p&gt;实验部分展示了CAD-GPT在各种条件下的性能表现，包括单图像输入、纯文本输入以及图文混合输入场景。结果表明，该模型不仅在生成精度上超越现有方法，还在处理复杂空间关系方面表现出色，充分验证了空间推理机制在多模态CAD建模任务中的有效性和必要性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;空间定位机制&lt;/strong&gt;：这是CAD-GPT的核心技术创新，通过设计三个系列的可学习定位token，将3D建模空间中的坐标、尺寸等参数映射到语言模型的1D表示空间。这种机制解决了传统多模态模型在处理三维空间信息时的语义失配问题，使模型能够真正理解并操作三维空间中的几何关系。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;两阶段训练策略&lt;/strong&gt;：研究采用分阶段训练方法，第一阶段让模型学习基础的CAD建模知识和空间关系，第二阶段则专注于优化具体的建模序列生成。这种渐进式训练设计既保证了模型的基础能力，又提升了其在特定任务上的表现精度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多模态输入融合&lt;/strong&gt;：CAD-GPT支持多种输入方式的灵活组合，包括单张图片、一句话描述或图文混合输入。这种多模态融合能力使得用户可以根据实际需求选择最便捷的交互方式，大大提升了工具的实用性和易用性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;构造序列合成&lt;/strong&gt;：与传统端到端的3D模型生成不同，CAD-GPT生成的是可执行的CAD建模构造序列，这种输出格式更具可解释性和可编辑性。用户可以在生成的序列基础上进行修改和优化，实现了从自动化到辅助设计的平滑过渡。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://arxiv.org/abs/2412.19663"&gt;CAD-GPT: Synthesising CAD Construction Sequence with Spatial Reasoning-Enhanced Multimodal LLMs&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;王思宇, 关新平, 陈彩莲&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;会议期刊&lt;/td&gt;
 &lt;td&gt;AAAI 2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>