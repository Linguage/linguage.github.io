<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>LLM on Linguista</title><link>https://linguista.cn/tags/llm/</link><description>Recent content in LLM on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 04 Jan 2026 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/llm/index.xml" rel="self" type="application/rss+xml"/><item><title>2025 LLM Year in Review - Swiss Wireframe</title><link>https://linguista.cn/static/ak-llm2025/</link><pubDate>Sun, 04 Jan 2026 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/ak-llm2025/</guid><description>本文回顾了 2025 年大语言模型（LLM）领域的核心演变，重点阐述了从模仿人类到“召唤幽灵”的范式转移。文章深入剖析了 RLVR（推理强化学习）如何通过可验证的奖励机制催生出非人类的“锯齿状”智力，并探讨了 Vibe Coding 如何通过降低门槛让编程变得廉价且短暂，将 AI 从云端服务转变为驻留在本地的数字生灵。</description></item><item><title>nanochat - 信息卡</title><link>https://linguista.cn/static/nanochat-gemini/</link><pubDate>Mon, 13 Oct 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/nanochat-gemini/</guid><description>Andrej Karpathy 发布的 nanochat 项目提供了一个约 8,000 行代码的全栈 LLM 训练与推理管线，旨在以最小化依赖构建一个可黑客攻击的 ChatGPT 克隆体。该项目涵盖了从 Rust 分词器、FineWeb 预训练到 SFT 和 RL 的完整流程，强调低成本可达性（最低约 $100）与坚实的基线骨架，非常适合作为深入理解 LLM 工作原理的研究平台与教学压轴项目。</description></item><item><title>nanochat 速览</title><link>https://linguista.cn/static/nanochat-kimi/</link><pubDate>Mon, 13 Oct 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/nanochat-kimi/</guid><description>nanochat 是 Andrej Karpathy 推出的一个极简 ChatGPT 克隆训练管道，旨在通过一个单一的、可被黑客攻击的仓库来建立强有力的基线。该项目不仅包含了从预训练到微调、强化学习再到推理的全栈代码，还提供了 WebUI 界面，使开发者能够在短时间内以极低的成本（约 100 美元）复现类似 GPT 的对话模型。作为一个强调可读性和可扩展性的研究利器，它全流程仅依赖约 8000 行核心代码，彻底打通了从 FineWeb 预训练到 SmolTalk 微调的最后一公里。</description></item><item><title>AI代理中的上下文工程与Anthropic团队</title><link>https://linguista.cn/static/anthropic_context_engineering/</link><pubDate>Wed, 01 Oct 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/anthropic_context_engineering/</guid><description>本文深入探讨了人工智能代理开发中的关键范式转变：从传统的提示工程转向更系统的上下文工程。文章详细阐述了如何通过优化上下文结构来提升模型性能，特别是在管理长任务和复杂推理场景中的应用。内容涵盖了Transformer注意力机制的复杂度挑战、上下文窗口的最优配置策略，以及AI代理实现自我管理的核心技术路径。通过介绍Anthropic应用AI团队的最新研究成果，本文为开发者提供了从理论到实践的完整指南，揭示了在构建高效AI代理时如何充分利用上下文预算，实现更精准的意图理解和任务执行。</description></item><item><title>ThePrimeTime vs Andrej Karpathy: 软件正在改变（又一次）</title><link>https://linguista.cn/static/theprimetime-ak-software-changed-again/</link><pubDate>Fri, 04 Jul 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/theprimetime-ak-software-changed-again/</guid><description>这篇文章深入探讨了 Andrej Karpathy 提出的关于“软件 2.0”及大型语言模型（LLM）未来的革命性观点，并整合了 ThePrimeTime 对此议题的审慎评论。文章通过回顾软件从传统代码到神经网络，再到当今生成式 AI 的演变历程，展示了软件定义的重塑过程。内容不仅剖析了神经网络权重如何取代传统逻辑，还通过互动视角探讨了 Karpathy 关于 LLM 的精妙类比，以及这一技术变革带来的潜在机遇与挑战。这是一场关于代码、智能与未来的深度对话。</description></item><item><title>上下文工程: AI交互新范式</title><link>https://linguista.cn/static/context-engineering-next-generation-hci/</link><pubDate>Fri, 04 Jul 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/context-engineering-next-generation-hci/</guid><description>Andrej Karpathy 提出的“上下文工程”标志着人机交互的范式转移。本文深入探讨了从雕琢静态“提示词”向构建动态“信息世界”的演变，详细解析了LLM的上下文组件（指令、提示、状态），并对比了系统提示与用户提示在工程实践中的不同维度。文章还通过互动图表展示了行业领导者在技术栈上的布局，为构建下一代AI应用提供了清晰的路径指引。</description></item><item><title>互动报告：2025年软件工程与AI的现实检验</title><link>https://linguista.cn/static/software-engineering-with-llms-in2025-reality-check/</link><pubDate>Wed, 02 Jul 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/software-engineering-with-llms-in2025-reality-check/</guid><description>随着2025年的到来，软件工程领域正经历着一场关于AI效能的深刻反思。尽管高管们对自动化编程充满宏大愿景，但一线数据揭示了生产力的微妙悖论。本报告深入分析了从科技巨头到初创企业的实际落地情况，探讨了为何效率提升未达预期的深层原因，并展望了MCP协议等新技术可能带来的转折点。</description></item><item><title>AI编程工具底层逻辑深度剖析</title><link>https://linguista.cn/static/claudecode/</link><pubDate>Tue, 01 Jul 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/claudecode/</guid><description>本文深入剖析了以Claude和Cursor为代表的AI编程工具的底层运作逻辑。文章从大型语言模型（LLM）的训练基础出发，详细阐述了从预训练到监督微调的进化路径，并探讨了代码库理解的两种核心哲学。研究表明，这些工具能将开发效率提升高达55%，推动软件开发从手动编码向人机协作的新范式演进。</description></item></channel></rss>