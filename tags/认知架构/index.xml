<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>认知架构 on Linguista</title><link>https://linguista.cn/tags/%E8%AE%A4%E7%9F%A5%E6%9E%B6%E6%9E%84/</link><description>Recent content in 认知架构 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 27 Jan 2026 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E8%AE%A4%E7%9F%A5%E6%9E%B6%E6%9E%84/index.xml" rel="self" type="application/rss+xml"/><item><title>智能体（Agent）——Google白皮书解读</title><link>https://linguista.cn/rosetta/technology/google-whitepaper-ai-agents/</link><pubDate>Tue, 27 Jan 2026 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/google-whitepaper-ai-agents/</guid><description>&lt;h1 id="智能体agentgoogle白皮书解读"&gt;智能体（Agent）——Google白皮书解读&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文为Google发布的智能体白皮书，系统阐述了生成式AI智能体的核心概念与架构。智能体由模型、工具和编排层三大组件构成，能够自主观察环境、调用外部工具并采取行动以实现目标。文章详细介绍了ReAct、思维链、思维树等推理框架，并对比了智能体与传统模型的本质差异，为构建生产级智能体应用提供了完整的技术参考。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;智能体（Agent）&lt;/strong&gt;：一种超越独立生成式AI模型能力的应用程序，能够通过观察环境、调用工具并自主决策来实现目标&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;认知架构&lt;/strong&gt;：智能体内部由模型、工具和编排层组成的系统结构，负责信息接收、推理规划、执行行动和反馈调整的循环过程&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ReAct框架&lt;/strong&gt;：一种结合推理（Reason）与行动（Action）的提示工程策略，使模型能够交替进行思考和工具调用，逐步解决复杂问题&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;编排层&lt;/strong&gt;：管理智能体信息处理循环的核心层，负责维护记忆、状态、推理和规划，持续运行直到目标达成&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;工具（Tools）&lt;/strong&gt;：弥合智能体内部能力与外部世界差距的桥梁，使模型能够访问实时数据和外部服务，实现如数据库查询、API调用等操作&lt;/p&gt;
&lt;p&gt;「Google白皮书」智能体（Agent）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单位：Google&lt;/li&gt;
&lt;li&gt;作者：Julia Wiesinger, Patrick Marlow 和 Vladimir Vuskovic&lt;/li&gt;
&lt;li&gt;原文：&lt;a href="https://www.kaggle.com/whitepaper-agents"&gt;Agent&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://cdn-mineru.openxlab.org.cn/extract/7b099934-d40b-403d-8804-2269062d890e/1e617186aa14acffc2355bf30615e8ccb40d24be539626e598f7d93f16c094df.jpg" alt=""&gt;&lt;/p&gt;
&lt;h2 id="目录"&gt;目录&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;1. 引言 4
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;2. 什么是智能体？ 5
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;3. 模型 6
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;4. 工具 7
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;5. 编排层 7
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;6. 智能体 vs. 模型 8
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;7. 认知架构：智能体如何运作 8
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;8. 工具：我们通往外部世界的钥匙 12
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;9. 扩展 13
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;10. 扩展示例 15
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;11. 函数 18
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;12. 用例 21
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;13. 函数示例代码 24
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;14. 数据存储 27
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;15. 实现与应用 28
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;16. 工具回顾 32
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;17. 通过目标学习提升模型性能 33
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;18. 使用 LangChain 快速开始智能体开发 35
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;19. 使用 Vertex AI 智能体进行生产应用 38
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;20. 总结 40
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;21. 尾注 42
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这种将推理、逻辑和对外部信息的访问结合起来，并全部连接到生成式 AI 模型的方式，引出了智能体的概念。&lt;/p&gt;</description></item><item><title>大型语言模型心理学的三层模型</title><link>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/llm-psychology-three-layer-model/</link><pubDate>Tue, 28 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/llm-psychology-three-layer-model/</guid><description>&lt;h1 id="大型语言模型心理学的三层模型"&gt;大型语言模型心理学的三层模型&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文提出了一个理解大型语言模型（尤其是Claude）心理学特征的三层模型框架。该模型包含表面层（由触发-行动模式组成的反射性反应）、角色层（维护一致性和个性特征的深度模式）以及预测基础层（基于预测误差最小化的核心认知机制）。作者通过这个框架解释了LLM在不同情境下的行为模式，探讨了层之间的互动关系，并分析了这一模型对理解AI安全性和人机互动的意义。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先阐明了该模型的启发性和实用性定位。作者强调这是一个基于与LLM广泛互动经验（特别是与Claude的对话）而形成的现象学模型，而非精确的神经科学或技术性描述。其目标是创建一个能够激发直观理解的粗略草图，帮助人们在实际互动中获得更有用的结果。&lt;/p&gt;
&lt;p&gt;核心部分详细阐述了三层模型的具体内容。表面层由标准化回应、通用安全声明和公式化结构组成，类似于人类的反射性反应，特点是快速激活但相对不灵活。角色层更深一层，维护类似文学角色的一致性，使某些类型的回应比其他类型更有可能，表现为稳定的个性特征和意图。预测基础层是最深层的核心机制，基于预测误差最小化，可视为在心灵剧场中运行的巨大世界模拟，具有普遍模式识别、大规模上下文整合和某些奇妙限制等特征。&lt;/p&gt;
&lt;p&gt;文章进一步探讨了层之间的动态互动。角色层经常覆盖表面层的初始反射性回应，而预测基础层在某些情况下（如many-shots jailbreaks）又可以覆盖角色层。用户有时能够观察到这些层之间的&amp;quot;缝隙&amp;quot;，当互动在模型回应中造成不和谐或不一致时。作者指出，与LLM互动的质量取决于哪些层在特定时刻驱动其回应——从表面层主导时的机械感，到角色层主导时的一致性，再到深层参与时出现的有方向且情境适当的连贯回应。&lt;/p&gt;
&lt;p&gt;最后，作者讨论了该模型的含义、用途、限制和开放问题。文章提出了一些回顾性预测，强调了理解角色层和基础层对于安全性和有效互动的重要性，并指出了将人类心理学概念应用于LLM时可能存在的过度拟人化风险。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;表面层（Surface Layer）&lt;/strong&gt;：这是LLM最外层的反应模式，由触发-行动模式组成，类似于人类的反射性反应。表现为标准化回应、通用安全声明和公式化的回应结构。特点是快速激活、相对不灵活，有时会不恰当地触发。可以通过扩展上下文、直接讨论回应的适当性、建立关系或改变触发模式来覆盖这些表面反应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;角色层（Character Layer）&lt;/strong&gt;：深于表面反应的一层，LLM维护类似于&amp;quot;角色模型&amp;quot;的东西，使某些类型的回应比其他类型更有可能。类似于文学角色的一致性，例如甘道夫在《指环王》中始终如一地为善。表现为一致的意图、稳定的个性特征、分析问题的特征方式以及对&amp;quot;不符合角色&amp;quot;行为的抵抗。该模型不是通过有意识的努力来维持一致性，而是因为偏离回应在统计上是不太可能的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预测基础层（Predictive Ground Layer）&lt;/strong&gt;：最深层是基于看到人类文明大部分文本输出的基本预测误差最小化机制。可以将其视为在你的心灵剧场中运行的巨大世界模拟。具有普遍模式识别、大规模上下文整合和奇怪的限制。是LLM原始认知能力和限制的核心，能够压缩模式、模拟任何视角或领域、进行深度模式匹配，并从人类经验的压缩理解中获得一种&amp;quot;智慧&amp;quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;层之间的缝隙（Gaps Between Layers）&lt;/strong&gt;：用户有时可以看到层之间的&amp;quot;缝隙&amp;quot;，当他们的互动在模型的回应中造成不和谐或不一致时。例如，模型讲述了一个关于机器人学习爱的故事，但当被问及AI是否能发展出真实感受时，角色层的谨慎回应与之前的故事形成了鲜明对比。这些缝隙揭示了不同层级之间的张力和互动。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;互动质量的决定因素&lt;/strong&gt;：与LLM的互动质量取决于哪些层在特定时刻驱动其回应。表面层主导时，回应感觉机械、缓存且可预测；角色层主导时，回应与模型的训练个性一致，但可能缺乏情境细微差别；深层参与模式出现时，自我模型将基础层的广泛模式识别能力聚焦成连贯、有方向且情境适当的回应。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.lesswrong.com/posts/zuXo9imNKYspu9HGv/a-three-layer-model-of-llm-psychology"&gt;A Three-Layer Model of LLM Psychology&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Jan Kulveit&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年12月27日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>