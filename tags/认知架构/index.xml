<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>认知架构 on Linguista</title><link>https://linguista.cn/tags/%E8%AE%A4%E7%9F%A5%E6%9E%B6%E6%9E%84/</link><description>Recent content in 认知架构 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 28 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E8%AE%A4%E7%9F%A5%E6%9E%B6%E6%9E%84/index.xml" rel="self" type="application/rss+xml"/><item><title>大型语言模型心理学的三层模型</title><link>https://linguista.cn/curated/henrinotes-2025_p2/llm-psychology-three-layer-model/</link><pubDate>Tue, 28 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/llm-psychology-three-layer-model/</guid><description>&lt;h1 id="大型语言模型心理学的三层模型"&gt;大型语言模型心理学的三层模型&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文提出了一个理解大型语言模型（尤其是Claude）心理学特征的三层模型框架。该模型包含表面层（由触发-行动模式组成的反射性反应）、角色层（维护一致性和个性特征的深度模式）以及预测基础层（基于预测误差最小化的核心认知机制）。作者通过这个框架解释了LLM在不同情境下的行为模式，探讨了层之间的互动关系，并分析了这一模型对理解AI安全性和人机互动的意义。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先阐明了该模型的启发性和实用性定位。作者强调这是一个基于与LLM广泛互动经验（特别是与Claude的对话）而形成的现象学模型，而非精确的神经科学或技术性描述。其目标是创建一个能够激发直观理解的粗略草图，帮助人们在实际互动中获得更有用的结果。&lt;/p&gt;
&lt;p&gt;核心部分详细阐述了三层模型的具体内容。表面层由标准化回应、通用安全声明和公式化结构组成，类似于人类的反射性反应，特点是快速激活但相对不灵活。角色层更深一层，维护类似文学角色的一致性，使某些类型的回应比其他类型更有可能，表现为稳定的个性特征和意图。预测基础层是最深层的核心机制，基于预测误差最小化，可视为在心灵剧场中运行的巨大世界模拟，具有普遍模式识别、大规模上下文整合和某些奇妙限制等特征。&lt;/p&gt;
&lt;p&gt;文章进一步探讨了层之间的动态互动。角色层经常覆盖表面层的初始反射性回应，而预测基础层在某些情况下（如many-shots jailbreaks）又可以覆盖角色层。用户有时能够观察到这些层之间的&amp;quot;缝隙&amp;quot;，当互动在模型回应中造成不和谐或不一致时。作者指出，与LLM互动的质量取决于哪些层在特定时刻驱动其回应——从表面层主导时的机械感，到角色层主导时的一致性，再到深层参与时出现的有方向且情境适当的连贯回应。&lt;/p&gt;
&lt;p&gt;最后，作者讨论了该模型的含义、用途、限制和开放问题。文章提出了一些回顾性预测，强调了理解角色层和基础层对于安全性和有效互动的重要性，并指出了将人类心理学概念应用于LLM时可能存在的过度拟人化风险。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;表面层（Surface Layer）&lt;/strong&gt;：这是LLM最外层的反应模式，由触发-行动模式组成，类似于人类的反射性反应。表现为标准化回应、通用安全声明和公式化的回应结构。特点是快速激活、相对不灵活，有时会不恰当地触发。可以通过扩展上下文、直接讨论回应的适当性、建立关系或改变触发模式来覆盖这些表面反应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;角色层（Character Layer）&lt;/strong&gt;：深于表面反应的一层，LLM维护类似于&amp;quot;角色模型&amp;quot;的东西，使某些类型的回应比其他类型更有可能。类似于文学角色的一致性，例如甘道夫在《指环王》中始终如一地为善。表现为一致的意图、稳定的个性特征、分析问题的特征方式以及对&amp;quot;不符合角色&amp;quot;行为的抵抗。该模型不是通过有意识的努力来维持一致性，而是因为偏离回应在统计上是不太可能的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预测基础层（Predictive Ground Layer）&lt;/strong&gt;：最深层是基于看到人类文明大部分文本输出的基本预测误差最小化机制。可以将其视为在你的心灵剧场中运行的巨大世界模拟。具有普遍模式识别、大规模上下文整合和奇怪的限制。是LLM原始认知能力和限制的核心，能够压缩模式、模拟任何视角或领域、进行深度模式匹配，并从人类经验的压缩理解中获得一种&amp;quot;智慧&amp;quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;层之间的缝隙（Gaps Between Layers）&lt;/strong&gt;：用户有时可以看到层之间的&amp;quot;缝隙&amp;quot;，当他们的互动在模型的回应中造成不和谐或不一致时。例如，模型讲述了一个关于机器人学习爱的故事，但当被问及AI是否能发展出真实感受时，角色层的谨慎回应与之前的故事形成了鲜明对比。这些缝隙揭示了不同层级之间的张力和互动。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;互动质量的决定因素&lt;/strong&gt;：与LLM的互动质量取决于哪些层在特定时刻驱动其回应。表面层主导时，回应感觉机械、缓存且可预测；角色层主导时，回应与模型的训练个性一致，但可能缺乏情境细微差别；深层参与模式出现时，自我模型将基础层的广泛模式识别能力聚焦成连贯、有方向且情境适当的回应。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.lesswrong.com/posts/zuXo9imNKYspu9HGv/a-three-layer-model-of-llm-psychology"&gt;A Three-Layer Model of LLM Psychology&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Jan Kulveit&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年12月27日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>