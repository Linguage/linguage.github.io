<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Email on Linguista</title>
    <link>http://localhost:1355/tags/email/</link>
    <description>Recent content in Email on Linguista</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="http://localhost:1355/tags/email/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Plan for Spam</title>
      <link>http://localhost:1355/paul_graham/essays_en/spam/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1355/paul_graham/essays_en/spam/</guid>
      <description>&lt;p&gt;→ &lt;a href=&#34;http://localhost:1355/paul_graham/essays_zh/spam/&#34;&gt;中文版本&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;a-plan-for-spam&#34;&gt;A Plan for Spam&lt;/h1&gt;&#xA;&lt;p&gt;August 2002&lt;/p&gt;&#xA;&lt;p&gt;(This article describes the spam-filtering techniques used in the spamproof web-based mail reader we built to exercise Arc. An improved algorithm is described in Better Bayesian Filtering.)&lt;/p&gt;&#xA;&lt;p&gt;I think it&amp;rsquo;s possible to stop spam, and that content-based filters are the way to do it. The Achilles heel of the spammers is their message. They can circumvent any other barrier you set up. They have so far, at least. But they have to deliver their message, whatever it is. If we can write software that recognizes their messages, there is no way they can get around that.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Better Bayesian Filtering</title>
      <link>http://localhost:1355/paul_graham/essays_en/better/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1355/paul_graham/essays_en/better/</guid>
      <description>&lt;p&gt;→ &lt;a href=&#34;http://localhost:1355/paul_graham/essays_zh/better/&#34;&gt;中文版本&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;better-bayesian-filtering&#34;&gt;Better Bayesian Filtering&lt;/h1&gt;&#xA;&lt;p&gt;January 2003&lt;/p&gt;&#xA;&lt;p&gt;(This article was given as a talk at the 2003 Spam Conference. It describes the work I&amp;rsquo;ve done to improve the performance of the algorithm described in A Plan for Spam, and what I plan to do in the future.)&lt;/p&gt;&#xA;&lt;p&gt;The first discovery I&amp;rsquo;d like to present here is an algorithm for lazy evaluation of research papers. Just write whatever you want and don&amp;rsquo;t cite any previous work, and indignant readers will send you references to all the papers you should have cited. I discovered this algorithm after &amp;ldquo;A Plan for Spam&amp;rdquo; [1] was on Slashdot.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Filters that Fight Back</title>
      <link>http://localhost:1355/paul_graham/essays_en/ffb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1355/paul_graham/essays_en/ffb/</guid>
      <description>&lt;p&gt;→ &lt;a href=&#34;http://localhost:1355/paul_graham/essays_zh/ffb/&#34;&gt;Chinese Version&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;filters-that-fight-back&#34;&gt;Filters that Fight Back&lt;/h1&gt;&#xA;&lt;p&gt;August 2003&lt;/p&gt;&#xA;&lt;p&gt;We may be able to improve the accuracy of Bayesian spam filters by having them follow links to see what&amp;rsquo;s waiting at the other end. Richard Jowsey of death2spam now does this in borderline cases, and reports that it works well.&lt;/p&gt;&#xA;&lt;p&gt;Why only do it in borderline cases? And why only do it once?&lt;/p&gt;&#xA;&lt;p&gt;As I mentioned in Will Filters Kill Spam?, following all the urls in a spam would have an amusing side-effect. If popular email clients did this in order to filter spam, the spammer&amp;rsquo;s servers would take a serious pounding. The more I think about this, the better an idea it seems. This isn&amp;rsquo;t just amusing; it would be hard to imagine a more perfectly targeted counterattack on spammers.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
