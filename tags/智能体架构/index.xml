<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>智能体架构 on Linguista</title><link>https://linguista.cn/tags/%E6%99%BA%E8%83%BD%E4%BD%93%E6%9E%B6%E6%9E%84/</link><description>Recent content in 智能体架构 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 13 Jun 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%99%BA%E8%83%BD%E4%BD%93%E6%9E%B6%E6%9E%84/index.xml" rel="self" type="application/rss+xml"/><item><title>Anthropic 如何构建多智能体研究系统</title><link>https://linguista.cn/rosetta/technology/how-we-built-multi-agent-research-system/</link><pubDate>Fri, 13 Jun 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/how-we-built-multi-agent-research-system/</guid><description>&lt;h1 id="anthropic-如何构建多智能体研究系统"&gt;Anthropic 如何构建多智能体研究系统&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Anthropic 分享了其多智能体研究系统从原型到产品的构建经验。该系统采用编排者-工作者模式，由主智能体协调多个并行子智能体完成复杂研究任务。文章详述了系统架构设计、工具选择、提示工程原则以及评估方法，并指出多智能体系统在广度优先的并行研究任务中性能比单智能体高出90.2%，但令牌消耗也达到普通聊天的15倍。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;编排者-工作者模式&lt;/strong&gt;：一种多智能体架构范式，由一个主智能体负责任务分解与协调，将子任务分派给多个并行运行的专用子智能体执行，最终汇总结果&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多智能体系统&lt;/strong&gt;：由多个自主使用工具的LLM智能体协同工作的系统，通过并行探索和独立上下文窗口实现对复杂问题的高效研究&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;提示工程&lt;/strong&gt;：通过精心设计提示词来引导智能体行为的技术，包括任务委派描述、复杂度匹配、搜索策略引导和思考过程控制等关键实践&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;检索增强生成(RAG)&lt;/strong&gt;：传统的静态检索方法，与本文多步骤动态搜索架构形成对比，后者能根据中间发现自适应调整检索策略&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;令牌经济性&lt;/strong&gt;：多智能体系统的核心权衡问题，令牌使用量解释了80%的性能差异，但系统消耗约为普通聊天的15倍，需要任务价值足以覆盖成本&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/094d7021ebd5cf57eabd63b456899c97f5231c88-1000x1000.svg" alt=""&gt;&lt;/p&gt;
&lt;h1 id="我们如何构建多智能体研究系统"&gt;我们如何构建多智能体研究系统&lt;/h1&gt;
&lt;p&gt;发布于 2025 年 6 月 13 日&lt;/p&gt;
&lt;p&gt;我们的研究功能利用多个 Claude 智能体来更有效地探索复杂主题。我们在此分享构建该系统过程中遇到的工程挑战和汲取的经验教训。&lt;/p&gt;
&lt;p&gt;Claude 现在具备了&lt;a href="https://www.anthropic.com/news/research"&gt;研究能力&lt;/a&gt;，使其能够搜索网络、Google Workspace 以及任何集成应用，以完成复杂任务。&lt;/p&gt;
&lt;p&gt;这个多智能体系统从原型到产品的整个过程，让我们在系统架构、工具设计和提示工程方面学到了关键的经验。一个多智能体系统由多个智能体（自主循环使用工具的 LLM）协同工作。我们的研究功能包含一个智能体，它根据用户查询规划研究过程，然后使用工具创建并行智能体，同时搜索信息。多智能体系统在智能体协调、评估和可靠性方面引入了新的挑战。&lt;/p&gt;
&lt;p&gt;本文将详细解析对我们行之有效的原则——我们希望您在构建自己的多智能体系统时会发现它们有所裨益。&lt;/p&gt;
&lt;h3 id="多智能体系统的优势"&gt;多智能体系统的优势&lt;/h3&gt;
&lt;p&gt;研究工作涉及开放式问题，很难预先预测所需的步骤。探索复杂主题无法硬编码固定路径，因为这个过程本质上是动态且路径依赖的。人们在进行研究时，往往会根据发现不断更新方法，追踪调查过程中出现的线索。&lt;/p&gt;
&lt;p&gt;这种不可预测性使得 AI 智能体特别适合研究任务。研究要求在调查展开时能够灵活调整方向或探索相关的分支。模型必须自主运行多个回合，根据中间结果决定追求哪个方向。线性的、一次性处理的流程无法处理这些任务。&lt;/p&gt;
&lt;p&gt;搜索的本质是压缩：从庞大的语料库中提炼洞见。子智能体通过在各自的上下文窗口中并行操作，同时探索问题的不同方面，然后将最重要的令牌（tokens）浓缩给主研究智能体，从而促进压缩。每个子智能体还实现了关注点分离——拥有独特的工具、提示和探索轨迹——这减少了路径依赖性，并实现了彻底、独立的调查。&lt;/p&gt;
&lt;p&gt;一旦智能达到某个阈值，多智能体系统就成为扩展性能的重要途径。例如，尽管个体人类在过去 10 万年中变得更加智能，但由于我们的&lt;em&gt;集体&lt;/em&gt;智能和协调能力，人类社会在信息时代的能力却实现了&lt;em&gt;指数级&lt;/em&gt;增长。即使是通用智能体，在作为个体运作时也会面临限制；智能体群体可以完成更多的工作。&lt;/p&gt;
&lt;p&gt;我们的内部评估表明，多智能体研究系统在涉及同时进行多个独立方向探索的广度优先查询方面表现尤为出色。我们发现，在我们的内部研究评估中，以 Claude Opus 4 为主智能体、Claude Sonnet 4 为子智能体的多智能体系统，其性能比单智能体的 Claude Opus 4 高出 90.2%。例如，当被要求识别信息技术标准普尔 500 指数中所有公司的董事会成员时，多智能体系统通过将任务分解给子智能体找到了正确答案，而单智能体系统则因缓慢的顺序搜索未能找到答案。&lt;/p&gt;
&lt;p&gt;多智能体系统之所以有效，主要是因为它们有助于消耗足够的令牌来解决问题。在我们的分析中，三个因素解释了 &lt;a href="https://openai.com/index/browsecomp/"&gt;BrowseComp&lt;/a&gt; 评估（测试浏览智能体定位难以找到信息的能力）中 95% 的性能差异。我们发现，仅令牌使用量本身就解释了 80% 的差异，工具调用次数和模型选择是另外两个解释因素。这一发现验证了我们的架构，该架构将工作分配给具有独立上下文窗口的智能体，以增加并行推理的能力。最新的 Claude 模型充当了令牌使用效率的大幅倍增器，因为升级到 Claude Sonnet 4 比在 Claude Sonnet 3.7 上将令牌预算翻倍带来的性能提升更大。多智能体架构有效地扩展了令牌使用量，以应对超出单个智能体限制的任务。&lt;/p&gt;
&lt;p&gt;但也有一个缺点：在实践中，这些架构消耗令牌的速度很快。我们的数据显示，智能体通常比聊天交互多使用约 4 倍的令牌，而多智能体系统比聊天多使用约 15 倍的令牌。为了实现经济可行性，多智能体系统需要任务的价值足够高，以支付其性能提升带来的成本。此外，一些需要所有智能体共享相同上下文或智能体之间存在许多依赖关系的领域，目前并不适合多智能体系统。例如，大多数编码任务涉及的可真正并行化的任务比研究要少，而且 LLM 智能体在实时协调和委派给其他智能体方面尚不擅长。我们发现，多智能体系统在涉及大量并行化、信息量超出单个上下文窗口以及与众多复杂工具交互的有价值任务中表现出色。&lt;/p&gt;</description></item></channel></rss>