<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI架构 on Linguista</title><link>https://linguista.cn/tags/ai%E6%9E%B6%E6%9E%84/</link><description>Recent content in AI架构 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 24 Aug 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/ai%E6%9E%B6%E6%9E%84/index.xml" rel="self" type="application/rss+xml"/><item><title>AGI的未来是系统工程而非模型训练</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/agi-future-systems-engineering-not-models/</link><pubDate>Sun, 24 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/agi-future-systems-engineering-not-models/</guid><description>&lt;h1 id="agi的未来是系统工程而非模型训练"&gt;AGI的未来是系统工程而非模型训练&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文核心观点是通往人工通用智能的道路不在于继续扩大语言模型的规模，而在于构建由模型、记忆、上下文和确定性工作流组成的工程化系统。当前主流大模型已接近能力极限，单纯依靠堆算力和扩参数已无法带来质的突破。AGI的本质是一个系统工程问题，需要分布式系统、上下文管理、记忆服务、确定性与概率性结合的工作流，以及多模型协作的架构创新。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先指出了现有大语言模型已达到能力平台期。日常使用者能明显感受到其局限性：虽然能生成高质量文本，但在跨会话保持上下文、持久记忆、复杂多步推理等方面表现不佳。这种技术发展轨迹与半导体行业类似，当主频提升遇到物理极限后，行业转向多核架构带来新一轮创新。AI领域也正处于类似拐点，继续做大模型的边际收益正在递减。&lt;/p&gt;
&lt;p&gt;未来的关键问题不再是如何让模型更大，而是如何让系统更智能。这意味着需要从模型训练转向系统工程，关注模型之间的协作、信息流动和可靠性。AGI的突破不在于更大的Transformer，而在于能编排数百专用模型、跨会话保持上下文、围绕概率性组件执行确定性工作流，并在生产级规模下实现容错操作的分布式系统。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;上下文管理基础设施&lt;/strong&gt;：现有模型的注意力跨度仅为数千token，而人类的上下文跨度可以覆盖数年甚至一生。这种差距不仅是数量级的，更是质量上的。理想的上下文管理系统需要具备按需检索和过滤相关信息、构建并维护可持续演化的世界模型、跨领域桥接上下文、处理冲突信息等能力。这需要从简单的向量检索升级到可操作知识图谱，实现实时更新、查询和推理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;记忆服务&lt;/strong&gt;：现有LLM没有真正的记忆，只能通过提示工程和上下文填充模拟记忆。AGI需要具备真正的记忆系统，能够在新证据出现时更新信念、跨多次体验整合信息形成一般性原则、忘记无关细节但避免灾难性遗忘、生成关于信息可靠性和来源的元知识。这不仅是数据库持久化，更是类人记忆系统，使用越多越牢固，久未使用则逐渐遗忘，遇新理解时能重组记忆结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;确定性工作流与概率性组件结合&lt;/strong&gt;：AGI的突破点在于用确定性框架包裹概率性组件。类似编译器的设计理念，整体流程可预测，但某些步骤可用启发式或概率优化。理想系统应根据问题特征将任务路由到合适的专用求解器、执行多步工作流并具备回滚与恢复能力、在接受概率性结果前进行确定性校验、以可预测方式组合各能力同时保留生成式模型的灵活性。不确定性应成为系统设计的一级公民。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;专用模型的模块化协作&lt;/strong&gt;：未来不是单一模型包打天下，而是数百数千个专用模型协同工作。语言模型在语言任务上表现优异，但在符号运算、视觉空间推理、时间规划、持续目标行为等方面表现不佳。应构建能够将问题路由到最适合的专用模型的系统、整合不同模型输出为统一解决方案、保持各组件兼容性允许独立进化、在个别模型失效时优雅处理不影响整体系统。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三阶段架构路线图&lt;/strong&gt;：第一阶段为基础层，包含上下文管理服务、记忆服务、工作流引擎和Agent协调层；第二阶段为能力层，包含专用模型控制、符号推理引擎、规划与目标管理、跨模态整合；第三阶段为涌现层，真正的AGI将从上述各组件的协同作用中涌现，而非单一模型突破。系统能力将超越各部分总和，依赖于精心设计的架构。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.vincirufus.com/posts/agi-is-engineering-problem/"&gt;AGI is an Engineering Problem&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Vinci Rufus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未注明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>构建长运行智能体的理论与实践</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/dont-build-multi-agents/</link><pubDate>Fri, 22 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/dont-build-multi-agents/</guid><description>&lt;h1 id="构建长运行智能体的理论与实践"&gt;构建长运行智能体的理论与实践&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;当前智能体开发尚处于早期阶段，主流的多智能体架构在实际生产环境中表现不佳。本文指出上下文工程是智能体开发的核心，远比提示工程更为重要。作者主张采用单线程线性智能体架构，确保所有决策和行动在同一上下文中连续进行，从而避免误解和冲突。对于超长任务，可通过专门的 LLM 模型压缩历史上下文来提升处理能力。现阶段多智能体协作技术尚未成熟，单智能体架构更为可靠。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章开篇即指出智能体开发领域缺乏统一标准，类似于网页开发早期的混沌状态。当前主流的多智能体框架（如 OpenAI Swarm、Microsoft Autogen）在复杂任务中容易导致错误累积和决策冲突。作者通过 Flappy Bird 克隆开发实例，说明了子智能体之间缺乏完整上下文共享会导致风格不一致和功能不匹配等问题。&lt;/p&gt;
&lt;p&gt;核心论点围绕&amp;quot;上下文工程&amp;quot;展开，这是智能体开发的关键原则。文章强调两大原则：共享上下文和行动隐含决策。所有子智能体必须获得完整的任务背景和前序决策轨迹，而每个行动都包含隐含决策，若各智能体的决策冲突，最终结果必然不理想。解决方案是采用单线程线性智能体架构，所有决策和行动都在同一上下文中连续进行。&lt;/p&gt;
&lt;p&gt;文章通过三个真实案例支撑论点：Claude Code 的子智能体设计选择了串行而非并行模式；代码编辑模型从分离式架构转向单一模型一次性完成；多智能体并行协作在理论上可行但现实中技术尚未成熟。作者认为，随着单智能体与人类沟通能力的提升，未来多智能体协作的瓶颈会自然突破。&lt;/p&gt;
&lt;p&gt;最后，文章提出了上下文工程框架和相应的心智模型。智能体开发者需时刻关注上下文传递和决策一致性，在架构设计时权衡上下文窗口限制与系统复杂度。对于超长任务，可采用专门模型压缩历史上下文，提取关键决策和事件。未来智能体发展需要保持开放心态，持续迭代框架和方法。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;上下文工程&lt;/strong&gt;：这是智能体开发的核心工作，远超传统的提示工程。它要求系统能自动、动态地为智能体提供最关键的任务背景和决策信息，确保所有行动都基于完整的任务背景和前序决策轨迹。在长运行智能体中，上下文工程是确保系统可靠性的关键，需要针对具体领域进行模型微调来压缩历史上下文。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;单线程线性智能体&lt;/strong&gt;：这是作者推荐的最简单且有效的架构。所有决策和行动都在同一上下文中连续进行，极大减少误解和冲突。与多智能体并行架构相比，单线程智能体避免了子智能体之间的上下文隔离问题，确保决策一致性。这种架构虽然可能在效率上有所妥协，但在可靠性方面具有显著优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;行动隐含决策&lt;/strong&gt;：每个行动都包含隐含的决策过程，若各智能体的决策冲突，最终结果必然不理想。这一概念揭示了多智能体架构失败的深层原因：即使各子智能体完成了各自的表面任务，如果背后的决策逻辑不一致，合成的结果仍然不可用。理解这一概念有助于开发者在设计智能体系统时更加注重决策过程的一致性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;前序决策轨迹&lt;/strong&gt;：这是共享上下文的重要组成部分，指的是所有子智能体必须获得的完整任务背景和历史决策记录。仅仅复制原始任务文本是不够的，因为实际生产系统往往是多轮对话，涉及工具调用和多层细节。前序决策轨迹确保每个后续行动都能充分理解之前的决策过程和原因，从而做出协调一致的决策。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上下文窗口溢出&lt;/strong&gt;：这是单线程架构面临的主要技术限制。当任务过于复杂时，历史行动和对话可能超出模型的上下文窗口容量。解决方案是引入专门的 LLM 模型，将历史行动和对话压缩为关键细节和决策。这一方法难度较高，但能显著提升智能体处理长上下文的能力，是实现真正可靠的长运行智能体的关键技术。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://cognition.ai/blog/dont-build-multi-agents"&gt;Don&amp;rsquo;t Build Multi-Agents&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Walden Yan&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-06-12&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>微软提出RAG应对用户四级查询难度的方案</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/microsoft-rag-four-level-query-classification/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/microsoft-rag-four-level-query-classification/</guid><description>&lt;h1 id="微软提出rag应对用户四级查询难度的方案"&gt;微软提出RAG应对用户四级查询难度的方案&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;微软研究院针对检索增强生成（RAG）技术在专业领域部署中面临的挑战，提出了用户查询任务的四级分类体系。该体系从显式事实查询到隐性推理依据查询，逐级递增复杂度，并为每个级别设计了相应的技术解决方案，包括迭代RAG、链式思维提示、微调等策略，旨在帮助开发者根据具体查询类型选择合适的知识注入方法。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;大语言模型通过整合外部数据能够显著提升其在特定领域的任务完成能力。外部数据增强不仅使模型能够获得领域专业知识，还增强了其时间相关性、输出可控性和可解释性。检索增强生成（RAG）和微调等技术因此受到广泛关注，但在实际部署到专业领域时仍面临诸多挑战。&lt;/p&gt;
&lt;p&gt;微软研究院的核心贡献在于建立了一个系统的用户查询分类框架。该框架将查询任务分为四个难度级别：第一级是显式事实查询，可通过明确文本片段直接回答；第二级是隐式事实查询，需要整合多个数据源进行逻辑推断；第三级是明确推理依据的查询，需要理解应用外部资源中明确提供的推理规则；第四级是隐性推理依据的查询，推理依据未明确记录，需要从数据中观察模式推断。&lt;/p&gt;
&lt;p&gt;针对这四个级别，研究团队给出了差异化的技术解决方案。对于简单的显式查询，重点解决数据处理和检索问题；对于复杂的隐式查询，则需要迭代RAG、基于图或树的问答、NL2SQL等高级技术；当涉及推理依据时，需要采用提示调整、链式思维提示或构建Agent工作流；而对于最复杂的隐性推理查询，则可能需要离线学习、上下文学习或模型微调。研究同时提出了给LLMs整合外部数据的三种主要形式，为开发者提供了系统的方法论指导。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;显式事实查询&lt;/strong&gt;：这是最基础的查询级别，答案可以通过明确的文本片段直接获得，通常依赖单一数据源。例如询问&amp;quot;2024年夏季奥运会举办地&amp;quot;，这类查询的主要挑战在于数据处理效率、检索准确性以及RAG系统性能的评估，而不涉及复杂的推理过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;隐式事实查询&lt;/strong&gt;：这类查询需要整合多个分散的数据来源，建立逻辑关联才能得出答案。例如&amp;quot;实验样本量大于1000的数量有多少&amp;quot;，信息可能分散在文档的不同部分。其挑战包括信息分散、复杂推理需求、自适应检索量控制、推理与检索的协调以及多跳推理。解决方案包括迭代RAG、基于图或树的问答系统、自然语言转SQL、智能检索与推理结合以及动态信息整合等技术。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;明确推理依据的查询&lt;/strong&gt;：这类查询不仅需要事实信息，还需要理解和应用特定的推理规则或工作流程，且这些依据在外部资源中有明确提供。例如胸痛患者的诊断治疗流程或客户服务工作流程应对。主要挑战包括提示优化成本高、可解释性有限、多步推理复杂性等。解决方案涉及提示调整技术、链式思维提示、利用LLM本身进行提示优化以及构建Agent工作流。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;隐性推理依据的查询&lt;/strong&gt;：这是最高级别的查询，推理依据或规则并未明确记录在文档中，需要从外部数据中观察模式和结果来推断。例如评估经济形势对公司未来发展的影响。主要挑战是逻辑检索困难和数据不足，解决方案包括离线学习、上下文学习和模型微调等方法，让模型通过数据学习隐含的推理模式。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/k-r4rfDftlsoSGkGoXOlGw"&gt;RAG怎么面对用户的4级查询难度？微软给出方案！&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;微软研究院&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>