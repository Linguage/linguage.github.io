<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>机器学习 on Linguista</title><link>https://linguista.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><description>Recent content in 机器学习 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 27 Jan 2026 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml"/><item><title>黄仁勋：人工智能的未来与NVIDIA的创新之路</title><link>https://linguista.cn/rosetta/chat-notes/jensen-huang-future-of-ai-and-nvidia-innovation/</link><pubDate>Tue, 27 Jan 2026 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/jensen-huang-future-of-ai-and-nvidia-innovation/</guid><description>&lt;h1 id="黄仁勋人工智能的未来与nvidia的创新之路"&gt;黄仁勋：人工智能的未来与NVIDIA的创新之路&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;NVIDIA CEO黄仁勋与WWT CEO Jim Kavanaugh展开深度对话，回顾了从IBM System/360到GPU革命的计算发展历程，阐述NVIDIA如何在十年内将计算性能提升百万倍，并展望AI代理、主权AI、AI教育等前沿话题，描绘人工智能开启新工业革命的宏大图景。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/q54RnCUwDuY]%28https://www.youtube.com/watch?v=q54RnCUwDuY?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="黄仁勋：人工智能的未来与NVIDIA的创新之路"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;主权AI&lt;/strong&gt;：指各国构建自主可控的人工智能基础设施，将数据和智能能力视为国家主权的一部分，以保护本国数据安全并推动本土AI发展&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI代理&lt;/strong&gt;：能够自主执行任务的智能软件实体，未来企业将部署大量AI代理承担营销、客服、开发等工作，与人类员工协同运作&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一性原理&lt;/strong&gt;：从最基本的事实和假设出发进行推理的思维方式，NVIDIA以此指导技术方向判断，坚定投入人形机器人和AI驱动的应用等前沿领域&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;摩尔定律突破&lt;/strong&gt;：传统摩尔定律预测性能每十年提升百倍，而NVIDIA通过GPU和加速计算架构创新，在十年内实现了百万倍的性能飞跃&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RAG模型&lt;/strong&gt;：检索增强生成技术，企业通过将自有数据与大语言模型结合，构建专属AI平台，实现业务场景的智能化和差异化竞争&lt;/p&gt;
&lt;p&gt;黄仁勋：人工智能的未来与NVIDIA的创新之路&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原文标题：The Future of AI with NVIDIA Founder and CEO Jensen Huang&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;链接：&lt;a href="https://www.youtube.com/watch?v=q54RnCUwDuY"&gt;https://www.youtube.com/watch?v=q54RnCUwDuY&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;文章类别&lt;/strong&gt;：访谈实录&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;内容整理&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文章框架&lt;/strong&gt;：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 开场介绍
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 主持人对黄仁勋的介绍
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 主持人对活动参与者的欢迎
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 黄仁勋的演讲
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 人工智能的历史与现状
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── NVIDIA的发展历程与技术突破
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 人工智能在各领域的应用
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 语言处理
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 图像与视频处理
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 科学计算与医疗
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 人工智能对行业的变革
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 未来展望与人工智能的潜力
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 互动环节
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 观众提问
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 人工智能与网络安全
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 人工智能与国家主权
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 人工智能与教育
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 黄仁勋的回答与观点
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└── 结语
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; ├── 主持人的总结
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; └── 黄仁勋对未来的展望
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;文章内容&lt;/strong&gt;：&lt;/p&gt;</description></item><item><title>文艺复兴科技公司交易策略揭秘</title><link>https://linguista.cn/rosetta/chat-notes/renaissance-technologies-trading-strategies-revealed/</link><pubDate>Mon, 26 Jan 2026 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/renaissance-technologies-trading-strategies-revealed/</guid><description>&lt;h1 id="文艺复兴科技公司交易策略揭秘"&gt;文艺复兴科技公司交易策略揭秘&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文详细介绍了文艺复兴科技公司的发展历程及其核心交易策略。创始人詹姆斯·西蒙斯从数学家转型为对冲基金经理，带领团队先后开发了均值回归模型、核方法机器学习模型和短期交易策略，将奖章基金打造为史上最成功的对冲基金，自1988年以来费前年均回报率达66%。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/lji-jNsXmAM?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="文艺复兴科技公司交易策略揭秘"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;均值回归&lt;/strong&gt;：一种统计策略，认为资产价格会围绕长期均值波动，偏离均值后将回归，适用于商品和货币等市场的趋势判断&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核方法&lt;/strong&gt;：一类用于模式分析的非线性机器学习算法，相比传统线性回归更能捕捉资产价格的非线性变动规律&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;凯利判据&lt;/strong&gt;：科学赌博方法的核心公式，主张投注规模应与对该投注的信心成正比，帮助在风险与收益之间实现最优配置&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大数定律&lt;/strong&gt;：统计学基本定律，表明在大量重复试验中结果趋近于期望值，文艺复兴科技以此思想支撑高频短期交易的盈利逻辑&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;市场冲击与滑点&lt;/strong&gt;：大规模交易执行时实际成交价格偏离预期价格的现象，文艺复兴科技通过建模交易成本解决了股票策略初期亏损的问题&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=lji-jNsXmAM"&gt;视频链接&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="引言"&gt;引言&lt;/h3&gt;
&lt;p&gt;文艺复兴科技公司是历史上盈利能力最强的对冲基金。这很可能是在业绩记录方面，行业历史上最成功的对冲基金。记住，他收费很高，但费用前，自 1988 年以来平均为 66%。这家公司取得巨大成功的背后，是一系列数学模型和强大的计算机。文艺复兴科技公司的量化模型在不断更新，但比这些模型更重要的是，用于发现交易信号的方式和方法。&lt;/p&gt;
&lt;h3 id="谁是詹姆斯西蒙斯"&gt;谁是詹姆斯·西蒙斯&lt;/h3&gt;
&lt;p&gt;詹姆斯·西蒙斯，文艺复兴科技公司的创始人，是一位传奇数学家。他开创了一种独特的研究和模型构建方法，并将其带入对冲基金领域。他身价 210 亿美元，是全球收入最高的对冲基金经理。&lt;/p&gt;
&lt;p&gt;吉姆·西蒙斯在马萨诸塞州布鲁克林长大，一直知道自己想成为一名数学家。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“我还是学生的时候，经常在深夜去一家熟食店，有一天我看到安布罗斯和辛格也深夜进来，他们显然在做数学，我见过好几次，我就想，哇，这才是世界上最棒的工作！你可以只是闲逛，在熟食店闲逛，然后做数学。”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;西蒙斯考入了麻省理工学院，甚至因为高中时修读了大学先修课程，跳过了数学的第一年。西蒙斯的学术生涯非常顺利，获得博士学位后，他很快成为数学教授，并同时在冷战时期担任密码破译员。但他渴望更多，尤其是更多的钱！西蒙斯在中产阶级家庭长大，一直想致富。与学术界其他不太关心钱的人不同，西蒙斯则清楚地知道如何赚钱——创业。还在上学期间，他就和他的南美同学一起创业，他们决定开一家工厂生产乙烯基地砖和 PVC 管道。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“嗯，我在麻省理工学院认识了一些朋友，是两个哥伦比亚男孩，他们在某个时候开始创业，事实上，正是在我的鼓励下他们才开始创业的，我的父亲和我投入了少量资金，最终，嗯，获得了巨大的成功。”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是詹姆斯·西蒙斯的一个故事，很多人都不知道，所以他抽出时间来经营这家公司，但一旦公司走上正轨，他立即将责任委托给其他人，我们在 RenTech 的故事中一次又一次地看到了这一点，但西蒙斯必须专注于他的学术生涯。1976 年，37 岁时，西蒙斯被美国数学学会授予奥斯瓦尔德·维布伦几何学奖，这个奖项是数学领域的最高荣誉，相当于诺贝尔奖。&lt;/p&gt;
&lt;p&gt;征服了一座高峰后，西蒙斯正在寻找新的高峰去攀登。1974 年，西蒙斯和他的朋友合伙创办的地砖公司出售了 50% 的股份，为西蒙斯和其他所有者带来了利润。西蒙斯和他的同学们从这家公司赚了很多钱。他说，让我们把钱投资出去。所以西蒙斯认识他的一位学生，名叫查理·弗拉特费尔德，他当时经营着一家对冲基金。出乎西蒙斯最疯狂的期望，他将他们的原始投资翻了 10 倍，总共赚了 600 万美元。这是西蒙斯意识到赚钱的最佳方式是金融的时刻。他想知道，我能做到同样的事情吗？1978 年，西蒙斯离开学术界，开始用他积攒的钱和他朋友的钱创办了自己的投资公司，名为 Money Metrics。&lt;/p&gt;
&lt;h3 id="西蒙斯的交易策略"&gt;西蒙斯的交易策略&lt;/h3&gt;
&lt;p&gt;在 Money Metrics 成立后的几年里，西蒙斯依靠直觉和基本面进行交易。那是金融业的好时代，基金运作良好，他真的不需要改变他的方法，但在他的脑海中，他一直在想，他能否用数学来模拟资产价格。但西蒙斯开始厌倦基本面交易。&lt;/p&gt;</description></item><item><title>动物与幽灵</title><link>https://linguista.cn/rosetta/technology/animals-vs-ghosts/</link><pubDate>Sat, 04 Oct 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/animals-vs-ghosts/</guid><description>&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;动物可能是一个很好的灵感来源。内在动机、乐趣、好奇心、赋能、多智能体自我博弈、文化。&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Andrej Karpathy在本文中探讨了人工智能领域中“动物”智能与大语言模型（“幽灵”）的差异，反思了学习机制、进化和预训练的本质，并提出动物或许能为AI带来新的灵感和范式。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://ts1.tc.mm.bing.net/th/id/R-C.5b6ee267317d44b17842e771033bc7f4?rik=U6xjpiLj2AM6Mw&amp;amp;riu=http%3a%2f%2fn.sinaimg.cn%2fsinakd20117%2f762%2fw1000h562%2f20230516%2f61f2-929bc75cae6683aec311ff02b0528b5e.jpg&amp;amp;ehk=YX8liBBPYwNpcJkyffP6ne%2b5uHTTJzeDIJnnV%2f%2fKEPM%3d&amp;amp;risl=&amp;amp;pid=ImgRaw&amp;amp;r=0" alt=""&gt;&lt;/p&gt;</description></item><item><title>大型语言模型与世界模型第一部分LLMs如何理解它们的世界</title><link>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-part-1/</link><pubDate>Sat, 22 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/llms-world-models-part-1/</guid><description>&lt;h1 id="大型语言模型与世界模型第一部分llms-如何理解它们的世界"&gt;大型语言模型与世界模型（第一部分）：LLMs 如何理解它们的&amp;quot;世界&amp;quot;&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文由 Melanie Mitchell 撰写，深入探讨了大型语言模型（LLMs）是否发展出了类似人类的&amp;quot;世界模型&amp;quot;以理解其运作的&amp;quot;世界&amp;quot;。文章回顾了早期机器学习系统的脆弱性问题，介绍了世界模型的概念定义与分类方法，并围绕 LLMs 是否真正具备世界模型能力展开了学术界的重要辩论。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先通过多个经典案例揭示了早期 AI 系统的根本局限性——它们依赖于训练数据中的启发式规则和表面特征，而非真正的概念理解。从皮肤病变分类错误地依赖尺子存在，到语言模型仅凭词汇重叠判断逻辑关系，再到强化学习系统在游戏设置微小变化下的性能崩溃，这些案例都指向同一个问题：缺乏对世界因果结构的理解。&lt;/p&gt;
&lt;p&gt;接着文章转向当前备受争议的话题——大型语言模型是否突破了这一局限。OpenAI 联合创始人 Ilya Sutskever 认为，通过预测下一个词的训练目标，LLMs 确实学习了世界的压缩表征，包括人类的情感和动机。然而，包括 Yann LeCun 在内的多位研究者对此表示强烈怀疑，认为仅靠语言训练无法达到真正的理解。2022 年的一项调查显示，NLP 研究者群体在这一问题上几乎呈现对半分的分裂态势。&lt;/p&gt;
&lt;p&gt;为了厘清这一辩论，文章详细梳理了&amp;quot;世界模型&amp;quot;的多种定义。从最基础的内部表征到保留因果结构的复杂模型，再到能够支持反事实推理的完整模拟器。MIT 教授 Jacob Andreas 提出了一个清晰的分类框架，从静态查找表、地图、机械天体仪到完整的模拟器，每种类型代表了对世界理解的不同深度。人类正是通过这样的世界模型，才能快速理解复杂场景、预测因果关系并规划行动。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;世界模型&lt;/strong&gt;：指智能体内部形成的、对外部世界的压缩且可模拟的表征，它不仅能够存储信息，还能捕捉世界的因果结构，支持预测、规划和回答反事实问题。人类的世界模型使我们能够在瞬间理解街景照片中的复杂场景，推断行为者的意图和可能的后续发展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启发式规则与表面特征&lt;/strong&gt;：早期机器学习系统依赖的捷径思维，它们通过发现训练数据中的统计关联来解决问题，但这种方式缺乏真正的理解。就像皮肤病变分类器记住&amp;quot;尺子=恶性&amp;quot;这样的关联，当环境变化时就会失效，因为系统并不理解尺子和病变之间的真实关系。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;情境模型&lt;/strong&gt;：LLMs 可能具备的一种中间层次世界模型，能够跟踪文本中的行为者、状态和动作变化。这类似于一个机械天体仪，可以模拟特定场景中的动态过程，但可能缺乏对更广泛世界因果知识的整合。目前尚不清楚 LLMs 的情境模型能否推广到训练数据之外的全新场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;因果模拟模型&lt;/strong&gt;：世界模型的最高层次，能够回答复杂的&amp;quot;如果-那么&amp;quot;类型反事实问题，需要对世界的深层因果结构有精确理解。目前缺乏证据表明 LLMs 具备这种能力，这是判断它们是否真正&amp;quot;理解&amp;quot;世界的关键检验标准。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://aiguide.substack.com/p/llms-and-world-models-part-1"&gt;LLMs and World Models, Part 1 - How do Large Language Models Make Sense of Their &amp;ldquo;Worlds&amp;rdquo;?&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Melanie Mitchell&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未明确说明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>听觉健康中的时间精度机器学习助力神经科学研究</title><link>https://linguista.cn/curated/henrinotes_2025_p4/hearing-timing-precision-machine-learning/</link><pubDate>Tue, 21 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p4/hearing-timing-precision-machine-learning/</guid><description>&lt;h1 id="听觉健康中的时间精度机器学习助力神经科学研究"&gt;听觉健康中的时间精度：机器学习助力神经科学研究&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;MIT麦戈文脑研究所通过人工神经网络模型模拟人类听觉系统，揭示了听觉神经元尖峰发射的时间精度对声音识别和定位的关键作用。研究表明，精确的时间编码是人类听觉功能的基础，这一发现为理解听力障碍机制和优化助听设备设计提供了重要科学依据。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本研究针对听觉神经科学中的一个核心问题——神经元时间精度对听觉处理的重要性——展开探索。由于动物模型无法提供人类语言和音乐感知的见解，而人类听觉神经又难以直接研究，研究团队采用了创新的人工神经网络方法来解决这一实验困境。&lt;/p&gt;
&lt;p&gt;研究人员开发了包含约32,000个模拟听觉感受器神经元的网络模型，并通过优化使其完成识别单词和声音等现实世界任务。实验分别在多种背景噪声条件下测试了模型表现，并与人类听觉行为进行了对比验证。研究发现，当降低模拟耳中神经元尖峰的时间精度时，模型在声音识别和声源定位方面的能力显著下降，这强有力地证明了时间编码的必要性。&lt;/p&gt;
&lt;p&gt;这项研究的意义超越了基础神经科学领域。它不仅为理解不同类型的听力障碍提供了新的诊断视角，更重要的是为助听器和人工耳蜗等听力辅助设备的设计优化指明了方向——未来的设备需要更好地模拟自然耳的精确时间编码机制。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;时间编码&lt;/strong&gt;：听觉神经元通过精确匹配声波振荡的发射时间来传递声音信息，这种毫秒级的时间精度是区分复杂声音信号的基础，研究证实其对听觉功能具有决定性影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人工神经网络模拟&lt;/strong&gt;：研究采用机器学习模型模拟人类听觉系统，包含32,000个模拟感受器神经元，这种方法克服了传统动物模型和人体直接研究的局限性，为听觉研究提供了新范式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;听觉障碍的异质性&lt;/strong&gt;：不同类型的听力损失可能源于时间编码机制的不同环节受损，这一发现有助于开发更精准的诊断方法和针对性更强的干预措施。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;听力辅助设备的优化方向&lt;/strong&gt;：现有的助听器和人工耳蜗主要关注声音放大，而研究结果表明，保留和还原自然耳的时间精度特征将是下一代设备设计的关键突破点。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://news.mit.edu/2025/for-healthy-hearing-timing-matters-0114"&gt;For healthy hearing, timing matters&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;MIT麦戈文脑研究所&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>新计算化学技术加速分子和材料预测</title><link>https://linguista.cn/curated/henrinotes_2025_p4/computational-chemistry-molecular-prediction-acceleration/</link><pubDate>Tue, 21 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p4/computational-chemistry-molecular-prediction-acceleration/</guid><description>&lt;h1 id="新计算化学技术加速分子和材料预测"&gt;新计算化学技术加速分子和材料预测&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;MIT研究团队开发了一种名为MEHnet的神经网络方法，基于量子化学&amp;quot;黄金标准&amp;quot;耦合簇理论CCSD(T)训练，能够以高于密度泛函理论DFT的精度预测分子和材料的多种电子属性。该技术采用E(3)等变图神经网络架构，可同时评估偶极矩、四极矩、电子极化率和光学激发带隙等多种属性，适用于基态和激发态分析，有望实现高通量分子筛选并推动新型聚合物、半导体及电池材料的开发。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本文从材料科学的历史演变切入，回顾了从古代炼金术到19世纪元素周期表的出现，再到过去十年机器学习在材料科学领域的应用历程。尽管这些进步极大地推动了材料设计发展，但现有基于密度泛函理论DFT的机器学习模型仍存在精度不均匀和只能提供最低总能量等局限性。&lt;/p&gt;
&lt;p&gt;为解决这些问题，MIT核科学与工程系Ju Li教授领导的团队转向耦合簇理论CCSD(T)，这种被公认为量子化学&amp;quot;黄金标准&amp;quot;的方法虽然计算精度可与实验媲美，但计算成本极高。研究团队开发的MEHnet神经网络通过定制算法，能够直接从量子力学原理中提取分子属性，在保持CCSD(T)级别精度的同时大幅降低计算成本。&lt;/p&gt;
&lt;p&gt;该技术的核心创新在于采用E(3)等变图神经网络架构，其中节点代表原子，边代表原子间的化学键。更关键的是，MEHnet采用多任务学习方法，能够同时评估分子的多种电子属性，不仅适用于基态分析，还适用于激发态研究，甚至可以预测分子的红外吸收光谱。在对已知烃类分子的测试中，MEHnet的表现优于DFT方法，并与文献中的实验结果高度一致。&lt;/p&gt;
&lt;p&gt;这项技术的应用前景广阔，有望实现高通量分子筛选，这对识别具有特定属性的新分子和材料至关重要。研究团队表示，该技术可用于设计新型聚合物或半导体材料，甚至可能推动电池材料的开发。目前模型能够处理多达数千个原子的分子，未来有望扩展到数万个原子的分子系统。团队的长期目标是覆盖整个元素周期表，并以低于DFT的计算成本实现CCSD(T)级别的精度。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;耦合簇理论CCSD(T)&lt;/strong&gt;：量子化学领域的&amp;quot;黄金标准&amp;quot;方法，其计算结果的准确性可与实验结果媲美。传统CCSD(T)方法的计算成本极高，限制了其应用范围。MIT团队通过神经网络技术，使这一高精度方法得以在更大规模分子系统中应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;E(3)等变图神经网络&lt;/strong&gt;：一种专门处理三维空间数据的神经网络架构。在MEHnet中，图神经网络的节点代表分子中的原子，边代表原子之间的化学键。这种架构能够保持三维空间中的旋转和平移不变性，非常适合处理分子结构数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多任务学习&lt;/strong&gt;：MEHnet能够同时学习分子的多种电子属性，包括偶极矩、四极矩、电子极化率和光学激发带隙等。与单一任务学习相比，多任务学习能够利用不同属性之间的相关性，提高模型的泛化能力和预测精度，同时也使得模型适用于基态和激发态分析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;高通量分子筛选&lt;/strong&gt;：指在短时间内对大量分子候选进行计算评估，从中筛选出具有目标特性的分子。传统高精度量子化学方法计算成本过高，无法实现高通量筛选。MEHnet在保持CCSD(T)级别精度的同时大幅降低计算成本，使得高通量分子筛选成为可能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;激发态与红外光谱预测&lt;/strong&gt;：与大多数只能处理基态的量子化学方法不同，MEHnet能够处理分子的激发态，这使其能够预测分子的光学吸收性质。此外，模型还可以预测分子的红外吸收光谱，这对于实验化学家进行分子结构确认和性质研究具有重要意义。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://news.mit.edu/2025/new-computational-chemistry-techniques-accelerate-prediction-molecules-materials-0114"&gt;New computational chemistry techniques accelerate the prediction of molecules and materials&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;MIT News&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-14&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>算法与人工智能助力社会进步</title><link>https://linguista.cn/curated/henrinotes_2025_p4/algorithms-ai-social-good/</link><pubDate>Tue, 21 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p4/algorithms-ai-social-good/</guid><description>&lt;h1 id="算法与人工智能助力社会进步"&gt;算法与人工智能助力社会进步&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文介绍MIT助理教授Manish Raghavan的研究工作，他专注于利用算法和人工智能技术解决社会问题。文章探讨了AI在招聘、医疗、社交媒体等领域的应用及其潜在风险，并提出通过提高AI系统的可观察性来减少偏见和歧视。Raghavan的研究强调，AI系统比人类决策更容易被监测和优化，这为改善社会系统提供了新的机会。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以Manish Raghavan的研究为主线，展现了算法与人工智能在社会问题上的双重作用。一方面，AI技术在招聘、医疗分诊等领域展现出提高效率的潜力；另一方面，基于历史数据的AI系统可能继承并放大人类已有的偏见。Raghavan的核心观点是，AI系统的&amp;quot;可观察性&amp;quot;恰恰是解决这些问题的关键——相比人类决策的黑箱，算法系统更容易被监测、评估和改进。&lt;/p&gt;
&lt;p&gt;在招聘领域，Raghavan指出传统招聘方式本身存在问题，而AI工具虽然可能继承偏见，但其透明性使发现问题成为可能。医疗领域的研究展示了算法如何与专家经验结合，提高患者分诊的准确性。社交媒体方面，他和团队开发了考虑用户短期与长期福祉的模型，该研究获得了ACM经济学与计算会议的应用建模奖。&lt;/p&gt;
&lt;p&gt;Raghavan的研究方法强调从复杂问题中寻找创新解决方案，他的工作获得了国家科学基金会、微软研究等机构的认可。除了学术研究，他还担任哈佛男子足球俱乐部教练，体现了工作与生活的平衡理念。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;算法可观察性&lt;/strong&gt;：这是Raghavan研究的核心洞见。相比人类决策过程的复杂性和不可预测性，AI系统的决策过程可以被记录、分析和改进。这种可观察性使得我们能够及时发现系统中的偏见和错误，并通过算法调整来纠正问题。在招聘等敏感领域，这种透明性尤为重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;短期满足与长期福祉的平衡&lt;/strong&gt;：社交媒体算法往往优化用户的短期参与度（如点击率、停留时间），但这可能与用户的长期福祉相冲突。Raghavan开发的模型试图将这两种维度结合起来，通过改变平台设计来鼓励更健康的用户行为。这为平台经济中企业利益与用户利益的统一提供了思路。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人机协作而非替代&lt;/strong&gt;：在医疗分诊的研究中，Raghavan并非追求完全自动化的AI决策，而是探索如何将高精度算法（如Glasgow-Blatchford Score）与专家医生的经验智慧相结合。这种人机协作的模式体现了对AI技术的理性态度——不是取代人类，而是增强人类决策能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史数据的双刃剑&lt;/strong&gt;：AI系统训练于历史数据，这意味着它们既可能学习到有价值的模式，也可能继承历史中的偏见和歧视。Raghavan的研究承认这一现实，但认为正视问题比回避问题更有意义。通过提高系统的可见性，我们可以主动识别并纠正这些偏见。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;复杂问题的搁置与重构&lt;/strong&gt;：Raghavan分享了一个独特的研究方法——当面对复杂棘手的问题时，先将其搁置一段时间，然后再重新思考。这种&amp;quot;冷处理&amp;quot;有助于打破思维定式，往往能带来新的视角和解决方案。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://news.mit.edu/2024/algorithms-ai-better-world-manish-raghavan-1206"&gt;Algorithms and AI for a better world&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;MIT News&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-12-06&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>2024年诺贝尔物理学奖得主John Hopfield和Geoffrey Hinton获奖演讲</title><link>https://linguista.cn/curated/henrinotes_2025_p4/nobel-physics-2024-hopfield-hinton-lectures/</link><pubDate>Fri, 17 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p4/nobel-physics-2024-hopfield-hinton-lectures/</guid><description>&lt;h1 id="2024年诺贝尔物理学奖得主john-hopfield和geoffrey-hinton获奖演讲"&gt;2024年诺贝尔物理学奖得主John Hopfield和Geoffrey Hinton获奖演讲&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文记录了2024年诺贝尔物理学奖得主John Hopfield和Geoffrey Hinton在颁奖典礼上的演讲内容。Hopfield以&amp;quot;问题选择&amp;quot;为主题，分享了从凝聚态物理转向神经科学的科研历程，详细阐述了霍普菲尔德模型的灵感来源及其与自旋系统的数学联系。Hinton则深入浅出地解释了霍普菲尔德网络、玻尔兹曼机和受限玻尔兹曼机的工作原理，以及如何利用随机神经元和热平衡概念构建深度学习系统。两位科学家的研究为现代人工智能的发展奠定了坚实基础。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;演讲从瑞典皇家科学院的开场致辞开始，回顾了诺贝尔奖自1901年以来的历史，强调在充满挑战的2024年，科学发现对人类应对全球危机的重要性。今年的诺贝尔物理学奖表彰了在人工神经网络和机器学习领域的奠基性工作，这些技术已经深刻影响了图像识别、语音识别和医疗应用等多个领域。&lt;/p&gt;
&lt;p&gt;John Hopfield的演讲围绕&amp;quot;问题选择&amp;quot;这一主题展开，分享了他从贝尔实验室理论物理小组开始的科研生涯。他强调了跨学科思维在科研中的重要性——从凝聚态物理到生物物理再到神经科学的转变过程。Hopfield详细描述了霍普菲尔德模型的诞生过程：将物理学中自旋系统的数学工具应用于神经科学，用能量函数描述联想记忆的动态行为。他特别指出，1982年发表在PNAS上的简洁论文因其未说明的内容反而扩大了影响力，吸引了众多物理学家和计算机科学家进入该领域。&lt;/p&gt;
&lt;p&gt;Geoffrey Hinton的演讲以通俗易懂的方式解释了复杂的技术概念。他从霍普菲尔德网络的基本原理开始，介绍了二元神经元、能量最小化和内容可寻址存储的概念。Hinton重点阐述了玻尔兹曼机的学习算法，包括&amp;quot;清醒阶段&amp;quot;和&amp;quot;睡眠阶段&amp;quot;的机制，以及如何通过随机神经元和热平衡避免局部最优解。尽管玻尔兹曼机因计算速度慢未被广泛应用，但受限玻尔兹曼机和对比散度算法的提出使得这一技术最终实用化，并在2009-2012年间推动了语音识别的革命性突破。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;霍普菲尔德网络与联想记忆&lt;/strong&gt;：Hopfield将物理学中自旋系统的数学模型应用于神经科学，提出用能量函数描述神经网络的动态行为。网络中的每个状态对应一个能量值，系统通过局部更新规则自动收敛到能量最小值，从而实现内容可寻址的联想记忆——即使输入部分信息也能恢复完整记忆。这种对称连接的二元网络为理解大脑记忆机制提供了物理学的定量框架。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;玻尔兹曼机与随机学习&lt;/strong&gt;：Hinton引入随机神经元概念，使系统能够跳出局部最优解。玻尔兹曼机的学习算法包含两个阶段：清醒阶段将图像钳制在可见单元并增加同时激活神经元间的连接权重，睡眠阶段让网络&amp;quot;做梦&amp;quot;并减少梦中同时激活的权重。这一简单而优雅的算法使网络能够自动学习数据的潜在特征，无需手工设计连接。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;热平衡与概率分布&lt;/strong&gt;：不同于确定性系统的稳定状态，随机神经网络在热平衡时稳定的是构型的概率分布——玻尔兹曼分布。在这个分布中，低能量构型（好的解释）比高能量构型更有可能出现。通过将大量相同网络的系综进行并行更新并观察比例变化，可以直观理解这一统计物理概念在机器学习中的应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;受限玻尔兹曼机与对比散度&lt;/strong&gt;：为解决玻尔兹曼机计算速度慢的问题，Hinton提出了限制隐藏神经元之间连接的架构，并开发了对比散度算法：只需将数据向上传递到隐藏层，再向下重构，再次向上传递即可。这个&amp;quot;偷懒&amp;quot;的捷径在实践中效果出色，使得玻尔兹曼机最终在Netflix推荐比赛和语音识别等领域得到实际应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;深度预训练与特征层次&lt;/strong&gt;：通过堆叠多个RBM，可以构建深层网络。每一层RBM学习前一层隐藏特征之间的相关性，形成越来越抽象的特征检测器。这种无监督预训练方法大幅提高了后续监督学习的速度和泛化能力，被认为是深度学习突破的关键技术之一，尽管后来被其他初始化方法取代，但作为&amp;quot;历史酶&amp;quot;开启了深度神经网络的新时代。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=lPIVl5eBPh8"&gt;2024 Nobel Prize lectures in physics | John Hopfield and Geoffrey Hinton - YouTube&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;John Hopfield, Geoffrey Hinton&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>AI领域新动态训练成本下降、桌面AI超级计算机、出口限制和改进的对比损失</title><link>https://linguista.cn/curated/henrinotes_2025_p4/ai-training-costs-export-restrictions-2025/</link><pubDate>Fri, 17 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p4/ai-training-costs-export-restrictions-2025/</guid><description>&lt;h1 id="ai领域新动态训练成本下降桌面ai超级计算机出口限制和改进的对比损失"&gt;AI领域新动态：训练成本下降、桌面AI超级计算机、出口限制和改进的对比损失&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文全面梳理了AI领域的最新重要动态。DeepSeek-V3模型以仅560万美元的训练成本超越GPT-4o，展现了基础模型训练成本的大幅下降趋势；美国出台新的AI出口限制，建立三级国际芯片获取体系；Nvidia发布桌面AI超级计算机Project Digits，定价3000美元；Meta团队提出X-CLR对比损失函数，在视觉模型训练中取得突破性成果。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;AI产品管理正迎来新的机遇期。随着软件开发成本尤其是原型开发成本的降低，对能够决定构建什么的产品经理需求将持续增长。AI产品经理需要具备技术熟练度、迭代开发思维、数据理解能力以及管理模糊性的能力，这将是一个快速发展的职业方向。&lt;/p&gt;
&lt;p&gt;在模型训练方面，DeepSeek-V3的开源发布标志着基础模型训练经济学的重大变化。该模型在6710亿参数规模上实现卓越性能，训练成本却仅为560万美元，不到Llama 3.1 405B训练成本的十分之一。如果这一成果可复制，将有更多团队具备训练GPT-4o级别模型的能力，AI领域的竞争格局可能被重塑。&lt;/p&gt;
&lt;p&gt;硬件层面，Nvidia推出Project Digits桌面AI超级计算机，配备128GB统一内存和基于Blackwell架构的GB10芯片，定价3000美元。这将使机器学习工程师能够在本地训练和运行更大规模的模型，降低对云基础设施的依赖。&lt;/p&gt;
&lt;p&gt;国际政策方面，美国提出新的AI出口限制，建立三级国际芯片获取体系。第一层级国家如日本、英国等维持几乎不受限制的访问权限；第二层级国家如以色列、新加坡面临TPP上限；第三层级国家包括中国和俄罗斯被阻止接收先进AI芯片。这些规则还将首次限制大型AI模型的封闭权重出口。&lt;/p&gt;
&lt;p&gt;机器学习研究方面，Meta、纽约大学等机构的团队提出X-CLR对比损失函数。与传统对比损失不同，X-CLR为示例分配连续的相似性分数而非简单的二元标签，使模型能够学习更细致的嵌入表示。在ImageNet分类任务中，X-CLR在训练数据较少时表现优于SimCLR和CLIP。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;基础模型训练成本下降&lt;/strong&gt;：DeepSeek-V3以560万美元的训练成本实现GPT-4o级别的性能，这一突破性进展可能彻底改变AI领域的竞争格局。如果更多团队能够以类似成本训练高质量的基础模型，AI巨头的算力壁垒将被削弱，行业可能迎来更多元化的创新生态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三级AI出口管制体系&lt;/strong&gt;：美国新建立的芯片出口三级分类体系实质上构建了一个以美国为核心盟友圈的技术壁垒。第一层级国家获得几乎不受限制的访问权限，第二层级国家面临计算能力上限，第三层级国家被完全排除在外。这一政策可能加速非美国国家在AI技术上的自主化进程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;桌面AI超级计算机&lt;/strong&gt;：Project Digits将企业级AI计算能力带入消费级价格区间，使个人开发者和小团队能够在本地进行模型微调和大规模推理。这一产品可能催生更多本地优先的AI工作流，降低数据隐私风险和云服务成本。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;X-CLR对比损失函数&lt;/strong&gt;：X-CLR通过使用连续相似性分数替代二元标签，使模型能够学习更细粒度的数据表示。这一方法在小样本学习场景下表现优异，为自监督学习提供了新的思路，可能推动视觉模型训练效率的进一步提升。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI产品管理的机遇与挑战&lt;/strong&gt;：AI开发工具的普及降低了编码门槛，但提高了对产品决策能力的要求。能够理解AI技术可能性、管理迭代开发过程、处理模糊性结果的产品经理将成为稀缺资源，这将重塑AI团队的技能结构。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://info.deeplearning.ai/tumbling-training-costs-desktop-ai-supercomputer-tighter-ai-export-restrictions-improved-contrastive-loss"&gt;Tumbling Training Costs, Desktop AI Supercomputer, Tighter AI Export Restrictions, Improved Contrastive Loss&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;DeepLearning.AI&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-17&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>强化学习基础与贝尔曼方程详解</title><link>https://linguista.cn/curated/henrinotes_2025_p3/reinforcement-learning-bellman-equation-fundamentals/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/reinforcement-learning-bellman-equation-fundamentals/</guid><description>&lt;h1 id="强化学习基础与贝尔曼方程详解"&gt;强化学习基础与贝尔曼方程详解&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文基于西湖大学赵世钰老师《强化学习的数学原理》课程，系统性地介绍了强化学习的核心概念体系。从策略、奖励、回报等基本要素出发，逐步构建马尔可夫决策过程的理论框架，重点阐述了贝尔曼方程的数学原理及其在状态值和动作值计算中的应用，为深入理解强化学习提供了清晰的数学基础。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先建立了强化学习的基本概念体系，通过具体示例说明了策略的概率分布特性、奖励的数值含义以及回报的累积计算方式。作者强调，奖励是依赖于当前状态和动作的标量值，可正可负，而回报则是沿轨迹收集的所有奖励之和，用于评估策略优劣。文章还引入了Episode的概念，将完整轨迹定义为一次回合。&lt;/p&gt;
&lt;p&gt;在理论基础部分，文章详细解析了马尔可夫决策过程的三大核心要素：马尔可夫属性的无记忆性特征、决策过程的策略定义、以及涉及状态转移概率和奖励概率的完整过程描述。这部分内容为后续的贝尔曼方程推导奠定了数学基础。&lt;/p&gt;
&lt;p&gt;文章的核心内容围绕贝尔曼方程展开，介绍了理查德·贝尔曼在1950年代提出的最优性原理。作者通过状态价值函数和动作价值函数两种形式，详细阐述了如何通过未来可能价值来计算当前价值。文章特别强调了回报与状态值的本质区别：回报针对单个轨迹，而状态值是对多个轨迹求回报后的平均值。&lt;/p&gt;
&lt;p&gt;在应用层面，文章讲解了动作值的定义和计算方法，阐明了状态值与动作值之间的数学关系，即状态值等于不同动作对应的动作值的加权平均。最后通过Bellman最优性方程，引入了最优策略的存在性和唯一性证明，完整构建了从基础概念到高级理论的强化学习知识体系。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;策略（Policy）&lt;/strong&gt;：策略定义了智能体在给定状态下应采取各种动作的概率分布。文章通过表格示例展示了在S1状态下执行a2、a3动作各为0.5的概率配置，并提供了相应的编程实现代码。策略的核心作用是将状态映射到动作空间，是强化学习中决策机制的基础。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bootstrap概念&lt;/strong&gt;：这是贝尔曼方程的核心思想，描述了所有状态之间值的相互依赖关系。通过bootstrap，当前状态的价值可以通过未来状态的价值来估计，这种递归性质使得强化学习能够通过迭代计算逐步优化策略。文章在策略评价和最优值计算中都强调了这一概念的重要性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;状态值与动作值的关系&lt;/strong&gt;：状态值V(s)表示从某个状态出发的期望回报，而动作值Q(s,a)则表示从某个状态执行特定动作的期望回报。两者的关键关系在于：状态值等于该状态下所有可能动作的动作值按策略概率加权平均。这一关系为策略改进和最优策略求解提供了数学基础。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最优性原理&lt;/strong&gt;：贝尔曼提出的这一原理指出，如果一个策略在每个子问题上都是最优的，那么它对整个问题就是全局最优的。这一原理不仅具有深刻的数学美感，更为动态规划和强化学习算法提供了理论支撑，是理解最优策略存在性和唯一性的关键。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/I1TjXMwSInlW7CFe1SXlGw"&gt;强化学习：概念和贝尔曼方程&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;赵世钰（西湖大学）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;来源&lt;/td&gt;
 &lt;td&gt;《强化学习的数学原理》课程整理&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>快速入门卷积神经网络CNN</title><link>https://linguista.cn/curated/henrinotes_2025_p3/cnn-convolutional-neural-network-guide/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/cnn-convolutional-neural-network-guide/</guid><description>&lt;h1 id="快速入门卷积神经网络cnn"&gt;快速入门卷积神经网络（CNN）&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;卷积神经网络（Convolutional Neural Network，CNN）是专门设计用于处理具有空间结构数据（如图像）的深度学习架构。本文通过通俗易懂的语言和生动的比喻，系统介绍了CNN的核心组成部分——卷积层、激活函数、池化层和全连接层，并提供PyTorch和Keras两种框架的完整代码实现示例，帮助读者从零开始理解并构建CNN模型。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先阐述了CNN的基本定义和核心优势——能够自动从图像等空间数据中提取特征。作者通过一个生动的例子：当我们观察一张苹果照片时，眼睛会先识别边缘、颜色、纹理等局部特征，大脑再整合这些信息最终识别出&amp;quot;苹果&amp;quot;。CNN正是模拟这一过程，通过层层特征提取实现图像识别。&lt;/p&gt;
&lt;p&gt;接下来，文章详细拆解了CNN的四大核心组件。卷积层如同用放大镜观察图像局部，通过滑动过滤器提取特征；激活函数引入非线性变换，使网络能够学习复杂的模式；池化层对特征图进行降维，减少计算量同时保留关键信息；全连接层则负责整合所有特征并输出最终分类结果。&lt;/p&gt;
&lt;p&gt;最后，文章以经典的CIFAR-10图像分类数据集为例，提供了完整的CNN模型实现代码，分别使用PyTorch和Keras两种主流深度学习框架，让读者能够直接上手实践。这种理论与实践相结合的方式，使抽象的神经网络概念变得具体可操作。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;卷积层&lt;/strong&gt;：CNN的核心特征提取组件，通过可学习的过滤器（Filter）在输入数据上滑动，执行卷积运算生成特征图。每个过滤器专注于提取特定类型的特征（如边缘、纹理、颜色模式），浅层卷积层提取简单特征，深层卷积层组合形成更复杂的抽象特征。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;激活函数&lt;/strong&gt;：为神经网络引入非线性的关键组件，最常用的是ReLU（Rectified Linear Unit），它将所有负值置零而保持正值不变。这种简单而有效的操作使网络能够学习和表示复杂的非线性关系，避免了线性模型的表达能力限制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;池化层&lt;/strong&gt;：用于降低特征图空间维度的下采样操作，最大池化（Max Pooling）取每个局部区域的最大值作为输出。池化不仅减少了计算量和参数数量，还提供了一定程度的平移不变性，使模型对物体位置的微小变化更加鲁棒。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;全连接层&lt;/strong&gt;：位于CNN末尾的分类器组件，将前面卷积层提取的局部特征整合成全局特征向量，通过矩阵运算输出每个类别的得分。全连接层负责将特征映射到最终的类别空间，完成从特征到决策的转换。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特征层次化&lt;/strong&gt;：CNN的核心设计理念是通过多层网络实现特征的层次化提取。低层网络学习简单的边缘和颜色特征，中层网络组合这些基础特征形成纹理和形状，高层网络则识别出完整的物体部件和整体概念，这种层层递进的特征抽象使CNN具备了强大的视觉理解能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/2ynT7bYrrWwNOP-NH8EbwQ"&gt;快速入门一个算法，CNN&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;chal1ce&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年01月05日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>重新思考 MoE 技术及其在大模型中的应用</title><link>https://linguista.cn/curated/henrinotes_2025_p3/moe-technology-rethinking-large-language-models/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/moe-technology-rethinking-large-language-models/</guid><description>&lt;h1 id="重新思考-moe-技术及其在大模型中的应用"&gt;重新思考 MoE 技术及其在大模型中的应用&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文系统性地梳理了混合专家技术在大语言模型中的演进历程。作者从内部世界模型对齐的视角出发，深入分析了GShard、DeepSeek MoE、DeepSeek-V3等架构的技术特点，探讨了RPC-Attention和MoDE等创新方法，并最终从认知框架层面重新解读了MoE的本质——一种基于先验知识的跨范畴采样策略。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章开篇提出了一个关键观点：MoE大模型如果不能在内部世界模型上实现对齐和互换，其输出将呈现人格分裂的状态。作者将内部世界模型定义为&amp;quot;现实的共享统计模型&amp;quot;或&amp;quot;以概率为表征的丰富范畴&amp;quot;，这为后续的技术分析奠定了理论基础。&lt;/p&gt;
&lt;p&gt;在架构演进方面，文章详细剖析了四个关键发展阶段。GShard作为早期的MoE实现，通过轻量级标注API和XLA编译器扩展，实现了万亿级参数的支持。DeepSeek MoE针对GShard存在的知识混杂和冗余问题，创新性地提出了细粒度专家分段和共享专家隔离策略。DeepSeek-V3则进一步整合了MLA注意力机制和无辅助损失的负载均衡策略，在6710亿总参数中每个token仅激活370亿参数，实现了训练与推理的高效平衡。&lt;/p&gt;
&lt;p&gt;技术创新部分，文章介绍了RPC-Attention通过核PCA框架推导自注意力，提供了对数据污染具有鲁棒性的解决方案。MoDE则将MoE思想扩展到扩散模型，通过噪声调节路由和专家缓存机制，将推理成本降低了90%。&lt;/p&gt;
&lt;p&gt;最后，作者从认知科学角度重新诠释了MoE的本质，将其视为一种分布式采样策略，这一策略可以基于人类先验知识，在高维语言概率空间中实现跨范畴的智能推理。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;内部世界模型对齐&lt;/strong&gt;：这是作者对MoE技术提出的核心要求。内部世界模型指模型对现实的共享统计表征，当不同的专家模块在这个表征上实现对齐时，模型才能产生连贯一致的输出，而非人格分裂的结果。这一概念将技术问题提升到了认知科学的高度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;细粒度专家分段&lt;/strong&gt;：DeepSeek MoE的核心创新之一。通过在保持参数量不变的情况下，将FFN中间隐藏维度拆分为更细粒度的专家，使模型能够激活更多专家并实现更灵活的组合。这种设计让多样化的知识能够更精确地分配到专门的专家中，提升专精度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;共享专家隔离&lt;/strong&gt;：针对知识冗余问题的解决方案。将某些专家设计为始终激活的共享专家，专门捕获跨上下文的共享知识，从而减少其他路由专家之间的冗余，提高整体参数效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;跨范畴采样&lt;/strong&gt;：作者对MoE本质的哲学解读。MoE中的&amp;quot;专家&amp;quot;本质上是&amp;quot;特定范畴&amp;quot;的形象化表达，模型推理的过程是在高维语言概率空间的子空间中进行采样，而类比推理则是跨范畴的采样过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;噪声条件路由&lt;/strong&gt;：MoDE架构的关键机制。将路由器设计为噪声条件化的，使得在推理前可以预先计算每个噪声水平使用的专家，从而去除路由器，仅保留选定专家，显著提升网络效率。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/p7C9zXZRY5iE0Q-d8GRkaQ"&gt;重新思考 MoE&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;未知作者&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>N-Gram模型与自然语言处理入门</title><link>https://linguista.cn/curated/henrinotes_2025_p3/n-gram-model-natural-language-processing-introduction/</link><pubDate>Thu, 09 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/n-gram-model-natural-language-processing-introduction/</guid><description>&lt;h1 id="n-gram模型与自然语言处理入门"&gt;N-Gram模型与自然语言处理入门&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文系统介绍了N-Gram模型的基本原理及其在自然语言处理中的重要作用。作为理解概率语言模型的基础和深入理解现代语言模型如GPT的重要前奏，文章详细阐述了N-Gram模型的定义、构建过程、优缺点以及实际应用场景。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先强调N-Gram模型在自然语言处理学习路径中的核心地位，指出理解N-Gram是迈向GPT等现代语言模型的第一步。GPT的核心思想正是对N-Gram思想的深度拓展和优化。&lt;/p&gt;
&lt;p&gt;文章详细介绍了N-Gram模型的基本概念：通过将文本分割成连续的N个词的组合来近似描述词序列的联合概率。根据N的不同取值，可以分为Unigram（一元组）、Bigram（二元组）和Trigram（三元组）等不同类型。每种类型都有其特定的上下文依赖假设，从仅考虑当前词到依赖前面N-1个词的序列。&lt;/p&gt;
&lt;p&gt;在实现方面，文章阐述了N-Gram模型的构建过程，包括文本分割、词频统计、条件概率计算和预测生成四个步骤。通过训练语料中的频率统计，可以近似得到条件概率，从而预测下一个词出现的可能性。文章还特别强调了&amp;quot;词&amp;quot;的定义在不同语言中的差异，以及子词分词算法在处理未登录词等问题上的优势。&lt;/p&gt;
&lt;p&gt;文章客观分析了N-Gram模型的优点和局限性。优点包括简单高效、广泛适用和灵活可调；缺点主要体现在数据稀疏性、上下文局限和维度增长等方面。尽管存在这些限制，N-Gram模型仍在拼写检查、机器翻译和文本生成等实际应用场景中发挥着重要作用。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;N-Gram定义&lt;/strong&gt;：N-Gram是指文本中连续的N个词的组合。它的核心思想是用有限的上下文信息（N-1个词）来近似预测下一个词的概率。这种简化使得概率计算成为可能，是构建统计语言模型的基础方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;条件概率估计&lt;/strong&gt;：通过训练语料中的频率统计来近似计算条件概率。具体公式为给定前N-1个词时，下一个词出现的条件概率等于该N-gram在语料中的共现次数除以前缀的出现次数。这种基于统计的方法简单直接，不需要复杂的参数学习。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据稀疏性&lt;/strong&gt;：N-Gram模型面临的主要挑战之一。当N值较大时，很多可能的N-gram组合在训练语料中从未出现，导致概率为零，这在实际应用中会造成问题。平滑技术是解决这一问题的常用方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;上下文局限&lt;/strong&gt;：N-Gram模型只能捕获有限长度（N-1个词）的上下文信息，无法理解文本中的长距离依赖关系。这是相对于现代深度学习语言模型的一个主要限制，也是GPT等模型通过注意力机制试图突破的瓶颈。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;子词分词&lt;/strong&gt;：将单词切分成更小有意义部分的算法。对于处理未登录词、拼写错误和词汇变化等问题非常有效。比如将&amp;quot;embedding&amp;quot;切分为[&amp;ldquo;em&amp;rdquo;, &amp;ldquo;bed&amp;rdquo;, &amp;ldquo;ding&amp;rdquo;]，能够在保证语义完整性的同时提高模型的泛化能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/itcpsLv6x-4Thk9B2-BtTQ"&gt;入门GPT（一）| N-Gram 带你了解自然语言处理（1）&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;原作者&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-09&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>2025年获取机器学习职位的六个秘密技巧</title><link>https://linguista.cn/curated/henrinotes_2025_p3/ml-job-tips-2025-six-secret-strategies/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/ml-job-tips-2025-six-secret-strategies/</guid><description>&lt;h1 id="2025年获取机器学习职位的六个秘密技巧"&gt;2025年获取机器学习职位的六个秘密技巧&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;在2025年，获取机器学习职位看似充满挑战，但关键在于如何有效地展示自己的技能和价值。本文作者结合自身成为顶尖AI初创公司研究员的经历，总结了六个实用技巧：通过个人项目展示实战能力、深入研究开源代码并贡献修复、积极参与开源社区、在社交媒体建立个人品牌、持续学习提升技能、以及利用专业网络平台建立联系。这些策略帮助求职者在竞争激烈的AI领域中脱颖而出。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从求职者的实际困境出发，指出了许多人在申请机器学习职位时面临的核心问题——不知道如何有效展示自己的能力。作者以亲身经历为例，说明仅仅拥有理论知识是不够的，更重要的是将技能转化为可证明的成果。&lt;/p&gt;
&lt;p&gt;文章主体部分详细阐述了六个具体可操作的技巧。第一个技巧强调个人项目的重要性，这不仅是技能的展示，更是解决实际问题能力的证明。第二个技巧通过真实案例说明深入研究开源代码的价值——作者的朋友在使用Hugging Face transformers库时发现并修复了一个bug，不仅提升了性能，也展示了对技术的深度理解。&lt;/p&gt;
&lt;p&gt;接下来的四个技巧构成了一个完整的职业发展闭环：参与社区和开源项目能够增加曝光率并建立有价值的行业联系；在社交媒体上建立个人品牌则能让潜在雇主看到你的专业见解和持续学习的热情；保持学习状态确保技能不过时；而有意识的网络建设则为机会创造条件。&lt;/p&gt;
&lt;p&gt;文章最后强调，在2025年的AI求职市场中，成功不再取决于单一的学历或证书，而是通过综合运用这些策略，构建起立体化的专业形象和技能证明体系。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;个人项目展示&lt;/strong&gt;：这不仅是代码练习，更是将抽象的机器学习知识转化为具体解决方案的过程。优秀的个人项目应该解决实际问题，而不仅仅是复现论文或教程。这种实战经验向雇主证明你能够将理论应用于真实场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;开源贡献&lt;/strong&gt;：深入研究开源代码库并发现bug、提出改进，展示了对技术的深度理解。这种贡献不仅证明技术能力，更体现主动性和对社区的参与度，是很多顶尖公司看重的品质。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;个人品牌建设&lt;/strong&gt;：在LinkedIn、Twitter等平台分享学习心得、项目经验和技术见解，能够建立起持续学习和专业思考的形象。这种可见度在被动求职时尤为重要，很多机会来源于雇主对你的主动关注。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;社区参与&lt;/strong&gt;：积极参与开源项目、技术论坛和线下活动，能够接触到行业前沿动态，建立有价值的职业网络。在AI领域，很多机会来自于人脉推荐而非常规申请渠道。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;持续学习&lt;/strong&gt;：机器学习领域更新迅速，保持学习状态是基本要求。但更重要的是将学习转化为可见的输出——项目、文章、贡献，而不仅仅是完成课程或阅读论文。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://towardsai.net/p/artificial-intelligence/my-6-secret-tips-for-getting-an-ml-job-in-2025?ref=dailydev"&gt;My 6 Secret Tips for Getting an ML Job in 2025&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Boris Meinardus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月7日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>下一代提示工程的七种技术</title><link>https://linguista.cn/curated/henrinotes_2025_p3/next-generation-prompt-engineering-techniques/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/next-generation-prompt-engineering-techniques/</guid><description>&lt;h1 id="下一代提示工程的七种技术"&gt;下一代提示工程的七种技术&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文深入探讨了七种下一代提示工程技术，这些技术旨在优化大型语言模型的性能和输出质量。文章通过详细的表格对比，系统介绍了每种技术的工作原理、应用场景、优势及挑战，并提供了具体示例，为AI从业者提供了实用的提示工程实践指南。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章开篇即点明提示工程在提升LLM性能中的关键作用，随后通过结构化的方式逐一介绍七种先进技术。每种技术都从定义、工作原理、优势、挑战和实际应用示例五个维度进行阐述，使读者能够全面理解并快速应用到实践中。&lt;/p&gt;
&lt;p&gt;这七种技术涵盖了从简单到复杂的多个层面：Meta Prompting让LLM自身生成和优化提示；Least-to-Most Prompting通过问题分解降低复杂度；Multi-Task Prompting实现单次执行多个任务；Role Prompting通过角色定位增强专业性；Task-Specific Prompting针对特定任务优化；PAL引入编程环境增强问题解决能力；CoVe则通过验证机制提升准确性。&lt;/p&gt;
&lt;p&gt;文章强调，这些技术并非孤立存在，而是可以根据具体需求组合使用。选择合适的技术需要考虑任务复杂性、所需输出质量以及模型的知识储备等因素。通过系统化的提示工程，用户可以显著提升LLM在实际应用中的表现。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Meta Prompting（元提示）&lt;/strong&gt;：这是一种递归式的提示方法，将提示本身视为输出内容。利用LLM生成、解释和优化提示，包括优化其自身的提示。这种方法特别适合需要持续迭代和调整的复杂任务，但效果受限于LLM的知识库范围。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Least-to-Most Prompting（最少到最多提示）&lt;/strong&gt;：核心思想是将复杂问题拆解为一系列有序的子问题，引导模型逐步解决。这种方法能够提高准确性，减少错误累积，特别适用于已知解决方案路径的复杂推理任务，如数学计算或逻辑推理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multi-Task Prompting（多任务提示）&lt;/strong&gt;：在一个提示中集成多个相关任务，要求模型同时处理并输出结果。这提高了效率，保持了上下文的连贯性，但随着任务数量增加，输出准确性可能下降，需要合理控制任务复杂度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Program-Aided Language Models (PAL)&lt;/strong&gt;：将外部编程环境引入提示工程，让模型生成程序代码来解决需要精确计算的问题。这种方法特别适合数学、逻辑推理等传统LLM表现不佳的领域，通过代码执行获得准确结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chain-of-Verification (CoVe) Prompting&lt;/strong&gt;：通过自我验证机制减少LLM的幻觉问题。模型先生成初步答案，然后生成验证问题并回答，最后整合验证结果优化输出。这种三步验证流程显著提高了事实性任务的准确性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://machinelearningmastery.com/7-next-generation-prompt-engineering-techniques/?ref=dailydev"&gt;7 Next-Generation Prompt Engineering Techniques&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Cornellius Yudha Wijaya&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月7日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>从机器学习模型的视角看机器学习研究</title><link>https://linguista.cn/curated/henrinotes-2025-p1/kaiming-he-ml-research-from-model-perspective/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/kaiming-he-ml-research-from-model-perspective/</guid><description>&lt;h1 id="从机器学习模型的视角看机器学习研究"&gt;从机器学习模型的视角看机器学习研究&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;何恺明教授在 NeurIPS 2024 NewInML Workshop 上发表演讲，从机器学习模型自身的视角出发，通过四个生动类比来阐释机器学习研究的本质与方向。这四个类比分别是：研究如同随机梯度下降、研究的目标是寻找&amp;quot;惊喜&amp;quot;、未来是真正的测试集、以及研究需要具备可扩展性。演讲深刻揭示了研究过程中的不确定性、探索性与长远价值。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;何恺明教授的这次演讲以一种独特的视角切入——用机器学习自身的概念和框架来审视机器学习研究本身。这种&amp;quot;元认知&amp;quot;式的思考方式，不仅展现了深刻的学术洞察力，也为研究者提供了一套理解和反思自身工作的思维工具。&lt;/p&gt;
&lt;p&gt;演讲的核心结构围绕四个类比展开。第一个类比将研究过程比作在非凸损失函数上执行随机梯度下降（SGD），强调研究中充满噪声和不确定性，大学习率代表快速探索新领域，小学习率则代表在已知方向上深入挖掘。第二个类比指出，机器学习模型追求的是期望收益的最大化，而研究的真正价值在于发现那些挑战现有认知的&amp;quot;惊喜&amp;quot;。&lt;/p&gt;
&lt;p&gt;第三个类比提出&amp;quot;未来是真正的测试集&amp;quot;这一深刻观点，提醒研究者警惕对当前基准和评估体系的&amp;quot;过拟合&amp;quot;，真正有价值的研究应当经得起未来的检验。第四个类比则聚焦于可扩展性，随着计算能力的持续提升，研究工作是否具备良好的扩展规律，将决定其长期影响力。&lt;/p&gt;
&lt;p&gt;整体而言，演讲通过这些精妙的类比，鼓励研究者在探索中保持开放心态，关注研究的长远价值与实际应用，而非仅仅追求短期的指标提升。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;研究即随机梯度下降&lt;/strong&gt;：何恺明将研究过程比作 SGD 在非凸损失函数中的优化过程。研究充满不确定性和噪声，每一次实验就像一步梯度更新。大学习率意味着敢于跳出舒适区探索全新方向，小学习率则意味着在有前景的方向上精细打磨。这个类比提醒研究者，既要有勇气进行大胆探索，也要有耐心做深入研究，二者的平衡至关重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;寻找&amp;quot;惊喜&amp;quot;而非期望&lt;/strong&gt;：机器学习模型以最大化期望收益为目标，但研究的突破往往来自于那些违反直觉、挑战常识的意外发现。这些&amp;quot;惊喜&amp;quot;可能最初只是偶然观察到的异常现象，但经过严谨验证后，可能颠覆现有理论，成为未来新范式的基石。这一类比鼓励研究者重视实验中的异常结果，而非简单忽略或丢弃。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;未来作为测试集&lt;/strong&gt;：在机器学习中，模型的真正能力体现在从未见过的测试数据上的表现。类似地，研究成果的真正价值取决于其对未来的影响力，而非仅仅在当前基准上的分数。研究者需要警惕对现有评估体系的&amp;quot;过拟合&amp;quot;——即过度针对特定数据集或指标进行优化，而忽视了方法的普适性和鲁棒性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;研究的可扩展性&lt;/strong&gt;：随着算力和数据规模的持续增长，研究方法是否具备良好的扩展规律（Scaling Law）变得愈发重要。一个在小规模上表现优异但无法扩展的方法，其长期价值可能有限。理解并利用扩展规律，有助于研究者将工作聚焦于那些能够随技术发展而持续受益的方向，从而在快速演进的领域中保持竞争力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;探索与利用的平衡&lt;/strong&gt;：贯穿整个演讲的一个隐含主题是研究中&amp;quot;探索&amp;quot;与&amp;quot;利用&amp;quot;的平衡问题。这与强化学习中的经典难题一脉相承——何时应该探索全新的未知方向，何时应该深入利用已知的有效路径。何恺明的四个类比从不同角度回应了这一根本问题，为研究者提供了多维度的思考框架。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/QtfAJ-I5KZfWSBmCwEam3A"&gt;何恺明 NeurIPS 2024 Talk 分享&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;何恺明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年12月27日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;会议&lt;/td&gt;
 &lt;td&gt;NeurIPS 2024 NewInML Workshop&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;论文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://people.csail.mit.edu/kaiming/neurips2024workshop/neurips2024_newinml_kaiming.pdf"&gt;PDF链接&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>深度神经网络的优势与应用</title><link>https://linguista.cn/curated/henrinotes-2025-p1/deep-neural-networks-advantages-applications/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/deep-neural-networks-advantages-applications/</guid><description>&lt;h1 id="深度神经网络的优势与应用"&gt;深度神经网络的优势与应用&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文探讨了深度神经网络相较于三层浅层网络的核心优势。虽然万能逼近定理证明了三层网络理论上可逼近任何连续函数，但深度网络在特征提取效率、参数利用和泛化能力上具有显著优势。通过分层特征学习、参数共享和稀疏连接等机制，深度网络能够更高效地处理复杂数据结构，在现代人工智能应用中发挥着不可替代的作用。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先阐述了三层神经网络的理论基础——万能逼近定理，同时指出了理论在实际应用中的局限性。浅层网络虽然理论上完备，但为了逼近高维复杂函数往往需要指数级增长的神经元数量，这在计算上是不可行的。此外，浅层网络在优化过程中容易陷入局部最优，且缺乏分层特征表示能力。&lt;/p&gt;
&lt;p&gt;接着，文章详细介绍了深度神经网络的三大核心优势。首先是分层特征提取机制，网络能够从低层的简单模式（如边缘、纹理）逐层抽象到高层的语义概念。其次是参数共享与稀疏连接设计，这大幅降低了模型复杂度和计算需求。最后是深度网络更强的表达能力，研究表明其可以用更少的参数实现比浅层网络更高的逼近能力。&lt;/p&gt;
&lt;p&gt;文章还介绍了深度神经网络的训练优化技术，包括反向传播、激活函数改进、批归一化、正则化技术以及预训练与迁移学习等。在实际应用层面，深度学习已在图像处理、自然语言处理和强化学习等领域取得突破性进展，成为推动人工智能发展的关键技术。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;万能逼近定理&lt;/strong&gt;：这是神经网络理论的基石，证明了具有单个隐藏层的前馈神经网络在合适的条件下可以逼近任何连续函数。然而，这并不意味着三层网络就是最优选择，因为定理仅保证了存在性，并未考虑实现这种逼近所需的计算资源和训练难度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分层特征提取&lt;/strong&gt;：深度网络的核心优势在于其能够自动学习多层次的特征表示。低层捕获简单模式如边缘和纹理，中层识别局部结构和形状，高层则理解全局概念和语义信息。这种层级抽象机制使得深度网络能够高效处理复杂的视觉和语言数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参数共享与稀疏连接&lt;/strong&gt;：这是卷积神经网络等架构的关键设计理念。通过在整个输入空间共享同一组权重，并限制神经元只与局部邻域连接，模型可以用更少的参数处理高维数据，这不仅降低了计算复杂度，也提高了模型的泛化能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反向传播与优化技巧&lt;/strong&gt;：深度网络的训练依赖于反向传播算法和梯度下降优化。为了解决深层网络训练中的梯度消失和过拟合问题，现代深度学习发展了多种技术，包括ReLU激活函数、批归一化、Dropout正则化以及预训练与迁移学习等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;泛化能力&lt;/strong&gt;：深度网络通过学习更具普适性的特征表示，能够在未见过的数据上保持良好性能。这种泛化能力源于深度架构能够捕获数据中的本质规律而非仅仅记忆训练样本，这也是深度学习在实际应用中取得成功的关键因素。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/D47cZT7DvATC1VGwWjUFgw"&gt;一般来说，三层神经网络可以逼近任何一个非线性函数，为什么还需要深度神经网络？为什么深度学习模型能够自动提取多层次特征？｜深度学习&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;深度学习&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-04&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>稀疏贝叶斯学习的理论与应用</title><link>https://linguista.cn/curated/henrinotes-2025-p1/sparse-bayesian-learning-theory-application/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/sparse-bayesian-learning-theory-application/</guid><description>&lt;h1 id="稀疏贝叶斯学习的理论与应用"&gt;稀疏贝叶斯学习的理论与应用&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;稀疏贝叶斯学习（SBL）是一种结合稀疏性与贝叶斯统计的学习方法，广泛应用于信号处理和机器学习领域。本文从贝叶斯统计与稀疏表示的理论基础出发，详细阐述了SBL模型的构建与优化过程，包括边缘似然最大化和EM算法的具体步骤，并通过实验对比了SBL与Ridge回归在不同噪声条件下的表现，验证了SBL在高噪声环境中更强的稳定性和适应性。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先介绍了稀疏贝叶斯学习的基本定义与核心特点。SBL与传统稀疏方法（如L1正则化）的关键区别在于，它不需要预先指定稀疏度参数，而是通过贝叶斯推理自适应地发现数据中的稀疏结构，这使得模型在应用中具有更高的灵活性。&lt;/p&gt;
&lt;p&gt;在理论基础部分，文章系统回顾了贝叶斯统计的核心要素——先验分布、似然函数、后验分布和边缘似然，并介绍了稀疏表示的基本概念，包括Lasso、L1和L2正则化等常见方法，为后续的模型构建奠定了理论基础。&lt;/p&gt;
&lt;p&gt;模型构建与优化是文章的核心内容。文章以线性回归模型为框架，采用零均值高斯分布作为参数的稀疏先验分布，通过独立的精度参数控制每个参数的方差。在优化过程中，采用期望最大化（EM）算法，通过E步骤计算参数的后验分布，M步骤更新超参数和噪声方差，逐步最大化边缘似然。&lt;/p&gt;
&lt;p&gt;实验部分通过生成高维稀疏数据，对比了SBL与Ridge回归在不同噪声水平下的性能表现，使用MSE、MAE、最大误差和R²分数等多维指标进行评估，结果表明SBL在高噪声条件下展现出更强的稳定性和抗噪能力。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;稀疏贝叶斯学习（SBL）&lt;/strong&gt;：一种将贝叶斯推理与稀疏性约束相结合的学习框架。其核心优势在于无需手动设定稀疏度参数，而是通过贝叶斯推理自动识别数据中的稀疏结构。模型通过精度参数的自适应调节实现稀疏性——当某个精度参数值很大时，对应的参数方差趋近于零，从而自然地实现参数的&amp;quot;裁剪&amp;quot;，得到稀疏解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;边缘似然最大化&lt;/strong&gt;：SBL模型优化的核心策略。边缘似然是在对模型参数积分后得到的数据概率，它综合考虑了模型复杂度和数据拟合度，天然具备奥卡姆剃刀效应。通过最大化边缘似然来估计精度参数和噪声方差，避免了过拟合风险，使模型能够在数据拟合与结构简洁之间取得平衡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;期望最大化（EM）算法&lt;/strong&gt;：SBL模型参数估计的迭代优化方法。E步骤在当前超参数下计算模型参数的后验分布，获得均值和协方差；M步骤利用后验统计量更新精度参数和噪声方差。两个步骤交替迭代直至收敛，逐步逼近边缘似然的最大值，是SBL实现自适应稀疏学习的关键算法机制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;稀疏先验分布&lt;/strong&gt;：SBL模型中对参数施加的先验假设，通常采用零均值高斯分布，并为每个参数引入独立的精度（逆方差）超参数。这种层级化的先验设计使模型能够对不同参数施加不同强度的约束，精度越大则参数越可能为零，从而在贝叶斯框架下自然地引导出稀疏解，而非通过硬性的正则化惩罚项实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SBL与Ridge回归的对比实验&lt;/strong&gt;：实验在不同噪声水平下对比了两种方法的性能。在低噪声条件下，两者表现相当；但在高噪声环境中，Ridge回归的解释方差（R²分数）波动较大，而SBL保持相对稳定，体现了贝叶斯方法在不确定性建模方面的天然优势，以及SBL通过自适应稀疏机制过滤噪声干扰的能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/D21HuJN6qq8QBjv86V5BTA"&gt;稀疏贝叶斯学习&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Machine Learning 的学习方法</title><link>https://linguista.cn/rosetta/chat-notes/how-to-learn-machine-learning/</link><pubDate>Mon, 01 Jan 2024 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/chat-notes/how-to-learn-machine-learning/</guid><description>&lt;h1 id="machine-learning-的学习方法"&gt;Machine Learning 的学习方法&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文介绍了学习机器学习的六个关键步骤，从掌握Python基础和数学概念入手，逐步学习ML开发者工具栈、机器学习与深度学习课程，再到通过Kaggle挑战和论文复现进行实践。作者结合自身经历，推荐了Andrew Ng课程、Andrej Karpathy神经网络系列等优质资源，强调以兴趣驱动、注重动手实践的学习方式。&lt;/p&gt;
&lt;div class="video-card group relative w-full overflow-hidden rounded-2xl border border-border bg-surface shadow-sm transition hover:shadow-md "&gt;
 &lt;div style="aspect-ratio: 16/9;" class="w-full relative bg-black/5 dark:bg-white/5"&gt;
 &lt;iframe
 src="https://www.youtube-nocookie.com/embed/gUmagAluXpk?rel=0&amp;amp;modestbranding=1&amp;amp;playsinline=1"
 title="Machine Learning 的学习方法"
 class="absolute inset-0 w-full h-full border-0"
 loading="lazy"
 allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
 allowfullscreen&gt;
 &lt;/iframe&gt;
 &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;ML开发者堆栈&lt;/strong&gt;：指机器学习开发中常用的工具组合，包括Jupyter笔记本、Pandas、NumPy和Matplotlib等Python库，是数据处理与可视化的基础设施&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;PyTorch&lt;/strong&gt;：由Meta开发的开源深度学习框架，以动态计算图和灵活易用著称，广泛应用于学术研究和工业实践&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Kaggle&lt;/strong&gt;：全球知名的数据科学与机器学习竞赛平台，提供数据集、挑战赛和社区交流，是实践ML技能的重要渠道&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hugging Face&lt;/strong&gt;：专注于自然语言处理的开源社区和工具库，提供预训练模型和便捷的NLP开发接口，已成为NLP领域的核心基础设施&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;论文复现&lt;/strong&gt;：指重新实现学术论文中的方法并再现其实验结果，是深入理解算法原理和提升工程能力的高效学习方式&lt;/p&gt;
&lt;h2 id="内容梗概"&gt;内容梗概&lt;/h2&gt;
&lt;p&gt;文章的核心思想是教授学习机器学习的六个关键步骤，帮助初学者更高效地掌握这一领域。这六个步骤涵盖了从学习Python编程语言和基础工具，到深入了解数学概念、学习机器学习框架，最终实践项目的全过程。作者强调了按步骤学习的重要性，建议初学者注重实践和项目经验，通过挑战和重新实现论文结果来加深理解，最终在机器学习领域取得更好的表现。文章还提到了多个机器学习工具和学习资源，为学习者提供了具体的指导和推荐。&lt;/p&gt;
&lt;p&gt;文章提到了学习机器学习的六个关键步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;学习Python基础知识：&lt;/strong&gt; 从掌握基本的Python编程开始，包括了解列表、字典、条件语句和循环等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;学习基础数学：&lt;/strong&gt; 虽然许多任务可以由Python库自动化处理，但仍需要理解微积分、线性代数和概率等基础数学概念。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;了解ML开发者堆栈：&lt;/strong&gt; 掌握Python基础后，学习使用Jupyter笔记本以及Pandas、NumPy和Matplotlib等库，这对机器学习至关重要。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;学习机器学习和深度学习：&lt;/strong&gt; 推荐通过免费的机器学习专业化课程学习基本概念，然后深入了解深度学习，包括使用PyTorch等框架。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;实践项目：&lt;/strong&gt; 在Kaggle上解决挑战，并尝试重新实现论文并重现结果，这将提升实际技能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;巩固知识并脱颖而出：&lt;/strong&gt; 学习并尝试一些更高级的概念，以在机器学习应用中脱颖而出，例如利用Kaggle竞赛、重新实现论文等。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;作者建议不要匆忙学习所有课程，而是以有趣和实用为导向，随时根据需要查阅基础知识。最终目标是建立实际项目经验，提高机器学习应用技能。&lt;/p&gt;
&lt;p&gt;在文章中，提到了以下机器学习工具和学习资源：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Python：&lt;/strong&gt; 建议从学习基础的Python编程开始，作为机器学习的编程语言基础。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Jupyter笔记本：&lt;/strong&gt; 用于学习和实践Python代码的工具。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Pandas、NumPy、Matplotlib：&lt;/strong&gt; Python库，用于处理和可视化数据，是机器学习开发者堆栈的重要组成部分。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;PyTorch：&lt;/strong&gt; 一种深度学习框架，推荐用于学习深度学习。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Kaggle：&lt;/strong&gt; 提供机器学习挑战和竞赛的平台，用于实践和应用学到的知识。&lt;/p&gt;</description></item><item><title>计算机距离自动化数学推理还有多远</title><link>https://linguista.cn/rosetta/humanity/how-close-are-computers-to-automating-mathematical-reasoning/</link><pubDate>Thu, 27 Aug 2020 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/humanity/how-close-are-computers-to-automating-mathematical-reasoning/</guid><description>&lt;h1 id="计算机距离自动化数学推理还有多远"&gt;计算机距离自动化数学推理还有多远&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文探讨了计算机在自动化数学推理方面的进展与局限。文章介绍了自动定理证明器和交互式定理证明器两大类工具，回顾了开普勒猜想、四色定理等由计算机辅助完成的著名证明，并讨论了数学家对这些工具的复杂态度。研究者正尝试将机器学习与传统证明系统结合，以实现更接近人类的演绎推理能力。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;自动定理证明器（ATP）——通过穷举搜索或强力计算自动验证数学命题的程序，无需人类交互但输出难以理解&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;交互式定理证明器（ITP）——需要人类参与和引导的证明助手，内含大量定理数据库，可验证证明的准确性，代表工具包括Coq和Isabelle&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;形式化证明——将数学证明转化为计算机可处理的严格逻辑语言，消除自然语言的模糊性，确保每一步推理都可被机器验证&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;神经网络生成猜想——利用在大量定理数据上训练的神经网络自动生成新的数学猜想，再由ATP验证其有效性，代表了归纳推理与演绎推理的结合尝试&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;开普勒猜想——描述球体最优堆叠方式的经典数学问题，其计算机辅助证明产生了3GB数据，成为机器证明能力与可读性争论的标志性案例&lt;/strong&gt;：&lt;/p&gt;
&lt;h2 id="计算机距离自动化数学推理还有多远-1"&gt;计算机距离自动化数学推理还有多远？&lt;/h2&gt;
&lt;p&gt;作者：斯蒂芬·奥恩斯 (Stephen Ornes)
2020年8月27日&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;文章来自于：Quanta Magazine: &lt;a href="https://www.quantamagazine.org/how-close-are-computers-to-automating-mathematical-reasoning-20200827/"&gt;查看原文&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;人工智能工具正在塑造下一代定理证明器，以及数学与机器之间的关系。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="引言"&gt;引言&lt;/h3&gt;
&lt;p&gt;据报道，在20世纪70年代，已故数学家保罗·科恩（Paul Cohen）——唯一一位因在数理逻辑方面的工作而获得菲尔兹奖的人——做出了一个影响深远的预测，至今仍在激动和刺激着数学家们：即“在某个未指明的未来时间，数学家将被计算机取代。”科恩因其在集合论中的大胆方法而闻名，他预测所有的数学都可以自动化，包括证明的编写。&lt;/p&gt;
&lt;p&gt;证明是一个逐步的逻辑论证，用于验证一个猜想或数学命题的真实性。（一旦被证明，猜想就变成了定理。）它既确立了一个陈述的有效性，也解释了它为什么是真的。然而，证明是奇怪的。它是抽象的，与物质经验脱节。“它们是想象中的、非物质世界与生物进化而来的生物之间的一种疯狂的联系，”卡内基梅隆大学的认知科学家西蒙·德迪奥（Simon DeDeo）说，他通过分析证明的结构来研究数学的确定性。“我们并非为做这件事而进化。”&lt;/p&gt;
&lt;p&gt;计算机对于大型计算很有用，但证明需要不同的东西。猜想源于归纳推理——一种关于有趣问题的直觉——而证明通常遵循演绎的、逐步的逻辑。它们往往需要复杂的创造性思维，以及填补空白的更费力的工作，而机器无法实现这种结合。&lt;/p&gt;
&lt;p&gt;计算机化的定理证明器可以分为两类。自动定理证明器（Automated theorem provers, ATPs）通常使用强力方法来处理大型计算。交互式定理证明器（Interactive theorem provers, ITPs）则充当证明助手，可以验证论证的准确性并检查现有证明中的错误。但这两种策略，即使结合起来（正如新型定理证明器的情况），也并不等同于自动化推理。&lt;/p&gt;
&lt;p&gt;此外，这些工具并未受到张开双臂的欢迎，大多数数学家不使用或不欢迎它们。“对于数学家来说，它们非常有争议，”德迪奥说。“他们中的大多数人不喜欢这个想法。”&lt;/p&gt;
&lt;p&gt;该领域一个艰巨的开放挑战是：证明的制作究竟能在多大程度上实现自动化？一个系统能否生成一个有趣的猜想并以人们能理解的方式证明它？来自世界各地实验室的一系列最新进展提出了人工智能工具可能回答这个问题的方法。布拉格捷克信息学、机器人学和控制论研究所的约瑟夫·乌尔班（Josef Urban）正在探索各种使用机器学习来提高现有证明器效率和性能的方法。今年7月，他的团队报告了一组由机器生成和验证的原创猜想和证明。而在6月，由克里斯蒂安·塞格迪（Christian Szegedy）领导的谷歌研究小组发布了利用自然语言处理优势使计算机证明在结构和解释上更像人类的最新成果。&lt;/p&gt;
&lt;p&gt;一些数学家将定理证明器视为训练本科生编写证明的潜在颠覆性工具。另一些人则表示，让计算机编写证明对于推进数学来说既不必要，也可能是不可能的。但是，一个能够预测有用猜想并证明新定理的系统将实现一些新的东西——某种机器版本的理解，塞格迪说。而这暗示了自动化推理本身的可能性。&lt;/p&gt;
&lt;h3 id="有用的机器"&gt;有用的机器&lt;/h3&gt;
&lt;p&gt;数学家、逻辑学家和哲学家长期以来一直在争论创造证明的哪一部分是根本上属于人类的，关于机械化数学的辩论至今仍在继续，尤其是在连接计算机科学和纯粹数学的深谷中。&lt;/p&gt;
&lt;p&gt;对于计算机科学家来说，定理证明器没有争议。它们提供了一种严格的方法来验证程序是否有效，而关于直觉和创造力的争论远不如找到解决问题的有效方法重要。例如，在麻省理工学院，计算机科学家亚当·奇利帕拉（Adam Chlipala）设计了定理证明工具，用于生成密码算法——传统上由人类编写——以保护互联网交易。他的团队的代码已经被用于谷歌Chrome浏览器上的大部分通信。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;约翰霍普金斯大学的艾米莉·里尔在教学中使用定理证明器，并在自己的研究中使用证明助手。“使用证明助手改变了我对编写证明的思考方式，”她说。
——威尔·柯克/约翰霍普金斯大学&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;“你可以用一个工具编写任何类型的数学论证，并将你的论证连接起来，创建安全性的证明，”奇利帕拉说。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在数学领域，定理证明器帮助产生了复杂的、计算量大的证明，否则这些证明可能会占用数学家数百年的生命。描述最佳堆叠球体（或者历史上是橙子或炮弹）方式的开普勒猜想提供了一个有说服力的例子。1998年，托马斯·黑尔斯（Thomas Hales）和他的学生萨姆·弗格森（Sam Ferguson）一起，使用各种计算机化的数学技术完成了一个证明。结果是如此繁琐——结果占用了3GB——以至于12位数学家花了数年时间分析它，然后才宣布他们有99%的把握认为它是正确的。&lt;/p&gt;
&lt;p&gt;开普勒猜想并不是唯一一个由机器解决的著名问题。四色定理指出，任何二维地图只需要四种颜色就可以保证没有两个相邻区域共享同一种颜色，该定理于1977年由数学家使用一个计算机程序解决，该程序穷举了所有五色地图，证明它们都可以简化为四色。而在2016年，三位数学家使用计算机程序证明了一个长期存在的开放挑战，称为布尔毕达哥拉斯三元组问题，但该证明的初始版本大小为200TB。使用高速互联网连接，一个人需要三个多星期才能下载完它。&lt;/p&gt;
&lt;h3 id="复杂的情感"&gt;复杂的情感&lt;/h3&gt;
&lt;p&gt;这些例子常常被誉为成功，但它们也加剧了争论。证明四色定理的计算机代码（该定理在40多年前就已解决）是人类无法自行检查的。“从那时起，数学家们就一直在争论这到底算不算一个证明，”哥伦比亚大学的数学家迈克尔·哈里斯（Michael Harris）说。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;许多数学家，如哥伦比亚大学的迈克尔·哈里斯，不同意计算机化定理证明器是必要的——或者它们将使人类数学家过时的观点。
——贝阿特丽斯·安托林 (Béatrice Antolin)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;另一个抱怨是，如果数学家想使用定理证明器，他们必须首先学习编程，然后弄清楚如何用计算机友好的语言表达他们的问题——这些活动分散了做数学的精力。“等我把我的问题重新组织成能适应这种技术的形式时，我自己就已经解决了这个问题，”哈里斯说。&lt;/p&gt;
&lt;p&gt;许多人只是觉得在他们的工作中不需要定理求解器。“他们有一套系统，那就是铅笔和纸，而且行之有效，”伦敦帝国理工学院的数学家凯文·巴泽德（Kevin Buzzard）说，他三年前将工作重心从纯粹数学转向定理证明器和形式化证明。“计算机为我们做了惊人的计算，但它们从未独立解决过一个难题，”他说。“在此之前，数学家是不会买账的。”&lt;/p&gt;
&lt;p&gt;但巴泽德和其他人认为也许他们应该接受。首先，“计算机证明可能并不像我们想象的那么陌生，”德迪奥说。最近，他与现就职于斯坦福大学的计算机科学家斯科特·维泰里（Scott Viteri）一起，逆向工程分析了一些著名的经典证明（包括欧几里得《几何原本》中的一个）和数十个使用名为Coq的定理证明器编写的机器生成证明，以寻找共同点。他们发现机器证明的网络结构与人类证明的结构惊人地相似。他说，这种共同的特性可能有助于研究人员找到一种方法，让证明助手在某种意义上能够解释自己。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“机器证明可能并不像看起来那么神秘，”德迪奥说。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其他人则表示，定理证明器可以成为有用的教学工具，无论是在计算机科学还是数学领域。在约翰霍普金斯大学，数学家艾米莉·里尔（Emily Riehl）开发了学生使用定理证明器编写证明的课程。“它迫使你非常有条理、清晰地思考，”她说。“第一次写证明的学生可能不知道自己需要什么，也难以理解逻辑结构。”&lt;/p&gt;
&lt;p&gt;里尔还表示，她也越来越多地在自己的工作中使用定理证明器。“它不一定是需要一直使用的东西，也永远不会取代在纸上涂写，”她说，“但使用证明助手改变了我对编写证明的思考方式。”&lt;/p&gt;
&lt;p&gt;定理证明器也提供了一种保持该领域诚实性的方法。1999年，俄裔美国数学家弗拉基米尔·沃埃沃德斯基（Vladimir Voevodsky）发现了他一个证明中的错误。从那时起直到2017年去世，他一直是使用计算机检查证明的积极倡导者。黑尔斯说，他和弗格森在用计算机检查他们最初的证明时发现了数百个错误。即使是欧几里得《几何原本》中的第一个命题也不是完美的。如果机器能帮助数学家避免这类错误，为什么不利用它呢？（实践上的反对意见，无论合理与否，正是哈里斯提出的那个：如果数学家必须花费时间将数学形式化以便计算机理解，那这些时间就没有花在做新的数学上。）&lt;/p&gt;
&lt;p&gt;但是，剑桥大学的数学家、菲尔兹奖得主蒂莫西·高尔斯（Timothy Gowers）想走得更远：他设想未来定理证明器将取代主要期刊的人类审稿人。“我可以看到这成为标准做法，即如果你想让你的论文被接受，你必须让它通过自动检查器，”他说。&lt;/p&gt;
&lt;h3 id="与计算机对话"&gt;与计算机对话&lt;/h3&gt;
&lt;p&gt;但在计算机能够普遍检查甚至设计证明之前，研究人员首先必须清除一个重大的障碍：人类语言和计算机语言之间的沟通障碍。&lt;/p&gt;
&lt;p&gt;今天的定理证明器并非为方便数学家而设计。第一类，ATPs，通常用于检查一个陈述是否正确，常常通过测试可能的情况。例如，要求一个ATP验证一个人可以从迈阿密开车到西雅图，它可能会搜索所有通过道路连接迈阿密的城市，并最终找到一个有道路通往西雅图的城市。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;并非所有数学家都讨厌定理证明器。剑桥大学的蒂莫西·高尔斯认为它们有一天可能会取代数学期刊的人类审稿人。
阿贝尔奖&lt;/p&gt;</description></item><item><title>苦涩的教训</title><link>https://linguista.cn/rosetta/technology/bitter-lesson/</link><pubDate>Wed, 13 Mar 2019 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/bitter-lesson/</guid><description>&lt;p&gt;本文是里奇·萨顿（Richard Sutton）2019年著名文章《&lt;a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html"&gt;The Bitter Lesson（苦涩的教训）&lt;/a&gt;》。&lt;/p&gt;
&lt;p&gt;&lt;img src="https://ts3.tc.mm.bing.net/th/id/OIP-C.5-o1C9ggTpwDMynLnfilkgHaE8?cb=12&amp;amp;rs=1&amp;amp;pid=ImgDetMain&amp;amp;o=7&amp;amp;rm=3" alt=""&gt;&lt;/p&gt;</description></item><item><title>博士生涯生存指南</title><link>https://linguista.cn/rosetta/humanity/phd-survival-guide-andrej-karpathy/</link><pubDate>Wed, 07 Sep 2016 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/humanity/phd-survival-guide-andrej-karpathy/</guid><description>&lt;h1 id="博士生涯生存指南"&gt;博士生涯生存指南&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;Andrej Karpathy 在博士生涯结束之际撰写的回顾性指南，涵盖是否应该读博的考量因素、如何选择学校与导师、研究课题的选择与迭代、论文写作与代码发布的技巧、学术报告与会议参与策略，以及以诚信为本的核心原则。文章结合个人经历与实用建议，为计算机科学领域的博士生提供了系统性的生存参考。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;外循环与内循环 - 博士研究中发现值得解决的问题属于外循环，是培养学术品味的关键，比具体执行（内循环）更重要&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;师生共生关系 - 导师与学生之间存在互利的激励机制，理解导师的教职阶段和研究风格有助于建立高效的合作关系&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;研究所有权 - 博士期间的研究成果与个人名字紧密绑定，这种归属感是区别于企业工作的核心价值之一&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;最大化未来选择 - 攻读博士不会关闭任何职业道路，反而能严格扩展未来的就业选项和起点，是一种面向长期的人生策略&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;学术品味 - 指识别哪些问题值得研究、哪些方向时机成熟的判断力，是博士训练中最难习得也最有价值的能力&lt;/strong&gt;：&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="博士生涯生存指南-简洁版"&gt;博士生涯生存指南 (简洁版)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;原文链接：&lt;a href="https://karpathy.github.io/2016/09/07/phd/"&gt;A Survival Guide to a PhD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;中译本链接：&lt;a href="https://linguista.bearblog.dev/andrejkarpathy-asurvivalguidetoaphd-cn/"&gt;博士生涯生存指南&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;日期：Sep 7, 2016&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1. 为什么要读博？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;考虑因素:&lt;/strong&gt; 追求学术自由、研究所有权、个人成长、深入专业知识、最大化未来选择。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;权衡:&lt;/strong&gt; 需要应对高强度工作、压力、不确定性、相对较低的收入和可能出现的心理挑战。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;关键:&lt;/strong&gt; 博士学位本身就是目的，而非仅仅是手段。确定你能在非结构化环境中茁壮成长。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2. 准备与选择&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;申请:&lt;/strong&gt; 强有力的推荐信至关重要，研究经历比成绩更重要。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;选校:&lt;/strong&gt; 选择顶尖学校，确保有&lt;strong&gt;多位&lt;/strong&gt;潜在导师，并考虑学校地点和环境。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;选导师:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;理解师生共生关系及其激励机制（如终身教职）。&lt;/li&gt;
&lt;li&gt;导师风格各异（亲力亲为/放手、理论/应用等），注意教职阶段（终身教职前/后）差异。&lt;/li&gt;
&lt;li&gt;通过与导师本人及其实验室学生交流来评估匹配度。&lt;/li&gt;
&lt;li&gt;实验室整体氛围和成员同样重要。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. 研究课题&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心:&lt;/strong&gt; 博士研究重在&lt;strong&gt;发现&lt;/strong&gt;值得解决且时机成熟的问题（外循环），培养“品味”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;选题:&lt;/strong&gt; 选择有潜力（肥沃）、有雄心（但有可行方法）、符合导师兴趣和优势的课题。目标是成为“做 X 的那个人”。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;过程:&lt;/strong&gt; 准备好迭代和调整方向，早期想法可能行不通。有时要相信自己的判断。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;超越论文:&lt;/strong&gt; 思考如何通过代码、工具、教学等方式为社区做贡献。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4. 成果产出&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;写论文:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;学习写作技巧（审阅他人论文很有帮助）。&lt;/li&gt;
&lt;li&gt;聚焦&lt;strong&gt;单一核心贡献&lt;/strong&gt;，结构清晰（引言/相关工作/模型/实验/结论）。&lt;/li&gt;
&lt;li&gt;注意论文的“整体感觉”和学术语言。&lt;/li&gt;
&lt;li&gt;避免流水账，充分论证每一步。&lt;/li&gt;
&lt;li&gt;设定内部截止日期。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;写代码:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;发布代码&lt;/strong&gt;：强制规范、利于他人、增加影响力。&lt;/li&gt;
&lt;li&gt;做好文档记录，方便自己回顾。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;做报告:&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;目标：激发兴趣、传授知识、娱乐听众，而非简单汇报。&lt;/li&gt;
&lt;li&gt;多用图片，少用文字；讲故事；充分引用；多加练习。&lt;/li&gt;
&lt;li&gt;避免信息过载或过于枯燥/难懂。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5. 学术社区&lt;/strong&gt;&lt;/p&gt;</description></item><item><title>阅读收藏</title><link>https://linguista.cn/bookmarks/reading_list/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://linguista.cn/bookmarks/reading_list/</guid><description>&lt;p&gt;本页为我在阅读过程中所收藏的网页目录。&lt;/p&gt;</description></item></channel></rss>