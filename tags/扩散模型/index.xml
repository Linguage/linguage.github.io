<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>扩散模型 on Linguista</title><link>https://linguista.cn/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 扩散模型 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 08 Jul 2025 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>扩散语言模型解析</title><link>https://linguista.cn/static/zed-diffustion-model/</link><pubDate>Tue, 08 Jul 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/static/zed-diffustion-model/</guid><description>本文深入探讨了扩散语言模型这一文本生成的新范式。文章通过交互式图表和对比分析，阐述了非自回归模型如何通过迭代去噪过程生成文本，并重点分析了模型在生成质量与推理速度之间的关键权衡，以及其在文本生成领域的独特优势与潜在挑战。</description></item><item><title>扩散模型原理及代码实现</title><link>https://linguista.cn/curated/henrinotes_2025_p4/diffusion-model-principle-implementation/</link><pubDate>Wed, 15 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p4/diffusion-model-principle-implementation/</guid><description>&lt;h1 id="扩散模型原理及代码实现"&gt;扩散模型原理及代码实现&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文系统介绍了扩散模型的理论基础与实现方法。文章首先回顾了扩散模型的发展历程，从2015年Sohl-Dickstein的开创性工作到2020年DDPM框架的提出。核心部分详细阐述了前向扩散过程（逐步添加噪声）和反向去噪过程（学习从噪声恢复数据）的数学原理。最后，文章提供了基于DDPM框架的完整Python代码实现，包括U-Net模型构建、GaussianDiffusion类设计以及训练采样流程，并展示了在动漫人脸数据集上的生成结果。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章分为三个主要部分。第一部分介绍扩散模型的历史发展，从概率图模型和统计物理学的理论渊源，到2015年首次将扩散过程引入深度生成模型，再到2020年DDPM框架的突破性工作。这一发展脉络清晰地展示了扩散模型如何从理论探索走向实用化，并在图像生成、语音合成等任务上取得优异表现。&lt;/p&gt;
&lt;p&gt;第二部分深入讲解扩散模型的核心原理。前向过程是一个固定的马尔可夫链，通过逐步添加高斯噪声将真实数据转化为纯噪声；反向过程则通过神经网络学习如何从噪声逐步恢复出清晰图像。这种设计巧妙地将生成问题转化为去噪问题，使得模型训练更加稳定和可控。文章还提供了关键的数学公式，解释了每一步噪声添加的强度计算方法。&lt;/p&gt;
&lt;p&gt;第三部分提供了完整的代码实现。遵循DDPM框架，代码采用模块化设计：U-Net模型负责预测每个时间步的噪声，GaussianDiffusion类封装扩散过程的核心逻辑，Trainer类管理训练流程。文章还分享了在动漫人脸数据集上的实践结果，指出了当前实现的局限性以及未来的改进方向，包括更高效的采样策略、更灵活的条件控制等。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;前向扩散过程&lt;/strong&gt;：这是扩散模型的&amp;quot;破坏&amp;quot;阶段，通过固定的马尔可夫链逐步向图像添加高斯噪声，使原始数据逐渐失去可识别性，最终接近标准高斯分布。这个过程不可学习但完全可逆，关键在于每一步的噪声强度由预定义的Beta参数控制，保证了数学上的可逆性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反向去噪过程&lt;/strong&gt;：这是扩散模型的&amp;quot;重建&amp;quot;阶段，目标是训练神经网络从纯噪声逐步恢复出清晰图像。模型输入是有噪声的图像和当前去噪步骤，输出是预测的噪声分量，通过减去预测噪声得到去噪结果。训练时使用前向过程产生的加噪图像作为训练数据，将实际添加的噪声作为监督信号。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;U-Net架构&lt;/strong&gt;：这是扩散模型的核心神经网络，采用编码器-解码器结构，包含多个卷积层、残差块和注意力机制。U-Net能够在不同尺度下捕捉图像特征，从局部细节到全局语义，为每个时间步准确预测噪声分量。其对称结构使得特征信息能够在编码和解码阶段有效传递。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DDPM框架&lt;/strong&gt;：这是2020年提出的高效扩散模型框架，将复杂的扩散过程简化为两个清晰阶段。DDPM证明了扩散模型的训练等价于简单的降噪任务，损失函数可以简化为实际噪声与预测噪声之间的均方误差，大大降低了实现难度和计算成本。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;高斯扩散类&lt;/strong&gt;：这是代码实现中的核心组件，封装了扩散模型的所有数学公式和超参数。它管理Beta调度、计算采样时间步、实现训练和采样流程，并提供损失函数计算。这种模块化设计使得扩散过程与神经网络架构解耦，便于实验和优化。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/YCYEmhGMNAUIMSZwmG3v4Q"&gt;扩散模型原理及代码实现&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>