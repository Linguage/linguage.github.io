<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Model Interpretability on Linguista</title><link>https://linguista.cn/tags/model-interpretability/</link><description>Recent content in Model Interpretability on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 31 Aug 2025 08:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/model-interpretability/index.xml" rel="self" type="application/rss+xml"/><item><title>认知可解释推理痕迹与LLM性能关系研究</title><link>https://linguista.cn/info/htmlcards/multi-agent-design-optimizing-agents-with-better-prompts-and-topologies/</link><pubDate>Sun, 31 Aug 2025 08:00:00 +0800</pubDate><guid>https://linguista.cn/info/htmlcards/multi-agent-design-optimizing-agents-with-better-prompts-and-topologies/</guid><description>本文基于亚利桑那州立大学的研究，深入探讨了链式思维（CoT）推理痕迹的可解释性与模型性能之间的悖论。研究通过对 DeepSeek R1 等 4 种痕迹类型的 100 人次人类评估实验，揭示了性能最佳的模型往往伴随着最低的可解释性和最高的认知负荷。这一发现对当前的模型对齐与知识蒸馏范式提出了挑战，强调了在追求强大推理能力的同时，需重新审视可解释性在 AI 系统中的实际定位与权衡。</description></item></channel></rss>