<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>技术政策 on Linguista</title><link>https://linguista.cn/tags/%E6%8A%80%E6%9C%AF%E6%94%BF%E7%AD%96/</link><description>Recent content in 技术政策 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Tue, 15 Apr 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%8A%80%E6%9C%AF%E6%94%BF%E7%AD%96/index.xml" rel="self" type="application/rss+xml"/><item><title>作为普通技术的人工智能</title><link>https://linguista.cn/rosetta/technology/ai-as-normal-technology/</link><pubDate>Tue, 15 Apr 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/ai-as-normal-technology/</guid><description>&lt;h1 id="作为普通技术的人工智能"&gt;作为普通技术的人工智能&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文提出将人工智能视为一种普通技术而非超级智能实体的分析框架。作者从技术扩散速度、人机协作分工、风险分类与政策韧性四个维度展开论述，指出AI的经济社会变革将以数十年为尺度渐进发生，主张拒绝技术决定论，通过韧性导向的政策应对不确定性，而非诉诸激进干预或末日叙事。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;普通技术框架&lt;/strong&gt;：将AI与电力、互联网等通用技术类比，强调其发展遵循可循规律而非神秘力量，拒绝将AI视为自主超级智能实体&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;创新-扩散滞后&lt;/strong&gt;：AI方法的发明、应用创新与社会扩散发生在不同时间尺度上，尤其在安全关键领域，扩散可能落后创新数十年&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术决定论批判&lt;/strong&gt;：反对AI自身作为决定未来的能动者的观念，强调人类、组织和制度在塑造技术轨迹中的主导作用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;韧性政策方法&lt;/strong&gt;：面对AI不确定性，主张以韧性为核心政策目标，优先减少不确定性，避免基于极端假设的激进干预&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能力-可靠性差距&lt;/strong&gt;：AI在基准测试上的表现与现实世界效用之间存在显著鸿沟，安全关键应用中尤为突出&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;原文链接：&lt;a href="https://www.aisnakeoil.com/p/ai-as-normal-technology?utm_source=multiple-personal-recommendations-email&amp;amp;utm_medium=email&amp;amp;triedRedirect=true"&gt;AI as Normal Technology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一篇我们将扩展为下一本书的新论文&lt;/li&gt;
&lt;li&gt;作者：Arvind Narayanan 和 Sayash Kapoor&lt;/li&gt;
&lt;li&gt;日期2025年4月15日&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id="文章导言"&gt;文章导言&lt;/h3&gt;
&lt;p&gt;人工智能（AI）正以前所未有的速度渗透到我们生活的方方面面，引发了从根本性社会变革到生存威胁的各种讨论。在众多激动人心或令人忧虑的预测中，本文旨在提供一个更为审慎和贴近现实的视角：将AI视为一种“普通技术”。这并非贬低其潜在影响力，而是强调它与其他改变历史的通用技术（如电力或互联网）一样，其发展和融入社会的过程遵循着可循的规律，而非某种神秘力量的降临。&lt;/p&gt;
&lt;p&gt;本文认为，当前围绕AI，特别是“超级智能”的许多讨论，往往脱离了技术发展的实际路径和社会采纳的复杂现实。我们将探讨为何AI带来的经济和社会变革可能比预期更为缓慢，需要数十年时间；在一个人与AI共存的未来，人类的角色将如何演变为对AI的控制和引导；以及如何从“普通技术”的角度重新审视AI风险，将焦点从科幻式的“失控”场景，更多地转向事故、滥用以及加剧现有社会问题的系统性风险。最后，基于这一视角，我们将讨论更具韧性和适应性的政策方针，主张在不确定性中优先考虑稳健性、减少极端干预，并积极创造条件以公平地实现AI的潜在益处。希望通过这种冷静、务实的分析，为理解和应对AI的未来提供一个更坚实的基础。&lt;/p&gt;
&lt;h3 id="内容纲要"&gt;内容纲要&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;人工智能万灵药 (AI Snake Oil)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 引言：将AI视为普通技术的愿景
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 定义：描述、预测与规范
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 核心观点：AI是工具，应由人控制，拒绝技术决定论
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 文章结构概述 (Part I-IV)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part I: 进步的速度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── AI方法、应用、采纳与扩散的区别与时间尺度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── AI在安全关键领域的扩散缓慢 (原因：安全限制)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 扩散受人类、组织和制度变革速度限制 (历史对比：电气化)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 外部世界对AI创新设置速度限制 (能力-可靠性差距、隐性知识、实验成本)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 基准测试不能衡量现实世界效用 (结构效度问题)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 经济影响可能是渐进的 (反馈循环、价值下降、目标转移)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── AI方法进步本身也存在速度限制 (羊群效应、硬件/成本、基准局限)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part II: 拥有先进AI的世界可能是什么样子
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 重新定义核心概念：从“智能”到“能力”与“权力”
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 人类能力并非受限于生物学 (技术增强视角)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 游戏提供了关于超级智能的误导性直觉 (速度 vs 其他、不可约误差)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 控制的多样性：超越对齐与人机回圈 (审计、监控、系统安全、网络安全原则等)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 预测：人类工作转向AI控制与任务规范 (卡车司机例子，市场与监管驱动)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part III: 风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 风险分类：事故、军备竞赛、滥用、失控、系统性风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 事故：主要责任在部署者/开发者，市场与监管可缓解
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 军备竞赛：历史常见，行业 специфичн, 可通过监管解决 (公司/国家层面分析)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 滥用：主要防御应在下游，模型对齐效果有限 (情境依赖性)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── AI对防御亦有助益 (攻防平衡视角)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 灾难性失控 (Misalignment)：推测性风险 (下游防御、现实部署过滤器、欺骗性对齐是工程问题)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 系统性风险：若AI为普通技术则更重要 (偏见、就业、不平等、权力集中等)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part IV: 政策
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 政策制定的挑战：不确定性与世界观分歧 (超级智能 vs 普通技术)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 对妥协与成本效益分析的批判 (概率问题、量化困难、正当性原则)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 政策目标：减少不确定性 (研究资助、监控、证据指导、证据收集)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 核心政策方法：韧性 (Resilience)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 定义与目标
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 四类韧性策略 (社会韧性、先决条件、无悔干预、促进竞争/多中心治理)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 对不扩散 (Nonproliferation) 的批判
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 执行困难、导致单点故障与脆弱性
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 不扩散作为一种有害心态及其干预措施
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 政策目标：实现AI的益处
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 扩散需要实验与灵活监管
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 监管可促进扩散 (法律确定性)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 投资于自动化的补充品 (素养、数据、基础设施)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 关注公平分配与补偿
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 公共部门需谨慎平衡采纳速度与风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└── 最终思考
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; └── 重申“AI作为普通技术”的世界观及其构成要素，呼吁相互理解
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="作为普通技术的人工智能-ai-as-normal-technology"&gt;作为普通技术的人工智能 (AI as Normal Technology)&lt;/h2&gt;
&lt;p&gt;我们阐述了一种将人工智能（AI）视为普通技术的愿景。将AI视为普通技术并非低估其影响——即使是像电力和互联网这样具有变革性的通用技术，在我们的概念中也是“普通的”。但这与关于AI未来的乌托邦和反乌托邦愿景形成对比，后者普遍倾向于将其视为一个独立的物种，一个高度自主、可能具有超级智能的实体。¹&lt;/p&gt;</description></item><item><title>Anthropic首席执行官Dario Amodei谈AI竞争与出口管制</title><link>https://linguista.cn/curated/henrinotes-2025_p2/anthropic-dario-amodei-ai-competition-export-controls/</link><pubDate>Fri, 07 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/anthropic-dario-amodei-ai-competition-export-controls/</guid><description>&lt;h1 id="anthropic首席执行官dario-amodei谈ai竞争与出口管制"&gt;Anthropic首席执行官Dario Amodei谈AI竞争与出口管制&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文记录了Anthropic公司首席执行官Dario Amodei关于中美AI竞争、出口管制政策以及AI安全性等核心议题的深度访谈。Amodei分析了中美在AI领域竞争的必然性，探讨了以DeepSeek为代表的中国AI公司的快速崛起对全球技术格局的影响，阐述了出口管制在维持美国技术领先地位中的作用，同时强调了AI安全治理与国际合作的紧迫性。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本次访谈围绕AI技术的全球竞争格局展开，核心议题涵盖中美AI竞赛的深层动因、技术出口管制的效果评估、AI安全性的多维挑战以及技术进步对民主制度的潜在影响。Amodei指出，AI技术将显著增强国家的经济和军事实力，这种能力的提升使得中美之间的AI竞争成为必然趋势。他特别强调，出口管制并非旨在完全限制技术发展，而是通过延缓竞争对手的技术进步速度，为美国在AI安全性和可靠性方面争取宝贵的缓冲时间。&lt;/p&gt;
&lt;p&gt;在AI安全性议题上，Amodei深入讨论了技术防御措施的重要性，包括检测模型蒸馏窃取行为、防止模型被用于生成有害信息等。他特别提到DeepSeek模型在某些安全测试中的表现不足，例如在生物武器相关信息的生成控制方面存在缺陷。尽管中美在AI领域存在激烈竞争，Amodei仍然认为在AI安全治理和国际协调方面存在合作空间，未来可能会因为AI技术的潜在系统性风险而迫使各国寻求对话与合作机制。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AI竞争的必然性&lt;/strong&gt;：Amodei认为中美AI竞争根植于技术对国家综合国力的决定性影响，AI既能够推动经济增长和科学研究，也可能应用于军事领域如无人机群控制和情报分析，这种双重属性使得两国都将AI技术视为战略必争领域。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;出口管制的战略价值&lt;/strong&gt;：出口管制通过限制高性能芯片等关键技术的扩散，能够延缓其他国家在AI领域的追赶速度，这种时间缓冲使得领先国家能够在AI安全性研究和可靠性保障方面保持优势，而非完全阻断技术发展。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI安全的技术防御&lt;/strong&gt;：面对模型窃取和恶意使用的风险，Anthropic正在开发检测模型蒸馏行为的技术手段，同时利用AI技术增强网络安全防护能力，这体现了以技术手段应对技术风险的前瞻性思路。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术与民主的关系&lt;/strong&gt;：AI技术具有强化民主制度或巩固专制统治的双重可能性，积极方面可用于改善司法系统、促进公共讨论和提升决策科学性，但具体影响取决于技术应用的社会制度和治理框架。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;竞争中的合作空间&lt;/strong&gt;：尽管中美AI竞争激烈，但在AI安全标准和国际治理规则制定方面仍存在合作需求，特别是面对AI技术可能带来的全球性系统性风险时，各国可能被迫寻求对话和协调机制。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.chinatalk.media/p/anthropics-dario-amodei-on-ai-competition"&gt;Anthropic&amp;rsquo;s Dario Amodei on AI Competition&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Dario Amodei&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>DeepSeek R1发布引发的思考 AI发展路径与未来趋势</title><link>https://linguista.cn/curated/henrinotes-2025_p2/deepseek-r1-ai-development-questions/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/deepseek-r1-ai-development-questions/</guid><description>&lt;h1 id="deepseek-r1发布引发的思考ai发展路径与未来趋势"&gt;DeepSeek R1发布引发的思考：AI发展路径与未来趋势&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;MIT经济学家Daron Acemoglu针对DeepSeek R1的发布提出了四个关键问题：美国科技行业是否在AI投资方向上出现群体思维、中国模式是否证明威权制度下的创新潜力、美国对华出口管制政策是否失效，以及DeepSeek是否真正推动我们接近AGI。这些问题直指当前AI发展的核心争议。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;Acemoglu首先指出美国AI投资规模已达1万亿美元，但科技行业可能陷入&amp;quot;群体思维&amp;quot;，忽视了更经济、更有前景的技术路径。DeepSeek以550万美元的训练成本实现了与数亿美元投资的美国模型相当的效果，其技术路径更依赖强化学习和混合专家模型，有效完善了思路链推理。这种差异化路径本应被美国工业界探索，却因炒作和从众心理被集体忽视。&lt;/p&gt;
&lt;p&gt;关于中美科技竞争，Acemoglu承认DeepSeek的成功令人思考威权主义制度下的创新潜力。但他强调，DeepSeek的所有技术方法均源于美国和欧洲多年的研究成果，中国企业的核心贡献在于将这些现有技术以创新方式组合。与其他依赖政府资助的中国AI公司不同，DeepSeek的&amp;quot;不为人知&amp;quot;的独立性可能是其成功的关键因素，但这种状态能否在未来持续仍是未知数。&lt;/p&gt;
&lt;p&gt;在出口管制政策方面，作者认为完全零和博弈的策略是错误的。这种策略只有在确信AGI即将实现且先行者将获得巨大地缘政治优势的前提下才有意义，而这两个假设本身就值得质疑。中美两国在AI领域存在广泛的合作空间，尤其是在能提高人类生产力的技术创新方面。&lt;/p&gt;
&lt;p&gt;关于AGI愿景，Acemoglu对近期实现AGI持怀疑态度。他认为DeepSeek确实证明了现有技术路径的优化潜力，但已知方法的改进和成本降低并不能奇迹般地在几年内实现AGI。Yann LeCun的评论进一步补充了重要观点：AGI不会是一个突发的单一事件，而是渐进过程；创新一旦开源发表就能惠及整个行业，地理起源并非决定性因素。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;群体思维与路径依赖&lt;/strong&gt;：美国科技行业在AI投资上表现出惊人的同质化，所有领先公司都采用相同的&amp;quot;海量数据预训练+下一个词预测&amp;quot;基础模型策略。这种集体忽视替代性路径的现象正是Acemoglu在《权力与进步》中预言的&amp;quot;群体思维+炒作&amp;quot;循环，导致对更经济有效方案（如DeepSeek的强化学习优先路径）的系统性盲视。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;榨取性制度与创新的悖论&lt;/strong&gt;：Acemoglu在《国家为何失败》中论证自上而下的&amp;quot;榨取性制度&amp;quot;阻碍创新，但DeepSeek的案例迫使学界重新思考这一命题。然而深入分析显示，DeepSeek的技术基础完全建立在西方学术研究成果之上，其创新本质是&amp;quot;组合式创新&amp;quot;而非&amp;quot;原创性突破&amp;quot;，这反而印证了开放社会在基础研究领域的长期优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;零和博弈的错误假设&lt;/strong&gt;：美国对华AI出口管制政策建立在一个隐含前提上：AGI竞赛是赢家通吃的零和游戏。Acemoglu犀利地指出这个双重假设本身存疑——既不能确定AGI的可行性，也无法证明先行者必然获得持久优势。这种地缘政治思维忽视了技术扩散的客观规律和合作的潜在收益。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AGI的渐进本质&lt;/strong&gt;：Yann LeCun的评论纠正了AGI认知的根本误区。AGI不应被想象为某个特定时刻的&amp;quot;奇点事件&amp;quot;，而是一个技术能力渐进累积的过程。一旦关键技术突破发生并公开，它将在短时间内被多方复制，这意味着地理先发优势在开源时代被显著削弱。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://x.com/DAcemogluMIT/status/1885755575289417919"&gt;Daron Acemoglu的推文&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Daron Acemoglu（MIT经济学家）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月20日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;评论者&lt;/td&gt;
 &lt;td&gt;Yann LeCun（Meta AI首席科学家）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>DeepSeek与出口管制深度分析</title><link>https://linguista.cn/curated/henrinotes_2025_p3/deepseek-export-controls-analysis/</link><pubDate>Mon, 03 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/deepseek-export-controls-analysis/</guid><description>&lt;h1 id="deepseek与出口管制深度分析"&gt;DeepSeek与出口管制深度分析&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文由Anthropic首席执行官Dario Amodei撰写，针对中国AI公司DeepSeek近期发布的模型进展进行深度分析。作者通过阐述AI发展的三个核心动态——规模法则、曲线移动和范式转变，解析了DeepSeek-V3和R1模型的真实技术成就与局限。文章核心论点认为，尽管DeepSeek取得了一定进展，但这反而验证了美国对华芯片出口管制政策的有效性与必要性。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先确立了出口管制政策的讨论背景。作者作为出口管制的长期支持者，此前曾撰文呼吁加强对中国高端芯片的出口限制。DeepSeek近期发布的模型在某些基准测试中接近美国前沿AI性能，这一现象表面上可能被视为出口管制政策的失败，但作者提出相反观点。&lt;/p&gt;
&lt;p&gt;接着，文章详细阐述了AI发展的三个关键动态。规模法则表明AI系统性能随训练规模扩大而提升；曲线移动指技术进步使相同性能的成本降低，但行业通常将节省的成本用于训练更智能的模型；范式转变则描述了从预训练到强化学习驱动的训练方式演变。这三个动态共同构成了理解DeepSeek进展的理论框架。&lt;/p&gt;
&lt;p&gt;在DeepSeek模型分析部分，作者重点考察了V3和R1两个模型。V3模型通过工程效率改进降低了训练成本，但作者澄清了外界对其成本的误解——DeepSeek并非用600万美元完成了美国公司数十亿美元的工作，其实际训练成本与美国模型相当。R1模型则是在V3基础上增加了强化学习第二阶段训练，创新性有限。&lt;/p&gt;
&lt;p&gt;最后，文章论证了出口管制的战略必要性。AI发展将需要更多芯片和资金，预计2026-2027年将达到关键节点。出口管制限制了中国获取高端芯片的能力，DeepSeek使用的芯片包括被禁的H100（可能走私）、禁令前进口的H800，以及未被禁的H20，这表明管制正在发挥作用。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;规模法则（Scaling Laws）&lt;/strong&gt;：AI模型性能与训练计算量、数据集大小和参数数量之间存在可预测的幂律关系。当投入更多资金用于训练时，模型性能会显著提升。这一法则自2020年以来一直是AI进步的核心驱动力，也是美国与中国AI竞争的关键因素。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;曲线移动（Moving the Curve）&lt;/strong&gt;：技术进步和硬件改进会使&amp;quot;性能-成本&amp;quot;曲线向更优方向移动，即相同性能的训练成本降低。然而，作者指出行业实践中，这种成本降低通常被用于训练更智能而非更便宜的模型。理解这一动态有助于正确评估DeepSeek的成本效率宣称。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;范式转变（Paradigm Shift）&lt;/strong&gt;：从2020-2023年的预训练主导范式，到2024年引入强化学习的新范式，AI训练方式正在演变。DeepSeek的R1模型采用了类似OpenAI o1的两阶段训练，即预训练后进行强化学习优化，这代表了当前AI领域的技术发展方向。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;出口管制的战略意义&lt;/strong&gt;：高端芯片是AI发展的战略资源，出口管制通过限制中国获取H100、H800等先进GPU，旨在保持美国在AI领域的领先地位。作者认为，尽管DeepSeek取得进展，但管制正在发挥作用，如果中国无法获取足够芯片，美国将在AI竞赛中保持长期优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;成本效率的真实含义&lt;/strong&gt;：外界误传DeepSeek用600万美元完成了美国公司数十亿美元的工作。作者澄清，DeepSeek-V3的600万主要是推理成本，实际训练成本与美国模型相当，且其使用的H800芯片是在禁令前进口的。工程效率改进确实存在，但不能简单解读为成本革命。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://darioamodei.com/on-deepseek-and-export-controls"&gt;Dario Amodei — On DeepSeek and Export Controls&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Dario Amodei&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>