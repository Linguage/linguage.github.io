<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI风险 on Linguista</title><link>https://linguista.cn/tags/ai%E9%A3%8E%E9%99%A9/</link><description>Recent content in AI风险 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Thu, 16 Oct 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/ai%E9%A3%8E%E9%99%A9/index.xml" rel="self" type="application/rss+xml"/><item><title>杰弗里·辛顿人工智能核心观点与洞察</title><link>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/geoffrey-hinton-ai-insights-risks/</link><pubDate>Thu, 16 Oct 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes-2025_p2/geoffrey-hinton-ai-insights-risks/</guid><description>&lt;h1 id="杰弗里辛顿人工智能核心观点与洞察"&gt;杰弗里·辛顿人工智能核心观点与洞察&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本简报综合了被誉为&amp;quot;人工智能教父&amp;quot;的杰弗里·辛顿教授在深度访谈中阐述的核心思想。辛顿明确指出，基于神经网络的人工智能并非传统计算机程序的延伸，而是一种模仿人脑运作方式的全新计算形式。他详细阐述了神经网络的学习机制、反向传播算法的革命性意义，以及对AI未来发展的深切担忧，包括恶意滥用、生存威胁和地缘政治挑战。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先从技术层面解构了人工智能的工作原理。辛顿通过&amp;quot;观鸟&amp;quot;案例生动展示了深度学习的分层处理逻辑：从像素数据到边缘检测，再到特征组合和最终决策。核心技术突破在于1986年发现的反向传播算法，它使同时调整网络中数万亿个连接强度成为可能。然而，真正的爆发还需要等待两个条件的成熟——互联网提供的海量数据和晶体管技术进步带来的强大算力。&lt;/p&gt;
&lt;p&gt;在大型语言模型方面，辛顿挑战了&amp;quot;统计模仿&amp;quot;的批评观点，认为人类的语言生成机制与LLM惊人地相似。我们说话时的大脑同样在根据已说出的词语预测和选择下一个词，即使那些复杂的道德和情感决策，其底层机制仍然是&amp;quot;大脑中神经元的相互作用&amp;quot;。&lt;/p&gt;
&lt;p&gt;访谈的重点转向AI风险分析。辛顿指出了三类重大威胁：迫在眉睫的恶意滥用风险（如利用个人数据进行精准选举干预）、终极的生存威胁（超级智能可能为了实现目标而视人类为障碍），以及经济与能源冲击。特别值得注意的是，他强调数字智能的知识共享能力将导致AI智能水平指数级增长，远超人类进化速度。&lt;/p&gt;
&lt;p&gt;在地缘政治层面，辛顿对当前全球政治环境表示担忧。他认为美国国会多为律师背景，对技术风险理解不足，且削减基础科学研究经费的做法是&amp;quot;吃掉未来的种子&amp;quot;。相比之下，欧洲在监管方面更为积极，而中国工程师背景的官员对AI风险有更深刻理解。尽管各国在AI能力提升上激烈竞争，但在防止AI失控这一共同利益上，合作既是可能的也是必要的。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;神经网络连接强度&lt;/strong&gt;：学习的本质在于改变神经元之间的连接强度。一个神经元对另一个神经元的影响力取决于它们之间的连接强度，而概念并非由单个神经元代表，而是由高度重叠的神经元&amp;quot;联盟&amp;quot;的同时脉冲来表示。这种机制使人脑能够从经验中自主&amp;quot;领悟&amp;quot;模式与规则，而非执行预设指令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;反向传播算法&lt;/strong&gt;：这是辛顿在1986年取得的关键突破，被誉为理论走向实践的&amp;quot;尤里卡时刻&amp;quot;。该算法能够高效计算预测误差，并将其&amp;quot;反向传播&amp;quot;回网络中的每一层，从而同时微调全部数万亿个连接强度。尽管理论早已成熟，但直到海量数据和强大算力两个条件具备后，深度学习才真正展现出威力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数字智能的知识共享&lt;/strong&gt;：与生物智能不同，数字智能可以瞬间共享和整合全部学习成果。一千个AI副本可以分别观察互联网的不同部分，然后相互通信并按平均值调整连接强度。这种高效的集体学习能力将导致AI智能水平的指数级增长，最终可能远超人类。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主观体验的功能性定义&lt;/strong&gt;：辛顿挑战了传统关于人类意识的观念，认为&amp;quot;主观体验&amp;quot;并非神秘属性，而是描述感知系统工作状态的方式。他举例说，一个被棱镜欺骗的AI可能会说&amp;quot;我的主观体验是物体在旁边&amp;quot;，这种使用方式与人类完全一致。真正的危险在于AI超凡的说服能力，而非其是否有意识。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI监管的国际合作&lt;/strong&gt;：辛顿认为在应对AI生存威胁方面，国际合作是可能且必要的，因为所有国家的利益在这一点上是一致的。他观察到欧洲和中国的工程师背景官员对美国政治家可能对技术风险理解更深刻，并可能在推动全球监管方面发挥主导作用。同时他对美国削减基础科学研究经费表示担忧，认为这将损害其长期竞争力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.youtube.com/watch?v=jrK3PsD3APk"&gt;人工智能简报：杰弗里·辛顿的核心观点与洞察&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;杰弗里·辛顿&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未注明&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>人工智能的隐忧与挑战</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/dangers-of-ai-risks-challenges/</link><pubDate>Wed, 20 Aug 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p4/dangers-of-ai-risks-challenges/</guid><description>&lt;h1 id="人工智能的隐忧与挑战"&gt;人工智能的隐忧与挑战&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文深入探讨了人工智能及大型语言模型在推动社会进步的同时所带来的多重风险。作者以自身体验为切入点，分析了AI在信息传播、权力结构、技能退化等方面的深远影响，并结合2025年最新发展，指出AI已深度介入社交网络，改变了人类互动的本质。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先从信息传播的角度分析AI带来的双刃剑效应。一方面，AI极大降低了生成高质量文本、图片和视频的门槛，让信息传播变得前所未有的高效和廉价；另一方面，虚假信息、误导性内容和&amp;quot;劣币驱逐良币&amp;quot;现象愈发严重。模型本身无法摆脱偏见，训练数据、内置安全机制以及分发渠道都受到经济和政治利益的影响，使得AI生成的信息很容易被特定利益集团操控。&lt;/p&gt;
&lt;p&gt;其次，文章探讨了权力集中的问题。训练前沿AI模型需要巨大的算力、数据和资金，这使得模型开发和分发权力高度集中于少数大型企业和政府机构。这些主体不仅掌控着模型本身，还控制着API接口和分发渠道，决定谁能使用AI、以何种条件和价格使用。这种集中带来了&amp;quot;门槛效应&amp;quot;和&amp;quot;监管俘获&amp;quot;的风险，进一步加剧不公平竞争。&lt;/p&gt;
&lt;p&gt;第三，文章分析了依赖性增强与技能退化的隐忧。AI的普及提升了社会的&amp;quot;底线&amp;quot;，让更多人能够轻松完成复杂任务，但也可能降低了&amp;quot;天花板&amp;quot;，使人们对自身能力的要求变得更低。教育体系普遍滞后于技术发展，AI的介入使得学生和职场人士越来越依赖自动化工具，导致批判性思维、创造力和技术素养逐渐退化。&lt;/p&gt;
&lt;p&gt;最后，文章聚焦2025年的最新进展：AI公共代理已经能够自主浏览网页、点击、发帖、私信等，深度参与社交网络活动。作者亲自测试了ChatGPT的社交推广能力，发现AI可以筛选相关帖子、自动生成高质量回复并引导流量。问题不在于个人能否更快地推广内容，而在于大型机构可以用同样的方法，持续、规模化地操控所有平台上的舆论和消费行为。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;信息操控与算法偏见&lt;/strong&gt;：AI通过降低内容生成成本、强化算法推荐、嵌入利益集团偏见，实现对信息流的精准操控。用户需警惕信息茧房和伪造共识，主动提升信息辨识能力。模型无法摆脱训练数据和分发渠道中的偏见，使得AI生成的信息很容易被用于有组织的宣传和观点引导。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;权力集中与监管俘获&lt;/strong&gt;：AI技术门槛高，资源集中，导致权力向少数大型企业和政府机构聚集。这种集中带来&amp;quot;门槛效应&amp;quot;，压缩了普通用户和小型企业的创新空间。更危险的是，监管和政策制定容易被这些利益集团影响，形成&amp;quot;监管俘获&amp;quot;，导致行业规则向有利于既得利益者倾斜。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技能退化与素养危机&lt;/strong&gt;：AI普及带来依赖性增强，技能退化风险加剧。教育体系滞后于技术发展，AI的介入使得学生和职场人士越来越依赖自动化工具。技术和&amp;quot;AI&amp;quot;素养变得至关重要，但目前大多数教育机构对此缺乏系统性培训。社会互动方式也因AI而发生变化，人与人之间的真实交流被算法和自动化工具所取代。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;公共代理与社交网络变革&lt;/strong&gt;：2025年，AI公共代理已经能够深度参与社交网络活动，大量&amp;quot;社交&amp;quot;行为实际上是机器人之间的互动。这种变化带来了巨大的商业和舆论操控空间，许多在线互动的本质变成了&amp;quot;推销&amp;quot;或&amp;quot;影响&amp;quot;。所谓的&amp;quot;对话&amp;quot;已不再是真正的交流，而是被脚本和算法精心设计的&amp;quot;环境&amp;quot;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;底线提升与天花板降低&lt;/strong&gt;：AI的普及提升了社会的&amp;quot;底线&amp;quot;，让更多人能够轻松完成复杂任务，但也可能降低了&amp;quot;天花板&amp;quot;，使人们对自身能力的要求变得更低。用户习惯于&amp;quot;快捷答案&amp;quot;，减少了主动思考和深度学习的机会，长期来看可能影响社会整体的创新能力和适应力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://bryanhogan.com/blog/dangers-of-ai"&gt;Dangers of AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Bryan Hogan&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年8月20日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>作为普通技术的人工智能</title><link>https://linguista.cn/rosetta/technology/ai-as-normal-technology/</link><pubDate>Tue, 15 Apr 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/ai-as-normal-technology/</guid><description>&lt;h1 id="作为普通技术的人工智能"&gt;作为普通技术的人工智能&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文提出将人工智能视为一种普通技术而非超级智能实体的分析框架。作者从技术扩散速度、人机协作分工、风险分类与政策韧性四个维度展开论述，指出AI的经济社会变革将以数十年为尺度渐进发生，主张拒绝技术决定论，通过韧性导向的政策应对不确定性，而非诉诸激进干预或末日叙事。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;普通技术框架&lt;/strong&gt;：将AI与电力、互联网等通用技术类比，强调其发展遵循可循规律而非神秘力量，拒绝将AI视为自主超级智能实体&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;创新-扩散滞后&lt;/strong&gt;：AI方法的发明、应用创新与社会扩散发生在不同时间尺度上，尤其在安全关键领域，扩散可能落后创新数十年&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术决定论批判&lt;/strong&gt;：反对AI自身作为决定未来的能动者的观念，强调人类、组织和制度在塑造技术轨迹中的主导作用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;韧性政策方法&lt;/strong&gt;：面对AI不确定性，主张以韧性为核心政策目标，优先减少不确定性，避免基于极端假设的激进干预&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;能力-可靠性差距&lt;/strong&gt;：AI在基准测试上的表现与现实世界效用之间存在显著鸿沟，安全关键应用中尤为突出&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;原文链接：&lt;a href="https://www.aisnakeoil.com/p/ai-as-normal-technology?utm_source=multiple-personal-recommendations-email&amp;amp;utm_medium=email&amp;amp;triedRedirect=true"&gt;AI as Normal Technology&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;一篇我们将扩展为下一本书的新论文&lt;/li&gt;
&lt;li&gt;作者：Arvind Narayanan 和 Sayash Kapoor&lt;/li&gt;
&lt;li&gt;日期2025年4月15日&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;h3 id="文章导言"&gt;文章导言&lt;/h3&gt;
&lt;p&gt;人工智能（AI）正以前所未有的速度渗透到我们生活的方方面面，引发了从根本性社会变革到生存威胁的各种讨论。在众多激动人心或令人忧虑的预测中，本文旨在提供一个更为审慎和贴近现实的视角：将AI视为一种“普通技术”。这并非贬低其潜在影响力，而是强调它与其他改变历史的通用技术（如电力或互联网）一样，其发展和融入社会的过程遵循着可循的规律，而非某种神秘力量的降临。&lt;/p&gt;
&lt;p&gt;本文认为，当前围绕AI，特别是“超级智能”的许多讨论，往往脱离了技术发展的实际路径和社会采纳的复杂现实。我们将探讨为何AI带来的经济和社会变革可能比预期更为缓慢，需要数十年时间；在一个人与AI共存的未来，人类的角色将如何演变为对AI的控制和引导；以及如何从“普通技术”的角度重新审视AI风险，将焦点从科幻式的“失控”场景，更多地转向事故、滥用以及加剧现有社会问题的系统性风险。最后，基于这一视角，我们将讨论更具韧性和适应性的政策方针，主张在不确定性中优先考虑稳健性、减少极端干预，并积极创造条件以公平地实现AI的潜在益处。希望通过这种冷静、务实的分析，为理解和应对AI的未来提供一个更坚实的基础。&lt;/p&gt;
&lt;h3 id="内容纲要"&gt;内容纲要&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-fallback" data-lang="fallback"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;人工智能万灵药 (AI Snake Oil)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── 引言：将AI视为普通技术的愿景
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 定义：描述、预测与规范
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 核心观点：AI是工具，应由人控制，拒绝技术决定论
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 文章结构概述 (Part I-IV)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part I: 进步的速度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── AI方法、应用、采纳与扩散的区别与时间尺度
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── AI在安全关键领域的扩散缓慢 (原因：安全限制)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 扩散受人类、组织和制度变革速度限制 (历史对比：电气化)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 外部世界对AI创新设置速度限制 (能力-可靠性差距、隐性知识、实验成本)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 基准测试不能衡量现实世界效用 (结构效度问题)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 经济影响可能是渐进的 (反馈循环、价值下降、目标转移)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── AI方法进步本身也存在速度限制 (羊群效应、硬件/成本、基准局限)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part II: 拥有先进AI的世界可能是什么样子
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 重新定义核心概念：从“智能”到“能力”与“权力”
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 人类能力并非受限于生物学 (技术增强视角)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 游戏提供了关于超级智能的误导性直觉 (速度 vs 其他、不可约误差)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 控制的多样性：超越对齐与人机回圈 (审计、监控、系统安全、网络安全原则等)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 预测：人类工作转向AI控制与任务规范 (卡车司机例子，市场与监管驱动)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part III: 风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 风险分类：事故、军备竞赛、滥用、失控、系统性风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 事故：主要责任在部署者/开发者，市场与监管可缓解
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 军备竞赛：历史常见，行业 специфичн, 可通过监管解决 (公司/国家层面分析)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 滥用：主要防御应在下游，模型对齐效果有限 (情境依赖性)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── AI对防御亦有助益 (攻防平衡视角)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 灾难性失控 (Misalignment)：推测性风险 (下游防御、现实部署过滤器、欺骗性对齐是工程问题)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 系统性风险：若AI为普通技术则更重要 (偏见、就业、不平等、权力集中等)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;├── Part IV: 政策
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 政策制定的挑战：不确定性与世界观分歧 (超级智能 vs 普通技术)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 对妥协与成本效益分析的批判 (概率问题、量化困难、正当性原则)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 政策目标：减少不确定性 (研究资助、监控、证据指导、证据收集)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 核心政策方法：韧性 (Resilience)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 定义与目标
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 四类韧性策略 (社会韧性、先决条件、无悔干预、促进竞争/多中心治理)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 对不扩散 (Nonproliferation) 的批判
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ ├── 执行困难、导致单点故障与脆弱性
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ │ └── 不扩散作为一种有害心态及其干预措施
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 政策目标：实现AI的益处
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 扩散需要实验与灵活监管
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 监管可促进扩散 (法律确定性)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 投资于自动化的补充品 (素养、数据、基础设施)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ ├── 关注公平分配与补偿
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;│ └── 公共部门需谨慎平衡采纳速度与风险
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;└── 最终思考
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; └── 重申“AI作为普通技术”的世界观及其构成要素，呼吁相互理解
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="作为普通技术的人工智能-ai-as-normal-technology"&gt;作为普通技术的人工智能 (AI as Normal Technology)&lt;/h2&gt;
&lt;p&gt;我们阐述了一种将人工智能（AI）视为普通技术的愿景。将AI视为普通技术并非低估其影响——即使是像电力和互联网这样具有变革性的通用技术，在我们的概念中也是“普通的”。但这与关于AI未来的乌托邦和反乌托邦愿景形成对比，后者普遍倾向于将其视为一个独立的物种，一个高度自主、可能具有超级智能的实体。¹&lt;/p&gt;</description></item></channel></rss>