<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>算法 on Linguista</title><link>https://linguista.cn/tags/%E7%AE%97%E6%B3%95/</link><description>Recent content in 算法 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Wed, 22 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E7%AE%97%E6%B3%95/index.xml" rel="self" type="application/rss+xml"/><item><title>图灵机从理论到实践</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/turing-machines-theory-to-practice/</link><pubDate>Wed, 22 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/turing-machines-theory-to-practice/</guid><description>&lt;h1 id="图灵机从理论到实践"&gt;图灵机从理论到实践&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;图灵机是现代计算机科学的理论基石，由艾伦·图灵于1936年提出，用于回答希尔伯特提出的决策问题。本文全面介绍了图灵机的组成结构、工作原理，深入探讨了可计算性理论、停机问题以及图灵完备性等核心概念。文章不仅提供了理论解释，还包含大量示例程序和交互式开发环境，帮助读者从实践角度理解这一基础理论模型。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从1928年希尔伯特提出的决策问题切入，阐述了图灵机产生的时代背景和科学意义。图灵和丘奇分别在1936年证明了不存在一种通用算法可以判断任意数学命题的真伪，这一结论催生了图灵机这一抽象计算模型。&lt;/p&gt;
&lt;p&gt;在定义部分，文章详细介绍了图灵机的四个核心组成部分：无限长的磁带用于存储数据、读写头用于读取和写入符号、程序控制机器行为、状态跟踪当前执行位置。基本指令包括打印符号、左右移动磁头、停止运行和状态跳转，这些看似简单的操作却构成了通用计算的基础。&lt;/p&gt;
&lt;p&gt;关于可计算性，文章解释了如果一个算法能够从给定输入产生预期输出，则该问题是可计算的。通过二进制与十进制的对比，展示了不同表示方法对程序复杂度的影响。停机问题部分揭示了一个深刻的数学真理：不存在通用算法能够判断任意程序在给定输入上是否会终止，这是计算理论的根本性限制。&lt;/p&gt;
&lt;p&gt;图灵完备性概念指出，任何能够模拟图灵机的系统都具有相同的计算能力。文章最后将理论与现实联系，说明现代计算机的寄存器架构本质上与图灵机等价，并提供了在线开发环境供读者实践。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;图灵机的组成&lt;/strong&gt;：图灵机由磁带、读写头、程序和状态四部分组成。磁带是无限长的存储介质，读写头可以在磁带上移动并读写符号，程序定义了机器的行为规则，状态则记录当前执行位置。这种看似简单的装置却能模拟任何算法过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;停机问题&lt;/strong&gt;：这是计算理论中最著名的不可计算问题。它问是否存在一个程序能够判断另一个程序在特定输入上是否会停止运行。图灵通过自指论证证明了这样的判断程序不存在，这一结论划定了计算的理论边界。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图灵完备性&lt;/strong&gt;：如果一个系统能够模拟图灵机，它就是图灵完备的。这意味着该系统具有通用计算能力，能够执行任何可计算的算法。现代编程语言、计算机架构都属于图灵完备系统，这一概念为计算能力提供了统一的衡量标准。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://samwho.dev/turing-machines/"&gt;Turing Machines&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;SamWho&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025-01-22&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>算法与人工智能助力社会进步</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/algorithms-ai-social-good/</link><pubDate>Tue, 21 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p4/algorithms-ai-social-good/</guid><description>&lt;h1 id="算法与人工智能助力社会进步"&gt;算法与人工智能助力社会进步&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文介绍MIT助理教授Manish Raghavan的研究工作，他专注于利用算法和人工智能技术解决社会问题。文章探讨了AI在招聘、医疗、社交媒体等领域的应用及其潜在风险，并提出通过提高AI系统的可观察性来减少偏见和歧视。Raghavan的研究强调，AI系统比人类决策更容易被监测和优化，这为改善社会系统提供了新的机会。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章以Manish Raghavan的研究为主线，展现了算法与人工智能在社会问题上的双重作用。一方面，AI技术在招聘、医疗分诊等领域展现出提高效率的潜力；另一方面，基于历史数据的AI系统可能继承并放大人类已有的偏见。Raghavan的核心观点是，AI系统的&amp;quot;可观察性&amp;quot;恰恰是解决这些问题的关键——相比人类决策的黑箱，算法系统更容易被监测、评估和改进。&lt;/p&gt;
&lt;p&gt;在招聘领域，Raghavan指出传统招聘方式本身存在问题，而AI工具虽然可能继承偏见，但其透明性使发现问题成为可能。医疗领域的研究展示了算法如何与专家经验结合，提高患者分诊的准确性。社交媒体方面，他和团队开发了考虑用户短期与长期福祉的模型，该研究获得了ACM经济学与计算会议的应用建模奖。&lt;/p&gt;
&lt;p&gt;Raghavan的研究方法强调从复杂问题中寻找创新解决方案，他的工作获得了国家科学基金会、微软研究等机构的认可。除了学术研究，他还担任哈佛男子足球俱乐部教练，体现了工作与生活的平衡理念。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;算法可观察性&lt;/strong&gt;：这是Raghavan研究的核心洞见。相比人类决策过程的复杂性和不可预测性，AI系统的决策过程可以被记录、分析和改进。这种可观察性使得我们能够及时发现系统中的偏见和错误，并通过算法调整来纠正问题。在招聘等敏感领域，这种透明性尤为重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;短期满足与长期福祉的平衡&lt;/strong&gt;：社交媒体算法往往优化用户的短期参与度（如点击率、停留时间），但这可能与用户的长期福祉相冲突。Raghavan开发的模型试图将这两种维度结合起来，通过改变平台设计来鼓励更健康的用户行为。这为平台经济中企业利益与用户利益的统一提供了思路。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;人机协作而非替代&lt;/strong&gt;：在医疗分诊的研究中，Raghavan并非追求完全自动化的AI决策，而是探索如何将高精度算法（如Glasgow-Blatchford Score）与专家医生的经验智慧相结合。这种人机协作的模式体现了对AI技术的理性态度——不是取代人类，而是增强人类决策能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史数据的双刃剑&lt;/strong&gt;：AI系统训练于历史数据，这意味着它们既可能学习到有价值的模式，也可能继承历史中的偏见和歧视。Raghavan的研究承认这一现实，但认为正视问题比回避问题更有意义。通过提高系统的可见性，我们可以主动识别并纠正这些偏见。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;复杂问题的搁置与重构&lt;/strong&gt;：Raghavan分享了一个独特的研究方法——当面对复杂棘手的问题时，先将其搁置一段时间，然后再重新思考。这种&amp;quot;冷处理&amp;quot;有助于打破思维定式，往往能带来新的视角和解决方案。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://news.mit.edu/2024/algorithms-ai-better-world-manish-raghavan-1206"&gt;Algorithms and AI for a better world&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;MIT News&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-12-06&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>高德纳访谈录：开源、多核架构与编程哲学</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/donald-knuth-interview-open-source-multicore-literate-programming/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/donald-knuth-interview-open-source-multicore-literate-programming/</guid><description>&lt;h1 id="高德纳访谈录开源多核架构与编程哲学"&gt;高德纳访谈录：开源、多核架构与编程哲学&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文是对计算机科学先驱高德纳（Donald Knuth）的深度访谈，涵盖了开源软件的发展前景、多核架构的技术局限、文学编程的独特价值以及编程方法论等核心议题。高德纳以他一贯的批判性思维，对当前技术趋势提出了不同于主流的观点，强调回归计算本质的重要性。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;访谈从开源软件的成功切入。高德纳认为开源的成功并不令人意外，其核心优势在于能够根据用户配置生成高度定制化的二进制文件，避免了通用软件中的效率浪费。他预测随着经济从产品转向服务，开源将占据主导地位，但也承认某些专业软件（如Photoshop）仍将保持优势。&lt;/p&gt;
&lt;p&gt;关于多核架构，高德纳表达了强烈的不满。他认为这反映了硬件设计者的创意枯竭，试图将摩尔定律放缓的责任推给软件开发者。在他50年编程生涯中编写的上千个程序里，几乎没有五个会因为并行化而明显受益。他承认并行计算在图形渲染、密码破解等特定领域有价值，但这些应用需要专用代码且技术更迭迅速。&lt;/p&gt;
&lt;p&gt;在编程方法论方面，高德纳澄清了&amp;quot;一次编译成功&amp;quot;的编程比赛传说——实际上他使用了两次运行。他对即时编译和单元测试持保留态度，认为仅在探索未知环境时才有价值。访谈还深入讨论了文学编程，这是他TeX项目中最重要但未被广泛接受的贡献。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;开源的定制化优势&lt;/strong&gt;：高德纳指出开源代码能够生成针对个人配置优化的数千个二进制文件，而商业软件通常只有几个通用版本，这避免了同步指令等不必要的开销。这种可配置性是开源相对于专有软件的内在优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多核架构的适用性局限&lt;/strong&gt;：高德纳批评多核趋势是硬件设计者推卸责任的表现。虽然多处理器对网络浏览等应用有帮助，但对大多数编程工作（包括TeX）并无实质提升。并行技术半衰期短，需要随硬件快速重构，这使其不适合作为长期教材内容。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;文学编程的个人化本质&lt;/strong&gt;：文学编程要求程序员同时擅长编程和写作，这限制了其普及。但对高德纳而言，它是处理MMIX元模拟器等复杂项目的不可或缺工具。他不强推这个理念，认为个人选择应优先于流行趋势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可重用代码的威胁论&lt;/strong&gt;：与主流观点不同，高德纳认为&amp;quot;可重新编辑的代码&amp;quot;远优于不可触碰的黑盒工具包。可重用代码虽然看似高效，但可能掩盖问题本质，降低程序员对系统的理解深度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;工具选择与个人工作流&lt;/strong&gt;：高德纳详细描述了他的编程环境——使用CWEB进行文学编程，Emacs作为编辑器，配合自制的拼写检查器和键盘快捷键。他坚持用纸笔先构思，再用计算机实现，这种传统工作方式展现了他对工具选择的独立判断。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.informit.com/articles/article.aspx?p=1193856"&gt;Interview with Donald Knuth&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Donald Knuth&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2008年4月25日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>更好的贝叶斯过滤</title><link>https://linguista.cn/person/paul_graham/essays_zh/better/</link><pubDate>Wed, 01 Jan 2003 00:00:00 +0800</pubDate><guid>https://linguista.cn/person/paul_graham/essays_zh/better/</guid><description>&lt;p&gt;→ &lt;a href="https://linguista.cn/person/paul_graham/essays_en/better/"&gt;English Version&lt;/a&gt;&lt;/p&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://www.paulgraham.com/better.html"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://www.paulgraham.com/better.html"
 target="_blank"
 rel="noopener"
 &gt;
 https://www.paulgraham.com/better.html
 &lt;/a&gt;
&lt;/div&gt;

&lt;h1 id="更好的贝叶斯过滤"&gt;更好的贝叶斯过滤&lt;/h1&gt;
&lt;p&gt;2003年1月&lt;/p&gt;
&lt;p&gt;（本文是在2003年垃圾邮件会议上的演讲。它描述了我在改进《垃圾邮件计划》中描述的算法性能方面所做的工作，以及我未来的计划。）&lt;/p&gt;
&lt;p&gt;我在这里要介绍的第一个发现是研究论文的懒惰评估算法。随便写你想写的内容，不要引用任何以前的工作，愤怒的读者会发送给你所有你应该引用的论文的参考文献。我在《垃圾邮件计划》[1]登上Slashdot后发现了这个算法。&lt;/p&gt;
&lt;p&gt;垃圾邮件过滤是文本分类的一个子集，这是一个已经成熟的领域，但是关于贝叶斯垃圾邮件过滤本身的第一篇论文似乎是在1998年同一会议上发表的两篇，一篇是Pantel和Lin的[2]，另一篇是微软研究院的一个小组[3]。&lt;/p&gt;
&lt;p&gt;当我听说这项工作时，我有点惊讶。如果人们在四年前就已经开始研究贝叶斯过滤，为什么不是每个人都在使用它呢？当我阅读这些论文时，我找到了原因。Pantel和Lin的过滤器是两个中更有效的，但它只捕获了92%的垃圾邮件，有1.16%的误报率。&lt;/p&gt;
&lt;p&gt;当我尝试编写贝叶斯垃圾邮件过滤器时，它捕获了99.5%的垃圾邮件，误报率低于0.03%[4]。当两个人尝试相同的实验得到截然不同的结果时，总是令人担忧。在这里尤其令人担忧，因为这两组数字可能会得出相反的结论。不同的用户有不同的要求，但我认为对于许多人来说，92%的过滤率和1.16%的误报率意味着过滤不是一个可接受的解决方案，而99.5%的过滤率和低于0.03%的误报率意味着它是可接受的。&lt;/p&gt;
&lt;p&gt;那么为什么我们会得到如此不同的数字呢？我没有尝试重现Pantel和Lin的结果，但是通过阅读论文，我看到了五个可能解释这种差异的原因。&lt;/p&gt;
&lt;p&gt;一个是他们用很少的数据训练他们的过滤器：160封垃圾邮件和466封非垃圾邮件。过滤器的性能在这么小的数据集上应该还在提升。所以他们的数字可能甚至不能准确衡量他们算法的性能，更不用说一般的贝叶斯垃圾邮件过滤了。&lt;/p&gt;
&lt;p&gt;但我认为最重要的区别可能是他们忽略了邮件头。对于任何从事垃圾邮件过滤工作的人来说，这似乎是一个错误的决定。然而，在我尝试编写的第一个过滤器中，我也忽略了邮件头。为什么？因为我想让问题保持整洁。那时我对邮件头了解不多，它们在我看来充满了随机的东西。这里有一个教训给过滤器编写者：不要忽略数据。你会觉得这个教训太明显了，不需要提及，但我已经不得不学习了好几次。&lt;/p&gt;
&lt;p&gt;第三，Pantel和Lin对词干进行了提取，意味着他们将例如&amp;quot;mailing&amp;quot;和&amp;quot;mailed&amp;quot;都简化为根词&amp;quot;mail&amp;quot;。他们可能觉得他们被迫这样做是因为他们的语料库很小，但如果是这样，这是一种过早的优化。&lt;/p&gt;
&lt;p&gt;第四，他们计算概率的方式不同。他们使用了所有的标记，而我只使用15个最显著的。如果你使用所有的标记，你往往会错过较长的垃圾邮件，就是那种有人告诉你他们的生活故事直到他们从某个多层次营销计划中致富的类型。而且这样的算法很容易被垃圾邮件发送者欺骗：只需添加一大块随机文本来平衡垃圾邮件术语。&lt;/p&gt;
&lt;p&gt;最后，他们没有针对误报进行偏置。我认为任何垃圾邮件过滤算法都应该有一个方便的旋钮，你可以转动它来降低误报率，代价是降低过滤率。我通过将非垃圾邮件语料库中标记的出现次数加倍来实现这一点。我认为将垃圾邮件过滤视为一个直接的文本分类问题是个坏主意。你可以使用文本分类技术，但解决方案可以也应该反映文本是邮件这一事实，特别是垃圾邮件。邮件不仅仅是文本；它有结构。垃圾邮件过滤不仅仅是分类，因为误报比漏报要糟糕得多，你应该将它们视为不同类型的错误。而且错误的来源不仅仅是随机变化，而是一个活跃的人类垃圾邮件发送者积极工作以击败你的过滤器。&lt;/p&gt;
&lt;h2 id="标记"&gt;标记&lt;/h2&gt;
&lt;p&gt;在Slashdot文章之后我听说的另一个项目是Bill Yerazunis的CRM114[5]。这证明了我刚才提到的设计原则的反例。它是一个直接的文本分类器，但它是如此惊人的有效，以至于它甚至不知道自己在做什么的情况下几乎完美地过滤垃圾邮件。&lt;/p&gt;
&lt;p&gt;一旦我理解了CRM114的工作原理，似乎我最终将不得不从基于单个词的过滤转向这样的方法。但是首先，我想，我会看看我用单个词能走多远。答案是，惊人的远。&lt;/p&gt;
&lt;p&gt;我主要在研究更智能的标记化。在当前的垃圾邮件上，我已经能够达到接近CRM114的过滤率。这些技术与Bill的技术大多是正交的；最优的解决方案可能包含两者。&lt;/p&gt;
&lt;p&gt;《垃圾邮件计划》使用了非常简单的标记定义。字母、数字、破折号、撇号和美元符号是组成字符，其他都是标记分隔符。我也忽略了大小写。&lt;/p&gt;
&lt;p&gt;现在我有一个更复杂的标记定义：保留大小写。感叹号是组成字符。句号和逗号如果出现在两个数字之间则是组成字符。这让我能够完整地获得IP地址和价格。像$20-25这样的价格范围产生两个标记，$20和$25。出现在To、From、Subject和Return-Path行中，或者url中的标记会相应地被标记。例如，Subject行中的&amp;quot;foo&amp;quot;变成&amp;quot;Subject*foo&amp;quot;。（星号可以是任何你不允许作为组成字符的字符。）这样的措施增加了过滤器的词汇量，使其更有区分力。例如，在当前的过滤器中，Subject行中的&amp;quot;free&amp;quot;有98%的垃圾邮件概率，而正文中的相同标记只有65%的垃圾邮件概率。&lt;/p&gt;
&lt;p&gt;以下是一些当前的概率[6]：&lt;/p&gt;
&lt;p&gt;Subject&lt;em&gt;FREE 0.9999
free!! 0.9999
To&lt;/em&gt;free 0.9998
Subject&lt;em&gt;free 0.9782
free! 0.9199
Free 0.9198
Url&lt;/em&gt;free 0.9091
FREE 0.8747
From*free 0.7636
free 0.6546&lt;/p&gt;
&lt;p&gt;在《垃圾邮件计划》过滤器中，所有这些标记都会有相同的概率，0.7602。那个过滤器识别了大约23,000个标记。当前的一个识别了大约187,000个。&lt;/p&gt;
&lt;p&gt;拥有更大的标记宇宙的缺点是有更多未命中的机会。将你的语料库分散到更多的标记上与使其变小的效果相同。例如，如果你将感叹号视为组成字符，那么你可能最终没有带有七个感叹号的free的垃圾邮件概率，即使你知道只有两个感叹号的free有99.99%的概率。&lt;/p&gt;
&lt;p&gt;对此的一个解决方案是我称之为退化的方法。如果你找不到标记的精确匹配，就将其视为不太具体的版本。我认为终端感叹号、大写字母以及出现在五个标记上下文中的任何一个使标记更具体。例如，如果我找不到&amp;quot;Subject&lt;em&gt;free!&amp;ldquo;的概率，我会查找&amp;quot;Subject&lt;/em&gt;free&amp;rdquo;、&amp;ldquo;free!&amp;ldquo;和&amp;quot;free&amp;quot;的概率，并取离0.5最远的那个。&lt;/p&gt;
&lt;p&gt;以下是过滤器在Subject行中看到&amp;quot;FREE!!!&amp;ldquo;且没有其概率时考虑的替代方案[7]：&lt;/p&gt;
&lt;p&gt;Subject&lt;em&gt;Free!!!
Subject&lt;/em&gt;free!!!
Subject&lt;em&gt;FREE!
Subject&lt;/em&gt;Free!
Subject&lt;em&gt;free!
Subject&lt;/em&gt;FREE
Subject&lt;em&gt;Free
Subject&lt;/em&gt;free
FREE!!!
Free!!!
free!!!
FREE!
Free!
free!
FREE
Free
free&lt;/p&gt;</description></item><item><title>垃圾邮件过滤计划</title><link>https://linguista.cn/person/paul_graham/essays_zh/spam/</link><pubDate>Thu, 01 Aug 2002 00:00:00 +0800</pubDate><guid>https://linguista.cn/person/paul_graham/essays_zh/spam/</guid><description>&lt;p&gt;→ &lt;a href="https://linguista.cn/person/paul_graham/essays_en/spam/"&gt;English Version&lt;/a&gt;&lt;/p&gt;
&lt;div
 class="link-card group relative my-3 w-full overflow-hidden rounded-xl border border-border bg-surface transition-shadow duration-300 hover:shadow-md"
 data-url="https://www.paulgraham.com/spam.html"
&gt;
 &lt;a
 class="link-card__fallback block px-4 py-3 text-sm font-medium text-accent underline-offset-4 hover:underline"
 href="https://www.paulgraham.com/spam.html"
 target="_blank"
 rel="noopener"
 &gt;
 https://www.paulgraham.com/spam.html
 &lt;/a&gt;
&lt;/div&gt;

&lt;h1 id="垃圾邮件过滤计划"&gt;垃圾邮件过滤计划&lt;/h1&gt;
&lt;p&gt;2002年8月&lt;/p&gt;
&lt;p&gt;（本文描述了在我们构建的用于测试Arc的反垃圾邮件网络邮件阅读器中使用的垃圾邮件过滤技术。改进的算法在《更好的贝叶斯过滤》中有描述。）我认为可以阻止垃圾邮件，而基于内容的过滤器是实现这一目标的方法。垃圾邮件发送者的致命弱点是他们的消息。他们可以绕过你设置的任何其他障碍。至少到目前为止是这样。但他们必须传递他们的信息，无论是什么。如果我们能够编写识别他们消息的软件，就没有办法能够绕过它。&lt;/p&gt;
&lt;p&gt;对收件人来说，垃圾邮件很容易识别。如果你雇佣某人阅读你的邮件并丢弃垃圾邮件，他们会毫无困难地做到这一点。我们需要做多少工作，除了人工智能之外，来自动化这个过程？&lt;/p&gt;
&lt;p&gt;我认为我们将能够用相当简单的算法解决这个问题。事实上，我发现你可以使用不比单个词的垃圾邮件概率的贝叶斯组合更多的东西来相当好地过滤现在的垃圾邮件。使用一个稍微调整的（如下所述）贝叶斯过滤器，我们现在在每1000封垃圾邮件中遗漏少于5封，误报率为0。&lt;/p&gt;
&lt;p&gt;统计方法通常不是人们编写垃圾邮件过滤器时首先尝试的方法。大多数黑客的第一本能是尝试编写识别垃圾邮件单个特征的软件。你看着垃圾邮件，想，这些家伙竟然敢给我发送以&amp;quot;亲爱的朋友&amp;quot;开头的邮件，或者主题行全是大写并以八个感叹号结尾的邮件。我可以用大约一行代码过滤掉这些东西。&lt;/p&gt;
&lt;p&gt;于是你这样做了，开始时它有效。几个简单的规则会大量减少你收到的垃圾邮件。仅仅查找&amp;quot;点击&amp;quot;这个词就会捕获我垃圾邮件语料库中79.7%的邮件，误报率只有1.2%。&lt;/p&gt;
&lt;p&gt;在尝试统计方法之前，我花了大约六个月编写查找单个垃圾邮件特征的软件。我发现的是，识别最后百分之几的垃圾邮件变得非常困难，而且当我使过滤器更严格时，我得到了更多的误报。&lt;/p&gt;
&lt;p&gt;误报是被错误识别为垃圾邮件的无辜邮件。对于大多数用户来说，错过合法邮件比收到垃圾邮件糟糕一个数量级，因此产生误报的过滤器就像带有死亡风险的痤疮治疗。&lt;/p&gt;
&lt;p&gt;用户收到的垃圾邮件越多，他们注意到一封无辜邮件坐在垃圾邮件文件夹中的可能性就越小。奇怪的是，你的垃圾邮件过滤器越好，误报就变得越危险，因为当过滤器真的很好时，用户更可能忽略它们捕获的一切。&lt;/p&gt;
&lt;p&gt;我不知道为什么我这么长时间才尝试统计方法。我想这是因为我对试图自己识别垃圾邮件特征上了瘾，好像我在和垃圾邮件发送者玩某种竞争游戏。（非黑客通常不会意识到这一点，但大多数黑客非常有竞争心。）当我尝试统计分析时，我立即发现它比我聪明得多。它当然发现了像&amp;quot;virtumundo&amp;quot;和&amp;quot;teens&amp;quot;这样的术语是垃圾邮件的良好指标。但它还发现&amp;quot;per&amp;quot;和&amp;quot;FL&amp;quot;和&amp;quot;ff0000&amp;quot;是垃圾邮件的良好指标。事实上，&amp;ldquo;ff0000&amp;rdquo;（亮红色的html）结果证明和任何色情术语一样是垃圾邮件的良好指标。&lt;/p&gt;
&lt;p&gt;以下是我如何进行统计过滤的概述。我从一个垃圾邮件语料库和一个非垃圾邮件语料库开始。目前每个语料库中大约有4000条消息。我扫描每个语料库中每条消息的整个文本，包括标题、嵌入的html和javascript。我目前认为字母数字字符、破折号、撇号和美元符号是标记的一部分，其他一切都是标记分隔符。（这里可能还有改进的空间。）我忽略全是数字的标记，我也忽略html注释，甚至不将它们视为标记分隔符。&lt;/p&gt;
&lt;p&gt;我计算每个标记（目前忽略大小写）在每个语料库中出现的次数。在这个阶段，我最终得到两个大的哈希表，每个语料库一个，将标记映射到出现次数。&lt;/p&gt;
&lt;p&gt;接下来我创建第三个哈希表，这次将每个标记映射到包含它的电子邮件是垃圾邮件的概率，我计算如下[1]：(let ((g (* 2 (or (gethash word good) 0))) (b (or (gethash word bad) 0))) (unless (&amp;lt; (+ g b) 5) (max .01 (min .99 (float (/ (min 1 (/ b nbad)) (+ (min 1 (/ g ngood)) (min 1 (/ b nbad))))))))) 其中word是我们计算其概率的标记，good和bad是我在第一步创建的哈希表，ngood和nbad分别是非垃圾邮件和垃圾邮件的数量。&lt;/p&gt;</description></item></channel></rss>