<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>推理时计算 on Linguista</title><link>https://linguista.cn/tags/%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97/</link><description>Recent content in 推理时计算 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Thu, 01 May 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%8E%A8%E7%90%86%E6%97%B6%E8%AE%A1%E7%AE%97/index.xml" rel="self" type="application/rss+xml"/><item><title>模型为何思考</title><link>https://linguista.cn/rosetta/technology/why-models-think/</link><pubDate>Thu, 01 May 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/rosetta/technology/why-models-think/</guid><description>&lt;h1 id="模型为何思考"&gt;模型为何思考&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文系统回顾了大语言模型在推理时如何通过额外计算提升性能的最新进展。从心理学双系统理论类比出发，探讨了思维链prompting、并行采样、序列修订等关键技术，分析了将计算视为资源和潜在变量建模两种理论视角，并梳理了从早期CoT到o1、R1等推理模型的发展脉络。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;推理时计算（Test-time Compute）&lt;/strong&gt;：指模型在推理阶段而非训练阶段投入额外计算资源，通过更多的思考步骤来提升输出质量&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思维链（Chain-of-Thought）&lt;/strong&gt;：让模型在给出最终答案前生成中间推理步骤的方法，类似人类逐步解题的过程&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;并行采样（Parallel Sampling）&lt;/strong&gt;：同时生成多个候选输出，再通过评分函数或多数投票选择最优结果的解码策略&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;序列修订（Sequential Revision）&lt;/strong&gt;：让模型对已有输出进行反思和迭代修正，逐步改进响应质量的方法&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;潜在变量建模（Latent Variable Modeling）&lt;/strong&gt;：将思考过程视为隐藏变量，通过边缘化所有可能的推理路径来建模最终答案分布的概率框架&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原文链接：&lt;a href="https://lilianweng.github.io/posts/2025-05-01-thinking/"&gt;Why We Think&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;日期：2025年5月1日&lt;/li&gt;
&lt;li&gt;预计阅读时间：40分钟&lt;/li&gt;
&lt;li&gt;作者：Lilian Weng&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;特别感谢 &lt;a href="https://scholar.google.com/citations?user=itSa94cAAAAJ&amp;amp;hl=en"&gt;John Schulman&lt;/a&gt; 为本文提供了大量极其宝贵的反馈和直接编辑。&lt;/p&gt;
&lt;p&gt;推理时计算 (&lt;a href="https://arxiv.org/abs/1603.08983"&gt;Graves et al. 2016&lt;/a&gt;、&lt;a href="https://arxiv.org/abs/1705.04146"&gt;Ling, et al. 2017&lt;/a&gt;、&lt;a href="https://arxiv.org/abs/2110.14168"&gt;Cobbe et al. 2021&lt;/a&gt;) 和思维链 (CoT) (&lt;a href="https://arxiv.org/abs/2201.11903"&gt;Wei et al. 2022&lt;/a&gt;、&lt;a href="https://arxiv.org/abs/2112.00114"&gt;Nye et al. 2021&lt;/a&gt;) 显著提升了模型性能，同时也引发了许多研究问题。本文旨在回顾关于如何有效利用推理时计算（即“思考时间”）及其益处的最新进展。&lt;/p&gt;
&lt;h1 id="动机"&gt;动机&lt;/h1&gt;
&lt;p&gt;让模型进行更长时间的思考，可以从几个不同方面进行阐述。&lt;/p&gt;
&lt;h2 id="心理学类比"&gt;心理学类比&lt;/h2&gt;
&lt;p&gt;核心思想与人类的思考方式息息相关。我们人类无法立即给出&lt;code&gt;“12345 乘以 56789 是多少？”&lt;/code&gt;这个问题的答案。相反，对于复杂问题，我们自然会花时间思考和分析，然后才能得出结果。在 &lt;a href="https://www.amazon.com/Thinking-Fast-Slow-Daniel-Kahneman/dp/0374533555"&gt;《思考，快与慢》(Kahneman, 2013)&lt;/a&gt; 一书中，丹尼尔·卡尼曼 (Daniel Kahneman) 借助 &lt;a href="https://en.wikipedia.org/wiki/Dual_process_theory"&gt;双系统理论&lt;/a&gt; 的视角，将人类思维划分为两种模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;快速思维（系统 1）&lt;/em&gt; 运作迅速且自动化，由直觉和情感驱动，几乎不需要努力。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;慢速思维（系统 2）&lt;/em&gt; 需要深思熟虑、逻辑推理和显著的认知努力。这种思维模式消耗更多的脑力，需要有意识的参与。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于系统 1 思维快速且容易，它常常成为主要的决策驱动因素，但代价是牺牲了准确性和逻辑性。它自然地依赖我们大脑的思维捷径（即启发式），并可能导致错误和偏见。通过有意识地放慢速度，花更多时间反思、改进和分析，我们可以运用系统 2 思维来挑战我们的直觉，做出更理性的选择。&lt;/p&gt;
&lt;h2 id="计算作为一种资源"&gt;计算作为一种资源&lt;/h2&gt;
&lt;p&gt;深度学习的一种观点认为，神经网络可以根据其在一次前向传播中可访问的计算量和存储量来表征；如果我们使用梯度下降优化它们来解决问题，优化过程将找出如何利用这些资源——它们将弄清楚如何将这些资源组织成用于计算和信息存储的电路。从这个角度来看，如果我们设计一个能够在推理时进行更多计算的架构或系统，并训练它有效利用这一资源，它将表现得更好。&lt;/p&gt;</description></item></channel></rss>