<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ChatGPT on Linguista</title><link>https://linguista.cn/tags/chatgpt/</link><description>Recent content in ChatGPT on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 09 Feb 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/chatgpt/index.xml" rel="self" type="application/rss+xml"/><item><title>ChatGPT的可靠性问题：两年投资后的现状</title><link>https://linguista.cn/curated/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</link><pubDate>Sun, 09 Feb 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025_p2/chatgpt-reliability-issues-after-two-years/</guid><description>&lt;h1 id="chatgpt的可靠性问题两年投资后的现状"&gt;ChatGPT的可靠性问题：两年投资后的现状&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文记录了作者对ChatGPT最新版本的测试结果，展示了其在处理基本任务时仍然存在的可靠性问题。通过美国各州收入与人口表格、加拿大省份元音计数等测试，暴露出ChatGPT在计数、完整性、基础事实判断等方面的不足。作者质疑在如此多错误存在的情况下，通用人工智能（AGI）是否真如某些预测所言即将实现。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章从软银集团孙正义对AGI的乐观预测切入，引出作者对ChatGPT实际表现的测试。测试内容包括两个主要案例：生成美国各州收入与人口表格，以及统计加拿大省份名称中的元音数量。&lt;/p&gt;
&lt;p&gt;在美国各州测试中，ChatGPT初始输出遗漏了多个州，补充人口密度列时出现计算错误，甚至将阿拉斯加完全遗漏。经过多次修正才最终得到正确结果。在加拿大省份元音计数测试中，ChatGPT将字母&amp;quot;h&amp;quot;误认为元音，计数多次出错，修正过程同样曲折。&lt;/p&gt;
&lt;p&gt;文章还引用了Sayash Kapoor对OpenAI新Operator代理的测试结果，显示即使是新发布的AI代理也存在可靠性问题。作者最后引用1841年经典著作中的论述，反思当前AI热潮中可能存在的盲目性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AGI预测与现实的差距&lt;/strong&gt;：软银孙正义预测AGI将在未来几年内实现，但基础测试显示当前AI模型连简单任务都无法可靠完成，这种预测与实际能力之间存在巨大鸿沟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可靠性问题的具体表现&lt;/strong&gt;：ChatGPT在计数、列表完整性、基础事实判断等方面频发错误，包括无法准确计数到50、遗漏美国州、错误识别元音字母等，这些问题在经过两年大规模投资后仍然存在。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AI模型的盲目自信&lt;/strong&gt;：ChatGPT在犯错时并未表现出不确定性，而是自信地给出错误答案，只有在被明确指出后才进行修正，这种特性增加了用户被误导的风险。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;修正过程的繁琐性&lt;/strong&gt;：即使是简单任务，也需要用户多次指出错误才能得到正确结果，这种交互方式大大降低了AI工具的实用性和可靠性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;历史警示的当代意义&lt;/strong&gt;：作者引用1841年关于群体盲目性的论述，暗示当前AI热潮可能存在类似的非理性现象，提醒人们需要更客观地评估AI技术的实际发展水平。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://garymarcus.substack.com/p/chatgpt-in-shambles?utm_source=post-email-title&amp;amp;publication_id=888615&amp;amp;post_id=156479923&amp;amp;utm_campaign=email-post-title&amp;amp;isFreemail=true&amp;amp;r=208yzy&amp;amp;triedRedirect=true&amp;amp;utm_medium=email"&gt;ChatGPT in Shambles&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Gary Marcus&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>科学中的聊天机器人ChatGPT应用指南</title><link>https://linguista.cn/curated/henrinotes-2025-p1/chatgpt-scientific-research-guide/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/chatgpt-scientific-research-guide/</guid><description>&lt;h1 id="科学中的聊天机器人chatgpt能为你做什么"&gt;科学中的聊天机器人：ChatGPT能为你做什么？&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文总结了Milton Pividori关于ChatGPT在科学研究中的应用经验，提出了有效使用聊天机器人的三条核心原则：精心设计提示、选择合适任务、以及认识写作与阅读的风险差异。文章强调了人类在科研创意过程中的主导作用，同时指出AI工具在减轻重复性工作负担方面的潜力。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章围绕ChatGPT在科学研究场景中的应用展开系统性分析。首先从提示工程的角度，详细阐述了如何通过清晰指令、角色设定、示例提供和格式规范来优化AI输出质量。这四项提示设计策略能够显著提升聊天机器人理解科研任务的准确性。&lt;/p&gt;
&lt;p&gt;其次，文章探讨了任务适配性的重要性。作者指出，在研究初期需要高度创造性思维的阶段，如文献回顾和问题定义，AI工具可能因缺乏深度理解而遗漏关键信息。相比之下，在研究后期使用聊天机器人进行文章总结和内容梳理则更为安全可靠。&lt;/p&gt;
&lt;p&gt;最后，文章对比了AI辅助写作与AI辅助阅读的不同风险水平。当研究人员使用聊天机器人生成内容时，他们能够主动验证输出的准确性；而当AI&amp;quot;阅读&amp;quot;和分析文献时，人类更容易错过重要信息。这种风险差异决定了科研工作者应该有选择地使用AI工具。&lt;/p&gt;
&lt;p&gt;Pividori的团队还开发了将ChatGPT整合到Manubot协作写作平台中的工具，这体现了将AI能力嵌入科研工作流的实践探索。文章的核心观点是：聊天机器人应当成为科研人员的辅助工具，而非替代人类创造性和批判性思维的解决方案。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;提示工程&lt;/strong&gt;：指通过精确设计输入指令来引导AI模型产生期望输出的技术。在科研场景中，有效的提示应包含明确的动作指令、专业角色定位、具体的输入输出示例，以及清晰的格式要求。这种系统性方法能够显著提升AI在学术任务中的表现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务适配性原则&lt;/strong&gt;：根据任务的创造性需求和风险程度来决定是否使用AI辅助。高创造性、高风险的任务（如研究问题定义）应保持人类主导；而低创造性、低风险的任务（如文章总结）则可以放心交给聊天机器人处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;不对称风险理论&lt;/strong&gt;：AI辅助写作和AI辅助阅读存在本质差异。写作时人类可以主动校验AI输出，风险可控；阅读时人类容易过度依赖AI判断，可能错过关键信息。理解这种风险差异有助于科研工作者制定合理的AI使用策略。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.nature.com/articles/d41586-024-02630-z"&gt;Chatbots in science: What can ChatGPT do for you?&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Milton Pividori&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-08-19&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>