<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>并行计算 on Linguista</title><link>https://linguista.cn/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/</link><description>Recent content in 并行计算 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 10 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/index.xml" rel="self" type="application/rss+xml"/><item><title>GPU与CUDA简介</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/gpu-cuda-introduction-guide/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/gpu-cuda-introduction-guide/</guid><description>&lt;h1 id="gpu与cuda简介"&gt;GPU与CUDA简介&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文是一篇关于GPU与CUDA基础知识的系统介绍，从计算机基础概念出发，逐步深入到GPU硬件架构和CUDA编程模型。文章首先讲解了计算机基础知识，包括IO设备、CPU与内存、并行与并发、编译器以及堆与栈等核心概念。接着详细介绍GPU的基础知识，包括GPU作为计算设备的特性、流多处理器执行单元、GPU产品架构分类以及GPU内存层级结构。最后重点阐述CUDA编程平台和模型，涵盖CUDA编程基础、线程模型、内存管理和nvcc编译器等内容。整篇文章为理解GPU并行计算和CUDA编程提供了完整的知识框架。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章采用递进式的知识结构，从计算机基础到GPU专业知识，再到CUDA编程实践，形成了完整的学习路径。第一部分计算机基础知识为后续内容奠定基础，帮助读者理解CPU、内存、并行并发等核心概念。第二部分GPU基础知识介绍GPU的独特架构和计算优势，特别是流多处理器SM的设计使GPU能够大规模并行执行任务。第三部分CUDA编程基础是文章的核心内容，详细解释了CUDA的线程模型、内存管理和编译流程。&lt;/p&gt;
&lt;p&gt;文章强调GPU与CPU的根本区别在于并行计算能力。一个CPU核心在同一时间点只能执行一个任务，而一个GPU的流多处理器SM可以同时执行多达32个任务。这种设计使GPU在处理大规模并行计算任务时具有显著优势，特别适合深度学习、科学计算等领域。CUDA作为英伟达推出的通用并行计算平台和编程模型，为开发者提供了使用GPU进行并行计算的标准化方法。&lt;/p&gt;
&lt;p&gt;文章还指出计算机知识体系的特点是会抽象出很多概念帮助读者理解，但真实运作方式往往更加复杂。计算机领域从业者喜欢&amp;quot;起名&amp;quot;来突出产品亮点，这在GPU和CUDA的术语体系中表现得尤为明显。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;流多处理器SM&lt;/strong&gt;：GPU的基本执行单元，是GPU实现大规模并行计算的关键。一个SM在同一时间点最多可以执行32个任务，而一个CPU Core只能执行1个任务。SM中包含多个CUDA Core作为实际运算单元，这种设计使GPU能够同时处理大量并行任务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CUDA线程模型&lt;/strong&gt;：CUDA编程的核心概念，采用嵌套式结构。多个线程构成线程块，多个线程块构成网格。Grid和Block可以是一维、二维或三维数组结构。在核函数中，通过gridDim、blockIdx、blockDim、threadIdx等对象来管理和协调线程的执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GPU内存层级&lt;/strong&gt;：GPU的内存系统采用多级缓存结构，从高到低依次是寄存器文件、L1 Cache、L2 Cache和DRAM。寄存器文件和L1 Cache属于片上内存，存在于SM上；L2 Cache和DRAM属于片外内存。当寄存器内存不足时会发生溢出，溢出部分称为本地内存。共享内存存在于L1 Cache之上，供同一个block中的所有线程访问，用于减少访问高带宽内存HBM的次数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主机与设备&lt;/strong&gt;：在GPU编程中，将计算机称为主机，GPU称为设备。两者之间是异步执行关系，通过PCIe总线连接。CUDA编程需要明确区分主机函数和设备函数，使用__host__和__device__修饰符来标识。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nvcc编译器&lt;/strong&gt;：CUDA程序的专用编译器，编译时将代码分为主机代码和设备代码。主机代码的编译过程与gcc类似，设备代码会先转换成PTX伪汇编代码，再编译成cubin形式的目标代码。这种分离式编译设计使得CUDA能够充分利用GPU的并行计算能力。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://zhuanlan.zhihu.com/p/686772546"&gt;GPU 与 CUDA 简介 - 知乎&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;知乎作者&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-01-10&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>为何我们仍然使用CPU而非仅依赖GPU</title><link>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/cpu-gpu-architectural-differences-use-cases/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/info/tldrcards/henrinotes_2025_p3/cpu-gpu-architectural-differences-use-cases/</guid><description>&lt;h1 id="为何我们仍然使用cpu而非仅依赖gpu"&gt;为何我们仍然使用CPU而非仅依赖GPU&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文通过对比CPU与GPU的架构特点和适用场景，揭示了两者在计算机系统中的互补关系。GPU虽然在并行计算能力上远超CPU，但CPU在处理复杂逻辑、任务调度和应对不可预测事件方面具有独特优势，因此现代芯片设计将两者结合以满足不同计算需求。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先通过TFLOPS指标对比了CPU与GPU的原始计算能力，指出GPU的浮点运算性能通常是CPU的30倍以上。但作者强调，这种性能差异只在特定类型的任务上才能体现。&lt;/p&gt;
&lt;p&gt;接着，文章将程序分为顺序程序和并行程序两类。顺序程序如斐波那契数列计算，每一步都依赖前一步的结果，无法并行化；而并行程序如对数字列表进行批量运算，各计算相互独立，可分配给多个处理器同时执行。现实中大型应用通常是两者的混合。&lt;/p&gt;
&lt;p&gt;在架构设计上，CPU采用少量大核心设计，擅长顺序执行和复杂决策，类似餐厅大厨能应对各种突发情况；GPU则拥有众多小核心，适合对大量数据执行相同的并行操作，如视频游戏中的像素渲染。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;TFLOPS（每秒万亿次浮点运算）&lt;/strong&gt;：衡量处理器计算能力的指标，Nvidia A100 GPU可达9.7 TFLOPS，而英特尔24核处理器仅0.33 TFLOPS。但这只是理论峰值，实际性能取决于程序类型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;顺序程序与并行程序&lt;/strong&gt;：顺序程序指令必须依次执行，每步依赖前步结果；并行程序指令相互独立，可同时执行。现实应用通常是两者的混合。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大核心与小核心架构&lt;/strong&gt;：CPU的少量大核心优化了单线程性能和任务切换能力；GPU的众多小核心优化了吞吐量，适合数据并行任务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务的灵活调度&lt;/strong&gt;：CPU需要处理各种不可预测事件，如应用启动停止、网络连接中断、文件访问等，其任务切换能力确保系统响应性和资源合理分配。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;协同计算模式&lt;/strong&gt;：现代计算机中，CPU负责任务管理和资源分配，GPU负责大规模并行计算，两者协同工作以发挥各自优势。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://codingstuff.substack.com/p/if-gpus-are-so-good-why-do-we-still"&gt;If GPUs Are So Good, Why Do We Still Use CPUs At All?&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;未知&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>