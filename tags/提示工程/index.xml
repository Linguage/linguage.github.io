<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>提示工程 on Linguista</title><link>https://linguista.cn/tags/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/</link><description>Recent content in 提示工程 on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Wed, 08 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/index.xml" rel="self" type="application/rss+xml"/><item><title>AI如何通过有效提问提升代码质量</title><link>https://linguista.cn/curated/henrinotes_2025_p3/ai-code-optimization-effective-prompts/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/ai-code-optimization-effective-prompts/</guid><description>&lt;h1 id="ai如何通过有效提问提升代码质量"&gt;AI如何通过有效提问提升代码质量&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;大型语言模型（LLMs）在代码生成和优化方面展现出显著潜力，但其表现很大程度上取决于提问方式的有效性。研究表明，通过简单迭代提示或复杂的提示工程技术，可以显著提升AI生成代码的性能，但这种方法仍需开发者具备一定的软件开发经验来判断代码质量和处理潜在错误。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本文基于Buzzfeed高级数据科学家Max Woolf的实验研究，探讨了如何通过有效的提示策略让大型语言模型（尤其是Anthropic的Claude）优化其生成的代码。实验从一个简单的Python编程任务开始——寻找数字之和为30的最小和最大数字之间的差异，初始代码运行时间为657毫秒。&lt;/p&gt;
&lt;p&gt;研究发现，当直接要求Claude&amp;quot;改进代码&amp;quot;时，AI能够生成性能提升2.7倍的优化版本。通过多次迭代改进，代码性能最终提升达到99.7倍。这表明LLMs确实具备自我反思和代码优化的能力。&lt;/p&gt;
&lt;p&gt;文章还深入分析了&amp;quot;提示工程&amp;quot;技术——通过提供更详细的期望和示例来指导LLM。这种方法能够更快速和一致地提升代码性能，但也更可能引入细微的错误。Woolf的实验显示，Claude在优化过程中曾使用多线程技术实现5.1倍性能提升，但也同时引入了需要修复的错误。&lt;/p&gt;
&lt;p&gt;来自东北大学、韦尔斯利学院和奥伯林学院的联合研究支持了这一发现，强调了提示内容在AI代码生成中的关键作用。然而，这也揭示了一个重要限制：AI代码帮助对新手的实用性受到开发者背景知识需求的制约。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;迭代式代码优化&lt;/strong&gt;：LLMs能够通过简单直接的提示（如&amp;quot;改进代码&amp;quot;）逐步优化其生成的代码。在Woolf的实验中，这种方法使Python代码性能从初始的657毫秒最终提升至99.7倍，展现了AI在代码性能优化方面的自我反思和持续改进能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;提示工程&lt;/strong&gt;：这是一种更高级的提示策略，通过修改系统提示、提供详细期望和具体改进指示来指导LLM采用特定的代码效率策略。虽然这种方法能更快速和一致地提升性能，但也增加了引入细微错误的风险，体现了AI优化中速度与准确性的权衡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;开发经验的重要性&lt;/strong&gt;：研究表明，虽然LLMs能够生成和优化代码，但有效利用这些工具仍需开发者具备判断代码质量和理解特定领域约束的背景知识。这一发现揭示了AI编程助手在帮助新手开发者方面的内在局限性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;性能与正确性的平衡&lt;/strong&gt;：实验中发现，Claude在使用多线程技术实现5.1倍性能提升的同时引入了错误，这凸显了AI代码优化中的一个核心挑战——在追求性能提升的同时确保代码的正确性和可靠性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.theregister.com/2025/01/07/ai_can_write_improved_code_research/?ref=dailydev"&gt;AI can improve on code it writes, but you have to know how to ask&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Thomas Claburn&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月7日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>下一代提示工程的七种技术</title><link>https://linguista.cn/curated/henrinotes_2025_p3/next-generation-prompt-engineering-techniques/</link><pubDate>Wed, 08 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes_2025_p3/next-generation-prompt-engineering-techniques/</guid><description>&lt;h1 id="下一代提示工程的七种技术"&gt;下一代提示工程的七种技术&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文深入探讨了七种下一代提示工程技术，这些技术旨在优化大型语言模型的性能和输出质量。文章通过详细的表格对比，系统介绍了每种技术的工作原理、应用场景、优势及挑战，并提供了具体示例，为AI从业者提供了实用的提示工程实践指南。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章开篇即点明提示工程在提升LLM性能中的关键作用，随后通过结构化的方式逐一介绍七种先进技术。每种技术都从定义、工作原理、优势、挑战和实际应用示例五个维度进行阐述，使读者能够全面理解并快速应用到实践中。&lt;/p&gt;
&lt;p&gt;这七种技术涵盖了从简单到复杂的多个层面：Meta Prompting让LLM自身生成和优化提示；Least-to-Most Prompting通过问题分解降低复杂度；Multi-Task Prompting实现单次执行多个任务；Role Prompting通过角色定位增强专业性；Task-Specific Prompting针对特定任务优化；PAL引入编程环境增强问题解决能力；CoVe则通过验证机制提升准确性。&lt;/p&gt;
&lt;p&gt;文章强调，这些技术并非孤立存在，而是可以根据具体需求组合使用。选择合适的技术需要考虑任务复杂性、所需输出质量以及模型的知识储备等因素。通过系统化的提示工程，用户可以显著提升LLM在实际应用中的表现。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Meta Prompting（元提示）&lt;/strong&gt;：这是一种递归式的提示方法，将提示本身视为输出内容。利用LLM生成、解释和优化提示，包括优化其自身的提示。这种方法特别适合需要持续迭代和调整的复杂任务，但效果受限于LLM的知识库范围。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Least-to-Most Prompting（最少到最多提示）&lt;/strong&gt;：核心思想是将复杂问题拆解为一系列有序的子问题，引导模型逐步解决。这种方法能够提高准确性，减少错误累积，特别适用于已知解决方案路径的复杂推理任务，如数学计算或逻辑推理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multi-Task Prompting（多任务提示）&lt;/strong&gt;：在一个提示中集成多个相关任务，要求模型同时处理并输出结果。这提高了效率，保持了上下文的连贯性，但随着任务数量增加，输出准确性可能下降，需要合理控制任务复杂度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Program-Aided Language Models (PAL)&lt;/strong&gt;：将外部编程环境引入提示工程，让模型生成程序代码来解决需要精确计算的问题。这种方法特别适合数学、逻辑推理等传统LLM表现不佳的领域，通过代码执行获得准确结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chain-of-Verification (CoVe) Prompting&lt;/strong&gt;：通过自我验证机制减少LLM的幻觉问题。模型先生成初步答案，然后生成验证问题并回答，最后整合验证结果优化输出。这种三步验证流程显著提高了事实性任务的准确性。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://machinelearningmastery.com/7-next-generation-prompt-engineering-techniques/?ref=dailydev"&gt;7 Next-Generation Prompt Engineering Techniques&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Cornellius Yudha Wijaya&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年1月7日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>OpenAI o1模型推理应用指南</title><link>https://linguista.cn/curated/henrinotes-2025-p1/openai-o1-model-reasoning-guide/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/openai-o1-model-reasoning-guide/</guid><description>&lt;h1 id="openai-o1模型推理应用指南"&gt;OpenAI o1模型推理应用指南&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本课程由OpenAI的AI解决方案负责人Colin Jarvis主讲，全面介绍o1模型的工作机制、性能特征及应用场景。课程时长1小时10分钟，涵盖o1模型的核心技术原理&amp;quot;测试时计算&amp;quot;和自动思维链提示，以及在规划、编码、图像推理等任务中的实际应用。学习者将掌握如何有效提示o1模型，理解何时委托给成本更低的模型，并通过元提示技术优化应用性能。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;课程从o1模型的基础介绍开始，详细解析了其在抽象推理任务中的核心优势。o1模型采用&amp;quot;测试时计算&amp;quot;技术，通过自动思维链提示将复杂问题分解为更小的步骤，尝试多种策略后给出答案。这种机制使其在规划、编码、分析、法律推理以及STEM学科等领域表现优异。&lt;/p&gt;
&lt;p&gt;课程的核心内容围绕如何有效使用o1模型展开。学习者将掌握四个关键的提示原则，从&amp;quot;简单直接&amp;quot;到&amp;quot;展示而非告诉&amp;quot;，并理解不同提示策略对性能的影响。课程特别强调任务与模型的匹配原则，教授学员识别o1适合的任务类型，以及何时应该使用更小更快的模型来平衡智能与成本。&lt;/p&gt;
&lt;p&gt;实践环节涵盖多个应用场景：使用o1作为协调器创建计划，委托4o-mini模型顺序执行；在编码任务中构建新应用或编辑现有代码；进行图像推理，通过层次化理解提升任务表现；以及运用元提示技术迭代优化提示质量。课程还提供了编码竞赛等实际案例来测试和验证o1的性能表现。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;测试时计算&lt;/strong&gt;：o1模型的核心技术创新，通过在推理阶段投入更多计算资源来提升复杂任务的性能。与传统模型不同，o1会在返回答案前进行多轮思考和策略尝试，将问题分解为子任务逐一解决。这种机制特别适合需要深度推理的场景，但也会增加响应延迟和计算成本。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自动思维链提示&lt;/strong&gt;：o1模型内置的推理机制，无需人工编写思维链提示即可自动将复杂问题分解。模型会自主识别任务类型，规划解决路径，尝试多种方法，并在最终回答前进行自我验证。这一特性使o1在需要逻辑推理的任务中显著优于传统模型，但也意味着提示策略需要相应调整。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务模型匹配原则&lt;/strong&gt;：有效使用o1的关键在于理解何时使用它，何时委托给更小的模型。对于需要深度推理的复杂任务，o1的智能提升值得其成本和延迟；但对于简单任务，使用4o-mini等轻量模型更经济高效。最佳实践是让o1作为协调器创建计划，然后委托其他模型执行具体步骤。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;元提示技术&lt;/strong&gt;：使用o1来改善和优化提示的方法论。通过让o1分析现有提示的不足，并提供改进建议，可以迭代提升模型在特定任务上的表现。课程通过客户支持评估集展示了如何系统化地应用这一技术，将手动提示优化转化为可重复的工程流程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多模态推理能力&lt;/strong&gt;：o1在图像理解任务中展现的层次化推理能力。不仅识别图像内容，还能通过推理理解图像中的结构关系和隐含信息。这种能力在视觉问答、文档分析、图表解读等场景中具有显著优势，突破了传统视觉模型的识别局限。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.deeplearning.ai/short-courses/reasoning-with-o1/"&gt;Reasoning with o1 - DeepLearning.AI&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Colin Jarvis（OpenAI AI解决方案负责人）&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;课程时长&lt;/td&gt;
 &lt;td&gt;1小时10分钟&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;课程难度&lt;/td&gt;
 &lt;td&gt;中级&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;合作机构&lt;/td&gt;
 &lt;td&gt;OpenAI&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>多种经典提示技术的应用与设置</title><link>https://linguista.cn/curated/henrinotes-2025-p1/classic-prompting-techniques-guide/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/classic-prompting-techniques-guide/</guid><description>&lt;h1 id="多种经典提示技术的应用与设置"&gt;多种经典提示技术的应用与设置&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文全面介绍了提示工程的核心要素，包括模型参数设置、提示词设计原则以及多种经典提示技术。文章从温度、Top_p等基础参数讲起，深入解析零样本、少样本、链式思考等主流提示方法，并探讨了思维树、自动推理工具、自我反思等进阶技术，为开发者提供了系统性的提示工程实践指南。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章首先阐述了大语言模型交互时的关键模型设置参数。温度参数控制输出的确定性与创造性，较低温度使模型输出更确定，较高温度则增加随机性，适合创造性任务。Top_p参数通过核采样控制响应多样性，最大长度限制防止冗余输出，停止序列精确控制输出结构，频率和存在惩罚则有效避免内容重复。&lt;/p&gt;
&lt;p&gt;在提示词设计方面，文章强调了四个核心要素。指令明确模型要执行的具体任务，上下文提供必要的外部信息，输入数据包含用户的实际问题，输出指示规范结果的格式类型。设计时应从简单入手逐步迭代，使用明确具体的指令，并通过示例引导模型产生期望输出。&lt;/p&gt;
&lt;p&gt;文章重点介绍了多种经典提示技术及其应用场景。零样本提示直接提问不提供示例，依赖模型预训练知识；少样本提示通过一到多个示例帮助模型理解任务模式；链式思考提示引导模型展示中间推理步骤，特别适合复杂逻辑问题。自动思维链通过聚类和抽样自动生成推理链，自我一致性方法则结合多条推理路径选择最稳定答案。&lt;/p&gt;
&lt;p&gt;进阶技术部分涵盖了生成知识提示、链式提示分解、思维树决策等高级方法。生成知识提示先让模型生成相关知识再回答问题，链式提示将复杂任务拆解为多个子任务逐步处理，思维树技术模仿人类决策过程用树状结构表示问题解决路径。自动推理工具技术结合中间推理步骤和外部工具使用，自我反思则通过语言反馈不断强化智能体的学习能力。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;温度参数&lt;/strong&gt;：控制模型输出随机性的关键参数。低温度如0.2使输出更加确定和保守，适合事实性问答；高温度如0.8增加随机性和创造性，适用于创意写作、头脑风暴等场景。实际应用中需根据任务性质谨慎调整。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Top_p采样&lt;/strong&gt;：又称核采样，通过累积概率阈值控制候选token范围。设为0.1时仅从最可能的10%token中选择，输出更准确；设为0.9时考虑更多可能性，响应更多样化。通常与温度参数配合使用，但建议二选一避免相互干扰。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;链式思考提示&lt;/strong&gt;：要求模型在给出最终答案前展示中间推理步骤，显著提升复杂问题的解决能力。例如数学问题中让模型&amp;quot;一步步思考&amp;quot;并说明计算过程，能大幅提高准确率。对于逻辑推理、多步骤任务特别有效。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;少样本学习&lt;/strong&gt;：在提示中提供一到多个完整示例，每个示例包含输入和期望输出。这种方式让模型通过类比学习任务模式，无需额外训练即可适应新场景。示例选择要具有代表性，数量通常在三到五个之间效果最佳。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思维树技术&lt;/strong&gt;：将问题解决过程表示为树状结构，每个节点代表一个思维状态，分支代表可能的行动。通过探索、评估和回溯机制，智能体能够在复杂决策空间中找到最优路径，比线性思维链更强大也更耗计算资源。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/aBrKnkVb2_qLSbT7a04SrA"&gt;多种经典提示技术——Prompt&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;简单的机器学习&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-12-24&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>完美提示：提示工程速查表</title><link>https://linguista.cn/curated/henrinotes-2025-p1/perfect-prompt-engineering-cheat-sheet/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/perfect-prompt-engineering-cheat-sheet/</guid><description>&lt;h1 id="完美提示提示工程速查表"&gt;完美提示：提示工程速查表&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文提供了一份关于提示工程的速查表，旨在帮助用户更好地与大型语言模型（LLM）进行交互。文章介绍了AUTOMAT和CO-STAR两种提示构建框架，以及少量学习、思维链、检索增强生成等实用技术，强调了构建有效提示的重要性。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;大型语言模型能够生成任意字符序列，但输出质量参差不齐，而提示的质量直接影响模型的输出效果。精确的提示能够引导模型产生更高质量的响应，因此提示工程已成为使用AI的必备技能，尤其是在构建应用时。&lt;/p&gt;
&lt;p&gt;文章介绍了两种主要的提示构建框架。AUTOMAT框架包含了六个关键要素：用户角色与受众、目标行动、输出定义、模式/语气/风格、特殊情况以及主题白名单。CO-STAR框架则包括背景信息、明确目标、风格和语气、目标受众以及输出格式。这两种框架都强调了结构化提示的重要性。&lt;/p&gt;
&lt;p&gt;除了框架，文章还介绍了几种实用的提示技术。少量学习通过在提示中展示实际问题和解决方案来帮助模型理解任务。思维链技术促使模型在给出最终答案之前进行推理。检索增强生成允许模型访问数据或文档以提供更全面的响应。格式化与分隔符确保模型能够理解提示的结构，而多提示方法则将复杂任务拆分为多个小任务以提高准确性。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;AUTOMAT框架&lt;/strong&gt;：一种构建完美提示的系统方法。A代表用户角色与受众，U代表目标行动，T代表输出定义，O代表模式/语气/风格，M代表特殊情况，第二个A代表主题白名单。这个框架确保了提示的完整性和针对性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CO-STAR框架&lt;/strong&gt;：另一种提示构建方法，强调背景信息和目标明确性。Context提供背景信息，Objective明确目标，Style &amp;amp; Tone指定风格和语气，Audience识别目标受众，Response定义输出格式。这个框架注重提示的上下文相关性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;少量学习&lt;/strong&gt;：一种通过示例学习的提示技术。在提示中展示几个实际问题和解决方案，让模型通过类比理解任务要求，特别适合需要特定格式或风格的场景。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思维链&lt;/strong&gt;：促使模型在给出最终答案之前进行推理的技术。这种逐步推理的方式可以提高复杂任务的输出质量，减少错误率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;检索增强生成（RAG）&lt;/strong&gt;：允许模型访问外部数据或文档的技术，使模型能够提供更全面、最新和准确的响应，特别适合需要特定领域知识的场景。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://medium.com/the-generator/the-perfect-prompt-prompt-engineering-cheat-sheet-d0b9c62a2bba"&gt;The Perfect Prompt: A Prompt Engineering Cheat Sheet&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Maximilian Vogel&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年4月8日&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>科学中的聊天机器人ChatGPT应用指南</title><link>https://linguista.cn/curated/henrinotes-2025-p1/chatgpt-scientific-research-guide/</link><pubDate>Sat, 04 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/curated/henrinotes-2025-p1/chatgpt-scientific-research-guide/</guid><description>&lt;h1 id="科学中的聊天机器人chatgpt能为你做什么"&gt;科学中的聊天机器人：ChatGPT能为你做什么？&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本文总结了Milton Pividori关于ChatGPT在科学研究中的应用经验，提出了有效使用聊天机器人的三条核心原则：精心设计提示、选择合适任务、以及认识写作与阅读的风险差异。文章强调了人类在科研创意过程中的主导作用，同时指出AI工具在减轻重复性工作负担方面的潜力。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;文章围绕ChatGPT在科学研究场景中的应用展开系统性分析。首先从提示工程的角度，详细阐述了如何通过清晰指令、角色设定、示例提供和格式规范来优化AI输出质量。这四项提示设计策略能够显著提升聊天机器人理解科研任务的准确性。&lt;/p&gt;
&lt;p&gt;其次，文章探讨了任务适配性的重要性。作者指出，在研究初期需要高度创造性思维的阶段，如文献回顾和问题定义，AI工具可能因缺乏深度理解而遗漏关键信息。相比之下，在研究后期使用聊天机器人进行文章总结和内容梳理则更为安全可靠。&lt;/p&gt;
&lt;p&gt;最后，文章对比了AI辅助写作与AI辅助阅读的不同风险水平。当研究人员使用聊天机器人生成内容时，他们能够主动验证输出的准确性；而当AI&amp;quot;阅读&amp;quot;和分析文献时，人类更容易错过重要信息。这种风险差异决定了科研工作者应该有选择地使用AI工具。&lt;/p&gt;
&lt;p&gt;Pividori的团队还开发了将ChatGPT整合到Manubot协作写作平台中的工具，这体现了将AI能力嵌入科研工作流的实践探索。文章的核心观点是：聊天机器人应当成为科研人员的辅助工具，而非替代人类创造性和批判性思维的解决方案。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;提示工程&lt;/strong&gt;：指通过精确设计输入指令来引导AI模型产生期望输出的技术。在科研场景中，有效的提示应包含明确的动作指令、专业角色定位、具体的输入输出示例，以及清晰的格式要求。这种系统性方法能够显著提升AI在学术任务中的表现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;任务适配性原则&lt;/strong&gt;：根据任务的创造性需求和风险程度来决定是否使用AI辅助。高创造性、高风险的任务（如研究问题定义）应保持人类主导；而低创造性、低风险的任务（如文章总结）则可以放心交给聊天机器人处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;不对称风险理论&lt;/strong&gt;：AI辅助写作和AI辅助阅读存在本质差异。写作时人类可以主动校验AI输出，风险可控；阅读时人类容易过度依赖AI判断，可能错过关键信息。理解这种风险差异有助于科研工作者制定合理的AI使用策略。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://www.nature.com/articles/d41586-024-02630-z"&gt;Chatbots in science: What can ChatGPT do for you?&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;Milton Pividori&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024-08-19&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>