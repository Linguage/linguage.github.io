<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RAG on Linguista</title><link>https://linguista.cn/tags/rag/</link><description>Recent content in RAG on Linguista</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Fri, 10 Jan 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://linguista.cn/tags/rag/index.xml" rel="self" type="application/rss+xml"/><item><title>2024年RAG技术发展综述</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/rag-technology-development-2024/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/rag-technology-development-2024/</guid><description>&lt;h1 id="2024年rag技术发展综述"&gt;2024年RAG技术发展综述&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;2024年被称作&amp;quot;RAG发展元年&amp;quot;，本文系统梳理了RAG技术在2024年的重要发展。文章从RAG的技术挑战出发，详细介绍了多模态文档解析、混合搜索、GraphRAG等标志性突破，深入分析了数据清洗、排序模型、语义鸿沟解决方案等核心技术细节，并探讨了RAG与Agent结合、多模态RAG等前沿方向，最后对2025年RAG技术的持续进化进行了展望。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;本文首先阐述了RAG技术在2024年的重要地位，指出尽管关于RAG的争论不断，但从成本和实时性角度，RAG已显示出压倒性优势。即使在需要微调介入的场景中，RAG也通常是不可或缺的组成部分。作者将2024年定位为RAG发展的关键转折点。&lt;/p&gt;
&lt;p&gt;文章详细分析了RAG面临的三大技术挑战：非结构化多模态文档问答难题、纯向量数据库的局限性以及语义鸿沟问题。这些挑战推动了2024年RAG技术的多项突破性进展，包括多模态文档解析工具的崛起、BM25和混合搜索的普及、GraphRAG的开源以及延迟交互模型与多模态RAG的发展。&lt;/p&gt;
&lt;p&gt;在技术细节方面，文章深入探讨了数据清洗的多模态处理、Text Chunking优化方法、混合搜索的三路召回策略、Embedding与Reranker模型的协同作用，以及基于张量的重排序模型等核心技术。特别强调了GraphRAG及其变种在解决语义鸿沟问题上的创新性贡献。&lt;/p&gt;
&lt;p&gt;最后，文章展望了RAG与Agent结合的Agentic RAG模式、多模态RAG的技术实现路径，以及RAG作为企业搜索引擎在大模型时代的进化方向。作者认为RAG类似于过去的数据库，是一个包含数据库、小模型和工具的复杂系统，将持续向更加智能化和集成化的方向发展。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;GraphRAG&lt;/strong&gt;：微软开源的GraphRAG架构是2024年RAG领域现象级事件，它通过利用大模型抽取文档内的命名实体并构建知识图谱，有效解决了RAG的语义鸿沟问题。该架构特别适用于意图不明的笼统提问或&amp;quot;多跳&amp;quot;问答场景。其变种如Fast GraphRAG、LightRAG等通过降低Token消耗，使得这一技术更加实用化和普及化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;混合搜索&lt;/strong&gt;：2024年混合搜索理念深入人心，它不再将向量数据库作为单独品类存在，而是采用向量搜索、稀疏向量搜索和全文搜索的三路混合召回策略。BM25等经典算法重新受到重视，Elasticsearch和Infinity等数据库提供了符合要求的全文搜索和混合搜索能力。这种混合方法在召回率和准确性方面都取得了显著提升。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;多模态RAG&lt;/strong&gt;：随着VLM（视觉语言模型）对图像理解能力的深入，多模态RAG成为重要发展方向。它能够处理PDF、PPT等非纯文本类数据，根据用户提问在文档中找到包含答案的图片和文字。技术实现上有两种主要路径：通过模型将多模态文档转成文本再建立索引，或直接生成向量规避OCR过程，如ColPali工作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Agentic RAG&lt;/strong&gt;：这是RAG与Agent结合的重要模式，RAG作为Agent的重要算子，解锁了Agent访问内部数据的能力。Agentic RAG可以让RAG在复杂场景下以可控方式提供适应性变化，同时RAG需要为Agent提供记忆管理功能，包括用户对话Session、个性化信息等，以支持Agent的Reasoning能力。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;语义鸿沟&lt;/strong&gt;：这是RAG技术的核心挑战之一，指在很多情况下（如意图不明的笼统提问或&amp;quot;多跳&amp;quot;问答），提问和答案之间存在明显的语义差距。除了GraphRAG外，RAPTOR、SiReRAG等方法也通过预聚类和细粒度定义文本召回，增强对数据宏观层面的理解，从而跨越这一鸿沟。&lt;/p&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://zhuanlan.zhihu.com/p/14116449727"&gt;万字长文梳理2024年的RAG&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;知乎作者&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2024年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Notion CEO Ivan Zhao 访谈录 AI时代的生产力工具与未来愿景</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/notion-ceo-ivan-zhao-interview-ai-productivity/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/notion-ceo-ivan-zhao-interview-ai-productivity/</guid><description>&lt;h1 id="notion-ceo-ivan-zhao-访谈录ai时代的生产力工具与未来愿景"&gt;Notion CEO Ivan Zhao 访谈录：AI时代的生产力工具与未来愿景&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;本访谈中，Notion CEO Ivan Zhao 深入探讨了 Notion 的产品理念、AI 战略以及对未来工作方式的思考。Notion 采用&amp;quot;乐高积木&amp;quot;式的软件构建方法，为用户提供统一的生产力工具平台。Ivan 分享了 Notion 如何快速拥抱 AI 技术，特别是 RAG（检索增强生成）和 AI 问答功能的应用，以及这些技术如何改变知识管理和工作流程。他还讨论了 SaaS 行业的&amp;quot;捆绑&amp;quot;与&amp;quot;解绑&amp;quot;周期，以及 AI 时代软件设计的新范式。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;h3 id="notion-的产品哲学"&gt;Notion 的产品哲学&lt;/h3&gt;
&lt;p&gt;Ivan Zhao 将 Notion 定义为一个集笔记、任务、知识库于一体的统一生产力工具。当前市场存在大量碎片化应用，Notion 的目标是打破这种局面，让用户在一个工具中完成大部分工作。不同于传统应用将功能强行整合，Notion 采用&amp;quot;乐高积木&amp;quot;式构建方法——提供底层的软件构建模块（文本编辑、关系数据库、权限控制等），让用户根据需求创造性地组合和构建个性化工作流程。&lt;/p&gt;
&lt;p&gt;这种理念并非全新，早在上世纪 70、80 年代就有过类似尝试。Notion 的创新在于用现代云计算和 AI 技术重新诠释这一方法，试图打破基于应用的软件限制，让软件回归早期计算先驱所倡导的可塑性和可定制性。&lt;/p&gt;
&lt;h3 id="ai-战略的转折与执行"&gt;AI 战略的转折与执行&lt;/h3&gt;
&lt;p&gt;Notion 是最早大规模应用 AI 的 SaaS 公司之一。Ivan 坦言，他最初对 GPT-3 并不感冒，认为它只能写写营销文案。转折点出现在他提前体验 GPT-4 之后——他意识到这个模型真正具备思考、推理和执行工作流的能力。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;这就像是恐龙遇到了小行星撞击地球，&amp;rdquo; Ivan 如此形容 AI 对行业的影响。知识工作的本质是信息处理和传递，而语言模型可以部分替代这些工作。Notion 决定全力押注 AI，而这恰恰与他们多年构建的&amp;quot;乐高积木&amp;quot;完美契合：AI 写作基于文本编辑器，AI 数据库基于关系数据库，AI 问答基于知识库和 RAG 系统。&lt;/p&gt;
&lt;p&gt;Ivan 将 AI 开发比作&amp;quot;烘焙&amp;quot;和&amp;quot;园艺&amp;quot;——与确定性软件工程不同，AI 开发需要准备原料、试验、等待、观察，需要概率性思维和耐心。Notion 需要两类人才：具备概率思维的 ML 专家，以及好奇心强、学习速度快的&amp;quot;AI 工程师&amp;quot;。&lt;/p&gt;</description></item><item><title>微软提出RAG应对用户四级查询难度的方案</title><link>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/microsoft-rag-four-level-query-classification/</link><pubDate>Fri, 10 Jan 2025 00:00:00 +0800</pubDate><guid>https://linguista.cn/infos/tldrcards/henrinotes_2025_p3/microsoft-rag-four-level-query-classification/</guid><description>&lt;h1 id="微软提出rag应对用户四级查询难度的方案"&gt;微软提出RAG应对用户四级查询难度的方案&lt;/h1&gt;
&lt;h2 id="摘要"&gt;摘要&lt;/h2&gt;
&lt;p&gt;微软研究院针对检索增强生成（RAG）技术在专业领域部署中面临的挑战，提出了用户查询任务的四级分类体系。该体系从显式事实查询到隐性推理依据查询，逐级递增复杂度，并为每个级别设计了相应的技术解决方案，包括迭代RAG、链式思维提示、微调等策略，旨在帮助开发者根据具体查询类型选择合适的知识注入方法。&lt;/p&gt;
&lt;h2 id="内容框架与概述"&gt;内容框架与概述&lt;/h2&gt;
&lt;p&gt;大语言模型通过整合外部数据能够显著提升其在特定领域的任务完成能力。外部数据增强不仅使模型能够获得领域专业知识，还增强了其时间相关性、输出可控性和可解释性。检索增强生成（RAG）和微调等技术因此受到广泛关注，但在实际部署到专业领域时仍面临诸多挑战。&lt;/p&gt;
&lt;p&gt;微软研究院的核心贡献在于建立了一个系统的用户查询分类框架。该框架将查询任务分为四个难度级别：第一级是显式事实查询，可通过明确文本片段直接回答；第二级是隐式事实查询，需要整合多个数据源进行逻辑推断；第三级是明确推理依据的查询，需要理解应用外部资源中明确提供的推理规则；第四级是隐性推理依据的查询，推理依据未明确记录，需要从数据中观察模式推断。&lt;/p&gt;
&lt;p&gt;针对这四个级别，研究团队给出了差异化的技术解决方案。对于简单的显式查询，重点解决数据处理和检索问题；对于复杂的隐式查询，则需要迭代RAG、基于图或树的问答、NL2SQL等高级技术；当涉及推理依据时，需要采用提示调整、链式思维提示或构建Agent工作流；而对于最复杂的隐性推理查询，则可能需要离线学习、上下文学习或模型微调。研究同时提出了给LLMs整合外部数据的三种主要形式，为开发者提供了系统的方法论指导。&lt;/p&gt;
&lt;h2 id="核心概念及解读"&gt;核心概念及解读&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;显式事实查询&lt;/strong&gt;：这是最基础的查询级别，答案可以通过明确的文本片段直接获得，通常依赖单一数据源。例如询问&amp;quot;2024年夏季奥运会举办地&amp;quot;，这类查询的主要挑战在于数据处理效率、检索准确性以及RAG系统性能的评估，而不涉及复杂的推理过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;隐式事实查询&lt;/strong&gt;：这类查询需要整合多个分散的数据来源，建立逻辑关联才能得出答案。例如&amp;quot;实验样本量大于1000的数量有多少&amp;quot;，信息可能分散在文档的不同部分。其挑战包括信息分散、复杂推理需求、自适应检索量控制、推理与检索的协调以及多跳推理。解决方案包括迭代RAG、基于图或树的问答系统、自然语言转SQL、智能检索与推理结合以及动态信息整合等技术。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;明确推理依据的查询&lt;/strong&gt;：这类查询不仅需要事实信息，还需要理解和应用特定的推理规则或工作流程，且这些依据在外部资源中有明确提供。例如胸痛患者的诊断治疗流程或客户服务工作流程应对。主要挑战包括提示优化成本高、可解释性有限、多步推理复杂性等。解决方案涉及提示调整技术、链式思维提示、利用LLM本身进行提示优化以及构建Agent工作流。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;隐性推理依据的查询&lt;/strong&gt;：这是最高级别的查询，推理依据或规则并未明确记录在文档中，需要从外部数据中观察模式和结果来推断。例如评估经济形势对公司未来发展的影响。主要挑战是逻辑检索困难和数据不足，解决方案包括离线学习、上下文学习和模型微调等方法，让模型通过数据学习隐含的推理模式。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id="原文信息"&gt;原文信息&lt;/h2&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;字段&lt;/th&gt;
 &lt;th&gt;内容&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;原文&lt;/td&gt;
 &lt;td&gt;&lt;a href="https://mp.weixin.qq.com/s/k-r4rfDftlsoSGkGoXOlGw"&gt;RAG怎么面对用户的4级查询难度？微软给出方案！&lt;/a&gt;&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;作者&lt;/td&gt;
 &lt;td&gt;微软研究院&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;发表日期&lt;/td&gt;
 &lt;td&gt;2025年&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;此文档由 AI 自动整理&lt;/em&gt;&lt;/p&gt;</description></item></channel></rss>